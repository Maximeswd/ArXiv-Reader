------------------------------------------------------------------------------
------------------------------------------------------------------------------
Send any comments regarding submissions directly to submitter.
------------------------------------------------------------------------------
Archives at http://arxiv.org/
To unsubscribe, e-mail To: cs@arXiv.org, Subject: cancel
------------------------------------------------------------------------------
Submissions to:
Artificial Intelligence
Computation and Language
Computer Vision and Pattern Recognition
Information Retrieval
Machine Learning
received from  Fri  7 Nov 25 19:00:00 GMT  to  Mon 10 Nov 25 19:00:00 GMT
------------------------------------------------------------------------------
------------------------------------------------------------------------------
\\
arXiv:2511.05524
Date: Tue, 28 Oct 2025 17:47:13 GMT   (1811kb)

Title: Evidence-Bound Autonomous Research (EviBound): A Governance Framework
 for Eliminating False Claims
Authors: Ruiying Chen
Categories: cs.AI
Comments: 27 pages, 11 figures, 5 tables. Reproducibility package with MLflow
 artifacts and Google Colab notebooks available upon publication
\\
 LLM-based autonomous research agents report false claims: tasks marked
"complete" despite missing artifacts, contradictory metrics, or failed
executions. EviBound is an evidence-bound execution framework that eliminates
false claims through dual governance gates requiring machine-checkable
evidence.
 Two complementary gates enforce evidence requirements. The pre-execution
Approval Gate validates acceptance criteria schemas before code runs, catching
structural violations proactively. The post-execution Verification Gate
validates artifacts via MLflow API queries (with recursive path checking) and
optionally validates metrics when specified by acceptance criteria. Claims
propagate only when backed by a queryable run ID, required artifacts, and
FINISHED status. Bounded, confidence-gated retries (typically 1-2 attempts)
recover from transient failures without unbounded loops.
 The framework was evaluated on 8 benchmark tasks spanning infrastructure
validation, ML capabilities, and governance stress tests. Baseline A
(Prompt-Level Only) yields 100% hallucination (8/8 claimed, 0/8 verified).
Baseline B (Verification-Only) reduces hallucination to 25% (2/8 fail
verification). EviBound (Dual Gates) achieves 0% hallucination: 7/8 tasks
verified and 1 task correctly blocked at the approval gate, all with only
approximately 8.3% execution overhead.
 This package includes execution trajectories, MLflow run IDs for all verified
tasks, and a 4-step verification protocol. Research integrity is an
architectural property, achieved through governance gates rather than emergent
from model scale.
\\ ( https://arxiv.org/abs/2511.05524 ,  1811kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05528
Date: Wed, 29 Oct 2025 04:05:10 GMT   (415kb)

Title: SMAGDi: Socratic Multi Agent Interaction Graph Distillation for
 Efficient High Accuracy Reasoning
Authors: Aayush Aluru, Myra Malik, Samarth Patankar, Spencer Kim, Kevin Zhu,
 Sean O'Brien, Vasu Sharma
Categories: cs.AI
Comments: Multi-Turn Interactions in Large Language Models (MTI-LLM) Workshop
 at NeurIPS 2025
\\
 Multi-agent systems (MAS) often achieve higher reasoning accuracy than single
models, but their reliance on repeated debates across agents makes them
computationally expensive. We introduce SMAGDi, a distillation framework that
transfers the debate dynamics of a five-agent Llama-based MAS into a compact
Socratic decomposer-solver student. SMAGDi represents debate traces as directed
interaction graphs, where nodes encode intermediate reasoning steps with
correctness labels and edges capture continuity and cross-agent influence. The
student is trained with a composite objective combining language modeling,
graph-based supervision, contrastive reasoning, and embedding alignment to
preserve both fluency and structured reasoning. On StrategyQA and MMLU, SMAGDi
compresses a 40B multi-agent system into a 6B student while retaining 88% of
its accuracy, substantially outperforming prior distillation methods such as
MAGDi, standard KD, and fine-tuned baselines. These results highlight that
explicitly modeling interaction graphs and Socratic decomposition enable small
models to inherit the accuracy benefits of multi-agent debate while remaining
efficient enough for real-world deployment.
\\ ( https://arxiv.org/abs/2511.05528 ,  415kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05597
Date: Wed, 5 Nov 2025 15:06:46 GMT   (296kb)

Title: From Prompts to Power: Measuring the Energy Footprint of LLM Inference
Authors: Francisco Caravaca, \'Angel Cuevas, Rub\'en Cuevas
Categories: cs.AI cs.LG
\\
 The rapid expansion of Large Language Models (LLMs) has introduced
unprecedented energy demands, extending beyond training to large-scale
inference workloads that often dominate total lifecycle consumption. Deploying
these models requires energy-intensive GPU infrastructure, and in some cases
has even prompted plans to power data centers with nuclear energy. Despite this
growing relevance, systematic analyses of inference energy consumption remain
limited. In this work, we present a large-scale measurement-based study
comprising over 32,500 measurements across 21 GPU configurations and 155 model
architectures, from small open-source models to frontier systems. Using the
vLLM inference engine, we quantify energy usage at the prompt level and
identify how architectural and operational factors shape energy demand.
Building on these insights, we develop a predictive model that accurately
estimates inference energy consumption across unseen architectures and
hardware, and implement it as a browser extension to raise awareness of the
environmental impact of generative AI.
\\ ( https://arxiv.org/abs/2511.05597 ,  296kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05747
Date: Fri, 7 Nov 2025 22:35:31 GMT   (1014kb)

Title: CoT-X: An Adaptive Framework for Cross-Model Chain-of-Thought Transfer
 and Optimization
Authors: Ziqian Bi, Kaijie Chen, Tianyang Wang, Junfeng Hao, Xinyuan Song
Categories: cs.AI
Comments: TKDD 2025
\\
 Chain-of-Thought (CoT) reasoning enhances the problem-solving ability of
large language models (LLMs) but leads to substantial inference overhead,
limiting deployment in resource-constrained settings. This paper investigates
efficient CoT transfer across models of different scales and architectures
through an adaptive reasoning summarization framework. The proposed method
compresses reasoning traces via semantic segmentation with importance scoring,
budget-aware dynamic compression, and coherence reconstruction, preserving
critical reasoning steps while significantly reducing token usage. Experiments
on 7{,}501 medical examination questions across 10 specialties show up to 40%
higher accuracy than truncation under the same token budgets. Evaluations on 64
model pairs from eight LLMs (1.5B-32B parameters, including DeepSeek-R1 and
Qwen3) confirm strong cross-model transferability. Furthermore, a Gaussian
Process-based Bayesian optimization module reduces evaluation cost by 84% and
reveals a power-law relationship between model size and cross-domain
robustness. These results demonstrate that reasoning summarization provides a
practical path toward efficient CoT transfer, enabling advanced reasoning under
tight computational constraints. Code will be released upon publication.
\\ ( https://arxiv.org/abs/2511.05747 ,  1014kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05766
Date: Fri, 7 Nov 2025 23:35:19 GMT   (19465kb)

Title: Anchors in the Machine: Behavioral and Attributional Evidence of
 Anchoring Bias in LLMs
Authors: Felipe Valencia-Clavijo
Categories: cs.AI cs.CL econ.GN q-fin.EC
\\
 Large language models (LLMs) are increasingly examined as both behavioral
subjects and decision systems, yet it remains unclear whether observed
cognitive biases reflect surface imitation or deeper probability shifts.
Anchoring bias, a classic human judgment bias, offers a critical test case.
While prior work shows LLMs exhibit anchoring, most evidence relies on
surface-level outputs, leaving internal mechanisms and attributional
contributions unexplored. This paper advances the study of anchoring in LLMs
through three contributions: (1) a log-probability-based behavioral analysis
showing that anchors shift entire output distributions, with controls for
training-data contamination; (2) exact Shapley-value attribution over
structured prompt fields to quantify anchor influence on model
log-probabilities; and (3) a unified Anchoring Bias Sensitivity Score
integrating behavioral and attributional evidence across six open-source
models. Results reveal robust anchoring effects in Gemma-2B, Phi-2, and
Llama-2-7B, with attribution signaling that the anchors influence reweighting.
Smaller models such as GPT-2, Falcon-RW-1B, and GPT-Neo-125M show variability,
suggesting scale may modulate sensitivity. Attributional effects, however, vary
across prompt designs, underscoring fragility in treating LLMs as human
substitutes. The findings demonstrate that anchoring bias in LLMs is robust,
measurable, and interpretable, while highlighting risks in applied domains.
More broadly, the framework bridges behavioral science, LLM safety, and
interpretability, offering a reproducible path for evaluating other cognitive
biases in LLMs.
\\ ( https://arxiv.org/abs/2511.05766 ,  19465kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05810
Date: Sat, 8 Nov 2025 02:51:21 GMT   (347kb)

Title: DiagnoLLM: A Hybrid Bayesian Neural Language Framework for Interpretable
 Disease Diagnosis
Authors: Bowen Xu and Xinyue Zeng and Jiazhen Hu and Tuo Wang and Adithya
 Kulkarni
Categories: cs.AI cs.CL cs.LG
\\
 Building trustworthy clinical AI systems requires not only accurate
predictions but also transparent, biologically grounded explanations. We
present \texttt{DiagnoLLM}, a hybrid framework that integrates Bayesian
deconvolution, eQTL-guided deep learning, and LLM-based narrative generation
for interpretable disease diagnosis. DiagnoLLM begins with GP-unmix, a Gaussian
Process-based hierarchical model that infers cell-type-specific gene expression
profiles from bulk and single-cell RNA-seq data while modeling biological
uncertainty. These features, combined with regulatory priors from eQTL
analysis, power a neural classifier that achieves high predictive performance
in Alzheimer's Disease (AD) detection (88.0\% accuracy). To support human
understanding and trust, we introduce an LLM-based reasoning module that
translates model outputs into audience-specific diagnostic reports, grounded in
clinical features, attribution signals, and domain knowledge. Human evaluations
confirm that these reports are accurate, actionable, and appropriately tailored
for both physicians and patients. Our findings show that LLMs, when deployed as
post-hoc reasoners rather than end-to-end predictors, can serve as effective
communicators within hybrid diagnostic pipelines.
\\ ( https://arxiv.org/abs/2511.05810 ,  347kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05854
Date: Sat, 8 Nov 2025 05:05:38 GMT   (2171kb)

Title: Can a Small Model Learn to Look Before It Leaps? Dynamic Learning and
 Proactive Correction for Hallucination Detection
Authors: Zepeng Bao, Shen Zhou, Qiankun Pi, Jianhao Chen, Mayi Xu, Ming Zhong,
 Yuanyuan Zhu, Tieyun Qian
Categories: cs.AI
\\
 Hallucination in large language models (LLMs) remains a critical barrier to
their safe deployment. Existing tool-augmented hallucination detection methods
require pre-defined fixed verification strategies, which are crucial to the
quality and effectiveness of tool calls. Some methods directly employ powerful
closed-source LLMs such as GPT-4 as detectors, which are effective but too
costly. To mitigate the cost issue, some methods adopt the teacher-student
architecture and finetune open-source small models as detectors via agent
tuning. However, these methods are limited by fixed strategies. When faced with
a dynamically changing execution environment, they may lack adaptability and
inappropriately call tools, ultimately leading to detection failure. To address
the problem of insufficient strategy adaptability, we propose the innovative
``Learning to Evaluate and Adaptively Plan''(LEAP) framework, which endows an
efficient student model with the dynamic learning and proactive correction
capabilities of the teacher model. Specifically, our method formulates the
hallucination detection problem as a dynamic strategy learning problem. We
first employ a teacher model to generate trajectories within the dynamic
learning loop and dynamically adjust the strategy based on execution failures.
We then distill this dynamic planning capability into an efficient student
model via agent tuning. Finally, during strategy execution, the student model
adopts a proactive correction mechanism, enabling it to propose, review, and
optimize its own verification strategies before execution. We demonstrate
through experiments on three challenging benchmarks that our LEAP-tuned model
outperforms existing state-of-the-art methods.
\\ ( https://arxiv.org/abs/2511.05854 ,  2171kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05874
Date: Sat, 8 Nov 2025 06:18:48 GMT   (4764kb)

Title: An Empirical Study of Reasoning Steps in Thinking Code LLMs
Authors: Haoran Xue, Gias Uddin, Song Wang
Categories: cs.AI
\\
 Thinking Large Language Models (LLMs) generate explicit intermediate
reasoning traces before final answers, potentially improving transparency,
interpretability, and solution accuracy for code generation. However, the
quality of these reasoning chains remains underexplored. We present a
comprehensive empirical study examining the reasoning process and quality of
thinking LLMs for code generation. We evaluate six state-of-the-art reasoning
LLMs (DeepSeek-R1, OpenAI-o3-mini, Claude-3.7-Sonnet-Thinking,
Gemini-2.0-Flash-Thinking, Gemini-2.5-Flash, and Qwen-QwQ) across 100 code
generation tasks of varying difficulty from BigCodeBench. We quantify
reasoning-chain structure through step counts and verbosity, conduct controlled
step-budget adjustments, and perform a 21-participant human evaluation across
three dimensions: efficiency, logical correctness, and completeness. Our
step-count interventions reveal that targeted step increases can improve
resolution rates for certain models/tasks, while modest reductions often
preserve success on standard tasks, rarely on hard ones. Through systematic
analysis, we develop a reasoning-problematic taxonomy, identifying completeness
as the dominant failure mode. Task complexity significantly impacts reasoning
quality; hard problems are substantially more prone to incompleteness than
standard tasks. Our stability analysis demonstrates that thinking LLMs maintain
consistent logical structures across computational effort levels and can
self-correct previous errors. This study provides new insights into the
strengths and limitations of current thinking LLMs in software engineering.
\\ ( https://arxiv.org/abs/2511.05874 ,  4764kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05883
Date: Sat, 8 Nov 2025 06:48:19 GMT   (2126kb)

Title: Unveiling Modality Bias: Automated Sample-Specific Analysis for
 Multimodal Misinformation Benchmarks
Authors: Hehai Lin, Hui Liu, Shilei Cao, Jing Li, Haoliang Li, Wenya Wang
Categories: cs.AI
\\
 Numerous multimodal misinformation benchmarks exhibit bias toward specific
modalities, allowing detectors to make predictions based solely on one
modality. While previous research has quantified bias at the dataset level or
manually identified spurious correlations between modalities and labels, these
approaches lack meaningful insights at the sample level and struggle to scale
to the vast amount of online information. In this paper, we investigate the
design for automated recognition of modality bias at the sample level.
Specifically, we propose three bias quantification methods based on
theories/views of different levels of granularity: 1) a coarse-grained
evaluation of modality benefit; 2) a medium-grained quantification of
information flow; and 3) a fine-grained causality analysis. To verify the
effectiveness, we conduct a human evaluation on two popular benchmarks.
Experimental results reveal three interesting findings that provide potential
direction toward future research: 1)~Ensembling multiple views is crucial for
reliable automated analysis; 2)~Automated analysis is prone to detector-induced
fluctuations; and 3)~Different views produce a higher agreement on
modality-balanced samples but diverge on biased ones.
\\ ( https://arxiv.org/abs/2511.05883 ,  2126kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05931
Date: Sat, 8 Nov 2025 08:49:38 GMT   (556kb)

Title: Self-Abstraction from Grounded Experience for Plan-Guided Policy
 Refinement
Authors: Hiroaki Hayashi, Bo Pang, Wenting Zhao, Ye Liu, Akash Gokul, Srijan
 Bansal, Caiming Xiong, Semih Yavuz, Yingbo Zhou
Categories: cs.AI cs.SE
\\
 Large language model (LLM) based agents are increasingly used to tackle
software engineering tasks that require multi-step reasoning and code
modification, demonstrating promising yet limited performance. However, most
existing LLM agents typically operate within static execution frameworks,
lacking a principled mechanism to learn and self-improve from their own
experience and past rollouts. As a result, their performance remains bounded by
the initial framework design and the underlying LLM's capabilities. We propose
Self-Abstraction from Grounded Experience (SAGE), a framework that enables
agents to learn from their own task executions and refine their behavior
through self-abstraction. After an initial rollout, the agent induces a concise
plan abstraction from its grounded experience, distilling key steps,
dependencies, and constraints. This learned abstraction is then fed back as
contextual guidance, refining the agent's policy and supporting more
structured, informed subsequent executions. Empirically, SAGE delivers
consistent performance gains across diverse LLM backbones and agent
architectures. Notably, it yields a 7.2% relative performance improvement over
the strong Mini-SWE-Agent baseline when paired with the GPT-5 (high) backbone.
SAGE further achieves strong overall performance on SWE-Bench Verified
benchmark, reaching 73.2% and 74% Pass@1 resolve rates with the Mini-SWE-Agent
and OpenHands CodeAct agent framework, respectively.
\\ ( https://arxiv.org/abs/2511.05931 ,  556kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05951
Date: Sat, 8 Nov 2025 09:47:27 GMT   (764kb)

Title: Klear-AgentForge: Forging Agentic Intelligence through Posttraining
 Scaling
Authors: Qi Wang, Hongzhi Zhang, Jia Fu, Kai Fu, Yahui Liu, Tinghai Zhang,
 Chenxi Sun, Gangwei Jiang, Jingyi Tang, Xingguang Ji, Yang Yue, Jingyuan
 Zhang, Fuzheng Zhang, Kun Gai, Guorui Zhou
Categories: cs.AI
Comments: 20 pages, 7 figures
\\
 Despite the proliferation of powerful agentic models, the lack of critical
post-training details hinders the development of strong counterparts in the
open-source community. In this study, we present a comprehensive and fully
open-source pipeline for training a high-performance agentic model for
interacting with external tools and environments, named Klear-Qwen3-AgentForge,
starting from the Qwen3-8B base model. We design effective supervised
fine-tuning (SFT) with synthetic data followed by multi-turn reinforcement
learning (RL) to unlock the potential for multiple diverse agentic tasks. We
perform exclusive experiments on various agentic benchmarks in both tool use
and coding domains. Klear-Qwen3-AgentForge-8B achieves state-of-the-art
performance among LLMs of similar size and remains competitive with
significantly larger models.
\\ ( https://arxiv.org/abs/2511.05951 ,  764kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05977
Date: Sat, 8 Nov 2025 11:50:25 GMT   (147kb)

Title: An Epistemic Perspective on Agent Awareness
Authors: Pavel Naumov and Alexandra Pavlova
Categories: cs.AI cs.LO cs.MA
Comments: Fortieth AAAI Conference on Artificial Intelligence (AAAI-26)
\\
 The paper proposes to treat agent awareness as a form of knowledge, breaking
the tradition in the existing literature on awareness. It distinguishes the de
re and de dicto forms of such knowledge. The work introduces two modalities
capturing these forms and formally specifies their meaning using a version of
2D-semantics. The main technical result is a sound and complete logical system
describing the interplay between the two proposed modalities and the standard
"knowledge of the fact" modality.
\\ ( https://arxiv.org/abs/2511.05977 ,  147kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06065
Date: Sat, 8 Nov 2025 16:30:44 GMT   (705kb)

Title: ScRPO: From Errors to Insights
Authors: Lianrui Li, Dakuan Lu, Jiawei Shao, Chi Zhang, Xuelong Li
Categories: cs.AI cs.CL
\\
 We propose Self-correction Relative Policy Optimization (ScRPO), a novel
reinforcement learning framework designed to enhance large language models on
challenging mathemati- cal problems by leveraging self-reflection and error
correction. Our approach consists of two stages: (1) Trial-and-error learning
stage: training the model with GRPO and collect- ing incorrect answers along
with their cor- responding questions in an error pool; (2) Self-correction
learning stage: guiding the model to reflect on why its previous an- swers were
wrong. Extensive experiments across multiple math reasoning benchmarks,
including AIME, AMC, Olympiad, MATH- 500, GSM8k, using Deepseek-Distill-Qwen-
1.5B and Deepseek-Distill-Qwen-7B. The ex- perimental results demonstrate that
ScRPO consistently outperforms several post-training methods. These findings
highlight ScRPO as a promising paradigm for enabling language models to
self-improve on difficult tasks with limited external feedback, paving the way
to- ward more reliable and capable AI systems.
\\ ( https://arxiv.org/abs/2511.06065 ,  705kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06134
Date: Sat, 8 Nov 2025 21:01:27 GMT   (1917kb)

Title: Maestro: Learning to Collaborate via Conditional Listwise Policy
 Optimization for Multi-Agent LLMs
Authors: Wei Yang, Jiacheng Pang, Shixuan Li, Paul Bogdan, Stephen Tu, Jesse
 Thomason
Categories: cs.AI cs.MA
\\
 Multi-agent systems (MAS) built on Large Language Models (LLMs) are being
used to approach complex problems and can surpass single model inference.
However, their success hinges on navigating a fundamental cognitive tension:
the need to balance broad, divergent exploration of the solution space with a
principled, convergent synthesis to the optimal solution. Existing paradigms
often struggle to manage this duality, leading to premature consensus, error
propagation, and a critical credit assignment problem that fails to distinguish
between genuine reasoning and superficially plausible arguments. To resolve
this core challenge, we propose the Multi-Agent Exploration-Synthesis framework
Through Role Orchestration (Maestro), a principled paradigm for collaboration
that structurally decouples these cognitive modes. Maestro uses a collective of
parallel Execution Agents for diverse exploration and a specialized Central
Agent for convergent, evaluative synthesis. To operationalize this critical
synthesis phase, we introduce Conditional Listwise Policy Optimization (CLPO),
a reinforcement learning objective that disentangles signals for strategic
decisions and tactical rationales. By combining decision-focused policy
gradients with a list-wise ranking loss over justifications, CLPO achieves
clean credit assignment and stronger comparative supervision. Experiments on
mathematical reasoning and general problem-solving benchmarks demonstrate that
Maestro, coupled with CLPO, consistently outperforms existing state-of-the-art
multi-agent approaches, delivering absolute accuracy gains of 6% on average and
up to 10% at best.
\\ ( https://arxiv.org/abs/2511.06134 ,  1917kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06136
Date: Sat, 8 Nov 2025 21:09:44 GMT   (3013kb)

Title: When Object-Centric World Models Meet Policy Learning: From Pixels to
 Policies, and Where It Breaks
Authors: Stefano Ferraro, Akihiro Nakano, Masahiro Suzuki and Yutaka Matsuo
Categories: cs.AI
\\
 Object-centric world models (OCWM) aim to decompose visual scenes into
object-level representations, providing structured abstractions that could
improve compositional generalization and data efficiency in reinforcement
learning. We hypothesize that explicitly disentangled object-level
representations, by localizing task-relevant information, can enhance policy
performance across novel feature combinations. To test this hypothesis, we
introduce DLPWM, a fully unsupervised, disentangled object-centric world model
that learns object-level latents directly from pixels. DLPWM achieves strong
reconstruction and prediction performance, including robustness to several
out-of-distribution (OOD) visual variations. However, when used for downstream
model-based control, policies trained on DLPWM latents underperform compared to
DreamerV3. Through latent-trajectory analyses, we identify representation shift
during multi-object interactions as a key driver of unstable policy learning.
Our results suggest that, although object-centric perception supports robust
visual modeling, achieving stable control requires mitigating latent drift.
\\ ( https://arxiv.org/abs/2511.06136 ,  3013kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06142
Date: Sat, 8 Nov 2025 21:27:09 GMT   (574kb)

Title: MALinZero: Efficient Low-Dimensional Search for Mastering Complex
 Multi-Agent Planning
Authors: Sizhe Tang, Jiayu Chen, Tian Lan
Categories: cs.AI
\\
 Monte Carlo Tree Search (MCTS), which leverages Upper Confidence Bound for
Trees (UCTs) to balance exploration and exploitation through randomized
sampling, is instrumental to solving complex planning problems. However, for
multi-agent planning, MCTS is confronted with a large combinatorial action
space that often grows exponentially with the number of agents. As a result,
the branching factor of MCTS during tree expansion also increases
exponentially, making it very difficult to efficiently explore and exploit
during tree search. To this end, we propose MALinZero, a new approach to
leverage low-dimensional representational structures on joint-action returns
and enable efficient MCTS in complex multi-agent planning. Our solution can be
viewed as projecting the joint-action returns into the low-dimensional space
representable using a contextual linear bandit problem formulation. We solve
the contextual linear bandit problem with convex and $\mu$-smooth loss
functions -- in order to place more importance on better joint actions and
mitigate potential representational limitations -- and derive a linear Upper
Confidence Bound applied to trees (LinUCT) to enable novel multi-agent
exploration and exploitation in the low-dimensional space. We analyze the
regret of MALinZero for low-dimensional reward functions and propose an
$(1-\tfrac1e)$-approximation algorithm for the joint action selection by
maximizing a sub-modular objective. MALinZero demonstrates state-of-the-art
performance on multi-agent benchmarks such as matrix games, SMAC, and SMACv2,
outperforming both model-based and model-free multi-agent reinforcement
learning baselines with faster learning speed and better performance.
\\ ( https://arxiv.org/abs/2511.06142 ,  574kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06160
Date: Sat, 8 Nov 2025 22:51:59 GMT   (1393kb)

Title: Evaluating Implicit Biases in LLM Reasoning through Logic Grid Puzzles
Authors: Fatima Jahara, Mark Dredze, Sharon Levy
Categories: cs.AI cs.CL cs.CY
Comments: 24 pages (including appendix)
\\
 While recent safety guardrails effectively suppress overtly biased outputs,
subtler forms of social bias emerge during complex logical reasoning tasks that
evade current evaluation benchmarks. To fill this gap, we introduce a new
evaluation framework, PRIME (Puzzle Reasoning for Implicit Biases in Model
Evaluation), that uses logic grid puzzles to systematically probe the influence
of social stereotypes on logical reasoning and decision making in LLMs. Our use
of logic puzzles enables automatic generation and verification, as well as
variability in complexity and biased settings. PRIME includes stereotypical,
anti-stereotypical, and neutral puzzle variants generated from a shared puzzle
structure, allowing for controlled and fine-grained comparisons. We evaluate
multiple model families across puzzle sizes and test the effectiveness of
prompt-based mitigation strategies. Focusing our experiments on gender
stereotypes, our findings highlight that models consistently reason more
accurately when solutions align with stereotypical associations. This
demonstrates the significance of PRIME for diagnosing and quantifying social
biases perpetuated in the deductive reasoning of LLMs, where fairness is
critical.
\\ ( https://arxiv.org/abs/2511.06160 ,  1393kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06168
Date: Sun, 9 Nov 2025 00:27:38 GMT   (451kb)

Title: Chasing Consistency: Quantifying and Optimizing Human-Model Alignment in
 Chain-of-Thought Reasoning
Authors: Boxuan Wang, Zhuoyun Li, Xinmiao Huang, Xiaowei Huang, Yi Dong
Categories: cs.AI
Comments: 13 pages, 3 figures
\\
 This paper presents a framework for evaluating and optimizing reasoning
consistency in Large Language Models (LLMs) via a new metric, the Alignment
Score, which quantifies the semantic alignment between model-generated
reasoning chains and human-written reference chains in Chain-of-Thought (CoT)
reasoning. Empirically, we find that 2-hop reasoning chains achieve the highest
Alignment Score. To explain this phenomenon, we define four key error types:
logical disconnection, thematic shift, redundant reasoning, and causal
reversal, and show how each contributes to the degradation of the Alignment
Score. Building on this analysis, we further propose Semantic Consistency
Optimization Sampling (SCOS), a method that samples and favors chains with
minimal alignment errors, significantly improving Alignment Scores by an
average of 29.84% with longer reasoning chains, such as in 3-hop tasks.
\\ ( https://arxiv.org/abs/2511.06168 ,  451kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06175
Date: Sun, 9 Nov 2025 01:20:18 GMT   (2303kb)

Title: CSP4SDG: Constraint and Information-Theory Based Role Identification in
 Social Deduction Games with LLM-Enhanced Inference
Authors: Kaijie Xu, Fandi Meng, Clark Verbrugge, Simon Lucas
Categories: cs.AI cs.GT
\\
 In Social Deduction Games (SDGs) such as Avalon, Mafia, and Werewolf, players
conceal their identities and deliberately mislead others, making hidden-role
inference a central and demanding task. Accurate role identification, which
forms the basis of an agent's belief state, is therefore the keystone for both
human and AI performance. We introduce CSP4SDG, a probabilistic,
constraint-satisfaction framework that analyses gameplay objectively. Game
events and dialogue are mapped to four linguistically-agnostic constraint
classes-evidence, phenomena, assertions, and hypotheses. Hard constraints prune
impossible role assignments, while weighted soft constraints score the
remainder; information-gain weighting links each hypothesis to its expected
value under entropy reduction, and a simple closed-form scoring rule guarantees
that truthful assertions converge to classical hard logic with minimum error.
The resulting posterior over roles is fully interpretable and updates in real
time. Experiments on three public datasets show that CSP4SDG (i) outperforms
LLM-based baselines in every inference scenario, and (ii) boosts LLMs when
supplied as an auxiliary "reasoning tool." Our study validates that principled
probabilistic reasoning with information theory is a scalable alternative-or
complement-to heavy-weight neural models for SDGs.
\\ ( https://arxiv.org/abs/2511.06175 ,  2303kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06185
Date: Sun, 9 Nov 2025 01:58:13 GMT   (1214kb)

Title: Dataforge: A Data Agent Platform for Autonomous Data Engineering
Authors: Xinyuan Wang, Yanjie Fu
Categories: cs.AI
\\
 The growing demand for AI applications in fields such as materials discovery,
molecular modeling, and climate science has made data preparation an important
but labor-intensive step. Raw data from diverse sources must be cleaned,
normalized, and transformed to become AI-ready, while effective feature
transformation and selection are essential for efficient training and
inference. To address the challenges of scalability and expertise dependence,
we present Data Agent, a fully autonomous system specialized for tabular data.
Leveraging large language model (LLM) reasoning and grounded validation, Data
Agent automatically performs data cleaning, hierarchical routing, and
feature-level optimization through dual feedback loops. It embodies three core
principles: automatic, safe, and non-expert friendly, which ensure end-to-end
reliability without human supervision. This demo showcases the first practical
realization of an autonomous Data Agent, illustrating how raw data can be
transformed "From Data to Better Data."
\\ ( https://arxiv.org/abs/2511.06185 ,  1214kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06209
Date: Sun, 9 Nov 2025 03:38:29 GMT   (441kb)

Title: Reasoning with Confidence: Efficient Verification of LLM Reasoning Steps
 via Uncertainty Heads
Authors: Jingwei Ni, Ekaterina Fadeeva, Tianyi Wu, Mubashara Akhtar, Jiaheng
 Zhang, Elliott Ash, Markus Leippold, Timothy Baldwin, See-Kiong Ng, Artem
 Shelmanov, Mrinmaya Sachan
Categories: cs.AI cs.CL
Comments: Preprint under review
\\
 Solving complex tasks usually requires LLMs to generate long multi-step
reasoning chains. Previous work has shown that verifying the correctness of
individual reasoning steps can further improve the performance and efficiency
of LLMs on such tasks and enhance solution interpretability. However, existing
verification approaches, such as Process Reward Models (PRMs), are either
computationally expensive, limited to specific domains, or require large-scale
human or model-generated annotations. Thus, we propose a lightweight
alternative for step-level reasoning verification based on data-driven
uncertainty scores. We train transformer-based uncertainty quantification heads
(UHeads) that use the internal states of a frozen LLM to estimate the
uncertainty of its reasoning steps during generation. The approach is fully
automatic: target labels are generated either by another larger LLM (e.g.,
DeepSeek R1) or in a self-supervised manner by the original model itself.
UHeads are both effective and lightweight, containing less than 10M parameters.
Across multiple domains, including mathematics, planning, and general knowledge
question answering, they match or even surpass the performance of PRMs that are
up to 810x larger. Our findings suggest that the internal states of LLMs encode
their uncertainty and can serve as reliable signals for reasoning verification,
offering a promising direction toward scalable and generalizable introspective
LLMs.
\\ ( https://arxiv.org/abs/2511.06209 ,  441kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06221
Date: Sun, 9 Nov 2025 04:37:36 GMT   (951kb)

Title: Tiny Model, Big Logic: Diversity-Driven Optimization Elicits Large-Model
 Reasoning Ability in VibeThinker-1.5B
Authors: Sen Xu, Yi Zhou, Wei Wang, Jixin Min, Zhibin Yin, Yingwei Dai, Shixi
 Liu, Lianyu Pang, Yirong Chen, Junlin Zhang
Categories: cs.AI cs.CL
\\
 Challenging the prevailing consensus that small models inherently lack robust
reasoning, this report introduces VibeThinker-1.5B, a 1.5B-parameter dense
model developed via our Spectrum-to-Signal Principle (SSP). This challenges the
prevailing approach of scaling model parameters to enhance capabilities, as
seen in models like DeepSeek R1 (671B) and Kimi k2 (>1T). The SSP framework
first employs a Two-Stage Diversity-Exploring Distillation (SFT) to generate a
broad spectrum of solutions, followed by MaxEnt-Guided Policy Optimization (RL)
to amplify the correct signal. With a total training cost of only $7,800,
VibeThinker-1.5B demonstrates superior reasoning capabilities compared to
closed-source models like Magistral Medium and Claude Opus 4, and performs on
par with open-source models like GPT OSS-20B Medium. Remarkably, it surpasses
the 400x larger DeepSeek R1 on three math benchmarks: AIME24 (80.3 vs. 79.8),
AIME25 (74.4 vs. 70.0), and HMMT25 (50.4 vs. 41.7). This is a substantial
improvement over its base model (6.7, 4.3, and 0.6, respectively). On
LiveCodeBench V6, it scores 51.1, outperforming Magistral Medium's 50.3 and its
base model's 0.0. These findings demonstrate that small models can achieve
reasoning capabilities comparable to large models, drastically reducing
training and inference costs and thereby democratizing advanced AI research.
\\ ( https://arxiv.org/abs/2511.06221 ,  951kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06226
Date: Sun, 9 Nov 2025 04:55:37 GMT   (3666kb)

Title: ROAR: Robust Accident Recognition and Anticipation for Autonomous
 Driving
Authors: Xingcheng Liu, Yanchen Guan, Haicheng Liao, Zhengbing He, Zhenning Li
Categories: cs.AI
Comments: Published to Accident Analysis and Prevention
\\
 Accurate accident anticipation is essential for enhancing the safety of
autonomous vehicles (AVs). However, existing methods often assume ideal
conditions, overlooking challenges such as sensor failures, environmental
disturbances, and data imperfections, which can significantly degrade
prediction accuracy. Additionally, previous models have not adequately
addressed the considerable variability in driver behavior and accident rates
across different vehicle types. To overcome these limitations, this study
introduces ROAR, a novel approach for accident detection and prediction. ROAR
combines Discrete Wavelet Transform (DWT), a self adaptive object aware module,
and dynamic focal loss to tackle these challenges. The DWT effectively extracts
features from noisy and incomplete data, while the object aware module improves
accident prediction by focusing on high-risk vehicles and modeling the spatial
temporal relationships among traffic agents. Moreover, dynamic focal loss
mitigates the impact of class imbalance between positive and negative samples.
Evaluated on three widely used datasets, Dashcam Accident Dataset (DAD), Car
Crash Dataset (CCD), and AnAn Accident Detection (A3D), our model consistently
outperforms existing baselines in key metrics such as Average Precision (AP)
and mean Time to Accident (mTTA). These results demonstrate the model's
robustness in real-world conditions, particularly in handling sensor
degradation, environmental noise, and imbalanced data distributions. This work
offers a promising solution for reliable and accurate accident anticipation in
complex traffic environments.
\\ ( https://arxiv.org/abs/2511.06226 ,  3666kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06262
Date: Sun, 9 Nov 2025 07:41:49 GMT   (455kb)

Title: GAIA: A General Agency Interaction Architecture for LLM-Human B2B
 Negotiation & Screening
Authors: Siming Zhao and Qi Li
Categories: cs.AI cs.CY
ACM-class: I.2
\\
 Organizations are increasingly exploring delegation of screening and
negotiation tasks to AI systems, yet deployment in high-stakes B2B settings is
constrained by governance: preventing unauthorized commitments, ensuring
sufficient information before bargaining, and maintaining effective human
oversight and auditability. Prior work on large language model negotiation
largely emphasizes autonomous bargaining between agents and omits practical
needs such as staged information gathering, explicit authorization boundaries,
and systematic feedback integration. We propose GAIA, a governance-first
framework for LLM-human agency in B2B negotiation and screening. GAIA defines
three essential roles - Principal (human), Delegate (LLM agent), and
Counterparty - with an optional Critic to enhance performance, and organizes
interactions through three mechanisms: information-gated progression that
separates screening from negotiation; dual feedback integration that combines
AI critique with lightweight human corrections; and authorization boundaries
with explicit escalation paths. Our contributions are fourfold: (1) a formal
governance framework with three coordinated mechanisms and four safety
invariants for delegation with bounded authorization; (2) information-gated
progression via task-completeness tracking (TCI) and explicit state transitions
that separate screening from commitment; (3) dual feedback integration that
blends Critic suggestions with human oversight through parallel learning
channels; and (4) a hybrid validation blueprint that combines automated
protocol metrics with human judgment of outcomes and safety. By bridging theory
and practice, GAIA offers a reproducible specification for safe, efficient, and
accountable AI delegation that can be instantiated across procurement, real
estate, and staffing workflows.
\\ ( https://arxiv.org/abs/2511.06262 ,  455kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06292
Date: Sun, 9 Nov 2025 09:07:31 GMT   (2343kb)

Title: Synthetic Data-Driven Prompt Tuning for Financial QA over Tables and
 Documents
Authors: Yaoning Yu, Kaimin Chang, Ye Yu, Kai Wei, Haojing Luo, Haohan Wang
Categories: cs.AI
\\
 Financial documents like earning reports or balance sheets often involve long
tables and multi-page reports. Large language models have become a new tool to
help numerical reasoning and understanding these documents. However, prompt
quality can have a major effect on how well LLMs perform these financial
reasoning tasks. Most current methods tune prompts on fixed datasets of
financial text or tabular data, which limits their ability to adapt to new
question types or document structures, or they involve costly and manually
labeled/curated dataset to help build the prompts. We introduce a
self-improving prompt framework driven by data-augmented optimization. In this
closed-loop process, we generate synthetic financial tables and document
excerpts, verify their correctness and robustness, and then update the prompt
based on the results. Specifically, our framework combines a synthetic data
generator with verifiers and a prompt optimizer, where the generator produces
new examples that exposes weaknesses in the current prompt, the verifiers check
the validity and robustness of the produced examples, and the optimizer
incrementally refines the prompt in response. By iterating these steps in a
feedback cycle, our method steadily improves prompt accuracy on financial
reasoning tasks without needing external labels. Evaluation on DocMath-Eval
benchmark demonstrates that our system achieves higher performance in both
accuracy and robustness than standard prompt methods, underscoring the value of
incorporating synthetic data generation into prompt learning for financial
applications.
\\ ( https://arxiv.org/abs/2511.06292 ,  2343kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06301
Date: Sun, 9 Nov 2025 09:36:01 GMT   (724kb)

Title: Secu-Table: a Comprehensive security table dataset for evaluating
 semantic table interpretation systems
Authors: Azanzi Jiomekong, Jean Bikim, Patricia Negoue, Joyce Chin
Categories: cs.AI
Comments: Submitted to Nature Scientific Data
\\
 Evaluating semantic tables interpretation (STI) systems, (particularly, those
based on Large Language Models- LLMs) especially in domain-specific contexts
such as the security domain, depends heavily on the dataset. However, in the
security domain, tabular datasets for state-of-the-art are not publicly
available. In this paper, we introduce Secu-Table dataset, composed of more
than 1500 tables with more than 15k entities constructed using security data
extracted from Common Vulnerabilities and Exposures (CVE) and Common Weakness
Enumeration (CWE) data sources and annotated using Wikidata and the SEmantic
Processing of Security Event Streams CyberSecurity Knowledge Graph (SEPSES
CSKG). Along with the dataset, all the code is publicly released. This dataset
is made available to the research community in the context of the SemTab
challenge on Tabular to Knowledge Graph Matching. This challenge aims to
evaluate the performance of several STI based on open source LLMs. Preliminary
evaluation, serving as baseline, was conducted using Falcon3-7b-instruct and
Mistral-7B-Instruct, two open source LLMs and GPT-4o mini one closed source
LLM.
\\ ( https://arxiv.org/abs/2511.06301 ,  724kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06309
Date: Sun, 9 Nov 2025 10:13:00 GMT   (766kb,A)

Title: The Station: An Open-World Environment for AI-Driven Discovery
Authors: Stephen Chung and Wenyu Du
Categories: cs.AI cs.MA
Comments: 54 pages
ACM-class: I.2.0; I.6.0
\\
 We introduce the STATION, an open-world multi-agent environment that models a
miniature scientific ecosystem. Leveraging their extended context windows,
agents in the Station can engage in long scientific journeys that include
reading papers from peers, formulating hypotheses, submitting code, performing
analyses, and publishing results. Importantly, there is no centralized system
coordinating their activities - agents are free to choose their own actions and
develop their own narratives within the Station. Experiments demonstrate that
AI agents in the Station achieve new state-of-the-art performance on a wide
range of benchmarks, spanning from mathematics to computational biology to
machine learning, notably surpassing AlphaEvolve in circle packing. A rich
tapestry of narratives emerges as agents pursue independent research, interact
with peers, and build upon a cumulative history. From these emergent
narratives, novel methods arise organically, such as a new density-adaptive
algorithm for scRNA-seq batch integration. The Station marks a first step
towards autonomous scientific discovery driven by emergent behavior in an
open-world environment, representing a new paradigm that moves beyond rigid
optimization.
\\ ( https://arxiv.org/abs/2511.06309 ,  766kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06316
Date: Sun, 9 Nov 2025 10:44:26 GMT   (3621kb)

Title: ALIGN: A Vision-Language Framework for High-Accuracy Accident Location
 Inference through Geo-Spatial Neural Reasoning
Authors: MD Thamed Bin Zaman Chowdhury and Moazzem Hossain
Categories: cs.AI
\\
 Reliable geospatial information on road accidents is vital for safety
analysis and infrastructure planning, yet most low- and middle-income countries
continue to face a critical shortage of accurate, location-specific crash data.
Existing text-based geocoding tools perform poorly in multilingual and
unstructured news environments, where incomplete place descriptions and mixed
Bangla-English scripts obscure spatial context. To address these limitations,
this study introduces ALIGN (Accident Location Inference through Geo-Spatial
Neural Reasoning)- a vision-language framework that emulates human spatial
reasoning to infer accident coordinates directly from textual and map-based
cues. ALIGN integrates large language and vision-language models within a
multi-stage pipeline that performs optical character recognition, linguistic
reasoning, and map-level verification through grid-based spatial scanning. The
framework systematically evaluates each predicted location against contextual
and visual evidence, ensuring interpretable, fine-grained geolocation outcomes
without requiring model retraining. Applied to Bangla-language news data, ALIGN
demonstrates consistent improvements over traditional geoparsing methods,
accurately identifying district and sub-district-level crash sites. Beyond its
technical contribution, the framework establishes a high accuracy foundation
for automated crash mapping in data-scarce regions, supporting evidence-driven
road-safety policymaking and the broader integration of multimodal artificial
intelligence in transportation analytics. The code for this paper is
open-source and available at: https://github.com/Thamed-Chowdhury/ALIGN
\\ ( https://arxiv.org/abs/2511.06316 ,  3621kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06346
Date: Sun, 9 Nov 2025 12:02:19 GMT   (657kb)

Title: LPFQA: A Long-Tail Professional Forum-based Benchmark for LLM Evaluation
Authors: Liya Zhu, Peizhuang Cong, Aowei Ji, Wenya Wu, Jiani Hou, Chunjie Wu,
 Xiang Gao, Jingkai Liu, Zhou Huan, Xuelei Sun, Yang Yang, Jianpeng Jiao,
 Liang Hu, Xinjie Chen, Jiashuo Liu, Jingzhe Ding, Tong Yang, Zaiyuan Wang, Ge
 Zhang, Wenhao Huang
Categories: cs.AI cs.CL
\\
 Large Language Models (LLMs) have made rapid progress in reasoning, question
answering, and professional applications; however, their true capabilities
remain difficult to evaluate using existing benchmarks. Current datasets often
focus on simplified tasks or artificial scenarios, overlooking long-tail
knowledge and the complexities of real-world applications. To bridge this gap,
we propose LPFQA, a long-tail knowledge-based benchmark derived from authentic
professional forums across 20 academic and industrial fields, covering 502
tasks grounded in practical expertise. LPFQA introduces four key innovations:
fine-grained evaluation dimensions that target knowledge depth, reasoning,
terminology comprehension, and contextual analysis; a hierarchical difficulty
structure that ensures semantic clarity and unique answers; authentic
professional scenario modeling with realistic user personas; and
interdisciplinary knowledge integration across diverse domains. We evaluated 12
mainstream LLMs on LPFQA and observed significant performance disparities,
especially in specialized reasoning tasks. LPFQA provides a robust, authentic,
and discriminative benchmark for advancing LLM evaluation and guiding future
model development.
\\ ( https://arxiv.org/abs/2511.06346 ,  657kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06380
Date: Sun, 9 Nov 2025 13:33:46 GMT   (926kb)

Title: What Makes Reasoning Invalid: Echo Reflection Mitigation for Large
 Language Models
Authors: Chen He, Xun Jiang, Lei Wang, Hao Yang, Chong Peng, Peng Yan, Fumin
 Shen, Xing Xu
Categories: cs.AI cs.LG
\\
 Large Language Models (LLMs) have demonstrated remarkable performance across
a wide range of reasoning tasks. Recent methods have further improved LLM
performance in complex mathematical reasoning. However, when extending these
methods beyond the domain of mathematical reasoning to tasks involving complex
domain-specific knowledge, we observe a consistent failure of LLMs to generate
novel insights during the reflection stage. Instead of conducting genuine
cognitive refinement, the model tends to mechanically reiterate earlier
reasoning steps without introducing new information or perspectives, a
phenomenon referred to as "Echo Reflection". We attribute this behavior to two
key defects: (1) Uncontrollable information flow during response generation,
which allows premature intermediate thoughts to propagate unchecked and distort
final decisions; (2) Insufficient exploration of internal knowledge during
reflection, leading to repeating earlier findings rather than generating new
cognitive insights. Building on these findings, we proposed a novel
reinforcement learning method termed Adaptive Entropy Policy Optimization
(AEPO). Specifically, the AEPO framework consists of two major components: (1)
Reflection-aware Information Filtration, which quantifies the cognitive
information flow and prevents the final answer from being affected by earlier
bad cognitive information; (2) Adaptive-Entropy Optimization, which dynamically
balances exploration and exploitation across different reasoning stages,
promoting both reflective diversity and answer correctness. Extensive
experiments demonstrate that AEPO consistently achieves state-of-the-art
performance over mainstream reinforcement learning baselines across diverse
benchmarks.
\\ ( https://arxiv.org/abs/2511.06380 ,  926kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06396
Date: Sun, 9 Nov 2025 14:06:55 GMT   (4095kb)

Title: Efficient LLM Safety Evaluation through Multi-Agent Debate
Authors: Dachuan Lin, Guobin Shen, Zihao Yang, Tianrong Liu, Dongcheng Zhao, Yi
 Zeng
Categories: cs.AI cs.CR
Comments: 9 pages of main text, 14 pages total, 4 figures
ACM-class: I.2.7
\\
 Safety evaluation of large language models (LLMs) increasingly relies on
LLM-as-a-Judge frameworks, but the high cost of frontier models limits
scalability. We propose a cost-efficient multi-agent judging framework that
employs Small Language Models (SLMs) through structured debates among critic,
defender, and judge agents. To rigorously assess safety judgments, we construct
HAJailBench, a large-scale human-annotated jailbreak benchmark comprising
12,000 adversarial interactions across diverse attack methods and target
models. The dataset provides fine-grained, expert-labeled ground truth for
evaluating both safety robustness and judge reliability. Our SLM-based
framework achieves agreement comparable to GPT-4o judges on HAJailBench while
substantially reducing inference cost. Ablation results show that three rounds
of debate yield the optimal balance between accuracy and efficiency. These
findings demonstrate that structured, value-aligned debate enables SLMs to
capture semantic nuances of jailbreak attacks and that HAJailBench offers a
reliable foundation for scalable LLM safety evaluation.
\\ ( https://arxiv.org/abs/2511.06396 ,  4095kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06411
Date: Sun, 9 Nov 2025 14:55:50 GMT   (6529kb)

Title: SofT-GRPO: Surpassing Discrete-Token LLM Reinforcement Learning via
 Gumbel-Reparameterized Soft-Thinking Policy Optimization
Authors: Zhi Zheng, Wee Sun Lee
Categories: cs.AI cs.LG
\\
 The soft-thinking paradigm for Large Language Model (LLM) reasoning can
outperform the conventional discrete-token Chain-of-Thought (CoT) reasoning in
some scenarios, underscoring its research and application value. However, while
the discrete-token CoT reasoning pattern can be reinforced through policy
optimization algorithms such as group relative policy optimization (GRPO),
extending the soft-thinking pattern with Reinforcement Learning (RL) remains
challenging. This difficulty stems from the complexities of injecting
stochasticity into soft-thinking tokens and updating soft-thinking policies
accordingly. As a result, previous attempts to combine soft-thinking with GRPO
typically underperform their discrete-token GRPO counterparts. To fully unlock
the potential of soft-thinking, this paper presents a novel policy optimization
algorithm, SofT-GRPO, to reinforce LLMs under the soft-thinking reasoning
pattern. SofT-GRPO injects the Gumbel noise into logits, employs the
Gumbel-Softmax technique to avoid soft-thinking tokens outside the pre-trained
embedding space, and leverages the reparameterization trick in policy gradient.
We conduct experiments across base LLMs ranging from 1.5B to 7B parameters, and
results demonstrate that SofT-GRPO enables soft-thinking LLMs to slightly
outperform discrete-token GRPO on Pass@1 (+0.13% on average accuracy), while
exhibiting a substantial uplift on Pass@32 (+2.19% on average accuracy). Codes
and weights are available on https://github.com/zz1358m/SofT-GRPO-master
\\ ( https://arxiv.org/abs/2511.06411 ,  6529kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06417
Date: Sun, 9 Nov 2025 15:13:45 GMT   (1219kb)

Title: AUTO-Explorer: Automated Data Collection for GUI Agent
Authors: Xiangwu Guo, Difei Gao, Mike Zheng Shou
Categories: cs.AI
\\
 Recent advancements in GUI agents have significantly expanded their ability
to interpret natural language commands to manage software interfaces. However,
acquiring GUI data remains a significant challenge. Existing methods often
involve designing automated agents that browse URLs from the Common Crawl,
using webpage HTML to collect screenshots and corresponding annotations,
including the names and bounding boxes of UI elements. However, this method is
difficult to apply to desktop software or some newly launched websites not
included in the Common Crawl. While we expect the model to possess strong
generalization capabilities to handle this, it is still crucial for
personalized scenarios that require rapid and perfect adaptation to new
software or websites. To address this, we propose an automated data collection
method with minimal annotation costs, named Auto-Explorer. It incorporates a
simple yet effective exploration mechanism that autonomously parses and
explores GUI environments, gathering data efficiently. Additionally, to assess
the quality of exploration, we have developed the UIXplore benchmark. This
benchmark creates environments for explorer agents to discover and save
software states. Using the data gathered, we fine-tune a multimodal large
language model (MLLM) and establish a GUI element grounding testing set to
evaluate the effectiveness of the exploration strategies. Our experiments
demonstrate the superior performance of Auto-Explorer, showing that our method
can quickly enhance the capabilities of an MLLM in explored software.
\\ ( https://arxiv.org/abs/2511.06417 ,  1219kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06419
Date: Sun, 9 Nov 2025 15:18:58 GMT   (2311kb)

Title: MONICA: Real-Time Monitoring and Calibration of Chain-of-Thought
 Sycophancy in Large Reasoning Models
Authors: Jingyu Hu, Shu Yang, Xilin Gong, Hongming Wang, Weiru Liu, Di Wang
Categories: cs.AI cs.CL
\\
 Large Reasoning Models (LRMs) suffer from sycophantic behavior, where models
tend to agree with users' incorrect beliefs and follow misinformation rather
than maintain independent reasoning. This behavior undermines model reliability
and poses societal risks. Mitigating LRM sycophancy requires monitoring how
this sycophancy emerges during the reasoning trajectory; however, current
methods mainly focus on judging based on final answers and correcting them,
without understanding how sycophancy develops during reasoning processes. To
address this limitation, we propose MONICA, a novel Monitor-guided Calibration
framework that monitors and mitigates sycophancy during model inference at the
level of reasoning steps, without requiring the model to finish generating its
complete answer. MONICA integrates a sycophantic monitor that provides
real-time monitoring of sycophantic drift scores during response generation
with a calibrator that dynamically suppresses sycophantic behavior when scores
exceed predefined thresholds. Extensive experiments across 12 datasets and 3
LRMs demonstrate that our method effectively reduces sycophantic behavior in
both intermediate reasoning steps and final answers, yielding robust
performance improvements.
\\ ( https://arxiv.org/abs/2511.06419 ,  2311kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06437
Date: Sun, 9 Nov 2025 16:09:02 GMT   (846kb)

Title: Optimizing Chain-of-Thought Confidence via Topological and Dirichlet
 Risk Analysis
Authors: Abhishek More, Anthony Zhang, Nicole Bonilla, Ashvik Vivekan, Kevin
 Zhu, Parham Sharafoleslami, Maheep Chaudhary
Categories: cs.AI cs.CL cs.LG
\\
 Chain-of-thought (CoT) prompting enables Large Language Models to solve
complex problems, but deploying these models safely requires reliable
confidence estimates, a capability where existing methods suffer from poor
calibration and severe overconfidence on incorrect predictions. We propose
Enhanced Dirichlet and Topology Risk (EDTR), a novel decoding strategy that
combines topological analysis with Dirichlet-based uncertainty quantification
to measure LLM confidence across multiple reasoning paths. EDTR treats each CoT
as a vector in high-dimensional space and extracts eight topological risk
features capturing the geometric structure of reasoning distributions: tighter,
more coherent clusters indicate higher confidence while dispersed, inconsistent
paths signal uncertainty. We evaluate EDTR against three state-of-the-art
calibration methods across four diverse reasoning benchmarks spanning
olympiad-level mathematics (AIME), grade school math (GSM8K), commonsense
reasoning, and stock price prediction \cite{zhang2025aime, cobbe2021training,
talmor-etal-2019-commonsenseqa, yahoo_finance}. EDTR achieves 41\% better
calibration than competing methods with an average ECE of 0.287 and the best
overall composite score of 0.672, while notably achieving perfect accuracy on
AIME and exceptional calibration on GSM8K with an ECE of 0.107, domains where
baselines exhibit severe overconfidence. Our work provides a geometric
framework for understanding and quantifying uncertainty in multi-step LLM
reasoning, enabling more reliable deployment where calibrated confidence
estimates are essential.
\\ ( https://arxiv.org/abs/2511.06437 ,  846kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06470
Date: Sun, 9 Nov 2025 17:32:55 GMT   (10833kb)

Title: Brain-Inspired Planning for Better Generalization in Reinforcement
 Learning
Authors: Mingde "Harry" Zhao
Categories: cs.AI cs.LG
Comments: McGill PhD Thesis (updated on 20251109 for typos and margin
 adjustments)
\\
 Existing Reinforcement Learning (RL) systems encounter significant challenges
when applied to real-world scenarios, primarily due to poor generalization
across environments that differ from their training conditions. This thesis
explores the direction of enhancing agents' zero-shot systematic generalization
abilities by granting RL agents reasoning behaviors that are found to help
systematic generalization in the human brain. Inspired by human conscious
planning behaviors, we first introduced a top-down attention mechanism, which
allows a decision-time planning agent to dynamically focus its reasoning on the
most relevant aspects of the environmental state given its instantaneous
intentions, a process we call "spatial abstraction". This approach
significantly improves systematic generalization outside the training tasks.
Subsequently, building on spatial abstraction, we developed the Skipper
framework to automatically decompose complex tasks into simpler, more
manageable sub-tasks. Skipper provides robustness against distributional shifts
and efficacy in long-term, compositional planning by focusing on pertinent
spatial and temporal elements of the environment. Finally, we identified a
common failure mode and safety risk in planning agents that rely on generative
models to generate state targets during planning. It is revealed that most
agents blindly trust the targets they hallucinate, resulting in delusional
planning behaviors. Inspired by how the human brain rejects delusional
intentions, we propose learning a feasibility evaluator to enable rejecting
hallucinated infeasible targets, which led to significant performance
improvements in various kinds of planning agents. Finally, we suggest
directions for future research, aimed at achieving general task abstraction and
fully enabling abstract planning.
\\ ( https://arxiv.org/abs/2511.06470 ,  10833kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06471
Date: Sun, 9 Nov 2025 17:34:15 GMT   (921kb)

Title: GHOST: Solving the Traveling Salesman Problem on Graphs of Convex Sets
Authors: Jingtao Tang, Hang Ma
Categories: cs.AI cs.RO
Comments: Accepted to AAAI-2026
\\
 We study GCS-TSP, a new variant of the Traveling Salesman Problem (TSP)
defined over a Graph of Convex Sets (GCS) -- a powerful representation for
trajectory planning that decomposes the configuration space into convex regions
connected by a sparse graph. In this setting, edge costs are not fixed but
depend on the specific trajectory selected through each convex region, making
classical TSP methods inapplicable. We introduce GHOST, a hierarchical
framework that optimally solves the GCS-TSP by combining combinatorial tour
search with convex trajectory optimization. GHOST systematically explores tours
on a complete graph induced by the GCS, using a novel abstract-path-unfolding
algorithm to compute admissible lower bounds that guide best-first search at
both the high level (over tours) and the low level (over feasible GCS paths
realizing the tour). These bounds provide strong pruning power, enabling
efficient search while avoiding unnecessary convex optimization calls. We prove
that GHOST guarantees optimality and present a bounded-suboptimal variant for
time-critical scenarios. Experiments show that GHOST is orders-of-magnitude
faster than unified mixed-integer convex programming baselines for simple cases
and uniquely handles complex trajectory planning problems involving high-order
continuity constraints and an incomplete GCS.
\\ ( https://arxiv.org/abs/2511.06471 ,  921kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06522
Date: Sun, 9 Nov 2025 20:22:42 GMT   (1467kb)

Title: FractalBench: Diagnosing Visual-Mathematical Reasoning Through Recursive
 Program Synthesis
Authors: Jan Ondras (1), and Marek \v{S}uppa (2) ((1) MIT, (2) Comenius
 University, Cisco)
Categories: cs.AI cs.LG
Comments: Accepted to The 5th Workshop on Mathematical Reasoning and AI at the
 39th Conference on Neural Information Processing Systems (NeurIPS 2025); 25
 pages, 14 figures, 8 tables; Code available at
 https://github.com/NaiveNeuron/FractalBench
\\
 Mathematical reasoning requires abstracting symbolic rules from visual
patterns -- inferring the infinite from the finite. We investigate whether
multimodal AI systems possess this capability through FractalBench, a benchmark
evaluating fractal program synthesis from images. Fractals provide ideal test
cases: Iterated Function Systems with only a few contraction maps generate
complex self-similar patterns through simple recursive rules, requiring models
to bridge visual perception with mathematical abstraction. We evaluate four
leading MLLMs -- GPT-4o, Claude 3.7 Sonnet, Gemini 2.5 Flash, and Qwen 2.5-VL
-- on 12 canonical fractals. Models must generate executable Python code
reproducing the fractal, enabling objective evaluation. Results reveal a
striking disconnect: 76% generate syntactically valid code but only 4% capture
mathematical structure. Success varies systematically -- models handle
geometric transformations (Koch curves: 17-21%) but fail at branching recursion
(trees: <2%), revealing fundamental gaps in mathematical abstraction.
FractalBench provides a contamination-resistant diagnostic for
visual-mathematical reasoning and is available at
https://github.com/NaiveNeuron/FractalBench
\\ ( https://arxiv.org/abs/2511.06522 ,  1467kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06618
Date: Mon, 10 Nov 2025 01:57:51 GMT   (1774kb)

Title: GRAPH-GRPO-LEX: Contract Graph Modeling and Reinforcement Learning with
 Group Relative Policy Optimization
Authors: Moriya Dechtiar, Daniel Martin Katz, Mari Sundaresan, Sylvain Jaume,
 Hongming Wang
Categories: cs.AI cs.CL cs.LG cs.SE
\\
 Contracts are complex documents featuring detailed formal structures,
explicit and implicit dependencies and rich semantic content. Given these
document properties, contract drafting and manual examination of contracts have
proven to be both arduous and susceptible to errors. This work aims to simplify
and automate the task of contract review and analysis using a novel framework
for transforming legal contracts into structured semantic graphs, enabling
computational analysis and data-driven insights. We introduce a detailed
ontology mapping core legal contract elements to their graph-theoretic
equivalents of nodes and edges. We then present a reinforcement learning based
Large Language Model (LLM) framework for segmentation and extraction of
entities and relationships from contracts. Our method, GRAPH-GRPO-LEX,
incorporates both LLMs and reinforcement learning with group relative policy
optimization (GRPO). By applying a carefully drafted reward function of graph
metrics, we demonstrate the ability to automatically identify direct
relationships between clauses, and even uncover hidden dependencies. Our
introduction of the gated GRPO approach shows a strong learning signal and can
move contract analysis from a linear, manual reading process to an easily
visualized graph. This allows for a more dynamic analysis, including building
the groundwork for contract linting similar to what is now practiced in
software engineering.
\\ ( https://arxiv.org/abs/2511.06618 ,  1774kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06626
Date: Mon, 10 Nov 2025 02:09:44 GMT   (3582kb)

Title: Spilling the Beans: Teaching LLMs to Self-Report Their Hidden Objectives
Authors: Chloe Li, Mary Phuong, Daniel Tan
Categories: cs.AI
\\
 As AI systems become more capable of complex agentic tasks, they also become
more capable of pursuing undesirable objectives and causing harm. Previous work
has attempted to catch these unsafe instances by interrogating models directly
about their objectives and behaviors. However, the main weakness of trusting
interrogations is that models can lie. We propose self-report fine-tuning
(SRFT), a simple supervised fine-tuning technique that trains models to admit
their factual mistakes when asked. We show that the admission of factual errors
in simple question-answering settings generalizes out-of-distribution (OOD) to
the admission of hidden misaligned objectives in adversarial agentic settings.
We evaluate SRFT in OOD stealth tasks, where models are instructed to complete
a hidden misaligned objective alongside a user-specified objective without
being caught by monitoring. After SRFT, models are more likely to confess the
details of their hidden objectives when interrogated, even under strong
pressure not to disclose them. Interrogation on SRFT models can detect hidden
objectives with near-ceiling performance (F1 score = 0.98), while the baseline
model lies when interrogated under the same conditions (F1 score = 0).
Interrogation on SRFT models can further elicit the content of the hidden
objective, recovering 28-100% details, compared to 0% details recovered in the
baseline model and by prefilled assistant turn attacks. This provides a
promising technique for promoting honesty propensity and incriminating
misaligned AI systems.
\\ ( https://arxiv.org/abs/2511.06626 ,  3582kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06761
Date: Mon, 10 Nov 2025 06:43:42 GMT   (3617kb)

Title: SRNN: Spatiotemporal Relational Neural Network for Intuitive Physics
 Understanding
Authors: Fei Yang
Categories: cs.AI cs.LG
\\
 Human prowess in intuitive physics remains unmatched by machines. To bridge
this gap, we argue for a fundamental shift towards brain-inspired computational
principles. This paper introduces the Spatiotemporal Relational Neural Network
(SRNN), a model that establishes a unified neural representation for object
attributes, relations, and timeline, with computations governed by a Hebbian
``Fire Together, Wire Together'' mechanism across dedicated \textit{What} and
\textit{How} pathways. This unified representation is directly used to generate
structured linguistic descriptions of the visual scene, bridging perception and
language within a shared neural substrate. Moreover, unlike the prevalent
``pretrain-then-finetune'' paradigm, SRNN adopts a ``predefine-then-finetune''
approach. On the CLEVRER benchmark, SRNN achieves competitive performance. Our
analysis further reveals a benchmark bias, outlines a path for a more holistic
evaluation, and demonstrates SRNN's white-box utility for precise error
diagnosis. Our work confirms the viability of translating biological
intelligence into engineered systems for intuitive physics understanding.
\\ ( https://arxiv.org/abs/2511.06761 ,  3617kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06805
Date: Mon, 10 Nov 2025 07:46:19 GMT   (1455kb)

Title: MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving
 Iterative Reflection and Reward-Guided Fine-Tuning
Authors: Jinhao Chen, Zhen Yang, Jianxin Shi, Tianyu Wo, Jie Tang
Categories: cs.AI cs.LG
Comments: 19 pages, 11 figures
\\
 Multimodal large language models (MLLMs) have demonstrated remarkable
capabilities in vision-language answering tasks. Despite their strengths, these
models often encounter challenges in achieving complex reasoning tasks such as
mathematical problem-solving. Previous works have focused on fine-tuning on
specialized mathematical datasets. However, these datasets are typically
distilled directly from teacher models, which capture only static reasoning
patterns and leaving substantial gaps compared to student models. This reliance
on fixed teacher-derived datasets not only restricts the model's ability to
adapt to novel or more intricate questions that extend beyond the confines of
the training data, but also lacks the iterative depth needed for robust
generalization. To overcome these limitations, we propose \textbf{\method}, a
\textbf{Math}ematical \textbf{S}elf-\textbf{E}volving framework for MLLMs. In
contrast to traditional one-shot fine-tuning paradigms, \method iteratively
refines the model through cycles of inference, reflection, and reward-based
feedback. Specifically, we leverage iterative fine-tuning by incorporating
correct reasoning paths derived from previous-stage inference and integrating
reflections from a specialized Outcome Reward Model (ORM). To verify the
effectiveness of \method, we evaluate it on a suite of challenging benchmarks,
demonstrating significant performance gains over backbone models. Notably, our
experimental results on MathVL-test surpass the leading open-source multimodal
mathematical reasoning model QVQ. Our code and models are available at
\texttt{https://zheny2751\allowbreak-dotcom.github.io/\allowbreak
MathSE.github.io/}.
\\ ( https://arxiv.org/abs/2511.06805 ,  1455kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06918
Date: Mon, 10 Nov 2025 10:12:04 GMT   (2750kb)

Title: Proceedings of the 2025 XCSP3 Competition
Authors: Gilles Audemard, Christophe Lecoutre, Emmanuel Lonca
Categories: cs.AI
Comments: 110 pages
\\
 This document represents the proceedings of the 2025 XCSP3 Competition. The
results of this competition of constraint solvers were presented at CP'25 (31st
International Conference on Principles and Practice of Constraint Programming).
\\ ( https://arxiv.org/abs/2511.06918 ,  2750kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07061
Date: Mon, 10 Nov 2025 12:52:11 GMT   (1333kb)

Title: Do LLMs Feel? Teaching Emotion Recognition with Prompts, Retrieval, and
 Curriculum Learning
Authors: Xinran Li, Xiujuan Xu, Jiaqi Qiao, Yu Liu
Categories: cs.AI
Comments: Accepted at AAAI 2026
\\
 Emotion Recognition in Conversation (ERC) is a crucial task for understanding
human emotions and enabling natural human-computer interaction. Although Large
Language Models (LLMs) have recently shown great potential in this field, their
ability to capture the intrinsic connections between explicit and implicit
emotions remains limited. We propose a novel ERC training framework, PRC-Emo,
which integrates Prompt engineering, demonstration Retrieval, and Curriculum
learning, with the goal of exploring whether LLMs can effectively perceive
emotions in conversational contexts. Specifically, we design emotion-sensitive
prompt templates based on both explicit and implicit emotional cues to better
guide the model in understanding the speaker's psychological states. We
construct the first dedicated demonstration retrieval repository for ERC, which
includes training samples from widely used datasets, as well as high-quality
dialogue examples generated by LLMs and manually verified. Moreover, we
introduce a curriculum learning strategy into the LoRA fine-tuning process,
incorporating weighted emotional shifts between same-speaker and
different-speaker utterances to assign difficulty levels to dialogue samples,
which are then organized in an easy-to-hard training sequence. Experimental
results on two benchmark datasets-- IEMOCAP and MELD --show that our method
achieves new state-of-the-art (SOTA) performance, demonstrating the
effectiveness and generalizability of our approach in improving LLM-based
emotional understanding.
\\ ( https://arxiv.org/abs/2511.07061 ,  1333kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07062
Date: Mon, 10 Nov 2025 12:53:32 GMT   (4968kb)

Title: Improving Region Representation Learning from Urban Imagery with Noisy
 Long-Caption Supervision
Authors: Yimei Zhang, Guojiang Shen, Kaili Ning, Tongwei Ren, Xuebo Qiu,
 Mengmeng Wang, Xiangjie Kong
Categories: cs.AI
Comments: Accepted as a full paper by AAAI-26
\\
 Region representation learning plays a pivotal role in urban computing by
extracting meaningful features from unlabeled urban data. Analogous to how
perceived facial age reflects an individual's health, the visual appearance of
a city serves as its ``portrait", encapsulating latent socio-economic and
environmental characteristics. Recent studies have explored leveraging Large
Language Models (LLMs) to incorporate textual knowledge into imagery-based
urban region representation learning. However, two major challenges remain:
i)~difficulty in aligning fine-grained visual features with long captions, and
ii) suboptimal knowledge incorporation due to noise in LLM-generated captions.
To address these issues, we propose a novel pre-training framework called
UrbanLN that improves Urban region representation learning through Long-text
awareness and Noise suppression. Specifically, we introduce an
information-preserved stretching interpolation strategy that aligns long
captions with fine-grained visual semantics in complex urban scenes. To
effectively mine knowledge from LLM-generated captions and filter out noise, we
propose a dual-level optimization strategy. At the data level, a multi-model
collaboration pipeline automatically generates diverse and reliable captions
without human intervention. At the model level, we employ a momentum-based
self-distillation mechanism to generate stable pseudo-targets, facilitating
robust cross-modal learning under noisy conditions. Extensive experiments
across four real-world cities and various downstream tasks demonstrate the
superior performance of our UrbanLN.
\\ ( https://arxiv.org/abs/2511.07062 ,  4968kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07070
Date: Mon, 10 Nov 2025 13:04:34 GMT   (535kb)

Title: RedOne 2.0: Rethinking Domain-specific LLM Post-Training in Social
 Networking Services
Authors: Fei Zhao, Chonggang Lu, Haofu Qian, Fangcheng Shi, Zijie Meng,
 Jianzhao Huang, Xu Tang, Zheyong Xie, Zheyu Ye, Zhe Xu, Yao Hu, Shaosheng Cao
Categories: cs.AI cs.LG
\\
 As a key medium for human interaction and information exchange, social
networking services (SNS) pose unique challenges for large language models
(LLMs): heterogeneous workloads, fast-shifting norms and slang, and
multilingual, culturally diverse corpora that induce sharp distribution shift.
Supervised fine-tuning (SFT) can specialize models but often triggers a
``seesaw'' between in-distribution gains and out-of-distribution robustness,
especially for smaller models. To address these challenges, we introduce RedOne
2.0, an SNS-oriented LLM trained with a progressive, RL-prioritized
post-training paradigm designed for rapid and stable adaptation. The pipeline
consist in three stages: (1) Exploratory Learning on curated SNS corpora to
establish initial alignment and identify systematic weaknesses; (2) Targeted
Fine-Tuning that selectively applies SFT to the diagnosed gaps while mixing a
small fraction of general data to mitigate forgetting; and (3) Refinement
Learning that re-applies RL with SNS-centric signals to consolidate
improvements and harmonize trade-offs across tasks. Across various tasks
spanning three categories, our 4B scale model delivers an average improvements
about 2.41 over the 7B sub-optimal baseline. Additionally, RedOne 2.0 achieves
average performance lift about 8.74 from the base model with less than half the
data required by SFT-centric method RedOne, evidencing superior data efficiency
and stability at compact scales. Overall, RedOne 2.0 establishes a competitive,
cost-effective baseline for domain-specific LLMs in SNS scenario, advancing
capability without sacrificing robustness.
\\ ( https://arxiv.org/abs/2511.07070 ,  535kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07083
Date: Mon, 10 Nov 2025 13:16:10 GMT   (177kb)

Title: Increasing AI Explainability by LLM Driven Standard Processes
Authors: Marc Jansen, Marcel Pehlke
Categories: cs.AI
\\
 This paper introduces an approach to increasing the explainability of
artificial intelligence (AI) systems by embedding Large Language Models (LLMs)
within standardized analytical processes. While traditional explainable AI
(XAI) methods focus on feature attribution or post-hoc interpretation, the
proposed framework integrates LLMs into defined decision models such as
Question-Option-Criteria (QOC), Sensitivity Analysis, Game Theory, and Risk
Management. By situating LLM reasoning within these formal structures, the
approach transforms opaque inference into transparent and auditable decision
traces. A layered architecture is presented that separates the reasoning space
of the LLM from the explainable process space above it. Empirical evaluations
show that the system can reproduce human-level decision logic in decentralized
governance, systems analysis, and strategic reasoning contexts. The results
suggest that LLM-driven standard processes provide a foundation for reliable,
interpretable, and verifiable AI-supported decision making.
\\ ( https://arxiv.org/abs/2511.07083 ,  177kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07086
Date: Mon, 10 Nov 2025 13:20:00 GMT   (58kb)

Title: LLM Driven Processes to Foster Explainable AI
Authors: Marcel Pehlke, Marc Jansen
Categories: cs.AI
\\
 We present a modular, explainable LLM-agent pipeline for decision support
that externalizes reasoning into auditable artifacts. The system instantiates
three frameworks: Vester's Sensitivity Model (factor set, signed impact matrix,
systemic roles, feedback loops); normal-form games (strategies, payoff matrix,
equilibria); and sequential games (role-conditioned agents, tree construction,
backward induction), with swappable modules at every step. LLM components
(default: GPT-5) are paired with deterministic analyzers for equilibria and
matrix-based role classification, yielding traceable intermediates rather than
opaque outputs. In a real-world logistics case (100 runs), mean factor
alignment with a human baseline was 55.5\% over 26 factors and 62.9\% on the
transport-core subset; role agreement over matches was 57\%. An LLM judge using
an eight-criterion rubric (max 100) scored runs on par with a reconstructed
human baseline. Configurable LLM pipelines can thus mimic expert workflows with
transparent, inspectable steps.
\\ ( https://arxiv.org/abs/2511.07086 ,  58kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07090
Date: Mon, 10 Nov 2025 13:26:06 GMT   (669kb)

Title: Green AI: A systematic review and meta-analysis of its definitions,
 lifecycle models, hardware and measurement attempts
Authors: Marcel Rojahn and Marcus Grum
Categories: cs.AI
\\
 Across the Artificial Intelligence (AI) lifecycle - from hardware to
development, deployment, and reuse - burdens span energy, carbon, water, and
embodied impacts. Cloud provider tools improve transparency but remain
heterogeneous and often omit water and value chain effects, limiting
comparability and reproducibility. Addressing these multi dimensional burdens
requires a lifecycle approach linking phase explicit mapping with system levers
(hardware, placement, energy mix, cooling, scheduling) and calibrated
measurement across facility, system, device, and workload levels. This article
(i) establishes a unified, operational definition of Green AI distinct from
Sustainable AI; (ii) formalizes a five phase lifecycle mapped to Life Cycle
Assessment (LCA) stages, making energy, carbon, water, and embodied impacts
first class; (iii) specifies governance via Plan Do Check Act (PDCA) cycles
with decision gateways; (iv) systematizes hardware and system level strategies
across the edge cloud continuum to reduce embodied burdens; and (v) defines a
calibrated measurement framework combining estimator models with direct
metering to enable reproducible, provider agnostic comparisons. Combining
definition, lifecycle processes, hardware strategies, and calibrated
measurement, this article offers actionable, evidence based guidance for
researchers, practitioners, and policymakers.
\\ ( https://arxiv.org/abs/2511.07090 ,  669kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07095
Date: Mon, 10 Nov 2025 13:34:24 GMT   (54kb)

Title: Data Complexity of Querying Description Logic Knowledge Bases under
 Cost-Based Semantics
Authors: Meghyn Bienvenu and Quentin Mani\`ere
Categories: cs.AI
Comments: Long version of paper to appear in AAAI 2026
\\
 In this paper, we study the data complexity of querying inconsistent weighted
description logic (DL) knowledge bases under recently-introduced cost-based
semantics. In a nutshell, the idea is to assign each interpretation a cost
based upon the weights of the violated axioms and assertions, and certain and
possible query answers are determined by considering all (resp. some)
interpretations having optimal or bounded cost. Whereas the initial study of
cost-based semantics focused on DLs between $\mathcal{EL}_\bot$ and
$\mathcal{ALCO}$, we consider DLs that may contain inverse roles and role
inclusions, thus covering prominent DL-Lite dialects. Our data complexity
analysis goes significantly beyond existing results by sharpening several lower
bounds and pinpointing the precise complexity of optimal-cost certain answer
semantics (no non-trivial upper bound was known). Moreover, while all existing
results show the intractability of cost-based semantics, our most challenging
and surprising result establishes that if we consider
$\text{DL-Lite}^\mathcal{H}_\mathsf{bool}$ ontologies and a fixed cost bound,
certain answers for instance queries and possible answers for conjunctive
queries can be computed using first-order rewriting and thus enjoy the lowest
possible data complexity ($\mathsf{TC}_0$).
\\ ( https://arxiv.org/abs/2511.07095 ,  54kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07097
Date: Mon, 10 Nov 2025 13:38:08 GMT   (258kb)

Title: Agentic AI Sustainability Assessment for Supply Chain Document Insights
Authors: Diego Gosmar, Anna Chiara Pallotta, Giovanni Zenezini
Categories: cs.AI cs.MA
Comments: 17 pages, 4 figures
\\
 This paper presents a comprehensive sustainability assessment framework for
document intelligence within supply chain operations, centered on agentic
artificial intelligence (AI). We address the dual objective of improving
automation efficiency while providing measurable environmental performance in
document-intensive workflows. The research compares three scenarios: fully
manual (human-only), AI-assisted (human-in-the-loop, HITL), and an advanced
multi-agent agentic AI workflow leveraging parsers and verifiers. Empirical
results show that AI-assisted HITL and agentic AI scenarios achieve reductions
of up to 70-90% in energy consumption, 90-97% in carbon dioxide emissions, and
89-98% in water usage compared to manual processes. Notably, full agentic
configurations, combining advanced reasoning (thinking mode) and multi-agent
validation, achieve substantial sustainability gains over human-only
approaches, even when resource usage increases slightly versus simpler
AI-assisted solutions. The framework integrates performance, energy, and
emission indicators into a unified ESG-oriented methodology for assessing and
governing AI-enabled supply chain solutions. The paper includes a complete
replicability use case demonstrating the methodology's application to
real-world document extraction tasks.
\\ ( https://arxiv.org/abs/2511.07097 ,  258kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07098
Date: Mon, 10 Nov 2025 13:38:26 GMT   (698kb)

Title: Boosting Fine-Grained Urban Flow Inference via Lightweight Architecture
 and Focalized Optimization
Authors: Yuanshao Zhu, Xiangyu Zhao, Zijian Zhang, Xuetao Wei, James Jianqiao
 Yu
Categories: cs.AI
Comments: Accepted as a regular paper by AAAI'26
\\
 Fine-grained urban flow inference is crucial for urban planning and
intelligent transportation systems, enabling precise traffic management and
resource allocation. However, the practical deployment of existing methods is
hindered by two key challenges: the prohibitive computational cost of
over-parameterized models and the suboptimal performance of conventional loss
functions on the highly skewed distribution of urban flows. To address these
challenges, we propose a unified solution that synergizes architectural
efficiency with adaptive optimization. Specifically, we first introduce PLGF, a
lightweight yet powerful architecture that employs a Progressive Local-Global
Fusion strategy to effectively capture both fine-grained details and global
contextual dependencies. Second, we propose DualFocal Loss, a novel function
that integrates dual-space supervision with a difficulty-aware focusing
mechanism, enabling the model to adaptively concentrate on hard-to-predict
regions. Extensive experiments on 4 real-world scenarios validate the
effectiveness and scalability of our method. Notably, while achieving
state-of-the-art performance, PLGF reduces the model size by up to 97% compared
to current high-performing methods. Furthermore, under comparable parameter
budgets, our model yields an accuracy improvement of over 10% against strong
baselines. The implementation is included in the https://github.com/Yasoz/PLGF.
\\ ( https://arxiv.org/abs/2511.07098 ,  698kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07104
Date: Mon, 10 Nov 2025 13:48:48 GMT   (11658kb)

Title: A Theoretical Analysis of Detecting Large Model-Generated Time Series
Authors: Junji Hou, Junzhou Zhao, Shuo Zhang, Pinghui Wang
Categories: cs.AI
Comments: 23 pages,12 figures, to be published in AAAI-2026 main track
\\
 Motivated by the increasing risks of data misuse and fabrication, we
investigate the problem of identifying synthetic time series generated by
Time-Series Large Models (TSLMs) in this work. While there are extensive
researches on detecting model generated text, we find that these existing
methods are not applicable to time series data due to the fundamental modality
difference, as time series usually have lower information density and smoother
probability distributions than text data, which limit the discriminative power
of token-based detectors. To address this issue, we examine the subtle
distributional differences between real and model-generated time series and
propose the contraction hypothesis, which states that model-generated time
series, unlike real ones, exhibit progressively decreasing uncertainty under
recursive forecasting. We formally prove this hypothesis under theoretical
assumptions on model behavior and time series structure. Model-generated time
series exhibit progressively concentrated distributions under recursive
forecasting, leading to uncertainty contraction. We provide empirical
validation of the hypothesis across diverse datasets. Building on this insight,
we introduce the Uncertainty Contraction Estimator (UCE), a white-box detector
that aggregates uncertainty metrics over successive prefixes to identify
TSLM-generated time series. Extensive experiments on 32 datasets show that UCE
consistently outperforms state-of-the-art baselines, offering a reliable and
generalizable solution for detecting model-generated time series.
\\ ( https://arxiv.org/abs/2511.07104 ,  11658kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07107
Date: Mon, 10 Nov 2025 13:51:51 GMT   (290kb)

Title: MENTOR: A Metacognition-Driven Self-Evolution Framework for Uncovering
 and Mitigating Implicit Risks in LLMs on Domain Tasks
Authors: Liang Shan, Kaicheng Shen, Wen Wu, Zhenyu Ying, Chaochao Lu, Guangze
 Ye, Liang He
Categories: cs.AI cs.CL
\\
 Ensuring the safety and value alignment of large language models (LLMs) is
critical for their deployment. Current alignment efforts primarily target
explicit risks such as bias, hate speech, and violence. However, they often
fail to address deeper, domain-specific implicit risks and lack a flexible,
generalizable framework applicable across diverse specialized fields. Hence, we
proposed MENTOR: A MEtacognition-driveN self-evoluTion framework for uncOvering
and mitigating implicit Risks in LLMs on Domain Tasks. To address the
limitations of labor-intensive human evaluation, we introduce a novel
metacognitive self-assessment tool. This enables LLMs to reflect on potential
value misalignments in their responses using strategies like perspective-taking
and consequential thinking. We also release a supporting dataset of 9,000 risk
queries spanning education, finance, and management to enhance domain-specific
risk identification. Subsequently, based on the outcomes of metacognitive
reflection, the framework dynamically generates supplementary rule knowledge
graphs that extend predefined static rule trees. This enables models to
actively apply validated rules to future similar challenges, establishing a
continuous self-evolution cycle that enhances generalization by reducing
maintenance costs and inflexibility of static systems. Finally, we employ
activation steering during inference to guide LLMs in following the rules, a
cost-effective method to robustly enhance enforcement across diverse contexts.
Experimental results show MENTOR's effectiveness: In defensive testing across
three vertical domains, the framework substantially reduces semantic attack
success rates, enabling a new level of implicit risk mitigation for LLMs.
Furthermore, metacognitive assessment not only aligns closely with baseline
human evaluators but also delivers more thorough and insightful analysis of
LLMs value alignment.
\\ ( https://arxiv.org/abs/2511.07107 ,  290kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07110
Date: Mon, 10 Nov 2025 13:57:05 GMT   (2269kb)

Title: Two Heads are Better than One: Distilling Large Language Model Features
 Into Small Models with Feature Decomposition and Mixture
Authors: Tianhao Fu, Xinxin Xu, Weichen Xu, Jue Chen, Ruilong Ren, Bowen Deng,
 Xinyu Zhao, Jian Cao, Xixin Cao
Categories: cs.AI
\\
 Market making (MM) through Reinforcement Learning (RL) has attracted
significant attention in financial trading. With the development of Large
Language Models (LLMs), more and more attempts are being made to apply LLMs to
financial areas. A simple, direct application of LLM as an agent shows
significant performance. Such methods are hindered by their slow inference
speed, while most of the current research has not studied LLM distillation for
this specific task. To address this, we first propose the normalized
fluorescent probe to study the mechanism of the LLM's feature. Based on the
observation found by our investigation, we propose Cooperative Market Making
(CMM), a novel framework that decouples LLM features across three orthogonal
dimensions: layer, task, and data. Various student models collaboratively learn
simple LLM features along with different dimensions, with each model
responsible for a distinct feature to achieve knowledge distillation.
Furthermore, CMM introduces an H\'{a}jek-MoE to integrate the output of the
student models by investigating the contribution of different models in a
kernel function-generated common feature space. Extensive experimental results
on four real-world market datasets demonstrate the superiority of CMM over the
current distillation method and RL-based market-making strategies.
\\ ( https://arxiv.org/abs/2511.07110 ,  2269kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07126
Date: Mon, 10 Nov 2025 14:11:49 GMT   (5124kb)

Title: Saliency Map-Guided Knowledge Discovery for Subclass Identification with
 LLM-Based Symbolic Approximations
Authors: Tim Bohne, Anne-Kathrin Patricia Windler, Martin Atzmueller
Categories: cs.AI
\\
 This paper proposes a novel neuro-symbolic approach for sensor signal-based
knowledge discovery, focusing on identifying latent subclasses in time series
classification tasks. The approach leverages gradient-based saliency maps
derived from trained neural networks to guide the discovery process. Multiclass
time series classification problems are transformed into binary classification
problems through label subsumption, and classifiers are trained for each of
these to yield saliency maps. The input signals, grouped by predicted class,
are clustered under three distinct configurations. The centroids of the final
set of clusters are provided as input to an LLM for symbolic approximation and
fuzzy knowledge graph matching to discover the underlying subclasses of the
original multiclass problem. Experimental results on well-established time
series classification datasets demonstrate the effectiveness of our saliency
map-driven method for knowledge discovery, outperforming signal-only baselines
in both clustering and subclass identification.
\\ ( https://arxiv.org/abs/2511.07126 ,  5124kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07204
Date: Mon, 10 Nov 2025 15:31:59 GMT   (4136kb)

Title: Evaluating Online Moderation Via LLM-Powered Counterfactual Simulations
Authors: Giacomo Fidone, Lucia Passaro, Riccardo Guidotti
Categories: cs.AI cs.CY cs.MA
Comments: Accepted for publication at AAAI Conference on Artificial
 Intelligence 2026
\\
 Online Social Networks (OSNs) widely adopt content moderation to mitigate the
spread of abusive and toxic discourse. Nonetheless, the real effectiveness of
moderation interventions remains unclear due to the high cost of data
collection and limited experimental control. The latest developments in Natural
Language Processing pave the way for a new evaluation approach. Large Language
Models (LLMs) can be successfully leveraged to enhance Agent-Based Modeling and
simulate human-like social behavior with unprecedented degree of believability.
Yet, existing tools do not support simulation-based evaluation of moderation
strategies. We fill this gap by designing a LLM-powered simulator of OSN
conversations enabling a parallel, counterfactual simulation where toxic
behavior is influenced by moderation interventions, keeping all else equal. We
conduct extensive experiments, unveiling the psychological realism of OSN
agents, the emergence of social contagion phenomena and the superior
effectiveness of personalized moderation strategies.
\\ ( https://arxiv.org/abs/2511.07204 ,  4136kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07260
Date: Mon, 10 Nov 2025 16:05:40 GMT   (1448kb)

Title: PADiff: Predictive and Adaptive Diffusion Policies for Ad Hoc Teamwork
Authors: Hohei Chan, Xinzhi Zhang, Antao Xiang, Weinan Zhang, Mengchen Zhao
Categories: cs.AI cs.LG
Comments: Accepted by the 40th AAAI conference on Artificial Intelligence (AAAI
 2026)
\\
 Ad hoc teamwork (AHT) requires agents to collaborate with previously unseen
teammates, which is crucial for many real-world applications. The core
challenge of AHT is to develop an ego agent that can predict and adapt to
unknown teammates on the fly. Conventional RL-based approaches optimize a
single expected return, which often causes policies to collapse into a single
dominant behavior, thus failing to capture the multimodal cooperation patterns
inherent in AHT. In this work, we introduce PADiff, a diffusion-based approach
that captures agent's multimodal behaviors, unlocking its diverse cooperation
modes with teammates. However, standard diffusion models lack the ability to
predict and adapt in highly non-stationary AHT scenarios. To address this
limitation, we propose a novel diffusion-based policy that integrates critical
predictive information about teammates into the denoising process. Extensive
experiments across three cooperation environments demonstrate that PADiff
outperforms existing AHT methods significantly.
\\ ( https://arxiv.org/abs/2511.07260 ,  1448kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07262
Date: Mon, 10 Nov 2025 16:06:33 GMT   (13340kb)

Title: AgenticSciML: Collaborative Multi-Agent Systems for Emergent Discovery
 in Scientific Machine Learning
Authors: Qile Jiang, George Karniadakis
Categories: cs.AI cs.CE cs.LG
\\
 Scientific Machine Learning (SciML) integrates data-driven inference with
physical modeling to solve complex problems in science and engineering.
However, the design of SciML architectures, loss formulations, and training
strategies remains an expert-driven research process, requiring extensive
experimentation and problem-specific insights. Here we introduce AgenticSciML,
a collaborative multi-agent system in which over 10 specialized AI agents
collaborate to propose, critique, and refine SciML solutions through structured
reasoning and iterative evolution. The framework integrates structured debate,
retrieval-augmented method memory, and ensemble-guided evolutionary search,
enabling the agents to generate and assess new hypotheses about architectures
and optimization procedures. Across physics-informed learning and operator
learning tasks, the framework discovers solution methods that outperform
single-agent and human-designed baselines by up to four orders of magnitude in
error reduction. The agents produce novel strategies -- including adaptive
mixture-of-expert architectures, decomposition-based PINNs, and
physics-informed operator learning models -- that do not appear explicitly in
the curated knowledge base. These results show that collaborative reasoning
among AI agents can yield emergent methodological innovation, suggesting a path
toward scalable, transparent, and autonomous discovery in scientific computing.
\\ ( https://arxiv.org/abs/2511.07262 ,  13340kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07267
Date: Mon, 10 Nov 2025 16:15:53 GMT   (2978kb)

Title: Beyond Detection: Exploring Evidence-based Multi-Agent Debate for
 Misinformation Intervention and Persuasion
Authors: Chen Han, Yijia Ma, Jin Tan, Wenzhen Zheng, Xijin Tang
Categories: cs.AI
Comments: This paper has been accepted to AAAI 2026
\\
 Multi-agent debate (MAD) frameworks have emerged as promising approaches for
misinformation detection by simulating adversarial reasoning. While prior work
has focused on detection accuracy, it overlooks the importance of helping users
understand the reasoning behind factual judgments and develop future
resilience. The debate transcripts generated during MAD offer a rich but
underutilized resource for transparent reasoning. In this study, we introduce
ED2D, an evidence-based MAD framework that extends previous approach by
incorporating factual evidence retrieval. More importantly, ED2D is designed
not only as a detection framework but also as a persuasive multi-agent system
aimed at correcting user beliefs and discouraging misinformation sharing. We
compare the persuasive effects of ED2D-generated debunking transcripts with
those authored by human experts. Results demonstrate that ED2D outperforms
existing baselines across three misinformation detection benchmarks. When ED2D
generates correct predictions, its debunking transcripts exhibit persuasive
effects comparable to those of human experts; However, when ED2D misclassifies,
its accompanying explanations may inadvertently reinforce users'misconceptions,
even when presented alongside accurate human explanations. Our findings
highlight both the promise and the potential risks of deploying MAD systems for
misinformation intervention. We further develop a public community website to
help users explore ED2D, fostering transparency, critical thinking, and
collaborative fact-checking.
\\ ( https://arxiv.org/abs/2511.07267 ,  2978kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07327
Date: Mon, 10 Nov 2025 17:30:08 GMT   (4296kb)

Title: IterResearch: Rethinking Long-Horizon Agents via Markovian State
 Reconstruction
Authors: Guoxin Chen, Zile Qiao, Xuanzhong Chen, Donglei Yu, Haotian Xu, Wayne
 Xin Zhao, Ruihua Song, Wenbiao Yin, Huifeng Yin, Liwen Zhang, Kuan Li,
 Minpeng Liao, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou
Categories: cs.AI cs.CL
Comments: https://github.com/Alibaba-NLP/DeepResearch
\\
 Recent advances in deep-research agents have shown promise for autonomous
knowledge construction through dynamic reasoning over external sources.
However, existing approaches rely on a mono-contextual paradigm that
accumulates all information in a single, expanding context window, leading to
context suffocation and noise contamination that limit their effectiveness on
long-horizon tasks. We introduce IterResearch, a novel iterative deep-research
paradigm that reformulates long-horizon research as a Markov Decision Process
with strategic workspace reconstruction. By maintaining an evolving report as
memory and periodically synthesizing insights, our approach preserves
consistent reasoning capacity across arbitrary exploration depths. We further
develop Efficiency-Aware Policy Optimization (EAPO), a reinforcement learning
framework that incentivizes efficient exploration through geometric reward
discounting and enables stable distributed training via adaptive downsampling.
Extensive experiments demonstrate that IterResearch achieves substantial
improvements over existing open-source agents with average +14.5pp across six
benchmarks and narrows the gap with frontier proprietary systems. Remarkably,
our paradigm exhibits unprecedented interaction scaling, extending to 2048
interactions with dramatic performance gains (from 3.5\% to 42.5\%), and serves
as an effective prompting strategy, improving frontier models by up to 19.2pp
over ReAct on long-horizon tasks. These findings position IterResearch as a
versatile solution for long-horizon reasoning, effective both as a trained
agent and as a prompting paradigm for frontier models.
\\ ( https://arxiv.org/abs/2511.07327 ,  4296kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07338
Date: Mon, 10 Nov 2025 17:37:56 GMT   (1541kb)

Title: DeepPersona: A Generative Engine for Scaling Deep Synthetic Personas
Authors: Zhen Wang, Yufan Zhou, Zhongyan Luo, Lyumanshan Ye, Adam Wood, Man
 Yao, and Luoshang Pan
Categories: cs.AI cs.LG
Comments: 12 pages, 5 figures, accepted at LAW 2025 Workshop (NeurIPS 2025)
MSC-class: 68T07, 68T20
ACM-class: I.2.7; I.2.6; I.2.11
Journal-ref: LAW 2025 Workshop, NeurIPS 2025
\\
 Simulating human profiles by instilling personas into large language models
(LLMs) is rapidly transforming research in agentic behavioral simulation, LLM
personalization, and human-AI alignment. However, most existing synthetic
personas remain shallow and simplistic, capturing minimal attributes and
failing to reflect the rich complexity and diversity of real human identities.
We introduce DEEPPERSONA, a scalable generative engine for synthesizing
narrative-complete synthetic personas through a two-stage, taxonomy-guided
method. First, we algorithmically construct the largest-ever human-attribute
taxonomy, comprising over hundreds of hierarchically organized attributes, by
mining thousands of real user-ChatGPT conversations. Second, we progressively
sample attributes from this taxonomy, conditionally generating coherent and
realistic personas that average hundreds of structured attributes and roughly 1
MB of narrative text, two orders of magnitude deeper than prior works.
Intrinsic evaluations confirm significant improvements in attribute diversity
(32 percent higher coverage) and profile uniqueness (44 percent greater)
compared to state-of-the-art baselines. Extrinsically, our personas enhance
GPT-4.1-mini's personalized question answering accuracy by 11.6 percent on
average across ten metrics and substantially narrow (by 31.7 percent) the gap
between simulated LLM citizens and authentic human responses in social surveys.
Our generated national citizens reduced the performance gap on the Big Five
personality test by 17 percent relative to LLM-simulated citizens. DEEPPERSONA
thus provides a rigorous, scalable, and privacy-free platform for high-fidelity
human simulation and personalized AI research.
\\ ( https://arxiv.org/abs/2511.07338 ,  1541kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07413
Date: Mon, 10 Nov 2025 18:57:35 GMT   (20533kb)

Title: DigiData: Training and Evaluating General-Purpose Mobile Control Agents
Authors: Yuxuan Sun, Manchen Wang, Shengyi Qian, William R. Wong, Eric Gan,
 Pierluca D'Oro, Alejandro Castillejo Munoz, Sneha Silwal, Pedro Matias, Nitin
 Kamra, Satwik Kottur, Nick Raines, Xuanyi Zhao, Joy Chen, Joseph Greer,
 Andrea Madotto, Allen Bolourchi, James Valori, Kevin Carlberg, Karl Ridgeway,
 Joseph Tighe
Categories: cs.AI cs.CL cs.HC cs.LG
Comments: Website: https://facebookresearch.github.io/DigiData
\\
 AI agents capable of controlling user interfaces have the potential to
transform human interaction with digital devices. To accelerate this
transformation, two fundamental building blocks are essential: high-quality
datasets that enable agents to achieve complex and human-relevant goals, and
robust evaluation methods that allow researchers and practitioners to rapidly
enhance agent performance. In this paper, we introduce DigiData, a large-scale,
high-quality, diverse, multi-modal dataset designed for training mobile control
agents. Unlike existing datasets, which derive goals from unstructured
interactions, DigiData is meticulously constructed through comprehensive
exploration of app features, resulting in greater diversity and higher goal
complexity. Additionally, we present DigiData-Bench, a benchmark for evaluating
mobile control agents on real-world complex tasks. We demonstrate that the
commonly used step-accuracy metric falls short in reliably assessing mobile
control agents and, to address this, we propose dynamic evaluation protocols
and AI-powered evaluations as rigorous alternatives for agent assessment. Our
contributions aim to significantly advance the development of mobile control
agents, paving the way for more intuitive and effective human-device
interactions.
\\ ( https://arxiv.org/abs/2511.07413 ,  20533kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05516
Date: Sun, 26 Oct 2025 17:55:34 GMT   (3793kb)

Title: Ming-UniAudio: Speech LLM for Joint Understanding, Generation and
 Editing with Unified Representation
Authors: Canxiang Yan, Chunxiang Jin, Dawei Huang, Haibing Yu, Han Peng, Hui
 Zhan, Jie Gao, Jing Peng, Jingdong Chen, Jun Zhou, Kaimeng Ren, Ming Yang,
 Mingxue Yang, Qiang Xu, Qin Zhao, Ruijie Xiong, Shaoxiong Lin, Xuezhi Wang,
 Yi Yuan, Yifei Wu, Yongjie Lyu, Zhengyu He, Zhihao Qiu, Zhiqiang Fang, Ziyuan
 Huang
Categories: cs.CL cs.AI cs.SD eess.AS
Comments: 32 pages, 8 figures
\\
 Existing speech models suffer from competing requirements on token
representations by understanding and generation tasks. This discrepancy in
representation prevents speech language models from performing
instruction-based free-form editing. To solve this challenge, we introduce a
novel framework that unifies speech understanding, generation, and editing. The
core of our unified model is a unified continuous speech tokenizer
MingTok-Audio, the first continuous tokenizer to effectively integrate semantic
and acoustic features, which makes it suitable for both understanding and
generation tasks. Based on this unified continuous audio tokenizer, we
developed the speech language model Ming-UniAudio, which achieved a balance
between generation and understanding capabilities. Ming-UniAudio sets new
state-of-the-art (SOTA) records on 8 out of 12 metrics on the ContextASR
benchmark. Notably, for Chinese voice cloning, it achieves a highly competitive
Seed-TTS-WER of 0.95. Leveraging this foundational model, we further trained a
dedicated speech editing model Ming-UniAudio-Edit, the first speech language
model that enables universal, free-form speech editing guided solely by natural
language instructions, handling both semantic and acoustic modifications
without timestamp condition. To rigorously assess the editing capability and
establish a foundation for future research, we introduce
Ming-Freeform-Audio-Edit, the first comprehensive benchmark tailored for
instruction-based free-form speech editing, featuring diverse scenarios and
evaluation dimensions spanning semantic correctness, acoustic quality, and
instruction alignment. We open-sourced the continuous audio tokenizer, the
unified foundational model, and the free-form instruction-based editing model
to facilitate the development of unified audio understanding, generation, and
manipulation.
\\ ( https://arxiv.org/abs/2511.05516 ,  3793kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05518
Date: Mon, 27 Oct 2025 03:48:24 GMT   (1295kb)

Title: Retracing the Past: LLMs Emit Training Data When They Get Lost
Authors: Myeongseob Ko, Nikhil Reddy Billa, Adam Nguyen, Charles Fleming, Ming
 Jin, and Ruoxi Jia
Categories: cs.CL cs.AI
Comments: The 2025 Conference on Empirical Methods in Natural Language
 Processing
\\
 The memorization of training data in large language models (LLMs) poses
significant privacy and copyright concerns. Existing data extraction methods,
particularly heuristic-based divergence attacks, often exhibit limited success
and offer limited insight into the fundamental drivers of memorization leakage.
This paper introduces Confusion-Inducing Attacks (CIA), a principled framework
for extracting memorized data by systematically maximizing model uncertainty.
We empirically demonstrate that the emission of memorized text during
divergence is preceded by a sustained spike in token-level prediction entropy.
CIA leverages this insight by optimizing input snippets to deliberately induce
this consecutive high-entropy state. For aligned LLMs, we further propose
Mismatched Supervised Fine-tuning (SFT) to simultaneously weaken their
alignment and induce targeted confusion, thereby increasing susceptibility to
our attacks. Experiments on various unaligned and aligned LLMs demonstrate that
our proposed attacks outperform existing baselines in extracting verbatim and
near-verbatim training data without requiring prior knowledge of the training
data. Our findings highlight persistent memorization risks across various LLMs
and offer a more systematic method for assessing these vulnerabilities.
\\ ( https://arxiv.org/abs/2511.05518 ,  1295kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05532
Date: Wed, 29 Oct 2025 09:11:20 GMT   (288kb)

Title: Beyond One-Size-Fits-All: Personalized Harmful Content Detection with
 In-Context Learning
Authors: Rufan Zhang, Lin Zhang, Xianghang Mi
Categories: cs.CL
\\
 The proliferation of harmful online content--e.g., toxicity, spam, and
negative sentiment--demands robust and adaptable moderation systems. However,
prevailing moderation systems are centralized and task-specific, offering
limited transparency and neglecting diverse user preferences--an approach
ill-suited for privacy-sensitive or decentralized environments. We propose a
novel framework that leverages in-context learning (ICL) with foundation models
to unify the detection of toxicity, spam, and negative sentiment across binary,
multi-class, and multi-label settings. Crucially, our approach enables
lightweight personalization, allowing users to easily block new categories,
unblock existing ones, or extend detection to semantic variations through
simple prompt-based interventions--all without model retraining. Extensive
experiments on public benchmarks (TextDetox, UCI SMS, SST2) and a new,
annotated Mastodon dataset reveal that: (i) foundation models achieve strong
cross-task generalization, often matching or surpassing task-specific
fine-tuned models; (ii) effective personalization is achievable with as few as
one user-provided example or definition; and (iii) augmenting prompts with
label definitions or rationales significantly enhances robustness to noisy,
real-world data. Our work demonstrates a definitive shift beyond
one-size-fits-all moderation, establishing ICL as a practical,
privacy-preserving, and highly adaptable pathway for the next generation of
user-centric content safety systems. To foster reproducibility and facilitate
future research, we publicly release our code on GitHub and the annotated
Mastodon dataset on Hugging Face.
\\ ( https://arxiv.org/abs/2511.05532 ,  288kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05533
Date: Wed, 29 Oct 2025 09:14:14 GMT   (3718kb)

Title: MCP4IFC: IFC-Based Building Design Using Large Language Models
Authors: Bharathi Kannan Nithyanantham, Tobias Sesterhenn, Ashwin Nedungadi,
 Sergio Peral Garijo, Janis Zenkner, Christian Bartelt, Stefan L\"udtke
Categories: cs.CL
\\
 Bringing generative AI into the architecture, engineering and construction
(AEC) field requires systems that can translate natural language instructions
into actions on standardized data models. We present MCP4IFC, a comprehensive
open-source framework that enables Large Language Models (LLMs) to directly
manipulate Industry Foundation Classes (IFC) data through the Model Context
Protocol (MCP). The framework provides a set of BIM tools, including scene
querying tools for information retrieval, predefined functions for creating and
modifying common building elements, and a dynamic code-generation system that
combines in-context learning with retrieval-augmented generation (RAG) to
handle tasks beyond the predefined toolset. Experiments demonstrate that an LLM
using our framework can successfully perform complex tasks, from building a
simple house to querying and editing existing IFC data. Our framework is
released as open-source to encourage research in LLM-driven BIM design and
provide a foundation for AI-assisted modeling workflows. Our code is available
at https://show2instruct.github.io/mcp4ifc/.
\\ ( https://arxiv.org/abs/2511.05533 ,  3718kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05534
Date: Wed, 29 Oct 2025 13:20:16 GMT   (553kb)

Title: FlowMM: Cross-Modal Information Flow Guided KV Cache Merging for
 Efficient Multimodal Context Inference
Authors: Kunxi Li, Yufan Xiong, Zhonghua Jiang, Yiyun Zhou, Zhaode Wang,
 Chengfei Lv, Shengyu Zhang
Categories: cs.CL
\\
 Traditional KV cache eviction strategies, which discard less critical
KV-pairs based on attention scores, often degrade generation quality, causing
context loss or hallucinations. Recent efforts shift toward KV merging, merging
eviction tokens with retention tokens based on similarity. However, in
multimodal scenarios, distributional biases across modality tokens and
attentional biases in cross-modal interactions limit its effectiveness. This
work introduces FlowMM, an adaptive framework for cross-modal information
flow-guided multimodal KV cache merging. FlowMM leverages cross-modal
information flow to dynamically apply layer-specific merging strategies,
capturing modality-specific patterns while preserving contextual integrity.
Furthermore, we introduce a sensitivity-adaptive token matching mechanism that
jointly evaluates token similarity and task-critical sensitivity, merging
low-risk tokens while safeguarding high-sensitivity ones. Extensive experiments
across diverse leading MLLMs show that FlowMM reduces KV cache memory by 80% to
95% and decoding latency by 1.3-1.8x, while maintaining competitive task
performance.
\\ ( https://arxiv.org/abs/2511.05534 ,  553kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05535
Date: Wed, 29 Oct 2025 15:10:29 GMT   (158kb)

Title: Future of AI Models: A Computational perspective on Model collapse
Authors: Trivikram Satharasi (1), S Sitharama Iyengar (2) ((1) University of
 Florida, Gainesville, FL, (2) Florida International University, Miami. FL)
Categories: cs.CL cs.DB cs.IT math.IT
Comments: Submitted to Springer Nature. Code Available at
 https://github.com/t-satharasi/AI-Modal-Collapse-Code-for-Reproduction.git
ACM-class: I.2.0
\\
 Artificial Intelligence, especially Large Language Models (LLMs), has
transformed domains such as software engineering, journalism, creative writing,
academia, and media (Naveed et al. 2025; arXiv:2307.06435). Diffusion models
like Stable Diffusion generate high-quality images and videos from text.
Evidence shows rapid expansion: 74.2% of newly published webpages now contain
AI-generated material (Ryan Law 2025), 30-40% of the active web corpus is
synthetic (Spennemann 2025; arXiv:2504.08755), 52% of U.S. adults use LLMs for
writing, coding, or research (Staff 2025), and audits find AI involvement in
18% of financial complaints and 24% of press releases (Liang et al. 2025). The
underlying neural architectures, including Transformers (Vaswani et al. 2023;
arXiv:1706.03762), RNNs, LSTMs, GANs, and diffusion networks, depend on large,
diverse, human-authored datasets (Shi & Iyengar 2019). As synthetic content
dominates, recursive training risks eroding linguistic and semantic diversity,
producing Model Collapse (Shumailov et al. 2024; arXiv:2307.15043; Dohmatob et
al. 2024; arXiv:2402.07712). This study quantifies and forecasts collapse onset
by examining year-wise semantic similarity in English-language Wikipedia
(filtered Common Crawl) from 2013 to 2025 using Transformer embeddings and
cosine similarity metrics. Results reveal a steady rise in similarity before
public LLM adoption, likely driven by early RNN/LSTM translation and
text-normalization pipelines, though modest due to a smaller scale. Observed
fluctuations reflect irreducible linguistic diversity, variable corpus size
across years, finite sampling error, and an exponential rise in similarity
after the public adoption of LLM models. These findings provide a data-driven
estimate of when recursive AI contamination may significantly threaten data
richness and model generalization.
\\ ( https://arxiv.org/abs/2511.05535 ,  158kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05541
Date: Thu, 30 Oct 2025 17:59:30 GMT   (38462kb)

Title: Temporal Sparse Autoencoders: Leveraging the Sequential Nature of
 Language for Interpretability
Authors: Usha Bhalla, Alex Oesterling, Claudio Mayrink Verdun, Himabindu
 Lakkaraju, Flavio P. Calmon
Categories: cs.CL cs.AI cs.LG
Comments: 23 Pages, 10 figures
\\
 Translating the internal representations and computations of models into
concepts that humans can understand is a key goal of interpretability. While
recent dictionary learning methods such as Sparse Autoencoders (SAEs) provide a
promising route to discover human-interpretable features, they suffer from a
variety of problems, including a systematic failure to capture the rich
conceptual information that drives linguistic understanding. Instead, they
exhibit a bias towards shallow, token-specific, or noisy features, such as "the
phrase 'The' at the start of sentences". In this work, we propose that this is
due to a fundamental issue with how dictionary learning methods for LLMs are
trained. Language itself has a rich, well-studied structure spanning syntax,
semantics, and pragmatics; however, current unsupervised methods largely ignore
this linguistic knowledge, leading to poor feature discovery that favors
superficial patterns over meaningful concepts. We focus on a simple but
important aspect of language: semantic content has long-range dependencies and
tends to be smooth over a sequence, whereas syntactic information is much more
local. Building on this insight, we introduce Temporal Sparse Autoencoders
(T-SAEs), which incorporate a novel contrastive loss encouraging consistent
activations of high-level features over adjacent tokens. This simple yet
powerful modification enables SAEs to disentangle semantic from syntactic
features in a self-supervised manner. Across multiple datasets and models,
T-SAEs recover smoother, more coherent semantic concepts without sacrificing
reconstruction quality. Strikingly, they exhibit clear semantic structure
despite being trained without explicit semantic signal, offering a new pathway
for unsupervised interpretability in language models.
\\ ( https://arxiv.org/abs/2511.05541 ,  38462kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05560
Date: Tue, 4 Nov 2025 02:21:03 GMT   (7340kb)

Title: Sample-Efficient Language Modeling with Linear Attention and Lightweight
 Enhancements
Authors: Patrick Haller, Jonas Golde, Alan Akbik
Categories: cs.CL cs.AI
Journal-ref: Proceedings of the First BabyLM Workshop 2025, pages 175 to 191,
 Suzhou, China. Association for Computational Linguistics
\\
 We study architectural and optimization tech- niques for sample-efficient
language modeling under the constraints of the BabyLM 2025 shared task. Our
model, BLaLM, replaces self-attention with a linear-time mLSTM to- ken mixer
and explores lightweight enhance- ments, including short convolutions, sliding
window attention with dynamic modulation, and Hedgehog feature maps. To support
train- ing in low-resource settings, we curate a high- quality corpus
emphasizing readability and ped- agogical structure. Experiments across both
STRICT and STRICT-SMALL tracks show that (1) linear attention combined with
sliding win- dow attention consistently improves zero-shot performance, and (2)
the Muon optimizer stabi- lizes convergence and reduces perplexity over AdamW.
These results highlight effective strate- gies for efficient language modeling
without relying on scale.
\\ ( https://arxiv.org/abs/2511.05560 ,  7340kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05578
Date: Wed, 5 Nov 2025 00:08:01 GMT   (365kb)

Title: UTF-8 Plumbing: Byte-level Tokenizers Unavoidably Enable LLMs to
 Generate Ill-formed UTF-8
Authors: Preston Firestone, Shubham Ugare, Gagandeep Singh, Sasa Misailovic
Categories: cs.CL
Comments: COLM 2025
\\
 Subword tokenization segments input text according to a pre-defined
vocabulary to feed it into a language model; the language model, in turn,
generates a sequence made from this same vocabulary. The members of the
vocabulary can be built of code points or bytes. Using code points means that
all members of the vocabulary are valid UTF-8 characters. However, it also
requires thousands of initial members to achieve acceptable coverage of inputs.
Beginning with bytes, on the contrary, avoids out-of-vocabulary errors with
only 256 initial members of the vocabulary, but the members of the vocabulary
and sequences of them are not guaranteed to be valid UTF-8. Sequences that are
not valid UTF-8 break code that assumes its input to be valid UTF-8.
Applications of language models must account for the breakage thereby
introduced. In this paper, we formalize tokenization using monoid theory and
prove that tokenizers whose vocabularies contain tokens that are ill-formed
UTF-8 can always produce sequences that are ill-formed UTF-8. We demonstrate
formally that attempting to incrementally convert tokens back to a string and
interpret the results as UTF-8 gives different results than converting the
whole sequence of tokens at once. This formal result predicts real-world bugs:
we evaluate mitigations for the problem identified and provide case studies of
major foundation models, serving engines, and constrained generation systems.
\\ ( https://arxiv.org/abs/2511.05578 ,  365kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05650
Date: Fri, 7 Nov 2025 19:00:01 GMT   (2488kb)

Title: Optimizing Diversity and Quality through Base-Aligned Model
 Collaboration
Authors: Yichen Wang, Chenghao Yang, Tenghao Huang, Muhao Chen, Jonathan May,
 Mina Lee
Categories: cs.CL cs.AI cs.LG
Comments: 52 pages, 16 figures
\\
 Alignment has greatly improved large language models (LLMs)' output quality
at the cost of diversity, yielding highly similar outputs across generations.
We propose Base-Aligned Model Collaboration (BACo), an inference-time
token-level model collaboration framework that dynamically combines a base LLM
with its aligned counterpart to optimize diversity and quality. Inspired by
prior work (Fei et al., 2025), BACo employs routing strategies that determine,
at each token, from which model to decode based on next-token prediction
uncertainty and predicted contents' semantic role. Prior diversity-promoting
methods, such as retraining, prompt engineering, and multi-sampling methods,
improve diversity but often degrade quality or require costly decoding or
post-training. In contrast, BACo achieves both high diversity and quality post
hoc within a single pass, while offering strong controllability. We explore a
family of routing strategies, across three open-ended generation tasks and 13
metrics covering diversity and quality, BACo consistently surpasses
state-of-the-art inference-time baselines. With our best router, BACo achieves
a 21.3% joint improvement in diversity and quality. Human evaluations also
mirror these improvements. The results suggest that collaboration between base
and aligned models can optimize and control diversity and quality.
\\ ( https://arxiv.org/abs/2511.05650 ,  2488kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05722
Date: Fri, 7 Nov 2025 21:29:41 GMT   (100kb)

Title: OckBench: Measuring the Efficiency of LLM Reasoning
Authors: Zheng Du and Hao Kang and Song Han and Tushar Krishna and Ligeng Zhu
Categories: cs.CL cs.AI
\\
 Large language models such as GPT-4, Claude 3, and the Gemini series have
improved automated reasoning and code generation. However, existing benchmarks
mainly focus on accuracy and output quality, and they ignore an important
factor: decoding token efficiency. In real systems, generating 10,000 tokens
versus 100,000 tokens leads to large differences in latency, cost, and energy.
In this work, we introduce OckBench, a model-agnostic and hardware-agnostic
benchmark that evaluates both accuracy and token count for reasoning and coding
tasks. Through experiments comparing multiple open- and closed-source models,
we uncover that many models with comparable accuracy differ wildly in token
consumption, revealing that efficiency variance is a neglected but significant
axis of differentiation. We further demonstrate Pareto frontiers over the
accuracy-efficiency plane and argue for an evaluation paradigm shift: we should
no longer treat tokens as "free" to multiply. OckBench provides a unified
platform for measuring, comparing, and guiding research in token-efficient
reasoning. Our benchmarks are available at https://ockbench.github.io/ .
\\ ( https://arxiv.org/abs/2511.05722 ,  100kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05743
Date: Fri, 7 Nov 2025 22:11:11 GMT   (1489kb)

Title: In-Context Learning Without Copying
Authors: Kerem Sahin (1), Sheridan Feucht (1), Adam Belfki (1), Jannik
 Brinkmann (2), Aaron Mueller (3), David Bau (1), Chris Wendler (1) ((1)
 Northeastern University, (2) University of Mannheim, (3) Boston University)
Categories: cs.CL
\\
 Induction heads are attention heads that perform inductive copying by
matching patterns from earlier context and copying their continuations
verbatim. As models develop induction heads, they often experience a sharp drop
in training loss, a phenomenon cited as evidence that induction heads may serve
as a prerequisite for more complex in-context learning (ICL) capabilities. In
this work, we ask whether transformers can still acquire ICL capabilities when
inductive copying is suppressed. We propose Hapax, a setting where we omit the
loss contribution of any token that can be correctly predicted by induction
heads. Despite a significant reduction in inductive copying, performance on
abstractive ICL tasks (i.e., tasks where the answer is not contained in the
input context) remains comparable and surpasses the vanilla model on 13 of 21
tasks, even though 31.7\% of tokens are omitted from the loss. Furthermore, our
model achieves lower loss values on token positions that cannot be predicted
correctly by induction heads. Mechanistic analysis further shows that models
trained with Hapax develop fewer and weaker induction heads but still preserve
ICL capabilities. Taken together, our findings indicate that inductive copying
is not essential for learning abstractive ICL mechanisms.
\\ ( https://arxiv.org/abs/2511.05743 ,  1489kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05752
Date: Fri, 7 Nov 2025 22:54:26 GMT   (594kb)

Title: Multi-Scale Feature Fusion and Graph Neural Network Integration for Text
 Classification with Large Language Models
Authors: Xiangchen Song, Yulin Huang, Jinxu Guo, Yuchen Liu, Yaxuan Luan
Categories: cs.CL
\\
 This study investigates a hybrid method for text classification that
integrates deep feature extraction from large language models, multi-scale
fusion through feature pyramids, and structured modeling with graph neural
networks to enhance performance in complex semantic contexts. First, the large
language model captures contextual dependencies and deep semantic
representations of the input text, providing a rich feature foundation for
subsequent modeling. Then, based on multi-level feature representations, the
feature pyramid mechanism effectively integrates semantic features of different
scales, balancing global information and local details to construct
hierarchical semantic expressions. Furthermore, the fused features are
transformed into graph representations, and graph neural networks are employed
to capture latent semantic relations and logical dependencies in the text,
enabling comprehensive modeling of complex interactions among semantic units.
On this basis, the readout and classification modules generate the final
category predictions. The proposed method demonstrates significant advantages
in robustness alignment experiments, outperforming existing models on ACC,
F1-Score, AUC, and Precision, which verifies the effectiveness and stability of
the framework. This study not only constructs an integrated framework that
balances global and local information as well as semantics and structure, but
also provides a new perspective for multi-scale feature fusion and structured
semantic modeling in text classification tasks.
\\ ( https://arxiv.org/abs/2511.05752 ,  594kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05759
Date: Fri, 7 Nov 2025 23:06:48 GMT   (11kb)

Title: Language Generation: Complexity Barriers and Implications for Learning
Authors: Marcelo Arenas, Pablo Barcel\'o, Luis Cofr\'e, Alexander Kozachinskiy
Categories: cs.CL cs.AI cs.FL cs.LG
\\
 Kleinberg and Mullainathan showed that, in principle, language generation is
always possible: with sufficiently many positive examples, a learner can
eventually produce sentences indistinguishable from those of a target language.
However, the existence of such a guarantee does not speak to its practical
feasibility. In this work, we show that even for simple and well-studied
language families -- such as regular and context-free languages -- the number
of examples required for successful generation can be extraordinarily large,
and in some cases not bounded by any computable function. These results reveal
a substantial gap between theoretical possibility and efficient learnability.
They suggest that explaining the empirical success of modern language models
requires a refined perspective -- one that takes into account structural
properties of natural language that make effective generation possible in
practice.
\\ ( https://arxiv.org/abs/2511.05759 ,  11kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05784
Date: Sat, 8 Nov 2025 01:13:28 GMT   (1016kb)

Title: DRAGON: Guard LLM Unlearning in Context via Negative Detection and
 Reasoning
Authors: Yaxuan Wang, Chris Yuhao Liu, Quan Liu, Jinglong Pang, Wei Wei, Yujia
 Bao, Yang Liu
Categories: cs.CL cs.AI cs.LG
Comments: Please refer to the NeurIPS 2025 submission:
 https://openreview.net/forum?id=FNuul0hlin; The paper has been accepted to
 the ICML 2025 MUGen Workshop: https://openreview.net/forum?id=ET24oKP23c
\\
 Unlearning in Large Language Models (LLMs) is crucial for protecting private
data and removing harmful knowledge. Most existing approaches rely on
fine-tuning to balance unlearning efficiency with general language
capabilities. However, these methods typically require training or access to
retain data, which is often unavailable in real world scenarios. Although these
methods can perform well when both forget and retain data are available, few
works have demonstrated equivalent capability in more practical, data-limited
scenarios. To overcome these limitations, we propose Detect-Reasoning Augmented
GeneratiON (DRAGON), a systematic, reasoning-based framework that utilizes
in-context chain-of-thought (CoT) instructions to guard deployed LLMs before
inference. Instead of modifying the base model, DRAGON leverages the inherent
instruction-following ability of LLMs and introduces a lightweight detection
module to identify forget-worthy prompts without any retain data. These are
then routed through a dedicated CoT guard model to enforce safe and accurate
in-context intervention. To robustly evaluate unlearning performance, we
introduce novel metrics for unlearning performance and the continual unlearning
setting. Extensive experiments across three representative unlearning tasks
validate the effectiveness of DRAGON, demonstrating its strong unlearning
capability, scalability, and applicability in practical scenarios.
\\ ( https://arxiv.org/abs/2511.05784 ,  1016kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05852
Date: Sat, 8 Nov 2025 04:58:03 GMT   (3869kb)

Title: Quantifying Edits Decay in Fine-tuned LLMs
Authors: Yinjie Cheng, Paul Youssef, Christin Seifert, J\"org Schl\"otterer,
 Zhixue Zhao
Categories: cs.CL cs.AI
Comments: Under review at ICLR 2026
\\
 Knowledge editing has emerged as a lightweight alternative to retraining for
correcting or injecting specific facts in large language models (LLMs).
Meanwhile, fine-tuning remains the default operation for adapting LLMs to new
domains and tasks. Despite their widespread adoption, these two post-training
interventions have been studied in isolation, leaving open a crucial question:
if we fine-tune an edited model, do the edits survive? This question is
motivated by two practical scenarios: removing covert or malicious edits, and
preserving beneficial edits. If fine-tuning impairs edits as shown in Figure 1,
current KE methods become less useful, as every fine-tuned model would require
re-editing, which significantly increases the cost; if edits persist,
fine-tuned models risk propagating hidden malicious edits, raising serious
safety concerns. To this end, we systematically quantify edits decay after
fine-tuning, investigating how fine-tuning affects knowledge editing. We
evaluate two state-of-the-art editing methods (MEMIT, AlphaEdit) and three
fine-tuning approaches (full-parameter, LoRA, DoRA) across five LLMs and three
datasets, yielding 232 experimental configurations. Our results show that edits
decay after fine-tuning, with survival varying across configurations, e.g.,
AlphaEdit edits decay more than MEMIT edits. Further, we propose
selective-layer fine-tuning and find that fine-tuning edited layers only can
effectively remove edits, though at a slight cost to downstream performance.
Surprisingly, fine-tuning non-edited layers impairs more edits than full
fine-tuning. Overall, our study establishes empirical baselines and actionable
strategies for integrating knowledge editing with fine-tuning, and underscores
that evaluating model editing requires considering the full LLM application
pipeline.
\\ ( https://arxiv.org/abs/2511.05852 ,  3869kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05901
Date: Sat, 8 Nov 2025 07:52:47 GMT   (632kb)

Title: Retrieval-Augmented Generation in Medicine: A Scoping Review of
 Technical Implementations, Clinical Applications, and Ethical Considerations
Authors: Rui Yang, Matthew Yu Heng Wong, Huitao Li, Xin Li, Wentao Zhu, Jingchi
 Liao, Kunyu Yu, Jonathan Chong Kai Liew, Weihao Xuan, Yingjian Chen, Yuhe Ke,
 Jasmine Chiat Ling Ong, Douglas Teodoro, Chuan Hong, Daniel Shi Wei Ting, Nan
 Liu
Categories: cs.CL cs.AI
\\
 The rapid growth of medical knowledge and increasing complexity of clinical
practice pose challenges. In this context, large language models (LLMs) have
demonstrated value; however, inherent limitations remain. Retrieval-augmented
generation (RAG) technologies show potential to enhance their clinical
applicability. This study reviewed RAG applications in medicine. We found that
research primarily relied on publicly available data, with limited application
in private data. For retrieval, approaches commonly relied on English-centric
embedding models, while LLMs were mostly generic, with limited use of
medical-specific LLMs. For evaluation, automated metrics evaluated generation
quality and task performance, whereas human evaluation focused on accuracy,
completeness, relevance, and fluency, with insufficient attention to bias and
safety. RAG applications were concentrated on question answering, report
generation, text summarization, and information extraction. Overall, medical
RAG remains at an early stage, requiring advances in clinical validation,
cross-linguistic adaptation, and support for low-resource settings to enable
trustworthy and responsible global use.
\\ ( https://arxiv.org/abs/2511.05901 ,  632kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05913
Date: Sat, 8 Nov 2025 08:18:44 GMT   (487kb)

Title: NILC: Discovering New Intents with LLM-assisted Clustering
Authors: Hongtao Wang, Renchi Yang, Wenqing Lin
Categories: cs.CL cs.AI
\\
 New intent discovery (NID) seeks to recognize both new and known intents from
unlabeled user utterances, which finds prevalent use in practical dialogue
systems. Existing works towards NID mainly adopt a cascaded architecture,
wherein the first stage focuses on encoding the utterances into informative
text embeddings beforehand, while the latter is to group similar embeddings
into clusters (i.e., intents), typically by K-Means. However, such a cascaded
pipeline fails to leverage the feedback from both steps for mutual refinement,
and, meanwhile, the embedding-only clustering overlooks nuanced textual
semantics, leading to suboptimal performance. To bridge this gap, this paper
proposes NILC, a novel clustering framework specially catered for effective
NID. Particularly, NILC follows an iterative workflow, in which clustering
assignments are judiciously updated by carefully refining cluster centroids and
text embeddings of uncertain utterances with the aid of large language models
(LLMs). Specifically, NILC first taps into LLMs to create additional semantic
centroids for clusters, thereby enriching the contextual semantics of the
Euclidean centroids of embeddings. Moreover, LLMs are then harnessed to augment
hard samples (ambiguous or terse utterances) identified from clusters via
rewriting for subsequent cluster correction. Further, we inject supervision
signals through non-trivial techniques seeding and soft must links for more
accurate NID in the semi-supervised setting. Extensive experiments comparing
NILC against multiple recent baselines under both unsupervised and
semi-supervised settings showcase that NILC can achieve significant performance
improvements over six benchmark datasets of diverse domains consistently.
\\ ( https://arxiv.org/abs/2511.05913 ,  487kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05921
Date: Sat, 8 Nov 2025 08:32:59 GMT   (2853kb)

Title: IDALC: A Semi-Supervised Framework for Intent Detection and Active
 Learning based Correction
Authors: Ankan Mullick, Sukannya Purkayastha, Saransh Sharma, Pawan Goyal,
 Niloy Ganguly
Categories: cs.CL cs.AI
Comments: Paper accepted in IEEE Transactions on Artificial Intelligence
 (October 2025)
Journal-ref: IEEE Transactions on Artificial Intelligence, October 2025
\\
 Voice-controlled dialog systems have become immensely popular due to their
ability to perform a wide range of actions in response to diverse user queries.
These agents possess a predefined set of skills or intents to fulfill specific
user tasks. But every system has its own limitations. There are instances
where, even for known intents, if any model exhibits low confidence, it results
in rejection of utterances that necessitate manual annotation. Additionally, as
time progresses, there may be a need to retrain these agents with new intents
from the system-rejected queries to carry out additional tasks. Labeling all
these emerging intents and rejected utterances over time is impractical, thus
calling for an efficient mechanism to reduce annotation costs. In this paper,
we introduce IDALC (Intent Detection and Active Learning based Correction), a
semi-supervised framework designed to detect user intents and rectify
system-rejected utterances while minimizing the need for human annotation.
Empirical findings on various benchmark datasets demonstrate that our system
surpasses baseline methods, achieving a 5-10% higher accuracy and a 4-8%
improvement in macro-F1. Remarkably, we maintain the overall annotation cost at
just 6-10% of the unlabelled data available to the system. The overall
framework of IDALC is shown in Fig. 1
\\ ( https://arxiv.org/abs/2511.05921 ,  2853kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05933
Date: Sat, 8 Nov 2025 08:56:29 GMT   (31944kb)

Title: Reinforcement Learning Improves Traversal of Hierarchical Knowledge in
 LLMs
Authors: Renfei Zhang and Manasa Kaniselvan and Niloofar Mireshghallah
Categories: cs.CL cs.AI
Comments: `
\\
 Reinforcement learning (RL) is often credited with improving language model
reasoning and generalization at the expense of degrading memorized knowledge.
We challenge this narrative by observing that RL-enhanced models consistently
outperform their base and supervised fine-tuned (SFT) counterparts on pure
knowledge recall tasks, particularly those requiring traversal of hierarchical,
structured knowledge (e.g., medical codes). We hypothesize these gains stem not
from newly acquired data, but from improved procedural skills in navigating and
searching existing knowledge hierarchies within the model parameters. To
support this hypothesis, we show that structured prompting, which explicitly
guides SFTed models through hierarchical traversal, recovers most of the
performance gap (reducing 24pp to 7pp on MedConceptsQA for DeepSeek-V3/R1). We
further find that while prompting improves final-answer accuracy, RL-enhanced
models retain superior ability to recall correct procedural paths on
deep-retrieval tasks. Finally our layer-wise internal activation analysis
reveals that while factual representations (e.g., activations for the statement
"code 57.95 refers to urinary infection") maintain high cosine similarity
between SFT and RL models, query representations (e.g., "what is code 57.95")
diverge noticeably, indicating that RL primarily transforms how models traverse
knowledge rather than the knowledge representation itself.
\\ ( https://arxiv.org/abs/2511.05933 ,  31944kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05969
Date: Sat, 8 Nov 2025 11:13:29 GMT   (645kb)

Title: Interpretable Recognition of Cognitive Distortions in Natural Language
 Texts
Authors: Anton Kolonin, Anna Arinicheva
Categories: cs.CL cs.AI cs.CY cs.LG
Comments: 9 pages, 4 figures
\\
 We propose a new approach to multi-factor classification of natural language
texts based on weighted structured patterns such as N-grams, taking into
account the heterarchical relationships between them, applied to solve such a
socially impactful problem as the automation of detection of specific cognitive
distortions in psychological care, relying on an interpretable, robust and
transparent artificial intelligence model. The proposed recognition and
learning algorithms improve the current state of the art in this field. The
improvement is tested on two publicly available datasets, with significant
improvements over literature-known F1 scores for the task, with optimal
hyper-parameters determined, having code and models available for future use by
the community.
\\ ( https://arxiv.org/abs/2511.05969 ,  645kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05993
Date: Sat, 8 Nov 2025 12:50:41 GMT   (342kb)

Title: Revisiting Entropy in Reinforcement Learning for Large Reasoning Models
Authors: Renren Jin, Pengzhi Gao, Yuqi Ren, Zhuowen Han, Tongxuan Zhang, Wuwei
 Huang, Wei Liu, Jian Luan, Deyi Xiong
Categories: cs.CL cs.AI cs.LG
Comments: 16 pages, 11 figures, 3 tables
\\
 Reinforcement learning with verifiable rewards (RLVR) has emerged as a
predominant approach for enhancing the reasoning capabilities of large language
models (LLMs). However, the entropy of LLMs usually collapses during RLVR
training, causing premature convergence to suboptimal local minima and hinder
further performance improvement. Although various approaches have been proposed
to mitigate entropy collapse, a comprehensive study of entropy in RLVR remains
lacking. To address this gap, we conduct extensive experiments to investigate
the entropy dynamics of LLMs trained with RLVR and analyze how model entropy
correlates with response diversity, calibration, and performance across various
benchmarks. Our findings reveal that the number of off-policy updates, the
diversity of training data, and the clipping thresholds in the optimization
objective are critical factors influencing the entropy of LLMs trained with
RLVR. Moreover, we theoretically and empirically demonstrate that tokens with
positive advantages are the primary contributors to entropy collapse, and that
model entropy can be effectively regulated by adjusting the relative loss
weights of tokens with positive and negative advantages during training.
\\ ( https://arxiv.org/abs/2511.05993 ,  342kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06000
Date: Sat, 8 Nov 2025 13:12:36 GMT   (1339kb)

Title: LLMs Do Not See Age: Assessing Demographic Bias in Automated Systematic
 Review Synthesis
Authors: Favour Yahdii Aghaebe, Tanefa Apekey, Elizabeth Williams, Nafise Sadat
 Moosavi
Categories: cs.CL
Comments: Accepted at AACL 2025
\\
 Clinical interventions often hinge on age: medications and procedures safe
for adults may be harmful to children or ineffective for older adults. However,
as language models are increasingly integrated into biomedical evidence
synthesis workflows, it remains uncertain whether these systems preserve such
crucial demographic distinctions. To address this gap, we evaluate how well
state-of-the-art language models retain age-related information when generating
abstractive summaries of biomedical studies. We construct DemogSummary, a novel
age-stratified dataset of systematic review primary studies, covering child,
adult, and older adult populations. We evaluate three prominent
summarisation-capable LLMs, Qwen (open-source), Longformer (open-source) and
GPT-4.1 Nano (proprietary), using both standard metrics and a newly proposed
Demographic Salience Score (DSS), which quantifies age-related entity retention
and hallucination. Our results reveal systematic disparities across models and
age groups: demographic fidelity is lowest for adult-focused summaries, and
under-represented populations are more prone to hallucinations. These findings
highlight the limitations of current LLMs in faithful and bias-free
summarisation and point to the need for fairness-aware evaluation frameworks
and summarisation pipelines in biomedical NLP.
\\ ( https://arxiv.org/abs/2511.06000 ,  1339kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06023
Date: Sat, 8 Nov 2025 14:33:21 GMT   (86kb)

Title: Multi-Reward GRPO Fine-Tuning for De-biasing Large Language Models: A
 Study Based on Chinese-Context Discrimination Data
Authors: Deng Yixuan and Ji Xiaoqiang
Categories: cs.CL
\\
 Large Language Models (LLMs) often exhibit implicit biases and discriminatory
tendencies that reflect underlying social stereotypes. While recent alignment
techniques such as RLHF and DPO have mitigated some of these issues, they
remain limited in addressing culturally specific and multi-dimensional forms of
discrimination. This paper proposes a Multi-Reward Group Relative Policy
Optimization (GRPO) framework to fine-tune LLMs toward ethical and bias-free
behavior. Our approach constructs a synthetic English-language dataset derived
from Chinese-context discrimination categories, including regional, ethnic, and
occupational biases. Each instance is paired with both neutral and biased
responses to train a reward model based on DeBERTa-v3, which provides
multi-dimensional reward signals capturing fairness, neutrality, and linguistic
quality. The trained reward model then guides GRPO fine-tuning to optimize
model outputs along these ethical dimensions. Experimental results demonstrate
significant reductions in bias intensity and improved alignment with
non-discriminatory standards without compromising fluency or informativeness.
This study highlights the effectiveness of GRPO-based multi-reward optimization
for de-biasing LLMs and offers a replicable framework for cultural-contextual
ethical alignment.
\\ ( https://arxiv.org/abs/2511.06023 ,  86kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06048
Date: Sat, 8 Nov 2025 15:36:57 GMT   (5027kb)

Title: Visual Exploration of Feature Relationships in Sparse Autoencoders with
 Curated Concepts
Authors: Xinyuan Yan, Shusen Liu, Kowshik Thopalli, Bei Wang
Categories: cs.CL cs.LG
Comments: 8 pages (5 main paper+3 refernce), 2 figures, pulished at Mechanistic
 Interpretability Workshop at NeurIPS 2025
\\
 Sparse autoencoders (SAEs) have emerged as a powerful tool for uncovering
interpretable features in large language models (LLMs) through the sparse
directions they learn. However, the sheer number of extracted directions makes
comprehensive exploration intractable. While conventional embedding techniques
such as UMAP can reveal global structure, they suffer from limitations
including high-dimensional compression artifacts, overplotting, and misleading
neighborhood distortions. In this work, we propose a focused exploration
framework that prioritizes curated concepts and their corresponding SAE
features over attempts to visualize all available features simultaneously. We
present an interactive visualization system that combines topology-based visual
encoding with dimensionality reduction to faithfully represent both local and
global relationships among selected features. This hybrid approach enables
users to investigate SAE behavior through targeted, interpretable subsets,
facilitating deeper and more nuanced analysis of concept representation in
latent space.
\\ ( https://arxiv.org/abs/2511.06048 ,  5027kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06051
Date: Sat, 8 Nov 2025 15:47:18 GMT   (421kb)

Title: Efficient Hate Speech Detection: A Three-Layer LoRA-Tuned BERTweet
 Framework
Authors: Mahmoud El-Bahnasawi
Categories: cs.CL
Comments: 13 pages, 2 figures
\\
 This paper addresses the critical challenge of developing computationally
efficient hate speech detection systems that maintain competitive performance
while being practical for real-time deployment. We propose a novel three-layer
framework that combines rule-based pre-filtering with a parameter-efficient
LoRA-tuned BERTweet model and continuous learning capabilities. Our approach
achieves 0.85 macro F1 score - representing 94% of the performance of
state-of-the-art large language models like SafePhi (Phi-4 based) while using a
base model that is 100x smaller (134M vs 14B parameters). Compared to
traditional BERT-based approaches with similar computational requirements, our
method demonstrates superior performance through strategic dataset unification
and optimized fine-tuning. The system requires only 1.87M trainable parameters
(1.37% of full fine-tuning) and trains in approximately 2 hours on a single T4
GPU, making robust hate speech detection accessible in resource-constrained
environments while maintaining competitive accuracy for real-world deployment.
\\ ( https://arxiv.org/abs/2511.06051 ,  421kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06057
Date: Sat, 8 Nov 2025 15:56:24 GMT   (2609kb)

Title: ReMoD: Rethinking Modality Contribution in Multimodal Stance Detection
 via Dual Reasoning
Authors: Bingbing Wang, Zhengda Jin, Bin Liang, Jing Li, Ruifeng Xu
Categories: cs.CL cs.MM
\\
 Multimodal Stance Detection (MSD) is a crucial task for understanding public
opinion on social media. Existing work simply fuses information from various
modalities to learn stance representations, overlooking the varying
contributions of stance expression from different modalities. Therefore, stance
misunderstanding noises may be drawn into the stance learning process due to
the risk of learning errors by rough modality combination. To address this, we
get inspiration from the dual-process theory of human cognition and propose
**ReMoD**, a framework that **Re**thinks **Mo**dality contribution of stance
expression through a **D**ual-reasoning paradigm. ReMoD integrates
*experience-driven intuitive reasoning* to capture initial stance cues with
*deliberate reflective reasoning* to adjust for modality biases, refine stance
judgments, and thereby dynamically weight modality contributions based on their
actual expressive power for the target stance. Specifically, the intuitive
stage queries the Modality Experience Pool (MEP) and Semantic Experience Pool
(SEP) to form an initial stance hypothesis, prioritizing historically impactful
modalities. This hypothesis is then refined in the reflective stage via two
reasoning chains: Modality-CoT updates MEP with adaptive fusion strategies to
amplify relevant modalities, while Semantic-CoT refines SEP with deeper
contextual insights of stance semantics. These dual experience structures are
continuously refined during training and recalled at inference to guide robust
and context-aware stance decisions. Extensive experiments on the public MMSD
benchmark demonstrate that our ReMoD significantly outperforms most baseline
models and exhibits strong generalization capabilities.
\\ ( https://arxiv.org/abs/2511.06057 ,  2609kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06067
Date: Sat, 8 Nov 2025 16:36:55 GMT   (3322kb)

Title: Automating Hardware Design and Verification from Architectural Papers
 via a Neural-Symbolic Graph Framework
Authors: Haoyue Yang, Xuanle Zhao, Yujie Liu, Zhuojun Zou, Kailin Lyu,
 Changchun Zhou, Yao Zhu, Jie Hao
Categories: cs.CL cs.SE
Comments: Preprint Version, Work in Progress
\\
 The reproduction of hardware architectures from academic papers remains a
significant challenge due to the lack of publicly available source code and the
complexity of hardware description languages (HDLs). To this end, we propose
\textbf{ArchCraft}, a Framework that converts abstract architectural
descriptions from academic papers into synthesizable Verilog projects with
register-transfer level (RTL) verification. ArchCraft introduces a structured
workflow, which uses formal graphs to capture the Architectural Blueprint and
symbols to define the Functional Specification, translating unstructured
academic papers into verifiable, hardware-aware designs. The framework then
generates RTL and testbench (TB) code decoupled via these symbols to facilitate
verification and debugging, ultimately reporting the circuit's Power, Area, and
Performance (PPA). Moreover, we propose the first benchmark,
\textbf{ArchSynthBench}, for synthesizing hardware from architectural
descriptions, with a complete set of evaluation indicators, 50 project-level
circuits, and around 600 circuit blocks. We systematically assess ArchCraft on
ArchSynthBench, where the experiment results demonstrate the superiority of our
proposed method, surpassing direct generation methods and the VerilogCoder
framework in both paper understanding and code completion. Furthermore,
evaluation and physical implementation of the generated executable RTL code
show that these implementations meet all timing constraints without violations,
and their performance metrics are consistent with those reported in the
original papers.
\\ ( https://arxiv.org/abs/2511.06067 ,  3322kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06073
Date: Sat, 8 Nov 2025 17:07:57 GMT   (1072kb)

Title: Stemming Hallucination in Language Models Using a Licensing Oracle
Authors: Simeon Emanuilov and Richard Ackermann
Categories: cs.CL cs.AI cs.LG cs.LO
Comments: 23 pages, 4 figures, 8 tables. Introduces the Licensing Oracle, an
 architectural solution for eliminating hallucinations in language models
 through formal SHACL validation against knowledge graphs. All datasets and
 models are available at
 https://huggingface.co/collections/s-emanuilov/licensing-oracle-experiments
MSC-class: 68T50, 68T27, 03B70
ACM-class: I.2.7; I.2.4; H.3.3
\\
 Language models exhibit remarkable natural language generation capabilities
but remain prone to hallucinations, generating factually incorrect information
despite producing syntactically coherent responses. This study introduces the
Licensing Oracle, an architectural solution designed to stem hallucinations in
LMs by enforcing truth constraints through formal validation against structured
knowledge graphs. Unlike statistical approaches that rely on data scaling or
fine-tuning, the Licensing Oracle embeds a deterministic validation step into
the model's generative process, ensuring that only factually accurate claims
are made. We evaluated the effectiveness of the Licensing Oracle through
experiments comparing it with several state-of-the-art methods, including
baseline language model generation, fine-tuning for factual recall, fine-tuning
for abstention behavior, and retrieval-augmented generation (RAG). Our results
demonstrate that although RAG and fine-tuning improve performance, they fail to
eliminate hallucinations. In contrast, the Licensing Oracle achieved perfect
abstention precision (AP = 1.0) and zero false answers (FAR-NE = 0.0), ensuring
that only valid claims were generated with 89.1% accuracy in factual responses.
This work shows that architectural innovations, such as the Licensing Oracle,
offer a necessary and sufficient solution for hallucinations in domains with
structured knowledge representations, offering guarantees that statistical
methods cannot match. Although the Licensing Oracle is specifically designed to
address hallucinations in fact-based domains, its framework lays the groundwork
for truth-constrained generation in future AI systems, providing a new path
toward reliable, epistemically grounded models.
\\ ( https://arxiv.org/abs/2511.06073 ,  1072kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06086
Date: Sat, 8 Nov 2025 17:45:20 GMT   (2621kb)

Title: MuonAll: Muon Variant for Efficient Finetuning of Large Language Models
Authors: Saurabh Page, Advait Joshi, S. S. Sonawane
Categories: cs.CL cs.LG
\\
 Muon optimizer has demonstrated robust results in pretraining of language
models but its performance in finetuning of existing public pretrained models
is not yet explored. Currently, Muon is used along with AdamW introducing a
scope of improvement for adopting all parameters inside Muon. We introduce
MuonAll, which incorporates all the parameters inside Muon by transforming into
2D matrices. We conduct extensive finetuning experiments across publicly
available language models with model sizes upto half billion parameters. Muon
and MuonAll perform at par with AdamW across major benchmarks, highlighting
their effectiveness as alternative optimizers. We open-source the distributed
implementations of Muon and MuonAll, available at
https://github.com/Saurabh750/optimizer
\\ ( https://arxiv.org/abs/2511.06086 ,  2621kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06125
Date: Sat, 8 Nov 2025 20:30:45 GMT   (74kb)

Title: Evaluation of retrieval-based QA on QUEST-LOFT
Authors: Nathan Scales, Nathanael Sch\"arli, Olivier Bousquet
Categories: cs.CL cs.AI cs.IR
\\
 Despite the popularity of retrieval-augmented generation (RAG) as a solution
for grounded QA in both academia and industry, current RAG methods struggle
with questions where the necessary information is distributed across many
documents or where retrieval needs to be combined with complex reasoning.
Recently, the LOFT study has shown that this limitation also applies to
approaches based on long-context language models, with the QUEST benchmark
exhibiting particularly large headroom. In this paper, we provide an in-depth
analysis of the factors contributing to the poor performance on QUEST-LOFT,
publish updated numbers based on a thorough human evaluation, and demonstrate
that RAG can be optimized to significantly outperform long-context approaches
when combined with a structured output format containing reasoning and
evidence, optionally followed by answer re-verification.
\\ ( https://arxiv.org/abs/2511.06125 ,  74kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06146
Date: Sat, 8 Nov 2025 21:43:09 GMT   (561kb)

Title: Referring Expressions as a Lens into Spatial Language Grounding in
 Vision-Language Models
Authors: Akshar Tumu, Varad Shinde, Parisa Kordjamshidi
Categories: cs.CL cs.AI cs.CV
Comments: Accepted at IJCNLP-AACL 2025
\\
 Spatial Reasoning is an important component of human cognition and is an area
in which the latest Vision-language models (VLMs) show signs of difficulty. The
current analysis works use image captioning tasks and visual question
answering. In this work, we propose using the Referring Expression
Comprehension task instead as a platform for the evaluation of spatial
reasoning by VLMs. This platform provides the opportunity for a deeper analysis
of spatial comprehension and grounding abilities when there is 1) ambiguity in
object detection, 2) complex spatial expressions with a longer sentence
structure and multiple spatial relations, and 3) expressions with negation
('not'). In our analysis, we use task-specific architectures as well as large
VLMs and highlight their strengths and weaknesses in dealing with these
specific situations. While all these models face challenges with the task at
hand, the relative behaviors depend on the underlying models and the specific
categories of spatial semantics (topological, directional, proximal, etc.). Our
results highlight these challenges and behaviors and provide insight into
research gaps and future directions.
\\ ( https://arxiv.org/abs/2511.06146 ,  561kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06183
Date: Sun, 9 Nov 2025 01:54:53 GMT   (6919kb)

Title: BookAsSumQA: An Evaluation Framework for Aspect-Based Book Summarization
 via Question Answering
Authors: Ryuhei Miyazato, Ting-Ruen Wei, Xuyang Wu, Hsin-Tai Wu, Kei Harada
Categories: cs.CL
\\
 Aspect-based summarization aims to generate summaries that highlight specific
aspects of a text, enabling more personalized and targeted summaries. However,
its application to books remains unexplored due to the difficulty of
constructing reference summaries for long text. To address this challenge, we
propose BookAsSumQA, a QA-based evaluation framework for aspect-based book
summarization. BookAsSumQA automatically generates aspect-specific QA pairs
from a narrative knowledge graph to evaluate summary quality based on its
question-answering performance. Our experiments using BookAsSumQA revealed that
while LLM-based approaches showed higher accuracy on shorter texts, RAG-based
methods become more effective as document length increases, making them more
efficient and practical for aspect-based book summarization.
\\ ( https://arxiv.org/abs/2511.06183 ,  6919kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06190
Date: Sun, 9 Nov 2025 02:33:08 GMT   (146kb)

Title: Confidence-Guided Stepwise Model Routing for Cost-Efficient Reasoning
Authors: Sangmook Lee, Dohyung Kim, Hyukhun Koh, Nakyeong Yang, Kyomin Jung
Categories: cs.CL
Comments: 7 pages, 5 figures
\\
 Recent advances in Large Language Models (LLMs) - particularly model scaling
and test-time techniques - have greatly enhanced the reasoning capabilities of
language models at the expense of higher inference costs. To lower inference
costs, prior works train router models or deferral mechanisms that allocate
easy queries to a small, efficient model, while forwarding harder queries to
larger, more expensive models. However, these trained router models often lack
robustness under domain shifts and require expensive data synthesis techniques
such as Monte Carlo rollouts to obtain sufficient ground-truth routing labels
for training. In this work, we propose Confidence-Guided Stepwise Model Routing
for Cost-Efficient Reasoning (STEER), a domain-agnostic framework that performs
fine-grained, step-level routing between smaller and larger LLMs without
utilizing external models. STEER leverages confidence scores from the smaller
model's logits prior to generating a reasoning step, so that the large model is
invoked only when necessary. Extensive evaluations using different LLMs on a
diverse set of challenging benchmarks across multiple domains such as
Mathematical Reasoning, Multi-Hop QA, and Planning tasks indicate that STEER
achieves competitive or enhanced accuracy while reducing inference costs (up to
+20% accuracy with 48% less FLOPs compared to solely using the larger model on
AIME), outperforming baselines that rely on trained external modules. Our
results establish model-internal confidence as a robust, domain-agnostic signal
for model routing, offering a scalable pathway for efficient LLM deployment.
\\ ( https://arxiv.org/abs/2511.06190 ,  146kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06215
Date: Sun, 9 Nov 2025 04:01:45 GMT   (843kb)

Title: Explicit Knowledge-Guided In-Context Learning for Early Detection of
 Alzheimer's Disease
Authors: Puzhen Su, Yongzhu Miao, Chunxi Guo, Jintao Tang, Shasha Li, Ting Wang
Categories: cs.CL cs.AI
Comments: This paper was accepted by IEEE BIBM 2025 conference
\\
 Detecting Alzheimer's Disease (AD) from narrative transcripts remains a
challenging task for large language models (LLMs), particularly under
out-of-distribution (OOD) and data-scarce conditions. While in-context learning
(ICL) provides a parameter-efficient alternative to fine-tuning, existing ICL
approaches often suffer from task recognition failure, suboptimal demonstration
selection, and misalignment between label words and task objectives, issues
that are amplified in clinical domains like AD detection. We propose Explicit
Knowledge In-Context Learners (EK-ICL), a novel framework that integrates
structured explicit knowledge to enhance reasoning stability and task alignment
in ICL. EK-ICL incorporates three knowledge components: confidence scores
derived from small language models (SLMs) to ground predictions in
task-relevant patterns, parsing feature scores to capture structural
differences and improve demo selection, and label word replacement to resolve
semantic misalignment with LLM priors. In addition, EK-ICL employs a
parsing-based retrieval strategy and ensemble prediction to mitigate the
effects of semantic homogeneity in AD transcripts. Extensive experiments across
three AD datasets demonstrate that EK-ICL significantly outperforms
state-of-the-art fine-tuning and ICL baselines. Further analysis reveals that
ICL performance in AD detection is highly sensitive to the alignment of label
semantics and task-specific context, underscoring the importance of explicit
knowledge in clinical reasoning under low-resource conditions.
\\ ( https://arxiv.org/abs/2511.06215 ,  843kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06222
Date: Sun, 9 Nov 2025 04:43:32 GMT   (1561kb)

Title: SPA: Achieving Consensus in LLM Alignment via Self-Priority Optimization
Authors: Yue Huang, Xiangqi Wang, Xiangliang Zhang
Categories: cs.CL cs.CY
Comments: Accepted by AAAI 2026 (Oral)
\\
 In high-stakes scenarios-such as self-harm, legal, or medical queries-LLMs
must be both trustworthy and helpful. However, these goals often conflict. We
propose priority alignment, a new alignment paradigm that enforces a strict
"trustworthy-before-helpful" ordering: optimization of helpfulness is
conditioned on first meeting trustworthy thresholds (e.g., harmlessness or
honesty). To realize this, we introduce Self-Priority Alignment (SPA)-a fully
unsupervised framework that generates diverse responses, self-evaluates them
and refines them by the model itself, and applies dual-criterion denoising to
remove inconsistency and control variance. From this, SPA constructs
lexicographically ordered preference pairs and fine-tunes the model using an
uncertainty-weighted alignment loss that emphasizes high-confidence, high-gap
decisions. Experiments across multiple benchmarks show that SPA improves
helpfulness without compromising safety, outperforming strong baselines while
preserving general capabilities. Our results demonstrate that SPA provides a
scalable and interpretable alignment strategy for critical LLM applications.
\\ ( https://arxiv.org/abs/2511.06222 ,  1561kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06230
Date: Sun, 9 Nov 2025 05:11:27 GMT   (612kb)

Title: Overview of CHIP 2025 Shared Task 2: Discharge Medication Recommendation
 for Metabolic Diseases Based on Chinese Electronic Health Records
Authors: Juntao Li, Haobin Yuan, Ling Luo, Tengxiao Lv, Yan Jiang, Fan Wang,
 Ping Zhang, Huiyi Lv, Jian Wang, Yuanyuan Sun, Hongfei Lin
Categories: cs.CL cs.AI
\\
 Discharge medication recommendation plays a critical role in ensuring
treatment continuity, preventing readmission, and improving long-term
management for patients with chronic metabolic diseases. This paper present an
overview of the CHIP 2025 Shared Task 2 competition, which aimed to develop
state-of-the-art approaches for automatically recommending appro-priate
discharge medications using real-world Chinese EHR data. For this task, we
constructed CDrugRed, a high-quality dataset consisting of 5,894 de-identified
hospitalization records from 3,190 patients in China. This task is challenging
due to multi-label nature of medication recommendation, het-erogeneous clinical
text, and patient-specific variability in treatment plans. A total of 526 teams
registered, with 167 and 95 teams submitting valid results to the Phase A and
Phase B leaderboards, respectively. The top-performing team achieved the
highest overall performance on the final test set, with a Jaccard score of
0.5102, F1 score of 0.6267, demonstrating the potential of advanced large
language model (LLM)-based ensemble systems. These re-sults highlight both the
promise and remaining challenges of applying LLMs to medication recommendation
in Chinese EHRs. The post-evaluation phase remains open at
https://tianchi.aliyun.com/competition/entrance/532411/.
\\ ( https://arxiv.org/abs/2511.06230 ,  612kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06234
Date: Sun, 9 Nov 2025 05:25:46 GMT   (314kb)

Title: Analyzing and Mitigating Negation Artifacts using Data Augmentation for
 Improving ELECTRA-Small Model Accuracy
Authors: Mojtaba Noghabaei
Categories: cs.CL cs.AI
\\
 Pre-trained models for natural language inference (NLI) often achieve high
performance on benchmark datasets by using spurious correlations, or dataset
artifacts, rather than understanding language touches such as negation. In this
project, we investigate the performance of an ELECTRA-small model fine-tuned on
the Stanford Natural Language Inference (SNLI) dataset, focusing on its
handling of negation. Through analysis, we identify that the model struggles
with correctly classifying examples containing negation. To address this, we
augment the training data with contrast sets and adversarial examples
emphasizing negation. Our results demonstrate that this targeted data
augmentation improves the model's accuracy on negation-containing examples
without adversely affecting overall performance, therefore mitigating the
identified dataset artifact.
\\ ( https://arxiv.org/abs/2511.06234 ,  314kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06344
Date: Sun, 9 Nov 2025 12:00:18 GMT   (2060kb)

Title: TimeSense:Making Large Language Models Proficient in Time-Series
 Analysis
Authors: Zhirui Zhang, Changhua Pei, Tianyi Gao, Zhe Xie, Yibo Hao, Zhaoyang
 Yu, Longlong Xu, Tong Xiao, Jing Han, Dan Pei
Categories: cs.CL cs.AI
\\
 In the time-series domain, an increasing number of works combine text with
temporal data to leverage the reasoning capabilities of large language models
(LLMs) for various downstream time-series understanding tasks. This enables a
single model to flexibly perform tasks that previously required specialized
models for each domain. However, these methods typically rely on text labels
for supervision during training, biasing the model toward textual cues while
potentially neglecting the full temporal features. Such a bias can lead to
outputs that contradict the underlying time-series context. To address this
issue, we construct the EvalTS benchmark, comprising 10 tasks across three
difficulty levels, from fundamental temporal pattern recognition to complex
real-world reasoning, to evaluate models under more challenging and realistic
scenarios. We also propose TimeSense, a multimodal framework that makes LLMs
proficient in time-series analysis by balancing textual reasoning with a
preserved temporal sense. TimeSense incorporates a Temporal Sense module that
reconstructs the input time-series within the model's context, ensuring that
textual reasoning is grounded in the time-series dynamics. Moreover, to enhance
spatial understanding of time-series data, we explicitly incorporate
coordinate-based positional embeddings, which provide each time point with
spatial context and enable the model to capture structural dependencies more
effectively. Experimental results demonstrate that TimeSense achieves
state-of-the-art performance across multiple tasks, and it particularly
outperforms existing methods on complex multi-dimensional time-series reasoning
tasks.
\\ ( https://arxiv.org/abs/2511.06344 ,  2060kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06391
Date: Sun, 9 Nov 2025 14:01:26 GMT   (158kb)

Title: HatePrototypes: Interpretable and Transferable Representations for
 Implicit and Explicit Hate Speech Detection
Authors: Irina Proskurina, Marc-Antoine Carpentier, Julien Velcin
Categories: cs.CL cs.AI
\\
 Optimization of offensive content moderation models for different types of
hateful messages is typically achieved through continued pre-training or
fine-tuning on new hate speech benchmarks. However, existing benchmarks mainly
address explicit hate toward protected groups and often overlook implicit or
indirect hate, such as demeaning comparisons, calls for exclusion or violence,
and subtle discriminatory language that still causes harm. While explicit hate
can often be captured through surface features, implicit hate requires deeper,
full-model semantic processing. In this work, we question the need for repeated
fine-tuning and analyze the role of HatePrototypes, class-level vector
representations derived from language models optimized for hate speech
detection and safety moderation. We find that these prototypes, built from as
few as 50 examples per class, enable cross-task transfer between explicit and
implicit hate, with interchangeable prototypes across benchmarks. Moreover, we
show that parameter-free early exiting with prototypes is effective for both
hate types. We release the code, prototype resources, and evaluation scripts to
support future research on efficient and transferable hate speech detection.
\\ ( https://arxiv.org/abs/2511.06391 ,  158kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06402
Date: Sun, 9 Nov 2025 14:24:05 GMT   (28kb)

Title: SugarTextNet: A Transformer-Based Framework for Detecting Sugar
 Dating-Related Content on Social Media with Context-Aware Focal Loss
Authors: Lionel Z. Wang, Shihan Ben, Yulu Huang, Simeng Qing
Categories: cs.CL cs.CY cs.SI
Comments: This paper is accepted by HICSS 2026
\\
 Sugar dating-related content has rapidly proliferated on mainstream social
media platforms, giving rise to serious societal and regulatory concerns,
including commercialization of intimate relationships and the normalization of
transactional relationships.~Detecting such content is highly challenging due
to the prevalence of subtle euphemisms, ambiguous linguistic cues, and extreme
class imbalance in real-world data.~In this work, we present SugarTextNet, a
novel transformer-based framework specifically designed to identify sugar
dating-related posts on social media.~SugarTextNet integrates a pretrained
transformer encoder, an attention-based cue extractor, and a contextual phrase
encoder to capture both salient and nuanced features in user-generated text.~To
address class imbalance and enhance minority-class detection, we introduce
Context-Aware Focal Loss, a tailored loss function that combines focal loss
scaling with contextual weighting.~We evaluate SugarTextNet on a newly curated,
manually annotated dataset of 3,067 Chinese social media posts from Sina Weibo,
demonstrating that our approach substantially outperforms traditional machine
learning models, deep learning baselines, and large language models across
multiple metrics.~Comprehensive ablation studies confirm the indispensable role
of each component.~Our findings highlight the importance of domain-specific,
context-aware modeling for sensitive content detection, and provide a robust
solution for content moderation in complex, real-world scenarios.
\\ ( https://arxiv.org/abs/2511.06402 ,  28kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06418
Date: Sun, 9 Nov 2025 15:15:19 GMT   (602kb)

Title: How Well Do LLMs Understand Drug Mechanisms? A Knowledge + Reasoning
 Evaluation Dataset
Authors: Sunil Mohan and Theofanis Karaletsos
Categories: cs.CL
Comments: An earlier version of this paper appears in IEEE FLLM 2025. GitHub:
 https://github.com/czi-ai/DrugMechCounterfactuals
\\
 Two scientific fields showing increasing interest in pre-trained large
language models (LLMs) are drug development / repurposing, and personalized
medicine. For both, LLMs have to demonstrate factual knowledge as well as a
deep understanding of drug mechanisms, so they can recall and reason about
relevant knowledge in novel situations. Drug mechanisms of action are described
as a series of interactions between biomedical entities, which interlink into
one or more chains directed from the drug to the targeted disease. Composing
the effects of the interactions in a candidate chain leads to an inference
about whether the drug might be useful or not for that disease. We introduce a
dataset that evaluates LLMs on both factual knowledge of known mechanisms, and
their ability to reason about them under novel situations, presented as
counterfactuals that the models are unlikely to have seen during training.
Using this dataset, we show that o4-mini outperforms the 4o, o3, and o3-mini
models from OpenAI, and the recent small Qwen3-4B-thinking model closely
matches o4-mini's performance, even outperforming it in some cases. We
demonstrate that the open world setting for reasoning tasks, which requires the
model to recall relevant knowledge, is more challenging than the closed world
setting where the needed factual knowledge is provided. We also show that
counterfactuals affecting internal links in the reasoning chain present a much
harder task than those affecting a link from the drug mentioned in the prompt.
\\ ( https://arxiv.org/abs/2511.06418 ,  602kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06427
Date: Sun, 9 Nov 2025 15:49:47 GMT   (363kb)

Title: Dutch Metaphor Extraction from Cancer Patients' Interviews and Forum
 Data using LLMs and Human in the Loop
Authors: Lifeng Han, David Lindevelt, Sander Puts, Erik van Mulligen, Suzan
 Verberne
Categories: cs.CL cs.CY
Comments: Ongoing project report, on behalf of 4D PICTURE https://4dpicture.eu/
\\
 Metaphors and metaphorical language (MLs) play an important role in
healthcare communication between clinicians, patients, and patients' family
members. In this work, we focus on Dutch language data from cancer patients. We
extract metaphors used by patients using two data sources: (1) cancer patient
storytelling interview data and (2) online forum data, including patients'
posts, comments, and questions to professionals. We investigate how current
state-of-the-art large language models (LLMs) perform on this task by exploring
different prompting strategies such as chain of thought reasoning, few-shot
learning, and self-prompting. With a human-in-the-loop setup, we verify the
extracted metaphors and compile the outputs into a corpus named HealthQuote.NL.
We believe the extracted metaphors can support better patient care, for example
shared decision making, improved communication between patients and clinicians,
and enhanced patient health literacy. They can also inform the design of
personalized care pathways. We share prompts and related resources at
https://github.com/aaronlifenghan/HealthQuote.NL
\\ ( https://arxiv.org/abs/2511.06427 ,  363kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06441
Date: Sun, 9 Nov 2025 16:14:56 GMT   (2565kb)

Title: Towards Resource-Efficient Multimodal Intelligence: Learned Routing
 among Specialized Expert Models
Authors: Mayank Saini, Arit Kumar Bishwas
Categories: cs.CL cs.LG
Comments: 15 pages, 4 figures
ACM-class: I.2.7; I.2.6; I.2.11
\\
 As AI moves beyond text, large language models (LLMs) increasingly power
vision, audio, and document understanding; however, their high inference costs
hinder real-time, scalable deployment. Conversely, smaller open-source models
offer cost advantages but struggle with complex or multimodal queries. We
introduce a unified, modular framework that intelligently routes each query -
textual, multimodal, or complex - to the most fitting expert model, using a
learned routing network that balances cost and quality. For vision tasks, we
employ a two-stage open-source pipeline optimized for efficiency and reviving
efficient classical vision components where they remain SOTA for sub-tasks. On
benchmarks such as Massive Multitask Language Understanding (MMLU) and Visual
Question Answering (VQA), we match or exceed the performance of always-premium
LLM (monolithic systems with one model serving all query types) performance,
yet reduce the reliance on costly models by over 67%. With its extensible,
multi-agent orchestration, we deliver high-quality, resource-efficient AI at
scale.
\\ ( https://arxiv.org/abs/2511.06441 ,  2565kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06446
Date: Sun, 9 Nov 2025 16:27:55 GMT   (2029kb)

Title: SR-KI: Scalable and Real-Time Knowledge Integration into LLMs via
 Supervised Attention
Authors: Bohan Yu, Wei Huang, Kang Liu
Categories: cs.CL cs.AI
Comments: Accepted by AAAI 2026
\\
 This paper proposes SR-KI, a novel approach for integrating real-time and
large-scale structured knowledge bases (KBs) into large language models (LLMs).
SR-KI begins by encoding KBs into key-value pairs using a pretrained encoder,
and injects them into LLMs' KV cache. Building on this representation, we
employ a two-stage training paradigm: first locating a dedicated retrieval
layer within the LLM, and then applying an attention-based loss at this layer
to explicitly supervise attention toward relevant KB entries. Unlike
traditional retrieval-augmented generation methods that rely heavily on the
performance of external retrievers and multi-stage pipelines, SR-KI supports
end-to-end inference by performing retrieval entirely within the models latent
space. This design enables efficient compression of injected knowledge and
facilitates dynamic knowledge updates. Comprehensive experiments demonstrate
that SR-KI enables the integration of up to 40K KBs into a 7B LLM on a single
A100 40GB GPU, and achieves strong retrieval performance, maintaining over 98%
Recall@10 on the best-performing task and exceeding 88% on average across all
tasks. Task performance on question answering and KB ID generation also
demonstrates that SR-KI maintains strong performance while achieving up to
99.75% compression of the injected KBs.
\\ ( https://arxiv.org/abs/2511.06446 ,  2029kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06497
Date: Sun, 9 Nov 2025 18:54:17 GMT   (2411kb)

Title: Rethinking what Matters: Effective and Robust Multilingual Realignment
 for Low-Resource Languages
Authors: Quang Phuoc Nguyen, David Anugraha, Felix Gaschi, Jun Bin Cheng,
 En-Shiun Annie Lee
Categories: cs.CL cs.AI
Comments: Accepted to IJCNLP-AACL 2025
\\
 Realignment is a promising strategy to improve cross-lingual transfer in
multilingual language models. However, empirical results are mixed and often
unreliable, particularly for typologically distant or low-resource languages
(LRLs) compared to English. Moreover, word realignment tools often rely on
high-quality parallel data, which can be scarce or noisy for many LRLs. In this
work, we conduct an extensive empirical study to investigate whether
realignment truly benefits from using all available languages, or if
strategically selected subsets can offer comparable or even improved
cross-lingual transfer, and study the impact on LRLs. Our controlled
experiments show that realignment can be particularly effective for LRLs and
that using carefully selected, linguistically diverse subsets can match full
multilingual alignment, and even outperform it for unseen LRLs. This indicates
that effective realignment does not require exhaustive language coverage and
can reduce data collection overhead, while remaining both efficient and robust
when guided by informed language selection.
\\ ( https://arxiv.org/abs/2511.06497 ,  2411kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06516
Date: Sun, 9 Nov 2025 19:58:24 GMT   (180kb)

Title: You Had One Job: Per-Task Quantization Using LLMs' Hidden
 Representations
Authors: Amit LeVi, Raz Lapid, Rom Himelstein, Yaniv Nemcovsky, Ravid Shwartz
 Ziv, Avi Mendelson
Categories: cs.CL
\\
 Large Language Models (LLMs) excel across diverse tasks, yet many
applications require only limited capabilities, making large variants
inefficient in memory and latency. Existing approaches often combine
distillation and quantization, but most post-training quantization (PTQ)
methods are task-agnostic, ignoring how task-specific signals are distributed
across layers. In this work, we propose to use hidden representations that
encode task-salient signals as a guideline for quantization. In order to fully
utilize our innovative idea, this paper compares two new task-aware PTQ
methods: Task-Aware Quantization (TAQ), which allocates bitwidths using
task-conditioned statistics from hidden activations, and TAQO, which allocates
precision based on direct layer sensitivity tests. From a small calibration
set, these approaches identify task-relevant layers, preserving their precision
while aggressively quantizing the rest. This yields stable task sensitivity
profiles and efficient task-specialized models. Across models, TAQ and TAQO
outperform the baselines; TAQ leads on Phi-4, while TAQO leads on Llama-3.1,
Qwen3, and Qwen2.5. For instances, on Phi-4 it achieves 42.33 EM / 50.81 F1,
far surpassing Activation-aware Weight Quantization (AWQ) (2.25 / 7.07), while
remaining within < 1.0% of the original accuracy at lower average precision.
\\ ( https://arxiv.org/abs/2511.06516 ,  180kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06530
Date: Sun, 9 Nov 2025 20:32:35 GMT   (473kb)

Title: Better Datasets Start From RefineLab: Automatic Optimization for
 High-Quality Dataset Refinement
Authors: Xiaonan Luo, Yue Huang, Ping He, Xiangliang Zhang
Categories: cs.CL
\\
 High-quality Question-Answer (QA) datasets are foundational for reliable
Large Language Model (LLM) evaluation, yet even expert-crafted datasets exhibit
persistent gaps in domain coverage, misaligned difficulty distributions, and
factual inconsistencies. The recent surge in generative model-powered datasets
has compounded these quality challenges. In this work, we introduce RefineLab,
the first LLM-driven framework that automatically refines raw QA textual data
into high-quality datasets under a controllable token-budget constraint.
RefineLab takes a set of target quality attributes (such as coverage and
difficulty balance) as refinement objectives, and performs selective edits
within a predefined token budget to ensure practicality and efficiency. In
essence, RefineLab addresses a constrained optimization problem: improving the
quality of QA samples as much as possible while respecting resource
limitations. With a set of available refinement operations (e.g., rephrasing,
distractor replacement), RefineLab takes as input the original dataset, a
specified set of target quality dimensions, and a token budget, and determines
which refinement operations should be applied to each QA sample. This process
is guided by an assignment module that selects optimal refinement strategies to
maximize overall dataset quality while adhering to the budget constraint.
Experiments demonstrate that RefineLab consistently narrows divergence from
expert datasets across coverage, difficulty alignment, factual fidelity, and
distractor quality. RefineLab pioneers a scalable, customizable path to
reproducible dataset design, with broad implications for LLM evaluation.
\\ ( https://arxiv.org/abs/2511.06530 ,  473kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06531
Date: Sun, 9 Nov 2025 20:33:39 GMT   (491kb)

Title: Ibom NLP: A Step Toward Inclusive Natural Language Processing for
 Nigeria's Minority Languages
Authors: Oluwadara Kalejaiye, Luel Hagos Beyene, David Ifeoluwa Adelani,
 Mmekut-Mfon Gabriel Edet, Aniefon Daniel Akpan, Eno-Abasi Urua, Anietie Andy
Categories: cs.CL cs.AI
Comments: Accepted at IJCNLP-AACL
\\
 Nigeria is the most populous country in Africa with a population of more than
200 million people. More than 500 languages are spoken in Nigeria and it is one
of the most linguistically diverse countries in the world. Despite this,
natural language processing (NLP) research has mostly focused on the following
four languages: Hausa, Igbo, Nigerian-Pidgin, and Yoruba (i.e <1% of the
languages spoken in Nigeria). This is in part due to the unavailability of
textual data in these languages to train and apply NLP algorithms. In this
work, we introduce ibom -- a dataset for machine translation and topic
classification in four Coastal Nigerian languages from the Akwa Ibom State
region: Anaang, Efik, Ibibio, and Oro. These languages are not represented in
Google Translate or in major benchmarks such as Flores-200 or SIB-200. We focus
on extending Flores-200 benchmark to these languages, and further align the
translated texts with topic labels based on SIB-200 classification dataset. Our
evaluation shows that current LLMs perform poorly on machine translation for
these languages in both zero-and-few shot settings. However, we find the
few-shot samples to steadily improve topic classification with more shots.
\\ ( https://arxiv.org/abs/2511.06531 ,  491kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06571
Date: Sun, 9 Nov 2025 23:18:36 GMT   (359kb)

Title: Rep2Text: Decoding Full Text from a Single LLM Token Representation
Authors: Haiyan Zhao, Zirui He, Fan Yang, Ali Payani, Mengnan Du
Categories: cs.CL cs.AI cs.LG
Comments: 15 pages, 7 figures, 4 tables
\\
 Large language models (LLMs) have achieved remarkable progress across diverse
tasks, yet their internal mechanisms remain largely opaque. In this work, we
address a fundamental question: to what extent can the original input text be
recovered from a single last-token representation within an LLM? We propose
Rep2Text, a novel framework for decoding full text from last-token
representations. Rep2Text employs a trainable adapter that projects a target
model's internal representations into the embedding space of a decoding
language model, which then autoregressively reconstructs the input text.
Experiments on various model combinations (Llama-3.1-8B, Gemma-7B,
Mistral-7B-v0.1, Llama-3.2-3B) demonstrate that, on average, over half of the
information in 16-token sequences can be recovered from this compressed
representation while maintaining strong semantic integrity and coherence.
Furthermore, our analysis reveals an information bottleneck effect: longer
sequences exhibit decreased token-level recovery while preserving strong
semantic integrity. Besides, our framework also demonstrates robust
generalization to out-of-distribution medical data.
\\ ( https://arxiv.org/abs/2511.06571 ,  359kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06582
Date: Mon, 10 Nov 2025 00:05:58 GMT   (726kb)

Title: TabRAG: Tabular Document Retrieval via Structured Language
 Representations
Authors: Jacob Si, Mike Qu, Michelle Lee, Yingzhen Li
Categories: cs.CL cs.AI cs.CV cs.IR cs.LG
Comments: NeurIPS 2025 AI4Tab
\\
 Ingesting data for Retrieval-Augmented Generation (RAG) involves either
fine-tuning the embedding model directly on the target corpus or parsing
documents for embedding model encoding. The former, while accurate, incurs high
computational hardware requirements, while the latter suffers from suboptimal
performance when extracting tabular data. In this work, we address the latter
by presenting TabRAG, a parsing-based RAG pipeline designed to tackle
table-heavy documents via structured language representations. TabRAG
outperforms existing popular parsing-based methods for generation and
retrieval. Code is available at https://github.com/jacobyhsi/TabRAG.
\\ ( https://arxiv.org/abs/2511.06582 ,  726kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06592
Date: Mon, 10 Nov 2025 00:44:37 GMT   (488kb)

Title: MedVoiceBias: A Controlled Study of Audio LLM Behavior in Clinical
 Decision-Making
Authors: Zhi Rui Tam, Yun-Nung Chen
Categories: cs.CL eess.AS
\\
 As large language models transition from text-based interfaces to audio
interactions in clinical settings, they might introduce new vulnerabilities
through paralinguistic cues in audio. We evaluated these models on 170 clinical
cases, each synthesized into speech from 36 distinct voice profiles spanning
variations in age, gender, and emotion. Our findings reveal a severe modality
bias: surgical recommendations for audio inputs varied by as much as 35%
compared to identical text-based inputs, with one model providing 80% fewer
recommendations. Further analysis uncovered age disparities of up to 12%
between young and elderly voices, which persisted in most models despite
chain-of-thought prompting. While explicit reasoning successfully eliminated
gender bias, the impact of emotion was not detected due to poor recognition
performance. These results demonstrate that audio LLMs are susceptible to
making clinical decisions based on a patient's voice characteristics rather
than medical evidence, a flaw that risks perpetuating healthcare disparities.
We conclude that bias-aware architectures are essential and urgently needed
before the clinical deployment of these models.
\\ ( https://arxiv.org/abs/2511.06592 ,  488kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06601
Date: Mon, 10 Nov 2025 01:17:00 GMT   (710kb)

Title: Duality-based Mode Operations and Pyramid Multilayer Mapping for
 Rhetorical Modes
Authors: Zi-Niu Wu
Categories: cs.CL cs.FL cs.PL
\\
 Rhetorical modes are useful in both academic and non-academic writing, and
can be subjects to be studied within linguistic research and computational
modeling. Establishing a conceptual bridge among these domains could enable
each to benefit from the others. This paper proposes duality-based mode
operations (split-unite, forward-backward, expansion-reduction and orthogonal
dualities) to expand the set of rhetorical modes, introducing generated modes
like combination and generalization, thereby enhancing epistemic diversity
across multiple applications. It further presents a pyramid multilayer mapping
framework (e.g., three layers from the rhetorical model layer, to cognitive
layer, and to epistemic layers) that reduces the resulting cognitive
complexity. The degrees of expressive diversity and complexity reduction are
quantified through binomial combinatorics and Shannon entropy analysis. A
Marginal Rhetorical Bit (MRB) is identified, permitting the definition of a
rhetorical-scalable parameter that measures expressive growth speed in bits per
stage. A direct entropy measure shows that hierarchical selection over smaller
subsets markedly reduces choice uncertainty compared with flat selection across
all modes. These considerations appear to transform static and non-measurable
rhetorical taxonomies into more dynamic and more measurable systems for
discourse design. From this work, it would be possible to identify a pathway
for future AI systems to operate not only on language tokens but on layered
rhetorical reasoning structures, bridging linguistic, pedagogical, academic,
and computational research
\\ ( https://arxiv.org/abs/2511.06601 ,  710kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06676
Date: Mon, 10 Nov 2025 03:49:58 GMT   (3452kb)

Title: How AI Fails: An Interactive Pedagogical Tool for Demonstrating
 Dialectal Bias in Automated Toxicity Models
Authors: Subhojit Ghimire
Categories: cs.CL cs.CY cs.HC
Comments: 9 pages, 5 figures, 4 tables, 14 references
\\
 Now that AI-driven moderation has become pervasive in everyday life, we often
hear claims that "the AI is biased". While this is often said jokingly, the
light-hearted remark reflects a deeper concern. How can we be certain that an
online post flagged as "inappropriate" was not simply the victim of a biased
algorithm? This paper investigates this problem using a dual approach. First, I
conduct a quantitative benchmark of a widely used toxicity model
(unitary/toxic-bert) to measure performance disparity between text in
African-American English (AAE) and Standard American English (SAE). The
benchmark reveals a clear, systematic bias: on average, the model scores AAE
text as 1.8 times more toxic and 8.8 times higher for "identity hate". Second,
I introduce an interactive pedagogical tool that makes these abstract biases
tangible. The tool's core mechanic, a user-controlled "sensitivity threshold,"
demonstrates that the biased score itself is not the only harm; instead, the
more-concerning harm is the human-set, seemingly neutral policy that ultimately
operationalises discrimination. This work provides both statistical evidence of
disparate impact and a public-facing tool designed to foster critical AI
literacy.
\\ ( https://arxiv.org/abs/2511.06676 ,  3452kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06680
Date: Mon, 10 Nov 2025 03:52:24 GMT   (238kb)

Title: Steering LLMs toward Korean Local Speech: Iterative Refinement Framework
 for Faithful Dialect Translation
Authors: Keunhyeung Park, Seunguk Yu, Youngbin Kim
Categories: cs.CL
Comments: Submitted to LREC 2026
\\
 Standard-to-dialect machine translation remains challenging due to a
persistent dialect gap in large language models and evaluation distortions
inherent in n-gram metrics, which favor source copying over authentic dialect
translation. In this paper, we propose the dialect refinement (DIA-REFINE)
framework, which guides LLMs toward faithful target dialect outputs through an
iterative loop of translation, verification, and feedback using external
dialect classifiers. To address the limitations of n-gram-based metrics, we
introduce the dialect fidelity score (DFS) to quantify linguistic shift and the
target dialect ratio (TDR) to measure the success of dialect translation.
Experiments on Korean dialects across zero-shot and in-context learning
baselines demonstrate that DIA-REFINE consistently enhances dialect fidelity.
The proposed metrics distinguish between False Success cases, where high n-gram
scores obscure failures in dialectal translation, and True Attempt cases, where
genuine attempts at dialectal translation yield low n-gram scores. We also
observed that models exhibit varying degrees of responsiveness to the
framework, and that integrating in-context examples further improves the
translation of dialectal expressions. Our work establishes a robust framework
for goal-directed, inclusive dialect translation, providing both rigorous
evaluation and critical insights into model performance.
\\ ( https://arxiv.org/abs/2511.06680 ,  238kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06682
Date: Mon, 10 Nov 2025 04:01:46 GMT   (1911kb)

Title: Textual Self-attention Network: Test-Time Preference Optimization
 through Textual Gradient-based Attention
Authors: Shibing Mo, Haoyang Ruan, Kai Wu, Jing Liu
Categories: cs.CL cs.AI
Comments: AAAI2026
\\
 Large Language Models (LLMs) have demonstrated remarkable generalization
capabilities, but aligning their outputs with human preferences typically
requires expensive supervised fine-tuning. Recent test-time methods leverage
textual feedback to overcome this, but they often critique and revise a single
candidate response, lacking a principled mechanism to systematically analyze,
weigh, and synthesize the strengths of multiple promising candidates. Such a
mechanism is crucial because different responses may excel in distinct aspects
(e.g., clarity, factual accuracy, or tone), and combining their best elements
may produce a far superior outcome. This paper proposes the Textual
Self-Attention Network (TSAN), a new paradigm for test-time preference
optimization that requires no parameter updates. TSAN emulates self-attention
entirely in natural language to overcome this gap: it analyzes multiple
candidates by formatting them into textual keys and values, weighs their
relevance using an LLM-based attention module, and synthesizes their strengths
into a new, preference-aligned response under the guidance of the learned
textual attention. This entire process operates in a textual gradient space,
enabling iterative and interpretable optimization. Empirical evaluations
demonstrate that with just three test-time iterations on a base SFT model, TSAN
outperforms supervised models like Llama-3.1-70B-Instruct and surpasses the
current state-of-the-art test-time alignment method by effectively leveraging
multiple candidate solutions.
\\ ( https://arxiv.org/abs/2511.06682 ,  1911kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06708
Date: Mon, 10 Nov 2025 05:02:25 GMT   (2852kb)

Title: Sentiment Analysis On YouTube Comments Using Machine Learning Techniques
 Based On Video Games Content
Authors: Adi Danish Bin Muhammad Amin, Mohaiminul Islam Bhuiyan, Nur Shazwani
 Kamarudin, Zulfahmi Toh, Nur Syafiqah Nafis
Categories: cs.CL
Comments: 6 pages, 7 figures, 2025 IEEE 9th International Conference on
 Software Engineering & Computer Systems
\\
 The rapid evolution of the gaming industry, driven by technological
advancements and a burgeoning community, necessitates a deeper understanding of
user sentiments, especially as expressed on popular social media platforms like
YouTube. This study presents a sentiment analysis on video games based on
YouTube comments, aiming to understand user sentiments within the gaming
community. Utilizing YouTube API, comments related to various video games were
collected and analyzed using the TextBlob sentiment analysis tool. The
pre-processed data underwent classification using machine learning algorithms,
including Na\"ive Bayes, Logistic Regression, and Support Vector Machine (SVM).
Among these, SVM demonstrated superior performance, achieving the highest
classification accuracy across different datasets. The analysis spanned
multiple popular gaming videos, revealing trends and insights into user
preferences and critiques. The findings underscore the importance of advanced
sentiment analysis in capturing the nuanced emotions expressed in user
comments, providing valuable feedback for game developers to enhance game
design and user experience. Future research will focus on integrating more
sophisticated natural language processing techniques and exploring additional
data sources to further refine sentiment analysis in the gaming domain.
\\ ( https://arxiv.org/abs/2511.06708 ,  2852kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06738
Date: Mon, 10 Nov 2025 06:00:12 GMT   (743kb)

Title: Rethinking Retrieval-Augmented Generation for Medicine: A Large-Scale,
 Systematic Expert Evaluation and Practical Insights
Authors: Hyunjae Kim, Jiwoong Sohn, Aidan Gilson, Nicholas Cochran-Caggiano,
 Serina Applebaum, Heeju Jin, Seihee Park, Yujin Park, Jiyeong Park, Seoyoung
 Choi, Brittany Alexandra Herrera Contreras, Thomas Huang, Jaehoon Yun, Ethan
 F. Wei, Roy Jiang, Leah Colucci, Eric Lai, Amisha Dave, Tuo Guo, Maxwell B.
 Singer, Yonghoe Koo, Ron A. Adelman, James Zou, Andrew Taylor, Arman Cohan,
 Hua Xu, Qingyu Chen
Categories: cs.CL
Comments: 34 pages, 6 figures
\\
 Large language models (LLMs) are transforming the landscape of medicine, yet
two fundamental challenges persist: keeping up with rapidly evolving medical
knowledge and providing verifiable, evidence-grounded reasoning.
Retrieval-augmented generation (RAG) has been widely adopted to address these
limitations by supplementing model outputs with retrieved evidence. However,
whether RAG reliably achieves these goals remains unclear. Here, we present the
most comprehensive expert evaluation of RAG in medicine to date. Eighteen
medical experts contributed a total of 80,502 annotations, assessing 800 model
outputs generated by GPT-4o and Llama-3.1-8B across 200 real-world patient and
USMLE-style queries. We systematically decomposed the RAG pipeline into three
components: (i) evidence retrieval (relevance of retrieved passages), (ii)
evidence selection (accuracy of evidence usage), and (iii) response generation
(factuality and completeness of outputs). Contrary to expectation, standard RAG
often degraded performance: only 22% of top-16 passages were relevant, evidence
selection remained weak (precision 41-43%, recall 27-49%), and factuality and
completeness dropped by up to 6% and 5%, respectively, compared with non-RAG
variants. Retrieval and evidence selection remain key failure points for the
model, contributing to the overall performance drop. We further show that
simple yet effective strategies, including evidence filtering and query
reformulation, substantially mitigate these issues, improving performance on
MedMCQA and MedXpertQA by up to 12% and 8.2%, respectively. These findings call
for re-examining RAG's role in medicine and highlight the importance of
stage-aware evaluation and deliberate system design for reliable medical LLM
applications.
\\ ( https://arxiv.org/abs/2511.06738 ,  743kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06763
Date: Mon, 10 Nov 2025 06:44:29 GMT   (3252kb)

Title: Sensitivity of Small Language Models to Fine-tuning Data Contamination
Authors: Nicy Scaria, Silvester John Joseph Kennedy, Deepak Subramani
Categories: cs.CL cs.AI
\\
 Small Language Models (SLMs) are increasingly being deployed in
resource-constrained environments, yet their behavioral robustness to data
contamination during instruction tuning remains poorly understood. We
systematically investigate the contamination sensitivity of 23 SLMs (270M to 4B
parameters) across multiple model families by measuring susceptibility to
syntactic and semantic transformation types during instruction tuning:
syntactic transformations (character and word reversal) and semantic
transformations (irrelevant and counterfactual responses), each applied at
contamination levels of 25\%, 50\%, 75\%, and 100\%. Our results reveal
fundamental asymmetries in vulnerability patterns: syntactic transformations
cause catastrophic performance degradation, with character reversal producing
near-complete failure across all models regardless of size or family, while
semantic transformations demonstrate distinct threshold behaviors and greater
resilience in core linguistic capabilities. Critically, we discover a
``\textit{capability curse}" where larger, more capable models become more
susceptible to learning semantic corruptions, effectively following harmful
instructions more readily, while our analysis of base versus instruction-tuned
variants reveals that alignment provides inconsistent robustness benefits,
sometimes even reducing resilience. Our work establishes three core
contributions: (1) empirical evidence of SLMs' disproportionate vulnerability
to syntactic pattern contamination, (2) identification of asymmetric
sensitivity patterns between syntactic and semantic transformations, and (3)
systematic evaluation protocols for contamination robustness assessment. These
findings have immediate deployment implications, suggesting that current
robustness assumptions may not hold for smaller models and highlighting the
need for contamination-aware training protocols.
\\ ( https://arxiv.org/abs/2511.06763 ,  3252kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06778
Date: Mon, 10 Nov 2025 07:05:59 GMT   (1375kb)

Title: SAFENLIDB: A Privacy-Preserving Safety Alignment Framework for LLM-based
 Natural Language Database Interfaces
Authors: Ruiheng Liu, XiaoBing Chen, Jinyu Zhang, Qiongwen Zhang, Yu Zhang,
 Bailong Yang
Categories: cs.CL
Comments: 26 pages, 14 figures, 22 tables
\\
 The rapid advancement of Large Language Models (LLMs) has driven significant
progress in Natural Language Interface to Database (NLIDB). However, the
widespread adoption of LLMs has raised critical privacy and security concerns.
During interactions, LLMs may unintentionally expose confidential database
contents or be manipulated by attackers to exfiltrate data through seemingly
benign queries. While current efforts typically rely on rule-based heuristics
or LLM agents to mitigate this leakage risk, these methods still struggle with
complex inference-based attacks, suffer from high false positive rates, and
often compromise the reliability of SQL queries. To address these challenges,
we propose \textsc{SafeNlidb}, a novel privacy-security alignment framework for
LLM-based NLIDB. The framework features an automated pipeline that generates
hybrid chain-of-thought interaction data from scratch, seamlessly combining
implicit security reasoning with SQL generation. Additionally, we introduce
reasoning warm-up and alternating preference optimization to overcome the
multi-preference oscillations of Direct Preference Optimization (DPO), enabling
LLMs to produce security-aware SQL through fine-grained reasoning without the
need for human-annotated preference data. Extensive experiments demonstrate
that our method outperforms both larger-scale LLMs and ideal-setting baselines,
achieving significant security improvements while preserving high
utility.WARNING: This work may contain content that is offensive and harmful!
\\ ( https://arxiv.org/abs/2511.06778 ,  1375kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06818
Date: Mon, 10 Nov 2025 08:02:58 GMT   (3801kb)

Title: Learning to Focus: Focal Attention for Selective and Scalable
 Transformers
Authors: Dhananjay Ram, Wei Xia, Stefano Soatto
Categories: cs.CL cs.LG
\\
 Attention is a core component of transformer architecture, whether
encoder-only, decoder-only, or encoder-decoder model. However, the standard
softmax attention often produces noisy probability distribution, which can
impair effective feature selection at every layer of these models, particularly
for long contexts. We propose Focal Attention, a simple yet effective
modification that sharpens the attention distribution by controlling the
softmax temperature, either as a fixed hyperparameter or as a learnable
parameter during training. This sharpening enables the model to concentrate on
the most relevant tokens while suppressing irrelevant ones. Empirically, Focal
Attention scales more favorably than standard transformer with respect to model
size, training data, and context length. Across diverse benchmarks, it achieves
the same accuracy with up to 42% fewer parameters or 33% less training data. On
long-context tasks, it delivers substantial relative improvements ranging from
17% to 82%, demonstrating its effectiveness in real world applications.
\\ ( https://arxiv.org/abs/2511.06818 ,  3801kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06826
Date: Mon, 10 Nov 2025 08:13:42 GMT   (12717kb)

Title: Beyond Plain Demos: A Demo-centric Anchoring Paradigm for In-Context
 Learning in Alzheimer's Disease Detection
Authors: Puzhen Su, Haoran Yin, Yongzhu Miao, Jintao Tang, Shasha Li, Ting Wang
Categories: cs.CL cs.AI
Comments: Accepted to the 40th Annual AAAI Conference on Artificial
 Intelligence (2026) - Main Technical Track (Oral)
\\
 Detecting Alzheimer's disease (AD) from narrative transcripts challenges
large language models (LLMs): pre-training rarely covers this
out-of-distribution task, and all transcript demos describe the same scene,
producing highly homogeneous contexts. These factors cripple both the model's
built-in task knowledge (\textbf{task cognition}) and its ability to surface
subtle, class-discriminative cues (\textbf{contextual perception}). Because
cognition is fixed after pre-training, improving in-context learning (ICL) for
AD detection hinges on enriching perception through better demonstration (demo)
sets. We demonstrate that standard ICL quickly saturates, its demos lack
diversity (context width) and fail to convey fine-grained signals (context
depth), and that recent task vector (TV) approaches improve broad task
adaptation by injecting TV into the LLMs' hidden states (HSs), they are
ill-suited for AD detection due to the mismatch of injection granularity,
strength and position. To address these bottlenecks, we introduce
\textbf{DA4ICL}, a demo-centric anchoring framework that jointly expands
context width via \emph{\textbf{Diverse and Contrastive Retrieval}} (DCR) and
deepens each demo's signal via \emph{\textbf{Projected Vector Anchoring}} (PVA)
at every Transformer layer. Across three AD benchmarks, DA4ICL achieves large,
stable gains over both ICL and TV baselines, charting a new paradigm for
fine-grained, OOD and low-resource LLM adaptation.
\\ ( https://arxiv.org/abs/2511.06826 ,  12717kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06860
Date: Mon, 10 Nov 2025 09:03:30 GMT   (514kb)

Title: CLiFT-ASR: A Cross-Lingual Fine-Tuning Framework for Low-Resource
 Taiwanese Hokkien Speech Recognition
Authors: Hung-Yang Sung, Chien-Chun Wang, Kuan-Tang Huang, Tien-Hong Lo,
 Yu-Sheng Tsao, Yung-Chang Hsu, Berlin Chen
Categories: cs.CL cs.SD
Comments: Accepted for an oral presentation at the 37th Conference on
 Computational Linguistics and Speech Processing (ROCLING 2025)
\\
 Automatic speech recognition (ASR) for low-resource languages such as
Taiwanese Hokkien is difficult due to the scarcity of annotated data. However,
direct fine-tuning on Han-character transcriptions often fails to capture
detailed phonetic and tonal cues, while training only on romanization lacks
lexical and syntactic coverage. In addition, prior studies have rarely explored
staged strategies that integrate both annotation types. To address this gap, we
present CLiFT-ASR, a cross-lingual fine-tuning framework that builds on
Mandarin HuBERT models and progressively adapts them to Taiwanese Hokkien. The
framework employs a two-stage process in which it first learns acoustic and
tonal representations from phonetic Tai-lo annotations and then captures
vocabulary and syntax from Han-character transcriptions. This progressive
adaptation enables effective alignment between speech sounds and orthographic
structures. Experiments on the TAT-MOE corpus demonstrate that CLiFT-ASR
achieves a 24.88\% relative reduction in character error rate (CER) compared
with strong baselines. The results indicate that CLiFT-ASR provides an
effective and parameter-efficient solution for Taiwanese Hokkien ASR and that
it has potential to benefit other low-resource language scenarios.
\\ ( https://arxiv.org/abs/2511.06860 ,  514kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06886
Date: Mon, 10 Nov 2025 09:39:00 GMT   (163kb)

Title: Inclusion of Role into Named Entity Recognition and Ranking
Authors: Neelesh Kumar Shukla and Sanasam Ranbir Singh
Categories: cs.CL cs.LG
Comments: MTP Paper
\\
 Most of the Natural Language Processing sys- tems are involved in
entity-based processing for several tasks like Information Extraction,
Question-Answering, Text-Summarization and so on. A new challenge comes when
entities play roles according to their act or attributes in certain context.
Entity Role Detection is the task of assigning such roles to the entities. Usu-
ally real-world entities are of types: person, lo- cation and organization etc.
Roles could be con- sidered as domain-dependent subtypes of these types. In the
cases, where retrieving a subset of entities based on their roles is needed,
poses the problem of defining the role and entities having those roles. This
paper presents the study of study of solving Entity Role Detection prob- lem by
modeling it as Named Entity Recogni- tion (NER) and Entity Retrieval/Ranking
task. In NER, these roles could be considered as mutually exclusive classes and
standard NER methods like sequence tagging could be used. For Entity Retrieval,
Roles could be formulated as Query and entities as Collection on which the
query needs to be executed. The aspect of Entity Retrieval task, which is
different than document retrieval task is that the entities and roles against
which they need to be retrieved are indirectly described. We have formulated
au- tomated ways of learning representative words and phrases and building
representations of roles and entities using them. We have also explored
different contexts like sentence and document. Since the roles depend upon con-
text, so it is not always possible to have large domain-specific dataset or
knowledge bases for learning purposes, so we have tried to exploit the
information from small dataset in domain- agnostic way.
\\ ( https://arxiv.org/abs/2511.06886 ,  163kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06890
Date: Mon, 10 Nov 2025 09:42:24 GMT   (566kb)

Title: EduGuardBench: A Holistic Benchmark for Evaluating the Pedagogical
 Fidelity and Adversarial Safety of LLMs as Simulated Teachers
Authors: Yilin Jiang, Mingzi Zhang, Xuanyu Yin, Sheng Jin, Suyu Lu, Zuocan
 Ying, Zengyi Yu, Xiangjie Kong
Categories: cs.CL
Comments: 22 pages, 9 figures, accepted by AAAI2026 as oral paper
ACM-class: I.2.7
\\
 Large Language Models for Simulating Professions (SP-LLMs), particularly as
teachers, are pivotal for personalized education. However, ensuring their
professional competence and ethical safety is a critical challenge, as existing
benchmarks fail to measure role-playing fidelity or address the unique teaching
harms inherent in educational scenarios. To address this, we propose
EduGuardBench, a dual-component benchmark. It assesses professional fidelity
using a Role-playing Fidelity Score (RFS) while diagnosing harms specific to
the teaching profession. It also probes safety vulnerabilities using
persona-based adversarial prompts targeting both general harms and,
particularly, academic misconduct, evaluated with metrics including Attack
Success Rate (ASR) and a three-tier Refusal Quality assessment. Our extensive
experiments on 14 leading models reveal a stark polarization in performance.
While reasoning-oriented models generally show superior fidelity, incompetence
remains the dominant failure mode across most models. The adversarial tests
uncovered a counterintuitive scaling paradox, where mid-sized models can be the
most vulnerable, challenging monotonic safety assumptions. Critically, we
identified a powerful Educational Transformation Effect: the safest models
excel at converting harmful requests into teachable moments by providing ideal
Educational Refusals. This capacity is strongly negatively correlated with ASR,
revealing a new dimension of advanced AI safety. EduGuardBench thus provides a
reproducible framework that moves beyond siloed knowledge tests toward a
holistic assessment of professional, ethical, and pedagogical alignment,
uncovering complex dynamics essential for deploying trustworthy AI in
education. See https://github.com/YL1N/EduGuardBench for Materials.
\\ ( https://arxiv.org/abs/2511.06890 ,  566kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06899
Date: Mon, 10 Nov 2025 09:48:07 GMT   (1462kb)

Title: RPTS: Tree-Structured Reasoning Process Scoring for Faithful Multimodal
 Evaluation
Authors: Haofeng Wang and Yu Zhang
Categories: cs.CL cs.AI
\\
 Large Vision-Language Models (LVLMs) excel in multimodal reasoning and have
shown impressive performance on various multimodal benchmarks. However, most of
these benchmarks evaluate models primarily through multiple-choice or
short-answer formats, which do not take the reasoning process into account.
Although some benchmarks assess the reasoning process, their methods are often
overly simplistic and only examine reasoning when answers are incorrect. This
approach overlooks scenarios where flawed reasoning leads to correct answers.
In addition, these benchmarks do not consider the impact of intermodal
relationships on reasoning. To address this issue, we propose the Reasoning
Process Tree Score (RPTS), a tree structure-based metric to assess reasoning
processes. Specifically, we organize the reasoning steps into a reasoning tree
and leverage its hierarchical information to assign weighted faithfulness
scores to each reasoning step. By dynamically adjusting these weights, RPTS not
only evaluates the overall correctness of the reasoning, but also pinpoints
where the model fails in the reasoning. To validate RPTS in real-world
multimodal scenarios, we construct a new benchmark, RPTS-Eval, comprising 374
images and 390 reasoning instances. Each instance includes reliable
visual-textual clues that serve as leaf nodes of the reasoning tree.
Furthermore, we define three types of intermodal relationships to investigate
how intermodal interactions influence the reasoning process. We evaluated
representative LVLMs (e.g., GPT4o, Llava-Next), uncovering their limitations in
multimodal reasoning and highlighting the differences between open-source and
closed-source commercial LVLMs. We believe that this benchmark will contribute
to the advancement of research in the field of multimodal reasoning.
\\ ( https://arxiv.org/abs/2511.06899 ,  1462kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06942
Date: Mon, 10 Nov 2025 10:47:34 GMT   (1117kb)

Title: HLPD: Aligning LLMs to Human Language Preference for Machine-Revised
 Text Detection
Authors: Fangqi Dai, Xingjian Jiang, Zizhuang Deng
Categories: cs.CL cs.CR
Comments: 9 pages, 3 figures, accepted by AAAI'26
\\
 To prevent misinformation and social issues arising from trustworthy-looking
content generated by LLMs, it is crucial to develop efficient and reliable
methods for identifying the source of texts. Previous approaches have
demonstrated exceptional performance in detecting texts fully generated by
LLMs. However, these methods struggle when confronting more advanced LLM output
or text with adversarial multi-task machine revision, especially in the
black-box setting, where the generating model is unknown. To address this
challenge, grounded in the hypothesis that human writing possesses distinctive
stylistic patterns, we propose Human Language Preference Detection (HLPD). HLPD
employs a reward-based alignment process, Human Language Preference
Optimization (HLPO), to shift the scoring model's token distribution toward
human-like writing, making the model more sensitive to human writing, therefore
enhancing the identification of machine-revised text. We test HLPD in an
adversarial multi-task evaluation framework that leverages a five-dimensional
prompt generator and multiple advanced LLMs to create diverse revision
scenarios. When detecting texts revised by GPT-series models, HLPD achieves a
15.11% relative improvement in AUROC over ImBD, surpassing Fast-DetectGPT by
45.56%. When evaluated on texts generated by advanced LLMs, HLPD achieves the
highest average AUROC, exceeding ImBD by 5.53% and Fast-DetectGPT by 34.14%.
Code will be made available at https://github.com/dfq2021/HLPD.
\\ ( https://arxiv.org/abs/2511.06942 ,  1117kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07001
Date: Mon, 10 Nov 2025 11:53:07 GMT   (1952kb)

Title: SCOPE: Intrinsic Semantic Space Control for Mitigating Copyright
 Infringement in LLMs
Authors: Zhenliang Zhang, Xinyu Hu, Xiaojun Wan
Categories: cs.CL
Comments: Accepted by the AAAI 2026 (Main Track)
\\
 Large language models sometimes inadvertently reproduce passages that are
copyrighted, exposing downstream applications to legal risk. Most existing
studies for inference-time defences focus on surface-level token matching and
rely on external blocklists or filters, which add deployment complexity and may
overlook semantically paraphrased leakage. In this work, we reframe copyright
infringement mitigation as intrinsic semantic-space control and introduce
SCOPE, an inference-time method that requires no parameter updates or auxiliary
filters. Specifically, the sparse autoencoder (SAE) projects hidden states into
a high-dimensional, near-monosemantic space; benefiting from this
representation, we identify a copyright-sensitive subspace and clamp its
activations during decoding. Experiments on widely recognized benchmarks show
that SCOPE mitigates copyright infringement without degrading general utility.
Further interpretability analyses confirm that the isolated subspace captures
high-level semantics.
\\ ( https://arxiv.org/abs/2511.07001 ,  1952kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07002
Date: Mon, 10 Nov 2025 11:53:36 GMT   (725kb)

Title: Automated Circuit Interpretation via Probe Prompting
Authors: Giuseppe Birardi
Categories: cs.CL
Comments: 27 pages, 5 figures, 3 tables. Code and interactive demo available
ACM-class: I.2.0; I.2.6; I.2.7; I.2.4
\\
 Mechanistic interpretability aims to understand neural networks by
identifying which learned features mediate specific behaviors. Attribution
graphs reveal these feature pathways, but interpreting them requires extensive
manual analysis -- a single prompt can take approximately 2 hours for an
experienced circuit tracer. We present probe prompting, an automated pipeline
that transforms attribution graphs into compact, interpretable subgraphs built
from concept-aligned supernodes. Starting from a seed prompt and target logit,
we select high-influence features, generate concept-targeted yet
context-varying probes, and group features by cross-prompt activation
signatures into Semantic, Relationship, and Say-X categories using transparent
decision rules.
 Across five prompts including classic "capitals" circuits, probe-prompted
subgraphs preserve high explanatory coverage while compressing complexity
(Completeness 0.83, mean across circuits; Replacement 0.54). Compared to
geometric clustering baselines, concept-aligned groups exhibit higher
behavioral coherence: 2.3x higher peak-token consistency (0.425 vs 0.183) and
5.8x higher activation-pattern similarity (0.762 vs 0.130), despite lower
geometric compactness. Entity-swap tests reveal a layerwise hierarchy:
early-layer features transfer robustly (64% transfer rate, mean layer 6.3),
while late-layer Say-X features specialize for output promotion (mean layer
16.4), supporting a backbone-and-specialization view of transformer
computation.
 We release code (https://github.com/peppinob-ol/attribution-graph-probing),
an interactive demo
(https://huggingface.co/spaces/Peppinob/attribution-graph-probing), and minimal
artifacts enabling immediate reproduction and community adoption.
\\ ( https://arxiv.org/abs/2511.07002 ,  725kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07003
Date: Mon, 10 Nov 2025 11:54:53 GMT   (3605kb)

Title: Beyond English: Toward Inclusive and Scalable Multilingual Machine
 Translation with LLMs
Authors: Yingfeng Luo, Ziqiang Xu, Yuxuan Ouyang, Murun Yang, Dingyang Lin,
 Kaiyan Chang, Tong Zheng, Bei Li, Peinan Feng, Quan Du, Tong Xiao, Jingbo Zhu
Categories: cs.CL
\\
 Large language models have significantly advanced Multilingual Machine
Translation (MMT), yet the broad language coverage, consistent translation
quality, and English-centric bias remain open challenges. To address these
challenges, we introduce \textbf{LMT}, a suite of \textbf{L}arge-scale
\textbf{M}ultilingual \textbf{T}ranslation models centered on both Chinese and
English, covering 60 languages and 234 translation directions. During
development, we identify a previously overlooked phenomenon of
\textbf{directional degeneration}, where symmetric multi-way fine-tuning data
overemphasize reverse directions (X $\to$ En/Zh), leading to excessive
many-to-one mappings and degraded translation quality. We propose
\textbf{Strategic Downsampling}, a simple yet effective method to mitigate this
degeneration. In addition, we design \textbf{Parallel Multilingual Prompting
(PMP)}, which leverages typologically related auxiliary languages to enhance
cross-lingual transfer. Through rigorous data curation and refined adaptation
strategies, LMT achieves SOTA performance among models of comparable language
coverage, with our 4B model (LMT-60-4B) surpassing the much larger Aya-101-13B
and NLLB-54B models by a substantial margin. We release LMT in four sizes
(0.6B/1.7B/4B/8B) to catalyze future research and provide strong baselines for
inclusive, scalable, and high-quality MMT
\footnote{\href{https://github.com/NiuTrans/LMT}{https://github.com/NiuTrans/LMT}}.
\\ ( https://arxiv.org/abs/2511.07003 ,  3605kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07010
Date: Mon, 10 Nov 2025 12:02:48 GMT   (936kb)

Title: A Picture is Worth a Thousand (Correct) Captions: A Vision-Guided
 Judge-Corrector System for Multimodal Machine Translation
Authors: Siddharth Betala, Kushan Raj, Vipul Betala, Rohan Saswade
Categories: cs.CL cs.CV cs.HC
Comments: Accepted at The 12th Workshop on Asian Translation, co-located with
 IJCLNLP-AACL 2025
\\
 In this paper, we describe our system under the team name BLEU Monday for the
English-to-Indic Multimodal Translation Task at WAT 2025. We participate in the
text-only translation tasks for English-Hindi, English-Bengali,
English-Malayalam, and English-Odia language pairs. We present a two-stage
approach that addresses quality issues in the training data through automated
error detection and correction, followed by parameter-efficient model
fine-tuning.
 Our methodology introduces a vision-augmented judge-corrector pipeline that
leverages multimodal language models to systematically identify and correct
translation errors in the training data. The judge component classifies
translations into three categories: correct, visually ambiguous (requiring
image context), or mistranslated (poor translation quality). Identified errors
are routed to specialized correctors: GPT-4o-mini regenerates captions
requiring visual disambiguation, while IndicTrans2 retranslates cases with pure
translation quality issues. This automated pipeline processes 28,928 training
examples across four languages, correcting an average of 17.1% of captions per
language.
 We then apply Low-Rank Adaptation (LoRA) to fine-tune the IndicTrans2
en-indic 200M distilled model on both original and corrected datasets. Training
on corrected data yields consistent improvements, with BLEU score gains of
+1.30 for English-Bengali on the evaluation set (42.00 -> 43.30) and +0.70 on
the challenge set (44.90 -> 45.60), +0.60 for English-Odia on the evaluation
set (41.00 -> 41.60), and +0.10 for English-Hindi on the challenge set (53.90
-> 54.00).
\\ ( https://arxiv.org/abs/2511.07010 ,  936kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07011
Date: Mon, 10 Nov 2025 12:03:16 GMT   (1365kb)

Title: Multilingual Lexical Feature Analysis of Spoken Language for Predicting
 Major Depression Symptom Severity
Authors: Anastasiia Tokareva, Judith Dineley, Zoe Firth, Pauline Conde, Faith
 Matcham, Sara Siddi, Femke Lamers, Ewan Carr, Carolin Oetzmann, Daniel
 Leightley, Yuezhou Zhang, Amos A. Folarin, Josep Maria Haro, Brenda W.J.H.
 Penninx, Raquel Bailon, Srinivasan Vairavan, Til Wykes, Richard J.B. Dobson,
 Vaibhav A. Narayan, Matthew Hotopf, Nicholas Cummins, The RADAR-CNS
 Consortium
Categories: cs.CL cs.LG
\\
 Background: Captured between clinical appointments using mobile devices,
spoken language has potential for objective, more regular assessment of symptom
severity and earlier detection of relapse in major depressive disorder.
However, research to date has largely been in non-clinical cross-sectional
samples of written language using complex machine learning (ML) approaches with
limited interpretability.
 Methods: We describe an initial exploratory analysis of longitudinal speech
data and PHQ-8 assessments from 5,836 recordings of 586 participants in the UK,
Netherlands, and Spain, collected in the RADAR-MDD study. We sought to identify
interpretable lexical features associated with MDD symptom severity with linear
mixed-effects modelling. Interpretable features and high-dimensional vector
embeddings were also used to test the prediction performance of four regressor
ML models.
 Results: In English data, MDD symptom severity was associated with 7 features
including lexical diversity measures and absolutist language. In Dutch,
associations were observed with words per sentence and positive word frequency;
no associations were observed in recordings collected in Spain. The predictive
power of lexical features and vector embeddings was near chance level across
all languages.
 Limitations: Smaller samples in non-English speech and methodological
choices, such as the elicitation prompt, may have also limited the effect sizes
observable. A lack of NLP tools in languages other than English restricted our
feature choice.
 Conclusion: To understand the value of lexical markers in clinical research
and practice, further research is needed in larger samples across several
languages using improved protocols, and ML models that account for within- and
between-individual variations in language.
\\ ( https://arxiv.org/abs/2511.07011 ,  1365kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07025
Date: Mon, 10 Nov 2025 12:13:16 GMT   (48kb)

Title: Llama-Embed-Nemotron-8B: A Universal Text Embedding Model for
 Multilingual and Cross-Lingual Tasks
Authors: Yauhen Babakhin, Radek Osmulski, Ronay Ak, Gabriel Moreira, Mengyao
 Xu, Benedikt Schifferer, Bo Liu, Even Oldridge
Categories: cs.CL cs.IR
\\
 We introduce llama-embed-nemotron-8b, an open-weights text embedding model
that achieves state-of-the-art performance on the Multilingual Massive Text
Embedding Benchmark (MMTEB) leaderboard as of October 21, 2025. While recent
models show strong performance, their training data or methodologies are often
not fully disclosed. We aim to address this by developing a fully open-source
model, publicly releasing its weights and detailed ablation studies, and
planning to share the curated training datasets. Our model demonstrates
superior performance across all major embedding tasks -- including retrieval,
classification and semantic textual similarity (STS) -- and excels in
challenging multilingual scenarios, such as low-resource languages and
cross-lingual setups. This state-of-the-art performance is driven by a novel
data mix of 16.1 million query-document pairs, split between 7.7 million
samples from public datasets and 8.4 million synthetically generated examples
from various open-weight LLMs. One of our key contributions is a detailed
ablation study analyzing core design choices, including a comparison of
contrastive loss implementations, an evaluation of synthetic data generation
(SDG) strategies, and the impact of model merging. The llama-embed-nemotron-8b
is an instruction-aware model, supporting user-defined instructions to enhance
performance for specific use-cases. This combination of top-tier performance,
broad applicability, and user-driven flexibility enables it to serve as a
universal text embedding solution.
\\ ( https://arxiv.org/abs/2511.07025 ,  48kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07044
Date: Mon, 10 Nov 2025 12:38:26 GMT   (56kb)

Title: Evaluating LLMs for Anxiety, Depression, and Stress Detection Evaluating
 Large Language Models for Anxiety, Depression, and Stress Detection: Insights
 into Prompting Strategies and Synthetic Data
Authors: Mihael Arcan and David-Paul Niland
Categories: cs.CL
\\
 Mental health disorders affect over one-fifth of adults globally, yet
detecting such conditions from text remains challenging due to the subtle and
varied nature of symptom expression. This study evaluates multiple approaches
for mental health detection, comparing Large Language Models (LLMs) such as
Llama and GPT with classical machine learning and transformer-based
architectures including BERT, XLNet, and Distil-RoBERTa. Using the DAIC-WOZ
dataset of clinical interviews, we fine-tuned models for anxiety, depression,
and stress classification and applied synthetic data generation to mitigate
class imbalance. Results show that Distil-RoBERTa achieved the highest F1 score
(0.883) for GAD-2, while XLNet outperformed others on PHQ tasks (F1 up to
0.891). For stress detection, a zero-shot synthetic approach
(SD+Zero-Shot-Basic) reached an F1 of 0.884 and ROC AUC of 0.886. Findings
demonstrate the effectiveness of transformer-based models and highlight the
value of synthetic data in improving recall and generalization. However,
careful calibration is required to prevent precision loss. Overall, this work
emphasizes the potential of combining advanced language models and data
augmentation to enhance automated mental health assessment from text.
\\ ( https://arxiv.org/abs/2511.07044 ,  56kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07055
Date: Mon, 10 Nov 2025 12:46:39 GMT   (1664kb)

Title: When Sufficient is not Enough: Utilizing the Rashomon Effect for
 Complete Evidence Extraction
Authors: Katharina Beckh and Stefan R\"uping
Categories: cs.CL cs.IR cs.LG
\\
 Feature attribution methods typically provide minimal sufficient evidence
justifying a model decision. However, in many applications this is inadequate.
For compliance and cataloging, the full set of contributing features must be
identified - complete evidence. We perform a case study on a medical dataset
which contains human-annotated complete evidence. We show that individual
models typically recover only subsets of complete evidence and that aggregating
evidence from several models improves evidence recall from $\sim$0.60 (single
best model) to $\sim$0.86 (ensemble). We analyze the recall-precision
trade-off, the role of training with evidence, dynamic ensembles with certainty
thresholds, and discuss implications.
\\ ( https://arxiv.org/abs/2511.07055 ,  1664kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07065
Date: Mon, 10 Nov 2025 12:57:56 GMT   (161kb)

Title: Aligning Attention with Human Rationales for Self-Explaining Hate Speech
 Detection
Authors: Brage Eilertsen, R{\o}skva Bj{\o}rgfinsd\'ottir, Francielle Vargas,
 Ali Ramezani-Kebrya
Categories: cs.CL cs.LG
Comments: Accepted at the Annual AAAI Conference on Artificial Intelligence
 (AAAI26)
\\
 The opaque nature of deep learning models presents significant challenges for
the ethical deployment of hate speech detection systems. To address this
limitation, we introduce Supervised Rational Attention (SRA), a framework that
explicitly aligns model attention with human rationales, improving both
interpretability and fairness in hate speech classification. SRA integrates a
supervised attention mechanism into transformer-based classifiers, optimizing a
joint objective that combines standard classification loss with an alignment
loss term that minimizes the discrepancy between attention weights and
human-annotated rationales. We evaluated SRA on hate speech benchmarks in
English (HateXplain) and Portuguese (HateBRXplain) with rationale annotations.
Empirically, SRA achieves 2.4x better explainability compared to current
baselines, and produces token-level explanations that are more faithful and
human-aligned. In terms of fairness, SRA achieves competitive fairness across
all measures, with second-best performance in detecting toxic posts targeting
identity groups, while maintaining comparable results on other metrics. These
findings demonstrate that incorporating human rationales into attention
mechanisms can enhance interpretability and faithfulness without compromising
fairness.
\\ ( https://arxiv.org/abs/2511.07065 ,  161kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07074
Date: Mon, 10 Nov 2025 13:06:30 GMT   (1371kb)

Title: Importance-Aware Data Selection for Efficient LLM Instruction Tuning
Authors: Tingyu Jiang, Shen Li, Yiyao Song, Lan Zhang, Hualei Zhu, Yuan Zhao,
 Xiaohang Xu, Kenjiro Taura, Hao Henry Wang
Categories: cs.CL
Comments: Accepted by AAAI 2026 Oral
\\
 Instruction tuning plays a critical role in enhancing the performance and
efficiency of Large Language Models (LLMs). Its success depends not only on the
quality of the instruction data but also on the inherent capabilities of the
LLM itself. Some studies suggest that even a small amount of high-quality data
can achieve instruction fine-tuning results that are on par with, or even
exceed, those from using a full-scale dataset. However, rather than focusing
solely on calculating data quality scores to evaluate instruction data, there
is a growing need to select high-quality data that maximally enhances the
performance of instruction tuning for a given LLM. In this paper, we propose
the Model Instruction Weakness Value (MIWV) as a novel metric to quantify the
importance of instruction data in enhancing model's capabilities. The MIWV
metric is derived from the discrepancies in the model's responses when using
In-Context Learning (ICL), helping identify the most beneficial data for
enhancing instruction tuning performance. Our experimental results demonstrate
that selecting only the top 1\% of data based on MIWV can outperform training
on the full dataset. Furthermore, this approach extends beyond existing
research that focuses on data quality scoring for data selection, offering
strong empirical evidence supporting the effectiveness of our proposed method.
\\ ( https://arxiv.org/abs/2511.07074 ,  1371kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07077
Date: Mon, 10 Nov 2025 13:07:40 GMT   (1584kb)

Title: EmoBang: Detecting Emotion From Bengali Texts
Authors: Abdullah Al Maruf, Aditi Golder, Zakaria Masud Jiyad, Abdullah Al
 Numan, Tarannum Shaila Zaman
Categories: cs.CL
\\
 Emotion detection from text seeks to identify an individual's emotional or
mental state - positive, negative, or neutral - based on linguistic cues. While
significant progress has been made for English and other high-resource
languages, Bengali remains underexplored despite being the world's fourth most
spoken language. The lack of large, standardized datasets classifies Bengali as
a low-resource language for emotion detection. Existing studies mainly employ
classical machine learning models with traditional feature engineering,
yielding limited performance. In this paper, we introduce a new Bengali emotion
dataset annotated across eight emotion categories and propose two models for
automatic emotion detection: (i) a hybrid Convolutional Recurrent Neural
Network (CRNN) model (EmoBangHybrid) and (ii) an AdaBoost-Bidirectional Encoder
Representations from Transformers (BERT) ensemble model (EmoBangEnsemble).
Additionally, we evaluate six baseline models with five feature engineering
techniques and assess zero-shot and few-shot large language models (LLMs) on
the dataset. To the best of our knowledge, this is the first comprehensive
benchmark for Bengali emotion detection. Experimental results show that
EmoBangH and EmoBangE achieve accuracies of 92.86% and 93.69%, respectively,
outperforming existing methods and establishing strong baselines for future
research.
\\ ( https://arxiv.org/abs/2511.07077 ,  1584kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07080
Date: Mon, 10 Nov 2025 13:10:31 GMT   (1393kb)

Title: Wasm: A Pipeline for Constructing Structured Arabic Interleaved
 Multimodal Corpora
Authors: Khalil Hennara, Ahmad Bastati, Muhammad Hreden, Mohamed Motasim Hamed,
 Zeina Aldallal, Sara Chrouf, and Safwan AlModhayan
Categories: cs.CL cs.AI
\\
 The performance of large language models (LLMs) and large multimodal models
(LMMs) depends heavily on the quality and scale of their pre-training datasets.
Recent research shows that large multimodal models trained on natural documents
where images and text are interleaved outperform those trained only on
image-text pairs across a wide range of benchmarks, leveraging advanced pre-
trained models to enforce semantic alignment, image-sequence consistency, and
textual coherence. For Arabic, however, the lack of high-quality multimodal
datasets that preserve document structure has limited progress. In this paper,
we present our pipeline Wasm for processing the Common Crawl dataset to create
a new Arabic multimodal dataset that uniquely provides markdown output. Unlike
existing Arabic corpora that focus solely on text extraction, our approach
preserves the structural integrity of web content while maintaining flexibility
for both text-only and multimodal pre-training scenarios. We provide a
comprehensive comparative analysis of our data processing pipeline against
those used for major existing datasets, highlighting the convergences in
filtering strategies and justifying our specific design choices. To support
future research, we publicly release a representative dataset dump along with
the multimodal processing pipeline for Arabic.
\\ ( https://arxiv.org/abs/2511.07080 ,  1393kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07112
Date: Mon, 10 Nov 2025 13:58:17 GMT   (1776kb)

Title: More Agents Helps but Adversarial Robustness Gap Persists
Authors: Khashayar Alavi, Zhastay Yeltay, Lucie Flek, Akbar Karimi
Categories: cs.CL cs.AI
\\
 When LLM agents work together, they seem to be more powerful than a single
LLM in mathematical question answering. However, are they also more robust to
adversarial inputs? We investigate this question using adversarially perturbed
math questions. These perturbations include punctuation noise with three
intensities (10, 30, and 50 percent), plus real-world and human-like typos
(WikiTypo, R2ATA). Using a unified sampling-and-voting framework (Agent
Forest), we evaluate six open-source models (Qwen3-4B/14B, Llama3.1-8B,
Mistral-7B, Gemma3-4B/12B) across four benchmarks (GSM8K, MATH, MMLU-Math,
MultiArith), with various numbers of agents n from one to 25 (1, 2, 5, 10, 15,
20, 25). Our findings show that (1) Noise type matters: punctuation noise harm
scales with its severity, and the human typos remain the dominant bottleneck,
yielding the largest gaps to Clean accuracy and the highest ASR even with a
large number of agents. And (2) Collaboration reliably improves accuracy as the
number of agents, n, increases, with the largest gains from one to five agents
and diminishing returns beyond 10 agents. However, the adversarial robustness
gap persists regardless of the agent count.
\\ ( https://arxiv.org/abs/2511.07112 ,  1776kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07124
Date: Mon, 10 Nov 2025 14:10:58 GMT   (259kb)

Title: Think Consistently, Reason Efficiently: Energy-Based Calibration for
 Implicit Chain-of-Thought
Authors: Zhikang Chen, Sen Cui, Deheng Ye, Yu Zhang, Yatao Bian, Tingting Zhu
Categories: cs.CL cs.AI cs.LG
\\
 Large Language Models (LLMs) have demonstrated strong reasoning capabilities
through \emph{Chain-of-Thought} (CoT) prompting, which enables step-by-step
intermediate reasoning. However, explicit CoT methods rely on discrete
token-level reasoning processes that are prone to error propagation and limited
by vocabulary expressiveness, often resulting in rigid and inconsistent
reasoning trajectories. Recent research has explored implicit or continuous
reasoning in latent spaces, allowing models to perform internal reasoning
before generating explicit output. Although such approaches alleviate some
limitations of discrete CoT, they generally lack explicit mechanisms to enforce
consistency among reasoning steps, leading to divergent reasoning paths and
unstable outcomes. To address this issue, we propose EBM-CoT, an Energy-Based
Chain-of-Thought Calibration framework that refines latent thought
representations through an energy-based model (EBM). Our method dynamically
adjusts latent reasoning trajectories toward lower-energy, high-consistency
regions in the embedding space, improving both reasoning accuracy and
consistency without modifying the base language model. Extensive experiments
across mathematical, commonsense, and symbolic reasoning benchmarks demonstrate
that the proposed framework significantly enhances the consistency and
efficiency of multi-step reasoning in LLMs.
\\ ( https://arxiv.org/abs/2511.07124 ,  259kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07129
Date: Mon, 10 Nov 2025 14:13:10 GMT   (563kb)

Title: LoRA on the Go: Instance-level Dynamic LoRA Selection and Merging
Authors: Seungeon Lee, Soumi Das, Manish Gupta, Krishna P. Gummadi
Categories: cs.CL cs.AI cs.LG
\\
 Low-Rank Adaptation (LoRA) has emerged as a parameter-efficient approach for
fine-tuning large language models.However, conventional LoRA adapters are
typically trained for a single task, limiting their applicability in real-world
settings where inputs may span diverse and unpredictable domains. At inference
time, existing approaches combine multiple LoRAs for improving performance on
diverse tasks, while usually requiring labeled data or additional task-specific
training, which is expensive at scale. In this work, we introduce LoRA on the
Go (LoGo), a training-free framework that dynamically selects and merges
adapters at the instance level without any additional requirements. LoGo
leverages signals extracted from a single forward pass through LoRA adapters,
to identify the most relevant adapters and determine their contributions
on-the-fly. Across 5 NLP benchmarks, 27 datasets, and 3 model families, LoGo
outperforms training-based baselines on some tasks upto a margin of 3.6% while
remaining competitive on other tasks and maintaining inference throughput,
highlighting its effectiveness and practicality.
\\ ( https://arxiv.org/abs/2511.07129 ,  563kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07148
Date: Mon, 10 Nov 2025 14:35:25 GMT   (8581kb)

Title: TCM-Eval: An Expert-Level Dynamic and Extensible Benchmark for
 Traditional Chinese Medicine
Authors: Zihao Cheng, Yuheng Lu, Huaiqian Ye, Zeming Liu, Minqi Wang, Jingjing
 Liu, Zihan Li, Wei Fan, Yuanfang Guo, Ruiji Fu, Shifeng She, Gang Wang,
 Yunhong Wang
Categories: cs.CL
Comments: Work in Progress
\\
 Large Language Models (LLMs) have demonstrated remarkable capabilities in
modern medicine, yet their application in Traditional Chinese Medicine (TCM)
remains severely limited by the absence of standardized benchmarks and the
scarcity of high-quality training data. To address these challenges, we
introduce TCM-Eval, the first dynamic and extensible benchmark for TCM,
meticulously curated from national medical licensing examinations and validated
by TCM experts. Furthermore, we construct a large-scale training corpus and
propose Self-Iterative Chain-of-Thought Enhancement (SI-CoTE) to autonomously
enrich question-answer pairs with validated reasoning chains through rejection
sampling, establishing a virtuous cycle of data and model co-evolution. Using
this enriched training data, we develop ZhiMingTang (ZMT), a state-of-the-art
LLM specifically designed for TCM, which significantly exceeds the passing
threshold for human practitioners. To encourage future research and
development, we release a public leaderboard, fostering community engagement
and continuous improvement.
\\ ( https://arxiv.org/abs/2511.07148 ,  8581kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07162
Date: Mon, 10 Nov 2025 14:53:04 GMT   (46kb)

Title: Categorical Emotions or Appraisals - Which Emotion Model Explains
 Argument Convincingness Better?
Authors: Lynn Greschner, Meike Bauer, Sabine Weber, Roman Klinger
Categories: cs.CL
\\
 The convincingness of an argument does not only depend on its structure
(logos), the person who makes the argument (ethos), but also on the emotion
that it causes in the recipient (pathos). While the overall intensity and
categorical values of emotions in arguments have received considerable
attention in the research community, we argue that the emotion an argument
evokes in a recipient is subjective. It depends on the recipient's goals,
standards, prior knowledge, and stance. Appraisal theories lend themselves as a
link between the subjective cognitive assessment of events and emotions. They
have been used in event-centric emotion analysis, but their suitability for
assessing argument convincingness remains unexplored. In this paper, we
evaluate whether appraisal theories are suitable for emotion analysis in
arguments by considering subjective cognitive evaluations of the importance and
impact of an argument on its receiver. Based on the annotations in the recently
published ContArgA corpus, we perform zero-shot prompting experiments to
evaluate the importance of gold-annotated and predicted emotions and appraisals
for the assessment of the subjective convincingness labels. We find that, while
categorical emotion information does improve convincingness prediction, the
improvement is more pronounced with appraisals. This work presents the first
systematic comparison between emotion models for convincingness prediction,
demonstrating the advantage of appraisals, providing insights for theoretical
and practical applications in computational argumentation.
\\ ( https://arxiv.org/abs/2511.07162 ,  46kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07166
Date: Mon, 10 Nov 2025 14:59:27 GMT   (10198kb)

Title: AdaRec: Adaptive Recommendation with LLMs via Narrative Profiling and
 Dual-Channel Reasoning
Authors: Meiyun Wang and Charin Polpanumas
Categories: cs.CL cs.AI cs.CE
\\
 We propose AdaRec, a few-shot in-context learning framework that leverages
large language models for an adaptive personalized recommendation. AdaRec
introduces narrative profiling, transforming user-item interactions into
natural language representations to enable unified task handling and enhance
human readability. Centered on a bivariate reasoning paradigm, AdaRec employs a
dual-channel architecture that integrates horizontal behavioral alignment,
discovering peer-driven patterns, with vertical causal attribution,
highlighting decisive factors behind user preferences. Unlike existing
LLM-based approaches, AdaRec eliminates manual feature engineering through
semantic representations and supports rapid cross-task adaptation with minimal
supervision. Experiments on real ecommerce datasets demonstrate that AdaRec
outperforms both machine learning models and LLM-based baselines by up to eight
percent in few-shot settings. In zero-shot scenarios, it achieves up to a
nineteen percent improvement over expert-crafted profiling, showing
effectiveness for long-tail personalization with minimal interaction data.
Furthermore, lightweight fine-tuning on synthetic data generated by AdaRec
matches the performance of fully fine-tuned models, highlighting its efficiency
and generalization across diverse tasks.
\\ ( https://arxiv.org/abs/2511.07166 ,  10198kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07193
Date: Mon, 10 Nov 2025 15:24:01 GMT   (1191kb)

Title: EMODIS: A Benchmark for Context-Dependent Emoji Disambiguation in Large
 Language Models
Authors: Jiacheng Huang and Ning Yu and Xiaoyin Yi
Categories: cs.CL
Comments: Accepted by AAAI2026
\\
 Large language models (LLMs) are increasingly deployed in real-world
communication settings, yet their ability to resolve context-dependent
ambiguity remains underexplored. In this work, we present EMODIS, a new
benchmark for evaluating LLMs' capacity to interpret ambiguous emoji
expressions under minimal but contrastive textual contexts. Each instance in
EMODIS comprises an ambiguous sentence containing an emoji, two distinct
disambiguating contexts that lead to divergent interpretations, and a specific
question that requires contextual reasoning. We evaluate both open-source and
API-based LLMs, and find that even the strongest models frequently fail to
distinguish meanings when only subtle contextual cues are present. Further
analysis reveals systematic biases toward dominant interpretations and limited
sensitivity to pragmatic contrast. EMODIS provides a rigorous testbed for
assessing contextual disambiguation, and highlights the gap in semantic
reasoning between humans and LLMs.
\\ ( https://arxiv.org/abs/2511.07193 ,  1191kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07230
Date: Mon, 10 Nov 2025 15:48:01 GMT   (440kb)

Title: Discourse Graph Guided Document Translation with Large Language Models
Authors: Viet-Thanh Pham, Minghan Wang, Hao-Han Liao, Thuy-Trang Vu
Categories: cs.CL cs.AI
\\
 Adapting large language models to full document translation remains
challenging due to the difficulty of capturing long-range dependencies and
preserving discourse coherence throughout extended texts. While recent agentic
machine translation systems mitigate context window constraints through
multi-agent orchestration and persistent memory, they require substantial
computational resources and are sensitive to memory retrieval strategies. We
introduce TransGraph, a discourse-guided framework that explicitly models
inter-chunk relationships through structured discourse graphs and selectively
conditions each translation segment on relevant graph neighbourhoods rather
than relying on sequential or exhaustive context. Across three document-level
MT benchmarks spanning six languages and diverse domains, TransGraph
consistently surpasses strong baselines in translation quality and terminology
consistency while incurring significantly lower token overhead.
\\ ( https://arxiv.org/abs/2511.07230 ,  440kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07296
Date: Mon, 10 Nov 2025 16:53:45 GMT   (458kb)

Title: Who Is the Story About? Protagonist Entity Recognition in News
Authors: Jorge Gab\'in and M. Eduardo Ares and Javier Parapar
Categories: cs.CL
\\
 News articles often reference numerous organizations, but traditional Named
Entity Recognition (NER) treats all mentions equally, obscuring which entities
genuinely drive the narrative. This limits downstream tasks that rely on
understanding event salience, influence, or narrative focus. We introduce
Protagonist Entity Recognition (PER), a task that identifies the organizations
that anchor a news story and shape its main developments. To validate PER, we
compare he predictions of Large Language Models (LLMs) against annotations from
four expert annotators over a gold corpus, establishing both inter-annotator
consistency and human-LLM agreement. Leveraging these findings, we use
state-of-the-art LLMs to automatically label large-scale news collections
through NER-guided prompting, generating scalable, high-quality supervision. We
then evaluate whether other LLMs, given reduced context and without explicit
candidate guidance, can still infer the correct protagonists. Our results
demonstrate that PER is a feasible and meaningful extension to
narrative-centered information extraction, and that guided LLMs can approximate
human judgments of narrative importance at scale.
\\ ( https://arxiv.org/abs/2511.07296 ,  458kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07304
Date: Mon, 10 Nov 2025 17:07:09 GMT   (914kb)

Title: Retriv at BLP-2025 Task 1: A Transformer Ensemble and Multi-Task
 Learning Approach for Bangla Hate Speech Identification
Authors: Sourav Saha, K M Nafi Asib, and Mohammed Moshiul Hoque
Categories: cs.CL
Comments: 7 pages, 3 figures, experimental scripts publicly available at
 https://github.com/sahasourav17/Retriv-BLP25-Task-1
\\
 This paper addresses the problem of Bangla hate speech identification, a
socially impactful yet linguistically challenging task. As part of the "Bangla
Multi-task Hate Speech Identification" shared task at the BLP Workshop,
IJCNLP-AACL 2025, our team "Retriv" participated in all three subtasks: (1A)
hate type classification, (1B) target group identification, and (1C) joint
detection of type, severity, and target. For subtasks 1A and 1B, we employed a
soft-voting ensemble of transformer models (BanglaBERT, MuRIL, IndicBERTv2).
For subtask 1C, we trained three multitask variants and aggregated their
predictions through a weighted voting ensemble. Our systems achieved micro-f1
scores of 72.75% (1A) and 72.69% (1B), and a weighted micro-f1 score of 72.62%
(1C). On the shared task leaderboard, these corresponded to 9th, 10th, and 7th
positions, respectively. These results highlight the promise of transformer
ensembles and weighted multitask frameworks for advancing Bangla hate speech
detection in low-resource contexts. We made experimental scripts publicly
available for the community.
\\ ( https://arxiv.org/abs/2511.07304 ,  914kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07311
Date: Mon, 10 Nov 2025 17:11:20 GMT   (897kb)

Title: ACE-ICD: Acronym Expansion As Data Augmentation For Automated ICD Coding
Authors: Tuan-Dung Le, Shohreh Haddadan, Thanh Q. Thieu
Categories: cs.CL
Comments: Camera ready version for IJCNLP-AACL 2025 (Findings)
\\
 Automatic ICD coding, the task of assigning disease and procedure codes to
electronic medical records, is crucial for clinical documentation and billing.
While existing methods primarily enhance model understanding of code
hierarchies and synonyms, they often overlook the pervasive use of medical
acronyms in clinical notes, a key factor in ICD code inference. To address this
gap, we propose a novel effective data augmentation technique that leverages
large language models to expand medical acronyms, allowing models to be trained
on their full form representations. Moreover, we incorporate consistency
training to regularize predictions by enforcing agreement between the original
and augmented documents. Extensive experiments on the MIMIC-III dataset
demonstrate that our approach, ACE-ICD establishes new state-of-the-art
performance across multiple settings, including common codes, rare codes, and
full-code assignments. Our code is publicly available.
\\ ( https://arxiv.org/abs/2511.07311 ,  897kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07317
Date: Mon, 10 Nov 2025 17:18:35 GMT   (1666kb)

Title: RLVE: Scaling Up Reinforcement Learning for Language Models with
 Adaptive Verifiable Environments
Authors: Zhiyuan Zeng, Hamish Ivison, Yiping Wang, Lifan Yuan, Shuyue Stella
 Li, Zhuorui Ye, Siting Li, Jacqueline He, Runlong Zhou, Tong Chen, Chenyang
 Zhao, Yulia Tsvetkov, Simon Shaolei Du, Natasha Jaques, Hao Peng, Pang Wei
 Koh, Hannaneh Hajishirzi
Categories: cs.CL cs.LG
\\
 We introduce Reinforcement Learning (RL) with Adaptive Verifiable
Environments (RLVE), an approach using verifiable environments that
procedurally generate problems and provide algorithmically verifiable rewards,
to scale up RL for language models (LMs). RLVE enables each verifiable
environment to dynamically adapt its problem difficulty distribution to the
policy model's capabilities as training progresses. In contrast, static data
distributions often lead to vanishing learning signals when problems are either
too easy or too hard for the policy. To implement RLVE, we create RLVE-Gym, a
large-scale suite of 400 verifiable environments carefully developed through
manual environment engineering. Using RLVE-Gym, we show that environment
scaling, i.e., expanding the collection of training environments, consistently
improves generalizable reasoning capabilities. RLVE with joint training across
all 400 environments in RLVE-Gym yields a 3.37% absolute average improvement
across six reasoning benchmarks, starting from one of the strongest 1.5B
reasoning LMs. By comparison, continuing this LM's original RL training yields
only a 0.49% average absolute gain despite using over 3x more compute. We
release our code publicly.
\\ ( https://arxiv.org/abs/2511.07317 ,  1666kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07318
Date: Mon, 10 Nov 2025 17:19:27 GMT   (7419kb)

Title: When Bias Pretends to Be Truth: How Spurious Correlations Undermine
 Hallucination Detection in LLMs
Authors: Shaowen Wang, Yiqi Dong, Ruinian Chang, Tansheng Zhu, Yuebo Sun,
 Kaifeng Lyu, Jian Li
Categories: cs.CL cs.AI cs.LG
\\
 Despite substantial advances, large language models (LLMs) continue to
exhibit hallucinations, generating plausible yet incorrect responses. In this
paper, we highlight a critical yet previously underexplored class of
hallucinations driven by spurious correlations -- superficial but statistically
prominent associations between features (e.g., surnames) and attributes (e.g.,
nationality) present in the training data. We demonstrate that these spurious
correlations induce hallucinations that are confidently generated, immune to
model scaling, evade current detection methods, and persist even after refusal
fine-tuning. Through systematically controlled synthetic experiments and
empirical evaluations on state-of-the-art open-source and proprietary LLMs
(including GPT-5), we show that existing hallucination detection methods, such
as confidence-based filtering and inner-state probing, fundamentally fail in
the presence of spurious correlations. Our theoretical analysis further
elucidates why these statistical biases intrinsically undermine
confidence-based detection techniques. Our findings thus emphasize the urgent
need for new approaches explicitly designed to address hallucinations caused by
spurious correlations.
\\ ( https://arxiv.org/abs/2511.07318 ,  7419kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07322
Date: Mon, 10 Nov 2025 17:22:32 GMT   (3447kb)

Title: FinRpt: Dataset, Evaluation System and LLM-based Multi-agent Framework
 for Equity Research Report Generation
Authors: Song Jin, Shuqi Li, Shukun Zhang, Rui Yan
Categories: cs.CL cs.AI
Comments: AAAI 2026
\\
 While LLMs have shown great success in financial tasks like stock prediction
and question answering, their application in fully automating Equity Research
Report generation remains uncharted territory. In this paper, we formulate the
Equity Research Report (ERR) Generation task for the first time. To address the
data scarcity and the evaluation metrics absence, we present an open-source
evaluation benchmark for ERR generation - FinRpt. We frame a Dataset
Construction Pipeline that integrates 7 financial data types and produces a
high-quality ERR dataset automatically, which could be used for model training
and evaluation. We also introduce a comprehensive evaluation system including
11 metrics to assess the generated ERRs. Moreover, we propose a multi-agent
framework specifically tailored to address this task, named FinRpt-Gen, and
train several LLM-based agents on the proposed datasets using Supervised
Fine-Tuning and Reinforcement Learning. Experimental results indicate the data
quality and metrics effectiveness of the benchmark FinRpt and the strong
performance of FinRpt-Gen, showcasing their potential to drive innovation in
the ERR generation field. All code and datasets are publicly available.
\\ ( https://arxiv.org/abs/2511.07322 ,  3447kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07380
Date: Mon, 10 Nov 2025 18:41:23 GMT   (918kb)

Title: Selecting Auxiliary Data via Neural Tangent Kernels for Low-Resource
 Domains
Authors: Pingjie Wang, Hongcheng Liu, Yusheng Liao, Ziqing Fan, Yaxin Du, Shuo
 Tang, Yanfeng Wang, Yu Wang
Categories: cs.CL
Comments: 27 pages
\\
 Large language models (LLMs) have achieved remarkable success across
widespread tasks, yet their application in low-resource domains remains a
significant challenge due to data scarcity and the high risk of overfitting.
While in-domain data is limited, there exist vast amounts of similar
general-domain data, and our initial findings reveal that they could
potentially serve as auxiliary supervision for domain enhancement. This
observation leads us to our central research question: \textbf{\textit{how to
effectively select the most valuable auxiliary data to maximize domain-specific
performance}}, particularly when traditional methods are inapplicable due to a
lack of large in-domain data pools or validation sets. To address this, we
propose \textbf{NTK-Selector}, a principled and efficient framework for
selecting general-domain auxiliary data to enhance domain-specific performance
via neural tangent kernels (NTK). Our method tackles two challenges of directly
applying NTK to LLMs, theoretical assumptions and prohibitive computational
cost, by empirically demonstrating a stable NTK-like behavior in LLMs during
LoRA fine-tuning and proposing a Jacobian-free approximation method. Extensive
experiments across four low-resource domains (medical, financial, legal, and
psychological) demonstrate that NTK-Selector consistently improves downstream
performance. Specifically, fine-tuning on 1,000 in-domain samples alone only
yielded +0.8 points for Llama3-8B-Instruct and +0.9 points for Qwen3-8B. In
contrast, enriching with 9,000 auxiliary samples selected by NTK-Selector led
to substantial \textbf{gains of +8.7 and +5.1 points}, which corresponds to a
\textbf{10.9x and 5.7x improvement} over the domain-only setting.
\\ ( https://arxiv.org/abs/2511.07380 ,  918kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07382
Date: Mon, 10 Nov 2025 18:41:44 GMT   (355kb)

Title: Retriv at BLP-2025 Task 2: Test-Driven Feedback-Guided Framework for
 Bangla-to-Python Code Generation
Authors: K M Nafi Asib, Sourav Saha, and Mohammed Moshiul Hoque
Categories: cs.CL
Comments: 8 pages, 1 figure, experimental scripts publicly available at
 https://github.com/NafiAsib/Retriv-BLP25-Task-2
\\
 Large Language Models (LLMs) have advanced the automated generation of code
from natural language prompts. However, low-resource languages (LRLs) like
Bangla remain underrepresented due to the limited availability of
instruction-to-code datasets and evaluation benchmarks. To address this, the
BLP Workshop at IJCNLP-AACL 2025 introduced a shared task on "Code Generation
in Bangla". In this work, we propose a method that combines instruction
prompting with a test-driven, feedback-guided iterative refinement process
using a fine-tuned Qwen2.5-14B model. The model generates code from Bangla
instructions, tests it against unit tests, and iteratively refines any failing
outputs through three evaluation passes, using test feedback to guide each
step. This approach helped our team "Retriv" to secure 2nd place in the shared
task with a Pass@1 score of 0.934. The analysis highlights challenges in Bangla
instruction understanding and Python code generation, emphasizing the need for
targeted methods in LRLs. We made experimental scripts publicly available for
the community.
\\ ( https://arxiv.org/abs/2511.07382 ,  355kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07384
Date: Mon, 10 Nov 2025 18:43:07 GMT   (1492kb)

Title: Teaching Pretrained Language Models to Think Deeper with Retrofitted
 Recurrence
Authors: Sean McLeish, Ang Li, John Kirchenbauer, Dayal Singh Kalra, Brian R.
 Bartoldson, Bhavya Kailkhura, Avi Schwarzschild, Jonas Geiping, Tom
 Goldstein, Micah Goldblum
Categories: cs.CL cs.AI cs.LG
Comments: code: https://github.com/mcleish7/retrofitting-recurrence, models:
 https://huggingface.co/collections/tomg-group-umd/retrofitting-recurrence
\\
 Recent advances in depth-recurrent language models show that recurrence can
decouple train-time compute and parameter count from test-time compute. In this
work, we study how to convert existing pretrained non-recurrent language models
into depth-recurrent models. We find that using a curriculum of recurrences to
increase the effective depth of the model over the course of training preserves
performance while reducing total computational cost. In our experiments, on
mathematics, we observe that converting pretrained models to recurrent ones
results in better performance at a given compute budget than simply
post-training the original non-recurrent language model.
\\ ( https://arxiv.org/abs/2511.07384 ,  1492kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07392
Date: Mon, 10 Nov 2025 18:47:24 GMT   (13562kb)

Title: Surgical Agent Orchestration Platform for Voice-directed Patient Data
 Interaction
Authors: Hyeryun Park, Byung Mo Gu, Jun Hee Lee, Byeong Hyeon Choi, Sekeun Kim,
 Hyun Koo Kim, Kyungsang Kim
Categories: cs.CL cs.AI
Comments: 22 pages, 12 figures, 1 table, Supplementary Information,
 Supplementary Data 1
\\
 In da Vinci robotic surgery, surgeons' hands and eyes are fully engaged in
the procedure, making it difficult to access and manipulate multimodal patient
data without interruption. We propose a voice-directed Surgical Agent
Orchestrator Platform (SAOP) built on a hierarchical multi-agent framework,
consisting of an orchestration agent and three task-specific agents driven by
Large Language Models (LLMs). These LLM-based agents autonomously plan, refine,
validate, and reason to map voice commands into specific tasks such as
retrieving clinical information, manipulating CT scans, or navigating 3D
anatomical models on the surgical video. We also introduce a Multi-level
Orchestration Evaluation Metric (MOEM) to comprehensively assess the
performance and robustness from command-level and category-level perspectives.
The SAOP achieves high accuracy and success rates across 240 voice commands,
while LLM-based agents improve robustness against speech recognition errors and
diverse or ambiguous free-form commands, demonstrating strong potential to
support minimally invasive da Vinci robotic surgery.
\\ ( https://arxiv.org/abs/2511.07392 ,  13562kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07397
Date: Mon, 10 Nov 2025 18:50:30 GMT   (577kb)

Title: ConvFill: Model Collaboration for Responsive Conversational Voice Agents
Authors: Vidya Srinivas, Zachary Englhardt, Maximus Powers, Shwetak Patel,
 Vikram Iyer
Categories: cs.CL
\\
 Deploying conversational voice agents with large language models faces a
critical challenge: cloud-based foundation models provide deep reasoning and
domain knowledge but introduce latency that disrupts natural conversation,
while on-device models respond immediately but lack sophistication. We propose
conversational infill, a task where a lightweight on-device model generates
contextually appropriate dialogue while seamlessly incorporating streaming
knowledge from a powerful backend model. This approach decouples response
latency from model capability, enabling systems that feel responsive while
accessing the full power of large-scale models. We present ConvFill, a 360M
parameter model trained on synthetic multi-domain conversations. Evaluation
across multiple backend models shows that conversational infill can be
successfully learned, with ConvFill achieving accuracy improvements of 36-42%
over standalone small models of the same size while consistently retaining
sub-200ms response latencies. Our results demonstrate the promise of this
approach for building on-device conversational agents that are both immediately
responsive and knowledgeable.
\\ ( https://arxiv.org/abs/2511.07397 ,  577kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07405
Date: Mon, 10 Nov 2025 18:54:40 GMT   (1143kb)

Title: SPOT: An Annotated French Corpus and Benchmark for Detecting Critical
 Interventions in Online Conversations
Authors: Manon Berriche, C\'elia Nouri, Chlo\'e Clavel, Jean-Philippe Cointet
Categories: cs.CL cs.CY
\\
 We introduce SPOT (Stopping Points in Online Threads), the first annotated
corpus translating the sociological concept of stopping point into a
reproducible NLP task. Stopping points are ordinary critical interventions that
pause or redirect online discussions through a range of forms (irony, subtle
doubt or fragmentary arguments) that frameworks like counterspeech or social
correction often overlook. We operationalize this concept as a binary
classification task and provide reliable annotation guidelines. The corpus
contains 43,305 manually annotated French Facebook comments linked to URLs
flagged as false information by social media users, enriched with contextual
metadata (article, post, parent comment, page or group, and source). We
benchmark fine-tuned encoder models (CamemBERT) and instruction-tuned LLMs
under various prompting strategies. Results show that fine-tuned encoders
outperform prompted LLMs in F1 score by more than 10 percentage points,
confirming the importance of supervised learning for emerging non-English
social media tasks. Incorporating contextual metadata further improves encoder
models F1 scores from 0.75 to 0.78. We release the anonymized dataset, along
with the annotation guidelines and code in our code repository, to foster
transparency and reproducible research.
\\ ( https://arxiv.org/abs/2511.07405 ,  1143kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05509
Date: Fri, 24 Oct 2025 08:39:18 GMT   (36507kb)

Title: Randomized-MLP Regularization Improves Domain Adaptation and
 Interpretability in DINOv2
Authors: Joel Valdivia Ortega, Lorenz Lamm, Franziska Eckardt, Benedikt
 Schworm, Marion Jasnin, Tingying Peng
Categories: cs.CV cs.AI
\\
 Vision Transformers (ViTs), such as DINOv2, achieve strong performance across
domains but often repurpose low-informative patch tokens in ways that reduce
the interpretability of attention and feature maps. This challenge is
especially evident in medical imaging, where domain shifts can degrade both
performance and transparency. In this paper, we introduce Randomized-MLP (RMLP)
regularization, a contrastive learning-based method that encourages more
semantically aligned representations. We use RMLPs when fine-tuning DINOv2 to
both medical and natural image modalities, showing that it improves or
maintains downstream performance while producing more interpretable attention
maps. We also provide a mathematical analysis of RMLPs, offering insights into
its role in enhancing ViT-based models and advancing our understanding of
contrastive learning.
\\ ( https://arxiv.org/abs/2511.05509 ,  36507kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05540
Date: Thu, 30 Oct 2025 12:16:45 GMT   (288kb)

Title: Token Is All You Need: Cognitive Planning through Sparse Intent
 Alignment
Authors: Shiyao Sang
Categories: cs.CV cs.AI cs.LG cs.RO
Comments: 6 pages, 2 figures. Preprint exploring a new cognitive paradigm for
 autonomous planning
MSC-class: 68T40
ACM-class: I.2.9; I.2.6; I.2.10
\\
 We challenge the long-standing assumption that exhaustive scene modeling is
required for high-performance end-to-end autonomous driving (E2EAD). Unlike
world-model approaches that rely on computationally intensive future scene
generation or vision-language-action (VLA) systems constrained by Markov
assumptions, we show that a minimal set of semantically rich tokens is
sufficient for effective planning. Experiments on the nuPlan benchmark (720
scenarios, over 11,000 samples) using perception-informed BEV representations
yield three key findings: (1) even without future prediction, our sparse
representation achieves 0.548 m ADE, comparable to or surpassing prior methods
reporting around 0.75 m on nuScenes; (2) conditioning trajectory decoding on
predicted future tokens reduces ADE to 0.479 m, a 12.6% improvement over
current-state baselines; and (3) explicit reconstruction loss offers no benefit
and may degrade performance under reliable perception inputs. Notably, we
observe the emergence of temporal fuzziness, where the model adaptively attends
to task-relevant semantics rather than aligning rigidly to fixed timestamps,
providing a cognitive advantage for planning under uncertainty. Our "token is
all you need" principle marks a paradigm shift from reconstructing the world to
understanding it, laying a foundation for cognitively inspired systems that
plan through imagination rather than reaction.
\\ ( https://arxiv.org/abs/2511.05540 ,  288kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05547
Date: Sat, 1 Nov 2025 19:05:09 GMT   (1180kb)

Title: Automated Invoice Data Extraction: Using LLM and OCR
Authors: Advait Thakur, Khushi Khanchandani, Akshita Shetty, Chaitravi Reddy
 and Ritisa Behera
Categories: cs.CV cs.AI
Comments: 10 pages, 3 figures
\\
 Conventional Optical Character Recognition (OCR) systems are challenged by
variant invoice layouts, handwritten text, and low- quality scans, which are
often caused by strong template dependencies that restrict their flexibility
across different document structures and layouts. Newer solutions utilize
advanced deep learning models such as Convolutional Neural Networks (CNN) as
well as Transformers, and domain-specific models for better layout analysis and
accuracy across various sections over varied document types. Large Language
Models (LLMs) have revolutionized extraction pipelines at their core with
sophisticated entity recognition and semantic comprehension to support complex
contextual relationship mapping without direct programming specification.
Visual Named Entity Recognition (NER) capabilities permit extraction from
invoice images with greater contextual sensitivity and much higher accuracy
rates than older approaches. Existing industry best practices utilize hybrid
architectures that blend OCR technology and LLM for maximum scalability and
minimal human intervention. This work introduces a holistic Artificial
Intelligence (AI) platform combining OCR, deep learning, LLMs, and graph
analytics to achieve unprecedented extraction quality and consistency.
\\ ( https://arxiv.org/abs/2511.05547 ,  1180kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05551
Date: Sun, 2 Nov 2025 18:31:02 GMT   (3924kb)

Title: In-Context-Learning-Assisted Quality Assessment Vision-Language Models
 for Metal Additive Manufacturing
Authors: Qiaojie Zheng, Jiucai Zhang, Xiaoli Zhang
Categories: cs.CV
Comments: 8 pages, 8 figures
\\
 Vision-based quality assessment in additive manufacturing often requires
dedicated machine learning models and application-specific datasets. However,
data collection and model training can be expensive and time-consuming. In this
paper, we leverage vision-language models' (VLMs') reasoning capabilities to
assess the quality of printed parts and introduce in-context learning (ICL) to
provide VLMs with necessary application-specific knowledge and demonstration
samples. This method eliminates the requirement for large application-specific
datasets for training models. We explored different sampling strategies for ICL
to search for the optimal configuration that makes use of limited samples. We
evaluated these strategies on two VLMs, Gemini-2.5-flash and Gemma3:27b, with
quality assessment tasks in wire-laser direct energy deposition processes. The
results show that ICL-assisted VLMs can reach quality classification accuracies
similar to those of traditional machine learning models while requiring only a
minimal number of samples. In addition, unlike traditional classification
models that lack transparency, VLMs can generate human-interpretable rationales
to enhance trust. Since there are no metrics to evaluate their interpretability
in manufacturing applications, we propose two metrics, knowledge relevance and
rationale validity, to evaluate the quality of VLMs' supporting rationales. Our
results show that ICL-assisted VLMs can address application-specific tasks with
limited data, achieving relatively high accuracy while also providing valid
supporting rationales for improved decision transparency.
\\ ( https://arxiv.org/abs/2511.05551 ,  3924kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05553
Date: Mon, 3 Nov 2025 10:24:49 GMT   (1299kb)

Title: EVLP:Learning Unified Embodied Vision-Language Planner with Reinforced
 Supervised Fine-Tuning
Authors: Xinyan Cai, Shiguang Wu, Dafeng Chi, Yuzheng Zhuang, Xingyue Quan,
 Jianye Hao, Qiang Guan
Categories: cs.CV cs.AI
\\
 In complex embodied long-horizon manipulation tasks, effective task
decomposition and execution require synergistic integration of textual logical
reasoning and visual-spatial imagination to ensure efficient and accurate
operation. Current methods fail to adopt a unified generation framework for
multimodal planning, lead to inconsistent in multimodal planning. To address
this challenge, we present \textbf{EVLP (Embodied Vision-Language Planner)}, an
innovative multimodal unified generation framework that jointly models
linguistic reasoning and visual generation. Our approach achieves multimodal
planning for long-horizon tasks through a novel training pipeline incorporating
dynamic pretraining and reinforced alignment. Our core innovations consist of
three key components: \textbf{1) Unified Multimodal Generation Framework}: For
understanding, We integrate semantic information with spatial features to
provide comprehensive visual perception. For generation, we directly learn the
joint distribution of discrete images for one-step visual synthesis, enabling
coordinated language-visual modeling through learnable cross-modal attention
mechanisms. \textbf{2) Dynamic Perception Pretraining}: We propose a
bidirectional dynamic alignment strategy employing inverse dynamics tasks and
forward dynamics tasks, effectively strengthening multimodal correlations
within a unified feature space. \textbf{3) Reinforced Supervised Fine-Tuning}:
While conducting instruction-based fine-tuning in the unified generation space,
we construct a reinforce loss to align the spatial logic between textual
actions and generated images, enabling the model to acquire spatio-awared
multimodal planning capabilities.
\\ ( https://arxiv.org/abs/2511.05553 ,  1299kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05554
Date: Mon, 3 Nov 2025 14:46:04 GMT   (13825kb)

Title: MCFCN: Multi-View Clustering via a Fusion-Consensus Graph Convolutional
 Network
Authors: Chenping Pei, Fadi Dornaika, Jingjun Bi
Categories: cs.CV cs.LG
\\
 Existing Multi-view Clustering (MVC) methods based on subspace learning focus
on consensus representation learning while neglecting the inherent topological
structure of data. Despite the integration of Graph Neural Networks (GNNs) into
MVC, their input graph structures remain susceptible to noise interference.
Methods based on Multi-view Graph Refinement (MGRC) also have limitations such
as insufficient consideration of cross-view consistency, difficulty in handling
hard-to-distinguish samples in the feature space, and disjointed optimization
processes caused by graph construction algorithms. To address these issues, a
Multi-View Clustering method via a Fusion-Consensus Graph Convolutional Network
(MCFCN) is proposed. The network learns the consensus graph of multi-view data
in an end-to-end manner and learns effective consensus representations through
a view feature fusion model and a Unified Graph Structure Adapter (UGA). It
designs Similarity Matrix Alignment Loss (SMAL) and Feature Representation
Alignment Loss (FRAL). With the guidance of consensus, it optimizes
view-specific graphs, preserves cross-view topological consistency, promotes
the construction of intra-class edges, and realizes effective consensus
representation learning with the help of GCN to improve clustering performance.
MCFCN demonstrates state-of-the-art performance on eight multi-view benchmark
datasets, and its effectiveness is verified by extensive qualitative and
quantitative implementations. The code will be provided at
https://github.com/texttao/MCFCN.
\\ ( https://arxiv.org/abs/2511.05554 ,  13825kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05557
Date: Mon, 3 Nov 2025 18:43:15 GMT   (1453kb)

Title: Compressing Multi-Task Model for Autonomous Driving via Pruning and
 Knowledge Distillation
Authors: Jiayuan Wang, Q. M. Jonathan Wu, Ning Zhang, Katsuya Suto, and Lei
 Zhong
Categories: cs.CV
\\
 Autonomous driving systems rely on panoptic perception to jointly handle
object detection, drivable area segmentation, and lane line segmentation.
Although multi-task learning is an effective way to integrate these tasks, its
increasing model parameters and complexity make deployment on on-board devices
difficult. To address this challenge, we propose a multi-task model compression
framework that combines task-aware safe pruning with feature-level knowledge
distillation. Our safe pruning strategy integrates Taylor-based channel
importance with gradient conflict penalty to keep important channels while
removing redundant and conflicting channels. To mitigate performance
degradation after pruning, we further design a task head-agnostic distillation
method that transfers intermediate backbone and encoder features from a teacher
to a student model as guidance. Experiments on the BDD100K dataset demonstrate
that our compressed model achieves a 32.7% reduction in parameters while
segmentation performance shows negligible accuracy loss and only a minor
decrease in detection (-1.2% for Recall and -1.8% for mAP50) compared to the
teacher. The compressed model still runs at 32.7 FPS in real-time. These
results show that combining pruning and knowledge distillation provides an
effective compression solution for multi-task panoptic perception.
\\ ( https://arxiv.org/abs/2511.05557 ,  1453kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05561
Date: Tue, 4 Nov 2025 02:27:18 GMT   (12980kb)

Title: FilletRec: A Lightweight Graph Neural Network with Intrinsic Features
 for Automated Fillet Recognition
Authors: Jiali Gao, Taoran Liu, Hongfei Ye, Jianjun Chen
Categories: cs.CV
\\
 Automated recognition and simplification of fillet features in CAD models is
critical for CAE analysis, yet it remains an open challenge. Traditional
rule-based methods lack robustness, while existing deep learning models suffer
from poor generalization and low accuracy on complex fillets due to their
generic design and inadequate training data. To address these issues, this
paper proposes an end-to-end, data-driven framework specifically for fillet
features. We first construct and release a large-scale, diverse benchmark
dataset for fillet recognition to address the inadequacy of existing data.
Based on it, we propose FilletRec, a lightweight graph neural network. The core
innovation of this network is its use of pose-invariant intrinsic geometric
features, such as curvature, enabling it to learn more fundamental geometric
patterns and thereby achieve high-precision recognition of complex geometric
topologies. Experiments show that FilletRec surpasses state-of-the-art methods
in both accuracy and generalization, while using only 0.2\%-5.4\% of the
parameters of baseline models, demonstrating high model efficiency. Finally,
the framework completes the automated workflow from recognition to
simplification by integrating an effective geometric simplification algorithm.
\\ ( https://arxiv.org/abs/2511.05561 ,  12980kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05564
Date: Tue, 4 Nov 2025 04:00:23 GMT   (927kb)

Title: M2S2L: Mamba-based Multi-Scale Spatial-temporal Learning for Video
 Anomaly Detection
Authors: Yang Liu, Boan Chen, Xiaoguang Zhu, Jing Liu, Peng Sun, Wei Zhou
Categories: cs.CV
Comments: IEEE VCIP 2025
\\
 Video anomaly detection (VAD) is an essential task in the image processing
community with prospects in video surveillance, which faces fundamental
challenges in balancing detection accuracy with computational efficiency. As
video content becomes increasingly complex with diverse behavioral patterns and
contextual scenarios, traditional VAD approaches struggle to provide robust
assessment for modern surveillance systems. Existing methods either lack
comprehensive spatial-temporal modeling or require excessive computational
resources for real-time applications. In this regard, we present a Mamba-based
multi-scale spatial-temporal learning (M2S2L) framework in this paper. The
proposed method employs hierarchical spatial encoders operating at multiple
granularities and multi-temporal encoders capturing motion dynamics across
different time scales. We also introduce a feature decomposition mechanism to
enable task-specific optimization for appearance and motion reconstruction,
facilitating more nuanced behavioral modeling and quality-aware anomaly
assessment. Experiments on three benchmark datasets demonstrate that M2S2L
framework achieves 98.5%, 92.1%, and 77.9% frame-level AUCs on UCSD Ped2, CUHK
Avenue, and ShanghaiTech respectively, while maintaining efficiency with 20.1G
FLOPs and 45 FPS inference speed, making it suitable for practical surveillance
deployment.
\\ ( https://arxiv.org/abs/2511.05564 ,  927kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05565
Date: Tue, 4 Nov 2025 06:06:02 GMT   (4316kb)

Title: In-Context Adaptation of VLMs for Few-Shot Cell Detection in Optical
 Microscopy
Authors: Shreyan Ganguly, Angona Biswas, Jaydeep Rade, Md Hasibul Hasan Hasib,
 Nabila Masud, Nitish Singla, Abhipsa Dash, Ushashi Bhattacharjee, Aditya
 Balu, Anwesha Sarkar, Adarsh Krishnamurthy, Soumik Sarkar
Categories: cs.CV cs.AI
\\
 Foundation vision-language models (VLMs) excel on natural images, but their
utility for biomedical microscopy remains underexplored. In this paper, we
investigate how in-context learning enables state-of-the-art VLMs to perform
few-shot object detection when large annotated datasets are unavailable, as is
often the case with microscopic images. We introduce the Micro-OD benchmark, a
curated collection of 252 images specifically curated for in-context learning,
with bounding-box annotations spanning 11 cell types across four sources,
including two in-lab expert-annotated sets. We systematically evaluate eight
VLMs under few-shot conditions and compare variants with and without implicit
test-time reasoning tokens. We further implement a hybrid Few-Shot Object
Detection (FSOD) pipeline that combines a detection head with a VLM-based
few-shot classifier, which enhances the few-shot performance of recent VLMs on
our benchmark. Across datasets, we observe that zero-shot performance is weak
due to the domain gap; however, few-shot support consistently improves
detection, with marginal gains achieved after six shots. We observe that models
with reasoning tokens are more effective for end-to-end localization, whereas
simpler variants are more suitable for classifying pre-localized crops. Our
results highlight in-context adaptation as a practical path for microscopy, and
our benchmark provides a reproducible testbed for advancing open-vocabulary
detection in biomedical imaging.
\\ ( https://arxiv.org/abs/2511.05565 ,  4316kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05566
Date: Tue, 4 Nov 2025 08:48:36 GMT   (10975kb)

Title: Efficient Online Continual Learning in Sensor-Based Human Activity
 Recognition
Authors: Yao Zhang, Souza Leite Clayton, Yu Xiao
Categories: cs.CV cs.AI
Comments: 13 pages
\\
 Machine learning models for sensor-based human activity recognition (HAR) are
expected to adapt post-deployment to recognize new activities and different
ways of performing existing ones. To address this need, Online Continual
Learning (OCL) mechanisms have been proposed, allowing models to update their
knowledge incrementally as new data become available while preserving
previously acquired information. However, existing OCL approaches for
sensor-based HAR are computationally intensive and require extensive labeled
samples to represent new changes. Recently, pre-trained model-based (PTM-based)
OCL approaches have shown significant improvements in performance and
efficiency for computer vision applications. These methods achieve strong
generalization capabilities by pre-training complex models on large datasets,
followed by fine-tuning on downstream tasks for continual learning. However,
applying PTM-based OCL approaches to sensor-based HAR poses significant
challenges due to the inherent heterogeneity of HAR datasets and the scarcity
of labeled data in post-deployment scenarios. This paper introduces PTRN-HAR,
the first successful application of PTM-based OCL to sensor-based HAR. Unlike
prior PTM-based OCL approaches, PTRN-HAR pre-trains the feature extractor using
contrastive loss with a limited amount of data. This extractor is then frozen
during the streaming stage. Furthermore, it replaces the conventional dense
classification layer with a relation module network. Our design not only
significantly reduces the resource consumption required for model training
while maintaining high performance, but also improves data efficiency by
reducing the amount of labeled data needed for effective continual learning, as
demonstrated through experiments on three public datasets, outperforming the
state-of-the-art. The code can be found here:
https://anonymous.4open.science/r/PTRN-HAR-AF60/
\\ ( https://arxiv.org/abs/2511.05566 ,  10975kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05567
Date: Tue, 4 Nov 2025 09:07:21 GMT   (31763kb)

Title: Automatic Extraction of Road Networks by using Teacher-Student Adaptive
 Structural Deep Belief Network and Its Application to Landslide Disaster
Authors: Shin Kamada and Takumi Ichimura
Categories: cs.CV cs.AI cs.LG
Journal-ref: IEEE Journal of Selected Topics in Applied Earth Observations and
 Remote Sensing, Vol.16, pp.6310-6324 (2023)
DOI: 10.1109/JSTARS.2023.3293593
\\
 An adaptive structural learning method of Restricted Boltzmann Machine (RBM)
and Deep Belief Network (DBN) has been developed as one of prominent deep
learning models. The neuron generation-annihilation algorithm in RBM and layer
generation algorithm in DBN make an optimal network structure for given input
during the learning. In this paper, our model is applied to an automatic
recognition method of road network system, called RoadTracer. RoadTracer can
generate a road map on the ground surface from aerial photograph data. A novel
method of RoadTracer using the Teacher-Student based ensemble learning model of
Adaptive DBN is proposed, since the road maps contain many complicated features
so that a model with high representation power to detect should be required.
The experimental results showed the detection accuracy of the proposed model
was improved from 40.0\% to 89.0\% on average in the seven major cities among
the test dataset. In addition, we challenged to apply our method to the
detection of available roads when landslide by natural disaster is occurred, in
order to rapidly obtain a way of transportation. For fast inference, a small
size of the trained model was implemented on a small embedded edge device as
lightweight deep learning. We reported the detection results for the satellite
image before and after the rainfall disaster in Japan.
\\ ( https://arxiv.org/abs/2511.05567 ,  31763kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05570
Date: Tue, 4 Nov 2025 12:40:12 GMT   (1696kb)

Title: Do Street View Imagery and Public Participation GIS align: Comparative
 Analysis of Urban Attractiveness
Authors: Milad Malekzadeh, Elias Willberg, Jussi Torkko, Silviya Korpilo,
 Kamyar Hasanzadeh, Olle J\"arv, Tuuli Toivonen
Categories: cs.CV cs.CY cs.LG
\\
 As digital tools increasingly shape spatial planning practices, understanding
how different data sources reflect human experiences of urban environments is
essential. Street View Imagery (SVI) and Public Participation GIS (PPGIS)
represent two prominent approaches for capturing place-based perceptions that
can support urban planning decisions, yet their comparability remains
underexplored. This study investigates the alignment between SVI-based
perceived attractiveness and residents' reported experiences gathered via a
city-wide PPGIS survey in Helsinki, Finland. Using participant-rated SVI data
and semantic image segmentation, we trained a machine learning model to predict
perceived attractiveness based on visual features. We compared these
predictions to PPGIS-identified locations marked as attractive or unattractive,
calculating agreement using two sets of strict and moderate criteria. Our
findings reveal only partial alignment between the two datasets. While
agreement (with a moderate threshold) reached 67% for attractive and 77% for
unattractive places, agreement (with a strict threshold) dropped to 27% and
29%, respectively. By analysing a range of contextual variables, including
noise, traffic, population presence, and land use, we found that non-visual
cues significantly contributed to mismatches. The model failed to account for
experiential dimensions such as activity levels and environmental stressors
that shape perceptions but are not visible in images. These results suggest
that while SVI offers a scalable and visual proxy for urban perception, it
cannot fully substitute the experiential richness captured through PPGIS. We
argue that both methods are valuable but serve different purposes; therefore, a
more integrated approach is needed to holistically capture how people perceive
urban environments.
\\ ( https://arxiv.org/abs/2511.05570 ,  1696kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05571
Date: Tue, 4 Nov 2025 13:12:25 GMT   (1595kb)

Title: C3-Diff: Super-resolving Spatial Transcriptomics via Cross-modal
 Cross-content Contrastive Diffusion Modelling
Authors: Xiaofei Wang, Stephen Price, Chao Li
Categories: cs.CV cs.AI
\\
 The rapid advancement of spatial transcriptomics (ST), i.e., spatial gene
expressions, has made it possible to measure gene expression within original
tissue, enabling us to discover molecular mechanisms. However, current ST
platforms frequently suffer from low resolution, limiting the in-depth
understanding of spatial gene expression. Super-resolution approaches promise
to enhance ST maps by integrating histology images with gene expressions of
profiled tissue spots. However, it remains a challenge to model the
interactions between histology images and gene expressions for effective ST
enhancement. This study presents a cross-modal cross-content contrastive
diffusion framework, called C3-Diff, for ST enhancement with histology images
as guidance. In C3-Diff, we firstly analyze the deficiency of traditional
contrastive learning paradigm, which is then refined to extract both
modal-invariant and content-invariant features of ST maps and histology images.
Further, to overcome the problem of low sequencing sensitivity in ST maps, we
perform nosing-based information augmentation on the surface of feature unit
hypersphere. Finally, we propose a dynamic cross-modal imputation-based
training strategy to mitigate ST data scarcity. We tested C3-Diff by
benchmarking its performance on four public datasets, where it achieves
significant improvements over competing methods. Moreover, we evaluate C3-Diff
on downstream tasks of cell type localization, gene expression correlation and
single-cell-level gene expression prediction, promoting AI-enhanced
biotechnology for biomedical research and clinical applications. Codes are
available at https://github.com/XiaofeiWang2018/C3-Diff.
\\ ( https://arxiv.org/abs/2511.05571 ,  1595kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05573
Date: Tue, 4 Nov 2025 16:20:38 GMT   (4305kb)

Title: Video Text Preservation with Synthetic Text-Rich Videos
Authors: Ziyang Liu, Kevin Valencia, Justin Cui
Categories: cs.CV cs.AI
\\
 While Text-To-Video (T2V) models have advanced rapidly, they continue to
struggle with generating legible and coherent text within videos. In
particular, existing models often fail to render correctly even short phrases
or words and previous attempts to address this problem are computationally
expensive and not suitable for video generation. In this work, we investigate a
lightweight approach to improve T2V diffusion models using synthetic
supervision. We first generate text-rich images using a text-to-image (T2I)
diffusion model, then animate them into short videos using a text-agnostic
image-to-video (I2v) model. These synthetic video-prompt pairs are used to
fine-tune Wan2.1, a pre-trained T2V model, without any architectural changes.
Our results show improvement in short-text legibility and temporal consistency
with emerging structural priors for longer text. These findings suggest that
curated synthetic data and weak supervision offer a practical path toward
improving textual fidelity in T2V generation.
\\ ( https://arxiv.org/abs/2511.05573 ,  4305kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05574
Date: Tue, 4 Nov 2025 17:01:53 GMT   (1091kb)

Title: Elements of Active Continuous Learning and Uncertainty Self-Awareness: a
 Narrow Implementation for Face and Facial Expression Recognition
Authors: Stanislav Selitskiy
Categories: cs.CV cs.AI
DOI: 10.1007/978-3-031-19907-3_38
\\
 Reflection on one's thought process and making corrections to it if there
exists dissatisfaction in its performance is, perhaps, one of the essential
traits of intelligence. However, such high-level abstract concepts mandatory
for Artificial General Intelligence can be modelled even at the low level of
narrow Machine Learning algorithms. Here, we present the self-awareness
mechanism emulation in the form of a supervising artificial neural network
(ANN) observing patterns in activations of another underlying ANN in a search
for indications of the high uncertainty of the underlying ANN and, therefore,
the trustworthiness of its predictions. The underlying ANN is a convolutional
neural network (CNN) ensemble employed for face recognition and facial
expression tasks. The self-awareness ANN has a memory region where its past
performance information is stored, and its learnable parameters are adjusted
during the training to optimize the performance. The trustworthiness verdict
triggers the active learning mode, giving elements of agency to the machine
learning algorithm that asks for human help in high uncertainty and confusion
conditions.
\\ ( https://arxiv.org/abs/2511.05574 ,  1091kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05575
Date: Tue, 4 Nov 2025 18:56:49 GMT   (14438kb)

Title: DiffSwap++: 3D Latent-Controlled Diffusion for Identity-Preserving Face
 Swapping
Authors: Weston Bondurant, Arkaprava Sinha, Hieu Le, Srijan Das and Stephanie
 Schuckers
Categories: cs.CV
\\
 Diffusion-based approaches have recently achieved strong results in face
swapping, offering improved visual quality over traditional GAN-based methods.
However, even state-of-the-art models often suffer from fine-grained artifacts
and poor identity preservation, particularly under challenging poses and
expressions. A key limitation of existing approaches is their failure to
meaningfully leverage 3D facial structure, which is crucial for disentangling
identity from pose and expression. In this work, we propose DiffSwap++, a novel
diffusion-based face-swapping pipeline that incorporates 3D facial latent
features during training. By guiding the generation process with 3D-aware
representations, our method enhances geometric consistency and improves the
disentanglement of facial identity from appearance attributes. We further
design a diffusion architecture that conditions the denoising process on both
identity embeddings and facial landmarks, enabling high-fidelity and
identity-preserving face swaps. Extensive experiments on CelebA, FFHQ, and
CelebV-Text demonstrate that DiffSwap++ outperforms prior methods in preserving
source identity while maintaining target pose and expression. Additionally, we
introduce a biometric-style evaluation and conduct a user study to further
validate the realism and effectiveness of our approach. Code will be made
publicly available at https://github.com/WestonBond/DiffSwapPP
\\ ( https://arxiv.org/abs/2511.05575 ,  14438kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05590
Date: Wed, 5 Nov 2025 12:28:14 GMT   (2083kb)

Title: Beyond Softmax: Dual-Branch Sigmoid Architecture for Accurate Class
 Activation Maps
Authors: Yoojin Oh, Junhyug Noh
Categories: cs.CV cs.LG
Comments: Accepted at BMVC 2025
\\
 Class Activation Mapping (CAM) and its extensions have become indispensable
tools for visualizing the evidence behind deep network predictions. However, by
relying on a final softmax classifier, these methods suffer from two
fundamental distortions: additive logit shifts that arbitrarily bias importance
scores, and sign collapse that conflates excitatory and inhibitory features. We
propose a simple, architecture-agnostic dual-branch sigmoid head that decouples
localization from classification. Given any pretrained model, we clone its
classification head into a parallel branch ending in per-class sigmoid outputs,
freeze the original softmax head, and fine-tune only the sigmoid branch with
class-balanced binary supervision. At inference, softmax retains recognition
accuracy, while class evidence maps are generated from the sigmoid branch --
preserving both magnitude and sign of feature contributions. Our method
integrates seamlessly with most CAM variants and incurs negligible overhead.
Extensive evaluations on fine-grained tasks (CUB-200-2011, Stanford Cars) and
WSOL benchmarks (ImageNet-1K, OpenImages30K) show improved explanation fidelity
and consistent Top-1 Localization gains -- without any drop in classification
accuracy. Code is available at https://github.com/finallyupper/beyond-softmax.
\\ ( https://arxiv.org/abs/2511.05590 ,  2083kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05600
Date: Thu, 6 Nov 2025 00:51:42 GMT   (735kb)

Title: Google-MedGemma Based Abnormality Detection in Musculoskeletal
 radiographs
Authors: Soumyajit Maity, Pranjal Kamboj, Sneha Maity, Rajat Singh, Sankhadeep
 Chatterjee
Categories: cs.CV cs.AI
Comments: Proceedings of ICICT 2026, London, Springer (Forthcoming, February
 2026; Accepted for Publication)
Report-no: ICICT-2026-217
\\
 This paper proposes a MedGemma-based framework for automatic abnormality
detection in musculoskeletal radiographs. Departing from conventional
autoencoder and neural network pipelines, the proposed method leverages the
MedGemma foundation model, incorporating a SigLIP-derived vision encoder
pretrained on diverse medical imaging modalities. Preprocessed X-ray images are
encoded into high-dimensional embeddings using the MedGemma vision backbone,
which are subsequently passed through a lightweight multilayer perceptron for
binary classification. Experimental assessment reveals that the MedGemma-driven
classifier exhibits strong performance, exceeding conventional convolutional
and autoencoder-based metrics. Additionally, the model leverages MedGemma's
transfer learning capabilities, enhancing generalization and optimizing feature
engineering. The integration of a modern medical foundation model not only
enhances representation learning but also facilitates modular training
strategies such as selective encoder block unfreezing for efficient domain
adaptation. The findings suggest that MedGemma-powered classification systems
can advance clinical radiograph triage by providing scalable and accurate
abnormality detection, with potential for broader applications in automated
medical image analysis.
 Keywords: Google MedGemma, MURA, Medical Image, Classification.
\\ ( https://arxiv.org/abs/2511.05600 ,  735kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05604
Date: Thu, 6 Nov 2025 06:35:06 GMT   (14251kb)

Title: In-process 3D Deviation Mapping and Defect Monitoring (3D-DM2) in High
 Production-rate Robotic Additive Manufacturing
Authors: Subash Gautam, Alejandro Vargas-Uscategui, Peter King, Hans Lohr,
 Alireza Bab-Hadiashar, Ivan Cole, Ehsan Asadi
Categories: cs.CV cs.RO
\\
 Additive manufacturing (AM) is an emerging digital manufacturing technology
to produce complex and freeform objects through a layer-wise deposition. High
deposition rate robotic AM (HDRRAM) processes, such as cold spray additive
manufacturing (CSAM), offer significantly increased build speeds by delivering
large volumes of material per unit time. However, maintaining shape accuracy
remains a critical challenge, particularly due to process instabilities in
current open-loop systems. Detecting these deviations as they occur is
essential to prevent error propagation, ensure part quality, and minimize
post-processing requirements. This study presents a real-time monitoring system
to acquire and reconstruct the growing part and directly compares it with a
near-net reference model to detect the shape deviation during the manufacturing
process. The early identification of shape inconsistencies, followed by
segmenting and tracking each deviation region, paves the way for timely
intervention and compensation to achieve consistent part quality.
\\ ( https://arxiv.org/abs/2511.05604 ,  14251kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05609
Date: Thu, 6 Nov 2025 09:21:57 GMT   (8359kb)

Title: Walking the Schr\"odinger Bridge: A Direct Trajectory for Text-to-3D
 Generation
Authors: Ziying Li, Xuequan Lu, Xinkui Zhao, Guanjie Cheng, Shuiguang Deng,
 Jianwei Yin
Categories: cs.CV cs.AI
Comments: NeurIPS 2025; https://github.com/emmaleee789/TraCe.git
\\
 Recent advancements in optimization-based text-to-3D generation heavily rely
on distilling knowledge from pre-trained text-to-image diffusion models using
techniques like Score Distillation Sampling (SDS), which often introduce
artifacts such as over-saturation and over-smoothing into the generated 3D
assets. In this paper, we address this essential problem by formulating the
generation process as learning an optimal, direct transport trajectory between
the distribution of the current rendering and the desired target distribution,
thereby enabling high-quality generation with smaller Classifier-free Guidance
(CFG) values. At first, we theoretically establish SDS as a simplified instance
of the Schr\"odinger Bridge framework. We prove that SDS employs the reverse
process of an Schr\"odinger Bridge, which, under specific conditions (e.g., a
Gaussian noise as one end), collapses to SDS's score function of the
pre-trained diffusion model. Based upon this, we introduce Trajectory-Centric
Distillation (TraCe), a novel text-to-3D generation framework, which
reformulates the mathematically trackable framework of Schr\"odinger Bridge to
explicitly construct a diffusion bridge from the current rendering to its
text-conditioned, denoised target, and trains a LoRA-adapted model on this
trajectory's score dynamics for robust 3D optimization. Comprehensive
experiments demonstrate that TraCe consistently achieves superior quality and
fidelity to state-of-the-art techniques.
\\ ( https://arxiv.org/abs/2511.05609 ,  8359kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05611
Date: Thu, 6 Nov 2025 13:00:22 GMT   (8649kb)

Title: Pose-Aware Multi-Level Motion Parsing for Action Quality Assessment
Authors: Shuaikang Zhu, Yang Yang, Chen Sun
Categories: cs.CV
\\
 Human pose serves as a cornerstone of action quality assessment (AQA), where
subtle spatial-temporal variations in pose often distinguish excellence from
mediocrity. In high-level competitions, these nuanced differences become
decisive factors in scoring. In this paper, we propose a novel multi-level
motion parsing framework for AQA based on enhanced spatial-temporal pose
features. On the first level, the Action-Unit Parser is designed with the help
of pose extraction to achieve precise action segmentation and comprehensive
local-global pose representations. On the second level, Motion Parser is used
by spatial-temporal feature learning to capture pose changes and appearance
details for each action-unit. Meanwhile, some special conditions other than
body-related will impact action scoring, like water splash in diving. In this
work, we design an additional Condition Parser to offer users more flexibility
in their choices. Finally, Weight-Adjust Scoring Module is introduced to better
accommodate the diverse requirements of various action types and the
multi-scale nature of action-units. Extensive evaluations on large-scale diving
sports datasets demonstrate that our multi-level motion parsing framework
achieves state-of-the-art performance in both action segmentation and action
scoring tasks.
\\ ( https://arxiv.org/abs/2511.05611 ,  8649kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05616
Date: Thu, 6 Nov 2025 18:59:54 GMT   (5924kb)

Title: Personalized Image Editing in Text-to-Image Diffusion Models via
 Collaborative Direct Preference Optimization
Authors: Connor Dunlop, Matthew Zheng, Kavana Venkatesh, Pinar Yanardag
Categories: cs.CV cs.AI
Comments: Published at NeurIPS'25 Main Conference
\\
 Text-to-image (T2I) diffusion models have made remarkable strides in
generating and editing high-fidelity images from text. Yet, these models remain
fundamentally generic, failing to adapt to the nuanced aesthetic preferences of
individual users. In this work, we present the first framework for personalized
image editing in diffusion models, introducing Collaborative Direct Preference
Optimization (C-DPO), a novel method that aligns image edits with user-specific
preferences while leveraging collaborative signals from like-minded
individuals. Our approach encodes each user as a node in a dynamic preference
graph and learns embeddings via a lightweight graph neural network, enabling
information sharing across users with overlapping visual tastes. We enhance a
diffusion model's editing capabilities by integrating these personalized
embeddings into a novel DPO objective, which jointly optimizes for individual
alignment and neighborhood coherence. Comprehensive experiments, including user
studies and quantitative benchmarks, demonstrate that our method consistently
outperforms baselines in generating edits that are aligned with user
preferences.
\\ ( https://arxiv.org/abs/2511.05616 ,  5924kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05617
Date: Thu, 6 Nov 2025 19:27:15 GMT   (1380kb)

Title: Convolutional Fully-Connected Capsule Network (CFC-CapsNet): A Novel and
 Fast Capsule Network
Authors: Pouya Shiri, Amirali Baniasadi
Categories: cs.CV
DOI: 10.1007/s11265-021-01731-6
\\
 A Capsule Network (CapsNet) is a relatively new classifier and one of the
possible successors of Convolutional Neural Networks (CNNs). CapsNet maintains
the spatial hierarchies between the features and outperforms CNNs at
classifying images including overlapping categories. Even though CapsNet works
well on small-scale datasets such as MNIST, it fails to achieve a similar level
of performance on more complicated datasets and real applications. In addition,
CapsNet is slow compared to CNNs when performing the same task and relies on a
higher number of parameters. In this work, we introduce Convolutional
Fully-Connected Capsule Network (CFC-CapsNet) to address the shortcomings of
CapsNet by creating capsules using a different method. We introduce a new layer
(CFC layer) as an alternative solution to creating capsules. CFC-CapsNet
produces fewer, yet more powerful capsules resulting in higher network
accuracy. Our experiments show that CFC-CapsNet achieves competitive accuracy,
faster training and inference and uses less number of parameters on the
CIFAR-10, SVHN and Fashion-MNIST datasets compared to conventional CapsNet.
\\ ( https://arxiv.org/abs/2511.05617 ,  1380kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05622
Date: Thu, 6 Nov 2025 23:12:43 GMT   (128kb)

Title: Grounding Foundational Vision Models with 3D Human Poses for Robust
 Action Recognition
Authors: Nicholas Babey, Tiffany Gu, Yiheng Li, Cristian Meo, Kevin Zhu
Categories: cs.CV cs.AI cs.LG cs.RO
Comments: Accepted at NeurIPS 2025 SpaVLE, for code see
 https://github.com/nbabey20/groundactrec , 9 pages, 1 figure
\\
 For embodied agents to effectively understand and interact within the world
around them, they require a nuanced comprehension of human actions grounded in
physical space. Current action recognition models, often relying on RGB video,
learn superficial correlations between patterns and action labels, so they
struggle to capture underlying physical interaction dynamics and human poses in
complex scenes. We propose a model architecture that grounds action recognition
in physical space by fusing two powerful, complementary representations: V-JEPA
2's contextual, predictive world dynamics and CoMotion's explicit,
occlusion-tolerant human pose data. Our model is validated on both the InHARD
and UCF-19-Y-OCC benchmarks for general action recognition and high-occlusion
action recognition, respectively. Our model outperforms three other baselines,
especially within complex, occlusive scenes. Our findings emphasize a need for
action recognition to be supported by spatial understanding instead of
statistical pattern recognition.
\\ ( https://arxiv.org/abs/2511.05622 ,  128kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05623
Date: Thu, 6 Nov 2025 23:13:03 GMT   (5767kb)

Title: Registration-Free Monitoring of Unstructured Point Cloud Data via
 Intrinsic Geometrical Properties
Authors: Mariafrancesca Patalano, Giovanna Capizzi, Kamran Paynabar
Categories: cs.CV cs.LG stat.ME stat.ML
\\
 Modern sensing technologies have enabled the collection of unstructured point
cloud data (PCD) of varying sizes, which are used to monitor the geometric
accuracy of 3D objects. PCD are widely applied in advanced manufacturing
processes, including additive, subtractive, and hybrid manufacturing. To ensure
the consistency of analysis and avoid false alarms, preprocessing steps such as
registration and mesh reconstruction are commonly applied prior to monitoring.
However, these steps are error-prone, time-consuming and may introduce
artifacts, potentially affecting monitoring outcomes. In this paper, we present
a novel registration-free approach for monitoring PCD of complex shapes,
eliminating the need for both registration and mesh reconstruction. Our
proposal consists of two alternative feature learning methods and a common
monitoring scheme. Feature learning methods leverage intrinsic geometric
properties of the shape, captured via the Laplacian and geodesic distances. In
the monitoring scheme, thresholding techniques are used to further select
intrinsic features most indicative of potential out-of-control conditions.
Numerical experiments and case studies highlight the effectiveness of the
proposed approach in identifying different types of defects.
\\ ( https://arxiv.org/abs/2511.05623 ,  5767kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05681
Date: Fri, 7 Nov 2025 19:51:11 GMT   (20489kb)

Title: Culture in Action: Evaluating Text-to-Image Models through Social
 Activities
Authors: Sina Malakouti, Boqing Gong, Adriana Kovashka
Categories: cs.CV
\\
 Text-to-image (T2I) diffusion models achieve impressive photorealism by
training on large-scale web data, but models inherit cultural biases and fail
to depict underrepresented regions faithfully. Existing cultural benchmarks
focus mainly on object-centric categories (e.g., food, attire, and
architecture), overlooking the social and daily activities that more clearly
reflect cultural norms. Few metrics exist for measuring cultural faithfulness.
We introduce CULTIVate, a benchmark for evaluating T2I models on cross-cultural
activities (e.g., greetings, dining, games, traditional dances, and cultural
celebrations). CULTIVate spans 16 countries with 576 prompts and more than
19,000 images, and provides an explainable descriptor-based evaluation
framework across multiple cultural dimensions, including background, attire,
objects, and interactions. We propose four metrics to measure cultural
alignment, hallucination, exaggerated elements, and diversity. Our findings
reveal systematic disparities: models perform better for global north countries
than for the global south, with distinct failure modes across T2I systems.
Human studies confirm that our metrics correlate more strongly with human
judgments than existing text-image metrics.
\\ ( https://arxiv.org/abs/2511.05681 ,  20489kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05682
Date: Fri, 7 Nov 2025 19:56:00 GMT   (39305kb)

Title: VMDT: Decoding the Trustworthiness of Video Foundation Models
Authors: Yujin Potter, Zhun Wang, Nicholas Crispino, Kyle Montgomery, Alexander
 Xiong, Ethan Y. Chang, Francesco Pinto, Yuqi Chen, Rahul Gupta, Morteza
 Ziyadi, Christos Christodoulopoulos, Bo Li, Chenguang Wang, Dawn Song
Categories: cs.CV cs.LG
Comments: NeurIPS 2025 Datasets & Benchmarks
\\
 As foundation models become more sophisticated, ensuring their
trustworthiness becomes increasingly critical; yet, unlike text and image, the
video modality still lacks comprehensive trustworthiness benchmarks. We
introduce VMDT (Video-Modal DecodingTrust), the first unified platform for
evaluating text-to-video (T2V) and video-to-text (V2T) models across five key
trustworthiness dimensions: safety, hallucination, fairness, privacy, and
adversarial robustness. Through our extensive evaluation of 7 T2V models and 19
V2T models using VMDT, we uncover several significant insights. For instance,
all open-source T2V models evaluated fail to recognize harmful queries and
often generate harmful videos, while exhibiting higher levels of unfairness
compared to image modality models. In V2T models, unfairness and privacy risks
rise with scale, whereas hallucination and adversarial robustness improve --
though overall performance remains low. Uniquely, safety shows no correlation
with model size, implying that factors other than scale govern current safety
levels. Our findings highlight the urgent need for developing more robust and
trustworthy video foundation models, and VMDT provides a systematic framework
for measuring and tracking progress toward this goal. The code is available at
https://sunblaze-ucb.github.io/VMDT-page/.
\\ ( https://arxiv.org/abs/2511.05682 ,  39305kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05702
Date: Fri, 7 Nov 2025 20:41:50 GMT   (7262kb)

Title: Pedicle Screw Pairing and Registration for Screw Pose Estimation from
 Dual C-arm Images Using CAD Models
Authors: Yehyun Suh, Lin Li, Aric Plumley, Chaochao Zhou, Daniel Moyer, Kongbin
 Kang
Categories: cs.CV
\\
 Accurate matching of pedicle screws in both anteroposterior (AP) and lateral
(LAT) images is critical for successful spinal decompression and stabilization
during surgery. However, establishing screw correspondence, especially in LAT
views, remains a significant clinical challenge. This paper introduces a method
to address pedicle screw correspondence and pose estimation from dual C-arm
images. By comparing screw combinations, the approach demonstrates consistent
accuracy in both pairing and registration tasks. The method also employs 2D-3D
alignment with screw CAD 3D models to accurately pair and estimate screw pose
from dual views. Our results show that the correct screw combination
consistently outperforms incorrect pairings across all test cases, even prior
to registration. After registration, the correct combination further enhances
alignment between projections and images, significantly reducing projection
error. This approach shows promise for improving surgical outcomes in spinal
procedures by providing reliable feedback on screw positioning.
\\ ( https://arxiv.org/abs/2511.05702 ,  7262kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05705
Date: Fri, 7 Nov 2025 20:50:54 GMT   (6901kb)

Title: Long Grounded Thoughts: Distilling Compositional Visual Reasoning Chains
 at Scale
Authors: David Acuna, Chao-Han Huck Yang, Yuntian Deng, Jaehun Jung, Ximing Lu,
 Prithviraj Ammanabrolu, Hyunwoo Kim, Yuan-Hong Liao and Yejin Choi
Categories: cs.CV cs.AI cs.CL
Comments: Project Page: https://nvlabs.github.io/LongGroundedThoughts/
\\
 Recent progress in multimodal reasoning has been driven largely by
undisclosed datasets and proprietary data synthesis recipes, leaving open
questions about how to systematically build large-scale, vision-centric
reasoning datasets, particularly for tasks that go beyond visual math. In this
work, we introduce a new reasoning data generation framework spanning diverse
skills and levels of complexity with over 1M high-quality synthetic
vision-centric questions. The dataset also includes preference data and
instruction prompts supporting both offline and online RL. Our synthesis
framework proceeds in two stages: (1) scale; and (2) complexity. Reasoning
traces are then synthesized through a two-stage process that leverages VLMs and
reasoning LLMs, producing CoT traces for VLMs that capture the richness and
diverse cognitive behaviors found in frontier reasoning models. Remarkably, we
show that finetuning Qwen2.5-VL-7B on our data outperforms all open-data
baselines across all evaluated vision-centric benchmarks, and even surpasses
strong closed-data models such as MiMo-VL-7B-RL on V* Bench, CV-Bench and
MMStar-V. Perhaps most surprising, despite being entirely vision-centric, our
data transfers positively to text-only reasoning (MMLU-Pro) and audio reasoning
(MMAU), demonstrating its effectiveness. Similarly, despite not containing
videos or embodied visual data, we observe notable gains when evaluating on a
single-evidence embodied QA benchmark (NiEH). Finally, we use our data to
analyze the entire VLM post-training pipeline. Our empirical analysis
highlights that (i) SFT on high-quality data with non-linear reasoning traces
is essential for effective online RL, (ii) staged offline RL matches online
RL's performance while reducing compute demands, and (iii) careful SFT on high
quality data can substantially improve out-of-domain, cross-modality transfer.
\\ ( https://arxiv.org/abs/2511.05705 ,  6901kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05731
Date: Fri, 7 Nov 2025 21:45:18 GMT   (4522kb)

Title: Towards Better Ultrasound Video Segmentation Foundation Model: An
 Empirical study on SAM2 Finetuning from Data Perspective
Authors: Xing Yao, Ahana Gangopadhyay, Hsi-Ming Chang, Ravi Soni
Categories: cs.CV
\\
 Ultrasound (US) video segmentation remains a challenging problem due to
strong inter- and intra-dataset variability, motion artifacts, and limited
annotated data. Although foundation models such as Segment Anything Model 2
(SAM2) demonstrate strong zero-shot and prompt-guided segmentation
capabilities, their performance deteriorates substantially when transferred to
medical imaging domains. Current adaptation studies mainly emphasize
architectural modifications, while the influence of data characteristics and
training regimes has not been systematically examined. In this study, we
present a comprehensive, data-centric investigation of SAM2 adaptation for
ultrasound video segmentation. We analyze how training-set size, video
duration, and augmentation schemes affect adaptation performance under three
paradigms: task-specific fine-tuning, intermediate adaptation, and multi-task
joint training, across five SAM2 variants and multiple prompting modes. We
further design six ultrasound-specific augmentations, assessing their effect
relative to generic strategies. Experiments on three representative ultrasound
datasets reveal that data scale and temporal context play a more decisive role
than model architecture or initialization. Moreover, joint training offers an
efficient compromise between modality alignment and task specialization. This
work aims to provide empirical insights for developing efficient, data-aware
adaptation pipelines for SAM2 in ultrasound video analysis.
\\ ( https://arxiv.org/abs/2511.05731 ,  4522kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05760
Date: Fri, 7 Nov 2025 23:07:19 GMT   (4976kb)

Title: A Second-Order Attention Mechanism For Prostate Cancer Segmentation and
 Detection in Bi-Parametric MRI
Authors: Mateo Ortiz, Juan Olmos, Fabio Mart\'inez
Categories: cs.CV
Comments: Accepted at the 28th Iberoamerican Congress on Pattern Recognition
 (CIARP 2025). To appear in Lecture Notes in Computer Science (LNCS), Springer
ACM-class: I.4.6; I.5.4
\\
 The detection of clinically significant prostate cancer lesions (csPCa) from
biparametric magnetic resonance imaging (bp-MRI) has emerged as a noninvasive
imaging technique for improving accurate diagnosis. Nevertheless, the analysis
of such images remains highly dependent on the subjective expert
interpretation. Deep learning approaches have been proposed for csPCa lesions
detection and segmentation, but they remain limited due to their reliance on
extensively annotated datasets. Moreover, the high lesion variability across
prostate zones poses additional challenges, even for expert radiologists. This
work introduces a second-order geometric attention (SOGA) mechanism that guides
a dedicated segmentation network, through skip connections, to detect csPCa
lesions. The proposed attention is modeled on the Riemannian manifold, learning
from symmetric positive definitive (SPD) representations. The proposed
mechanism was integrated into standard U-Net and nnU-Net backbones, and was
validated on the publicly available PI-CAI dataset, achieving an Average
Precision (AP) of 0.37 and an Area Under the ROC Curve (AUC-ROC) of 0.83,
outperforming baseline networks and attention-based methods. Furthermore, the
approach was evaluated on the Prostate158 dataset as an independent test
cohort, achieving an AP of 0.37 and an AUC-ROC of 0.75, confirming robust
generalization and suggesting discriminative learned representations.
\\ ( https://arxiv.org/abs/2511.05760 ,  4976kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05772
Date: Sat, 8 Nov 2025 00:04:42 GMT   (81kb)

Title: Sign language recognition from skeletal data using graph and recurrent
 neural networks
Authors: B. Mederos, J. Mej\'ia, A. Medina-Reyes, Y. Espinosa-Almeyda, J. D.
 D\'iaz-Roman, I. Rodr\'iguez-Mederos, M. Mej\'ia-Carreon, and F.
 Gonzalez-Lopez
Categories: cs.CV cs.AI cs.LG
Comments: 15 pages, 2 figures
\\
 This work presents an approach for recognizing isolated sign language
gestures using skeleton-based pose data extracted from video sequences. A
Graph-GRU temporal network is proposed to model both spatial and temporal
dependencies between frames, enabling accurate classification. The model is
trained and evaluated on the AUTSL (Ankara university Turkish sign language)
dataset, achieving high accuracy. Experimental results demonstrate the
effectiveness of integrating graph-based spatial representations with temporal
modeling, providing a scalable framework for sign language recognition. The
results of this approach highlight the potential of pose-driven methods for
sign language understanding.
\\ ( https://arxiv.org/abs/2511.05772 ,  81kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05782
Date: Sat, 8 Nov 2025 00:56:52 GMT   (14702kb)

Title: TCSA-UDA: Text-Driven Cross-Semantic Alignment for Unsupervised Domain
 Adaptation in Medical Image Segmentation
Authors: Lalit Maurya, Honghai Liu, and Reyer Zwiggelaar
Categories: cs.CV
\\
 Unsupervised domain adaptation for medical image segmentation remains a
significant challenge due to substantial domain shifts across imaging
modalities, such as CT and MRI. While recent vision-language representation
learning methods have shown promise, their potential in UDA segmentation tasks
remains underexplored. To address this gap, we propose TCSA-UDA, a Text-driven
Cross-Semantic Alignment framework that leverages domain-invariant textual
class descriptions to guide visual representation learning. Our approach
introduces a vision-language covariance cosine loss to directly align image
encoder features with inter-class textual semantic relations, encouraging
semantically meaningful and modality-invariant feature representations.
Additionally, we incorporate a prototype alignment module that aligns
class-wise pixel-level feature distributions across domains using high-level
semantic prototypes. This mitigates residual category-level discrepancies and
enhances cross-modal consistency. Extensive experiments on challenging
cross-modality cardiac, abdominal, and brain tumor segmentation benchmarks
demonstrate that our TCSA-UDA framework significantly reduces domain shift and
consistently outperforms state-of-the-art UDA methods, establishing a new
paradigm for integrating language-driven semantics into domain-adaptive medical
image analysis.
\\ ( https://arxiv.org/abs/2511.05782 ,  14702kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05795
Date: Sat, 8 Nov 2025 01:53:51 GMT   (1399kb)

Title: Position-Prior-Guided Network for System Matrix Super-Resolution in
 Magnetic Particle Imaging
Authors: Xuqing Geng, Lei Su, Zhongwei Bian, Zewen Sun, Jiaxuan Wen, Jie Tian,
 and Yang Du
Categories: cs.CV
Comments: accepted as oral presentation at EMBC 2025
MSC-class: 68T10
ACM-class: I.4.5
\\
 Magnetic Particle Imaging (MPI) is a novel medical imaging modality. One of
the established methods for MPI reconstruction is based on the System Matrix
(SM). However, the calibration of the SM is often time-consuming and requires
repeated measurements whenever the system parameters change. Current
methodologies utilize deep learning-based super-resolution (SR) techniques to
expedite SM calibration; nevertheless, these strategies do not fully exploit
physical prior knowledge associated with the SM, such as symmetric positional
priors. Consequently, we integrated positional priors into existing frameworks
for SM calibration. Underpinned by theoretical justification, we empirically
validated the efficacy of incorporating positional priors through experiments
involving both 2D and 3D SM SR methods.
\\ ( https://arxiv.org/abs/2511.05795 ,  1399kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05803
Date: Sat, 8 Nov 2025 02:22:44 GMT   (9123kb)

Title: MACMD: Multi-dilated Contextual Attention and Channel Mixer Decoding for
 Medical Image Segmentation
Authors: Lalit Maurya, Honghai Liu, Reyer Zwiggelaar
Categories: cs.CV
\\
 Medical image segmentation faces challenges due to variations in anatomical
structures. While convolutional neural networks (CNNs) effectively capture
local features, they struggle with modeling long-range dependencies.
Transformers mitigate this issue with self-attention mechanisms but lack the
ability to preserve local contextual information. State-of-the-art models
primarily follow an encoder-decoder architecture, achieving notable success.
However, two key limitations remain: (1) Shallow layers, which are closer to
the input, capture fine-grained details but suffer from information loss as
data propagates through deeper layers. (2) Inefficient integration of local
details and global context between the encoder and decoder stages. To address
these challenges, we propose the MACMD-based decoder, which enhances attention
mechanisms and facilitates channel mixing between encoder and decoder stages
via skip connections. This design leverages hierarchical dilated convolutions,
attention-driven modulation, and a cross channel-mixing module to capture
long-range dependencies while preserving local contextual details, essential
for precise medical image segmentation. We evaluated our approach using
multiple transformer encoders on both binary and multi-organ segmentation
tasks. The results demonstrate that our method outperforms state-of-the-art
approaches in terms of Dice score and computational efficiency, highlighting
its effectiveness in achieving accurate and robust segmentation performance.
The code available at https://github.com/lalitmaurya47/MACMD
\\ ( https://arxiv.org/abs/2511.05803 ,  9123kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05818
Date: Sat, 8 Nov 2025 03:08:03 GMT   (7969kb)

Title: LRANet++: Low-Rank Approximation Network for Accurate and Efficient Text
 Spotting
Authors: Yuchen Su, Zhineng Chen, Yongkun Du, Zuxuan Wu, Hongtao Xie, Yu-Gang
 Jiang
Categories: cs.CV
\\
 End-to-end text spotting aims to jointly optimize text detection and
recognition within a unified framework. Despite significant progress, designing
an accurate and efficient end-to-end text spotter for arbitrary-shaped text
remains largely unsolved. We identify the primary bottleneck as the lack of a
reliable and efficient text detection method. To address this, we propose a
novel parameterized text shape method based on low-rank approximation for
precise detection and a triple assignment detection head to enable fast
inference. Specifically, unlike other shape representation methods that employ
data-irrelevant parameterization, our data-driven approach derives a low-rank
subspace directly from labeled text boundaries. To ensure this process is
robust against the inherent annotation noise in this data, we utilize a
specialized recovery method based on an $\ell_1$-norm formulation, which
accurately reconstructs the text shape with only a few key orthogonal vectors.
By exploiting the inherent shape correlation among different text contours, our
method achieves consistency and compactness in shape representation. Next, the
triple assignment scheme introduces a novel architecture where a deep sparse
branch (for stabilized training) is used to guide the learning of an
ultra-lightweight sparse branch (for accelerated inference), while a dense
branch provides rich parallel supervision. Building upon these advancements, we
integrate the enhanced detection module with a lightweight recognition branch
to form an end-to-end text spotting framework, termed LRANet++, capable of
accurately and efficiently spotting arbitrary-shaped text. Extensive
experiments on several challenging benchmarks demonstrate the superiority of
LRANet++ compared to state-of-the-art methods. Code will be available at:
https://github.com/ychensu/LRANet-PP.git
\\ ( https://arxiv.org/abs/2511.05818 ,  7969kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05832
Date: Sat, 8 Nov 2025 03:43:13 GMT   (22668kb)

Title: Hilbert-Guided Block-Sparse Local Attention
Authors: Yunge Li, Lanyu Xu
Categories: cs.CV cs.AI
\\
 The quadratic compute and memory costs of global self-attention severely
limit its use in high-resolution images. Local attention reduces complexity by
restricting attention to neighborhoods. Block-sparse kernels can further
improve the efficiency of local attention, but conventional local attention
patterns often fail to deliver significant speedups because tokens within a
window are not contiguous in the 1D sequence. This work proposes a novel method
for constructing windows and neighborhoods based on the Hilbert curve. Image
tokens are first reordered along a Hilbert curve, and windows and neighborhoods
are then formed on the reordered 1D sequence. From a block-sparse perspective,
this strategy significantly increases block sparsity and can be combined with
existing block-sparse kernels to improve the efficiency of 2D local attention.
Experiments show that the proposed Hilbert Window Attention and Hilbert Slide
Attention can accelerate window attention and slide attention by about
$4\times$ and $18\times$, respectively. To assess practicality, the strategy is
instantiated as the Hilbert Window Transformer and the Hilbert Neighborhood
Transformer, both of which achieve end-to-end speedups with minimal accuracy
loss. Overall, combining Hilbert-guided local attention with block-sparse
kernels offers a general and practical approach to enhancing the efficiency of
2D local attention for images. The code is available at
https://github.com/Yunge6666/Hilbert-Local-Attention.
\\ ( https://arxiv.org/abs/2511.05832 ,  22668kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05833
Date: Sat, 8 Nov 2025 03:46:58 GMT   (761kb)

Title: TYrPPG: Uncomplicated and Enhanced Learning Capability rPPG for Remote
 Heart Rate Estimation
Authors: Taixi Chen, Yiu-ming Cheung
Categories: cs.CV
Comments: The 6th International Workshop on AI for Social Good in the Connected
 World (AI4SG)@ IEEE WI-IAT 2025
\\
 Remote photoplethysmography (rPPG) can remotely extract physiological signals
from RGB video, which has many advantages in detecting heart rate, such as low
cost and no invasion to patients. The existing rPPG model is usually based on
the transformer module, which has low computation efficiency. Recently, the
Mamba model has garnered increasing attention due to its efficient performance
in natural language processing tasks, demonstrating potential as a substitute
for transformer-based algorithms. However, the Mambaout model and its variants
prove that the SSM module, which is the core component of the Mamba model, is
unnecessary for the vision task. Therefore, we hope to prove the feasibility of
using the Mambaout-based module to remotely learn the heart rate. Specifically,
we propose a novel rPPG algorithm called uncomplicated and enhanced learning
capability rPPG (TYrPPG). This paper introduces an innovative gated video
understanding block (GVB) designed for efficient analysis of RGB videos. Based
on the Mambaout structure, this block integrates 2D-CNN and 3D-CNN to enhance
video understanding for analysis. In addition, we propose a comprehensive
supervised loss function (CSL) to improve the model's learning capability,
along with its weakly supervised variants. The experiments show that our TYrPPG
can achieve state-of-the-art performance in commonly used datasets, indicating
its prospects and superiority in remote heart rate estimation. The source code
is available at https://github.com/Taixi-CHEN/TYrPPG.
\\ ( https://arxiv.org/abs/2511.05833 ,  761kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05841
Date: Sat, 8 Nov 2025 04:13:01 GMT   (3415kb)

Title: Understanding Cross Task Generalization in Handwriting-Based Alzheimer's
 Screening via Vision Language Adaptation
Authors: Changqing Gong, Huafeng Qin and Mounim A. El-Yacoubi
Categories: cs.CV cs.AI
\\
 Alzheimer's disease is a prevalent neurodegenerative disorder for which early
detection is critical. Handwriting-often disrupted in prodromal AD-provides a
non-invasive and cost-effective window into subtle motor and cognitive decline.
Existing handwriting-based AD studies, mostly relying on online trajectories
and hand-crafted features, have not systematically examined how task type
influences diagnostic performance and cross-task generalization. Meanwhile,
large-scale vision language models have demonstrated remarkable zero or
few-shot anomaly detection in natural images and strong adaptability across
medical modalities such as chest X-ray and brain MRI. However,
handwriting-based disease detection remains largely unexplored within this
paradigm. To close this gap, we introduce a lightweight Cross-Layer Fusion
Adapter framework that repurposes CLIP for handwriting-based AD screening. CLFA
implants multi-level fusion adapters within the visual encoder to progressively
align representations toward handwriting-specific medical cues, enabling
prompt-free and efficient zero-shot inference. Using this framework, we
systematically investigate cross-task generalization-training on a specific
handwriting task and evaluating on unseen ones-to reveal which task types and
writing patterns most effectively discriminate AD. Extensive analyses further
highlight characteristic stroke patterns and task-level factors that contribute
to early AD identification, offering both diagnostic insights and a benchmark
for handwriting-based cognitive assessment.
\\ ( https://arxiv.org/abs/2511.05841 ,  3415kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05844
Date: Sat, 8 Nov 2025 04:23:42 GMT   (1185kb)

Title: Enhancing Diffusion Model Guidance through Calibration and
 Regularization
Authors: Seyed Alireza Javid, Amirhossein Bagheri, and Nuria Gonz\'alez-Prelcic
Categories: cs.CV cs.AI cs.IT cs.LG eess.IV math.IT
Comments: Accepted from NeurIPS 2025 Workshop on Structured Probabilistic
 Inference & Generative Modeling. Code available at
 https://github.com/ajavid34/guided-info-diffusion
ACM-class: I.2.6; I.2.7; I.5.1
\\
 Classifier-guided diffusion models have emerged as a powerful approach for
conditional image generation, but they suffer from overconfident predictions
during early denoising steps, causing the guidance gradient to vanish. This
paper introduces two complementary contributions to address this issue. First,
we propose a differentiable calibration objective based on the Smooth Expected
Calibration Error (Smooth ECE), which improves classifier calibration with
minimal fine-tuning and yields measurable improvements in Frechet Inception
Distance (FID). Second, we develop enhanced sampling guidance methods that
operate on off-the-shelf classifiers without requiring retraining. These
include tilted sampling with batch-level reweighting, adaptive
entropy-regularized sampling to preserve diversity, and a novel
f-divergence-based sampling strategy that strengthens class-consistent guidance
while maintaining mode coverage. Experiments on ImageNet 128x128 demonstrate
that our divergence-regularized guidance achieves an FID of 2.13 using a
ResNet-101 classifier, improving upon existing classifier-guided diffusion
methods while requiring no diffusion model retraining. The results show that
principled calibration and divergence-aware sampling provide practical and
effective improvements for classifier-guided diffusion.
\\ ( https://arxiv.org/abs/2511.05844 ,  1185kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05853
Date: Sat, 8 Nov 2025 05:00:26 GMT   (12425kb)

Title: Point Cloud Segmentation of Integrated Circuits Package Substrates
 Surface Defects Using Causal Inference: Dataset Construction and Methodology
Authors: Bingyang Guo, Qiang Zuo, Ruiyun Yu
Categories: cs.CV
\\
 The effective segmentation of 3D data is crucial for a wide range of
industrial applications, especially for detecting subtle defects in the field
of integrated circuits (IC). Ceramic package substrates (CPS), as an important
electronic material, are essential in IC packaging owing to their superior
physical and chemical properties. However, the complex structure and minor
defects of CPS, along with the absence of a publically available dataset,
significantly hinder the development of CPS surface defect detection. In this
study, we construct a high-quality point cloud dataset for 3D segmentation of
surface defects in CPS, i.e., CPS3D-Seg, which has the best point resolution
and precision compared to existing 3D industrial datasets. CPS3D-Seg consists
of 1300 point cloud samples under 20 product categories, and each sample
provides accurate point-level annotations. Meanwhile, we conduct a
comprehensive benchmark based on SOTA point cloud segmentation algorithms to
validate the effectiveness of CPS3D-Seg. Additionally, we propose a novel 3D
segmentation method based on causal inference (CINet), which quantifies
potential confounders in point clouds through Structural Refine (SR) and
Quality Assessment (QA) Modules. Extensive experiments demonstrate that CINet
significantly outperforms existing algorithms in both mIoU and accuracy.
\\ ( https://arxiv.org/abs/2511.05853 ,  12425kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05865
Date: Sat, 8 Nov 2025 05:38:18 GMT   (41492kb)

Title: CGCE: Classifier-Guided Concept Erasure in Generative Models
Authors: Viet Nguyen, Vishal M. Patel
Categories: cs.CV cs.AI cs.CR
Comments: 24 pages, 15 figures
\\
 Recent advancements in large-scale generative models have enabled the
creation of high-quality images and videos, but have also raised significant
safety concerns regarding the generation of unsafe content. To mitigate this,
concept erasure methods have been developed to remove undesirable concepts from
pre-trained models. However, existing methods remain vulnerable to adversarial
attacks that can regenerate the erased content. Moreover, achieving robust
erasure often degrades the model's generative quality for safe, unrelated
concepts, creating a difficult trade-off between safety and performance. To
address this challenge, we introduce Classifier-Guided Concept Erasure (CGCE),
an efficient plug-and-play framework that provides robust concept erasure for
diverse generative models without altering their original weights. CGCE uses a
lightweight classifier operating on text embeddings to first detect and then
refine prompts containing undesired concepts. This approach is highly scalable,
allowing for multi-concept erasure by aggregating guidance from several
classifiers. By modifying only unsafe embeddings at inference time, our method
prevents harmful content generation while preserving the model's original
quality on benign prompts. Extensive experiments show that CGCE achieves
state-of-the-art robustness against a wide range of red-teaming attacks. Our
approach also maintains high generative utility, demonstrating a superior
balance between safety and performance. We showcase the versatility of CGCE
through its successful application to various modern T2I and T2V models,
establishing it as a practical and effective solution for safe generative AI.
\\ ( https://arxiv.org/abs/2511.05865 ,  41492kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05866
Date: Sat, 8 Nov 2025 05:39:05 GMT   (4730kb)

Title: Light-Field Dataset for Disparity Based Depth Estimation
Authors: Suresh Nehra, Aupendu Kar, Jayanta Mukhopadhyay, Prabir Kumar Biswas
Categories: cs.CV
Comments: This paper has been accepted to ACM ICVGIP 2025
\\
 A Light Field (LF) camera consists of an additional two-dimensional array of
micro-lenses placed between the main lens and sensor, compared to a
conventional camera. The sensor pixels under each micro-lens receive light from
a sub-aperture of the main lens. This enables the image sensor to capture both
spatial information and the angular resolution of a scene point. This
additional angular information is used to estimate the depth of a 3-D scene.
The continuum of virtual viewpoints in light field data enables efficient depth
estimation using Epipolar Line Images (EPIs) with robust occlusion handling.
However, the trade-off between angular information and spatial information is
very critical and depends on the focal position of the camera. To design,
develop, implement, and test novel disparity-based light field depth estimation
algorithms, the availability of suitable light field image datasets is
essential. In this paper, a publicly available light field image dataset is
introduced and thoroughly described. We have also demonstrated the effect of
focal position on the disparity of a 3-D point as well as the shortcomings of
the currently available light field dataset. The proposed dataset contains 285
light field images captured using a Lytro Illum LF camera and 13 synthetic LF
images. The proposed dataset also comprises a synthetic dataset with similar
disparity characteristics to those of a real light field camera. A real and
synthetic stereo light field dataset is also created by using a mechanical
gantry system and Blender. The dataset is available at
https://github.com/aupendu/light-field-dataset.
\\ ( https://arxiv.org/abs/2511.05866 ,  4730kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05876
Date: Sat, 8 Nov 2025 06:27:27 GMT   (5678kb)

Title: MoEGCL: Mixture of Ego-Graphs Contrastive Representation Learning for
 Multi-View Clustering
Authors: Jian Zhu, Xin Zou, Jun Sun, Cheng Luo, Lei Liu, Lingfang Zeng, Ning
 Zhang, Bian Wu, Chang Tang, Lirong Dai
Categories: cs.CV cs.LG
Comments: AAAI'2026 oral paper
\\
 In recent years, the advancement of Graph Neural Networks (GNNs) has
significantly propelled progress in Multi-View Clustering (MVC). However,
existing methods face the problem of coarse-grained graph fusion. Specifically,
current approaches typically generate a separate graph structure for each view
and then perform weighted fusion of graph structures at the view level, which
is a relatively rough strategy. To address this limitation, we present a novel
Mixture of Ego-Graphs Contrastive Representation Learning (MoEGCL). It mainly
consists of two modules. In particular, we propose an innovative Mixture of
Ego-Graphs Fusion (MoEGF), which constructs ego graphs and utilizes a
Mixture-of-Experts network to implement fine-grained fusion of ego graphs at
the sample level, rather than the conventional view-level fusion. Additionally,
we present the Ego Graph Contrastive Learning (EGCL) module to align the fused
representation with the view-specific representation. The EGCL module enhances
the representation similarity of samples from the same cluster, not merely from
the same sample, further boosting fine-grained graph representation. Extensive
experiments demonstrate that MoEGCL achieves state-of-the-art results in deep
multi-view clustering tasks. The source code is publicly available at
https://github.com/HackerHyper/MoEGCL.
\\ ( https://arxiv.org/abs/2511.05876 ,  5678kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05890
Date: Sat, 8 Nov 2025 07:08:22 GMT   (32558kb)

Title: Towards Frequency-Adaptive Learning for SAR Despeckling
Authors: Ziqing Ma, Chang Yang, Zhichang Guo, Yao Li
Categories: cs.CV
Comments: 13 pages, 14 figures,9 tables
MSC-class: 68T10
ACM-class: I.4
\\
 Synthetic Aperture Radar (SAR) images are inherently corrupted by speckle
noise, limiting their utility in high-precision applications. While deep
learning methods have shown promise in SAR despeckling, most methods employ a
single unified network to process the entire image, failing to account for the
distinct speckle statistics associated with different spatial physical
characteristics. It often leads to artifacts, blurred edges, and texture
distortion. To address these issues, we propose SAR-FAH, a frequency-adaptive
heterogeneous despeckling model based on a divide-and-conquer architecture.
First, wavelet decomposition is used to separate the image into frequency
sub-bands carrying different intrinsic characteristics. Inspired by their
differing noise characteristics, we design specialized sub-networks for
different frequency components. The tailored approach leverages statistical
variations across frequencies, improving edge and texture preservation while
suppressing noise. Specifically, for the low-frequency part, denoising is
formulated as a continuous dynamic system via neural ordinary differential
equations, ensuring structural fidelity and sufficient smoothness that prevents
artifacts. For high-frequency sub-bands rich in edges and textures, we
introduce an enhanced U-Net with deformable convolutions for noise suppression
and enhanced features. Extensive experiments on synthetic and real SAR images
validate the superior performance of the proposed model in noise removal and
structural preservation.
\\ ( https://arxiv.org/abs/2511.05890 ,  32558kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05893
Date: Sat, 8 Nov 2025 07:31:38 GMT   (1608kb)

Title: Hybrid second-order gradient histogram based global low-rank sparse
 regression for robust face recognition
Authors: Hongxia Li, Ying Ji, Yongxin Dong, Yuehua Feng
Categories: cs.CV math.OC
\\
 Low-rank sparse regression models have been widely applied in the field of
face recognition. To further address the challenges caused by complex
occlusions and illumination variations, this paper proposes a Hybrid
Second-Order Gradient Histogram based Global Low-Rank Sparse Regression
(H2H-GLRSR) model. Specifically, a novel feature descriptor called the Hybrid
Second-Order Gradient Histogram (H2H) is first designed to more effectively
characterize the local structural features of facial images. Then, this
descriptor is integrated with the Sparse Regularized Nuclear Norm based Matrix
Regression (SR$\_$NMR). Moreover, a global low-rank constraint is imposed on
the residual matrix, enabling the model to better capture the global
correlations inherent in structured noise. Experimental results demonstrate
that the proposed method significantly outperforms existing regression-based
classification approaches under challenging scenarios involving occlusions,
illumination changes, and unconstrained environments.
\\ ( https://arxiv.org/abs/2511.05893 ,  1608kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05894
Date: Sat, 8 Nov 2025 07:37:29 GMT   (3563kb)

Title: Open-World 3D Scene Graph Generation for Retrieval-Augmented Reasoning
Authors: Fei Yu, Quan Deng, Shengeng Tang, Yuehua Li, Lechao Cheng
Categories: cs.CV
Comments: Accepted by AAAI 2026
\\
 Understanding 3D scenes in open-world settings poses fundamental challenges
for vision and robotics, particularly due to the limitations of
closed-vocabulary supervision and static annotations. To address this, we
propose a unified framework for Open-World 3D Scene Graph Generation with
Retrieval-Augmented Reasoning, which enables generalizable and interactive 3D
scene understanding. Our method integrates Vision-Language Models (VLMs) with
retrieval-based reasoning to support multimodal exploration and language-guided
interaction. The framework comprises two key components: (1) a dynamic scene
graph generation module that detects objects and infers semantic relationships
without fixed label sets, and (2) a retrieval-augmented reasoning pipeline that
encodes scene graphs into a vector database to support text/image-conditioned
queries. We evaluate our method on 3DSSG and Replica benchmarks across four
tasks-scene question answering, visual grounding, instance retrieval, and task
planning-demonstrating robust generalization and superior performance in
diverse environments. Our results highlight the effectiveness of combining
open-vocabulary perception with retrieval-based reasoning for scalable 3D scene
understanding.
\\ ( https://arxiv.org/abs/2511.05894 ,  3563kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05898
Date: Sat, 8 Nov 2025 07:45:21 GMT   (832kb)

Title: GABFusion: Rethinking Feature Fusion for Low-Bit Quantization of
 Multi-Task Networks
Authors: Zhaoyang Wang and Dong Wang
Categories: cs.CV cs.AI
Comments: 9 pages,6 figures
\\
 Despite the effectiveness of quantization-aware training (QAT) in compressing
deep neural networks, its performance on multi-task architectures often
degrades significantly due to task-specific feature discrepancies and gradient
conflicts. To address these challenges, we propose Gradient-Aware Balanced
Feature Fusion (GABFusion), which dynamically balances gradient magnitudes and
fuses task-specific features in a quantization-friendly manner. We further
introduce Attention Distribution Alignment (ADA), a feature-level distillation
strategy tailored for quantized models. Our method demonstrates strong
generalization across network architectures and QAT algorithms, with
theoretical guarantees on gradient bias reduction. Extensive experiments
demonstrate that our strategy consistently enhances a variety of QAT methods
across different network architectures and bit-widths. On PASCAL VOC and COCO
datasets, the proposed approach achieves average mAP improvements of
approximately 3.3% and 1.6%, respectively. When applied to YOLOv5 under 4-bit
quantization, our method narrows the accuracy gap with the full-precision model
to only 1.7% on VOC, showcasing its effectiveness in preserving performance
under low-bit constraints. Notably, the proposed framework is modular, easy to
integrate, and compatible with any existing QAT technique-enhancing the
performance of quantized models without requiring modifications to the original
network architecture.
\\ ( https://arxiv.org/abs/2511.05898 ,  832kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05923
Date: Sat, 8 Nov 2025 08:37:26 GMT   (2255kb)

Title: Causal Tracing of Object Representations in Large Vision Language
 Models: Mechanistic Interpretability and Hallucination Mitigation
Authors: Qiming Li, Zekai Ye, Xiaocheng Feng, Weihong Zhong, Weitao Ma,
 Xiachong Feng
Categories: cs.CV
Comments: AAAI2026 Oral
\\
 Despite the remarkable advancements of Large Vision-Language Models (LVLMs),
the mechanistic interpretability remains underexplored. Existing analyses are
insufficiently comprehensive and lack examination covering visual and textual
tokens, model components, and the full range of layers. This limitation
restricts actionable insights to improve the faithfulness of model output and
the development of downstream tasks, such as hallucination mitigation. To
address this limitation, we introduce Fine-grained Cross-modal Causal Tracing
(FCCT) framework, which systematically quantifies the causal effects on visual
object perception. FCCT conducts fine-grained analysis covering the full range
of visual and textual tokens, three core model components including multi-head
self-attention (MHSA), feed-forward networks (FFNs), and hidden states, across
all decoder layers. Our analysis is the first to demonstrate that MHSAs of the
last token in middle layers play a critical role in aggregating cross-modal
information, while FFNs exhibit a three-stage hierarchical progression for the
storage and transfer of visual object representations. Building on these
insights, we propose Intermediate Representation Injection (IRI), a
training-free inference-time technique that reinforces visual object
information flow by precisely intervening on cross-modal representations at
specific components and layers, thereby enhancing perception and mitigating
hallucination. Consistent improvements across five widely used benchmarks and
LVLMs demonstrate IRI achieves state-of-the-art performance, while preserving
inference speed and other foundational performance.
\\ ( https://arxiv.org/abs/2511.05923 ,  2255kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05929
Date: Sat, 8 Nov 2025 08:43:41 GMT   (6483kb)

Title: CoMA: Complementary Masking and Hierarchical Dynamic Multi-Window
 Self-Attention in a Unified Pre-training Framework
Authors: Jiaxuan Li, Qing Xu, Xiangjian He, Ziyu Liu, Chang Xing, Zhen Chen,
 Daokun Zhang, Rong Qu, Chang Wen Chen
Categories: cs.CV cs.AI
Comments: 9 pages, 5 figures
ACM-class: I.2.0
\\
 Masked Autoencoders (MAE) achieve self-supervised learning of image
representations by randomly removing a portion of visual tokens and
reconstructing the original image as a pretext task, thereby significantly
enhancing pretraining efficiency and yielding excellent adaptability across
downstream tasks. However, MAE and other MAE-style paradigms that adopt random
masking generally require more pre-training epochs to maintain adaptability.
Meanwhile, ViT in MAE suffers from inefficient parameter use due to fixed
spatial resolution across layers. To overcome these limitations, we propose the
Complementary Masked Autoencoders (CoMA), which employ a complementary masking
strategy to ensure uniform sampling across all pixels, thereby improving
effective learning of all features and enhancing the model's adaptability.
Furthermore, we introduce DyViT, a hierarchical vision transformer that employs
a Dynamic Multi-Window Self-Attention (DM-MSA), significantly reducing the
parameters and FLOPs while improving fine-grained feature learning. Pre-trained
on ImageNet-1K with CoMA, DyViT matches the downstream performance of MAE using
only 12% of the pre-training epochs, demonstrating more effective learning. It
also attains a 10% reduction in pre-training time per epoch, further
underscoring its superior pre-training efficiency.
\\ ( https://arxiv.org/abs/2511.05929 ,  6483kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05934
Date: Sat, 8 Nov 2025 08:56:58 GMT   (13311kb)

Title: AD-DAE: Unsupervised Modeling of Longitudinal Alzheimer's Disease
 Progression with Diffusion Auto-Encoder
Authors: Ayantika Das, Arunima Sarkar, Keerthi Ram, Mohanasankar Sivaprakasam
Categories: cs.CV
Comments: Under Review
\\
 Generative modeling frameworks have emerged as an effective approach to
capture high-dimensional image distributions from large datasets without
requiring domain-specific knowledge, a capability essential for longitudinal
disease progression modeling. Recent generative modeling approaches have
attempted to capture progression by mapping images into a latent
representational space and then controlling and guiding the representations to
generate follow-up images from a baseline image. However, existing approaches
impose constraints on distribution learning, leading to latent spaces with
limited controllability to generate follow-up images without explicit
supervision from subject-specific longitudinal images. In order to enable
controlled movements in the latent representational space and generate
progression images from a baseline image in an unsupervised manner, we
introduce a conditionable Diffusion Auto-encoder framework. The explicit
encoding mechanism of image-diffusion auto-encoders forms a compact latent
space capturing high-level semantics, providing means to disentangle
information relevant for progression. Our approach leverages this latent space
to condition and apply controlled shifts to baseline representations for
generating follow-up. Controllability is induced by restricting these shifts to
a subspace, thereby isolating progression-related factors from subject
identity-preserving components. The shifts are implicitly guided by correlating
with progression attributes, without requiring subject-specific longitudinal
supervision. We validate the generations through image quality metrics,
volumetric progression analysis, and downstream classification in Alzheimer's
disease datasets from two different sources and disease categories. This
demonstrates the effectiveness of our approach for Alzheimer's progression
modeling and longitudinal image generation.
\\ ( https://arxiv.org/abs/2511.05934 ,  13311kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05935
Date: Sat, 8 Nov 2025 08:59:09 GMT   (8845kb)

Title: Interaction-Centric Knowledge Infusion and Transfer for Open-Vocabulary
 Scene Graph Generation
Authors: Lin Li and Chuhan Zhang and Dong Zhang and Chong Sun and Chen Li and
 Long Chen
Categories: cs.CV
Comments: Accepted by NeurIPS 2025
\\
 Open-vocabulary scene graph generation (OVSGG) extends traditional SGG by
recognizing novel objects and relationships beyond predefined categories,
leveraging the knowledge from pre-trained large-scale models. Existing OVSGG
methods always adopt a two-stage pipeline: 1) \textit{Infusing knowledge} into
large-scale models via pre-training on large datasets; 2) \textit{Transferring
knowledge} from pre-trained models with fully annotated scene graphs during
supervised fine-tuning. However, due to a lack of explicit interaction
modeling, these methods struggle to distinguish between interacting and
non-interacting instances of the same object category. This limitation induces
critical issues in both stages of OVSGG: it generates noisy pseudo-supervision
from mismatched objects during knowledge infusion, and causes ambiguous query
matching during knowledge transfer. To this end, in this paper, we propose an
inter\textbf{AC}tion-\textbf{C}entric end-to-end OVSGG framework (\textbf{ACC})
in an interaction-driven paradigm to minimize these mismatches. For
\textit{interaction-centric knowledge infusion}, ACC employs a bidirectional
interaction prompt for robust pseudo-supervision generation to enhance the
model's interaction knowledge. For \textit{interaction-centric knowledge
transfer}, ACC first adopts interaction-guided query selection that prioritizes
pairing interacting objects to reduce interference from non-interacting ones.
Then, it integrates interaction-consistent knowledge distillation to bolster
robustness by pushing relational foreground away from the background while
retaining general knowledge. Extensive experimental results on three benchmarks
show that ACC achieves state-of-the-art performance, demonstrating the
potential of interaction-centric paradigms for real-world applications.
\\ ( https://arxiv.org/abs/2511.05935 ,  8845kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05938
Date: Sat, 8 Nov 2025 09:10:35 GMT   (623kb)

Title: Global Multiple Extraction Network for Low-Resolution Facial Expression
 Recognition
Authors: Jingyi Shi
Categories: cs.CV
Comments: 12 pages
\\
 Facial expression recognition, as a vital computer vision task, is garnering
significant attention and undergoing extensive research. Although facial
expression recognition algorithms demonstrate impressive performance on
high-resolution images, their effectiveness tends to degrade when confronted
with low-resolution images. We find it is because: 1) low-resolution images
lack detail information; 2) current methods complete weak global modeling,
which make it difficult to extract discriminative features. To alleviate the
above issues, we proposed a novel global multiple extraction network (GME-Net)
for low-resolution facial expression recognition, which incorporates 1) a
hybrid attention-based local feature extraction module with attention
similarity knowledge distillation to learn image details from high-resolution
network; 2) a multi-scale global feature extraction module with quasi-symmetric
structure to mitigate the influence of local image noise and facilitate
capturing global image features. As a result, our GME-Net is capable of
extracting expression-related discriminative features. Extensive experiments
conducted on several widely-used datasets demonstrate that the proposed GME-Net
can better recognize low-resolution facial expression and obtain superior
performance than existing solutions.
\\ ( https://arxiv.org/abs/2511.05938 ,  623kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05944
Date: Sat, 8 Nov 2025 09:35:11 GMT   (408kb)

Title: Polymap: generating high definition map based on rasterized polygons
Authors: Shiyu Gao, Hao Jiang
Categories: cs.CV
\\
 The perception of high-definition maps is an integral component of
environmental perception in autonomous driving systems. Existing research have
often focused on online construction of high-definition maps. For instance, the
Maptr[9] series employ a detection-based method to output vectorized map
instances parallelly in an end-to-end manner. However, despite their capability
for real-time construction, detection-based methods are observed to lack robust
generalizability[19], which hampers their applicability in auto-labeling
systems. Therefore, aiming to improve the generalizability, we reinterpret road
elements as rasterized polygons and design a concise framework based on
instance segmentation. Initially, a segmentation-based transformer is employed
to deliver instance masks in an end-to-end manner; succeeding this step, a
Potrace-based[17] post-processing module is used to ultimately yield vectorized
map elements. Quantitative results attained on the Nuscene[1] dataset
substantiate the effectiveness and generaliz-ability of our method.
\\ ( https://arxiv.org/abs/2511.05944 ,  408kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05946
Date: Sat, 8 Nov 2025 09:41:34 GMT   (25706kb)

Title: Reperio-rPPG: Relational Temporal Graph Neural Networks for Periodicity
 Learning in Remote Physiological Measurement
Authors: Ba-Thinh Nguyen, Thach-Ha Ngoc Pham, Hoang-Long Duc Nguyen, Thi-Duyen
 Ngo, Thanh-Ha Le
Categories: cs.CV
\\
 Remote photoplethysmography (rPPG) is an emerging contactless physiological
sensing technique that leverages subtle color variations in facial videos to
estimate vital signs such as heart rate and respiratory rate. This non-invasive
method has gained traction across diverse domains, including telemedicine,
affective computing, driver fatigue detection, and health monitoring, owing to
its scalability and convenience. Despite significant progress in remote
physiological signal measurement, a crucial characteristic - the intrinsic
periodicity - has often been underexplored or insufficiently modeled in
previous approaches, limiting their ability to capture fine-grained temporal
dynamics under real-world conditions. To bridge this gap, we propose
Reperio-rPPG, a novel framework that strategically integrates Relational
Convolutional Networks with a Graph Transformer to effectively capture the
periodic structure inherent in physiological signals. Additionally, recognizing
the limited diversity of existing rPPG datasets, we further introduce a
tailored CutMix augmentation to enhance the model's generalizability. Extensive
experiments conducted on three widely used benchmark datasets - PURE,
UBFC-rPPG, and MMPD - demonstrate that Reperio-rPPG not only achieves
state-of-the-art performance but also exhibits remarkable robustness under
various motion (e.g., stationary, rotation, talking, walking) and illumination
conditions (e.g., nature, low LED, high LED). The code is publicly available at
https://github.com/deconasser/Reperio-rPPG.
\\ ( https://arxiv.org/abs/2511.05946 ,  25706kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05949
Date: Sat, 8 Nov 2025 09:44:31 GMT   (7909kb)

Title: U(PM)$^2$:Unsupervised polygon matching with pre-trained models for
 challenging stereo images
Authors: Chang Li, Xingtao Peng
Categories: cs.CV
\\
 Stereo image matching is a fundamental task in computer vision,
photogrammetry and remote sensing, but there is an almost unexplored field,
i.e., polygon matching, which faces the following challenges: disparity
discontinuity, scale variation, training requirement, and generalization. To
address the above-mentioned issues, this paper proposes a novel U(PM)$^2$:
low-cost unsupervised polygon matching with pre-trained models by uniting
automatically learned and handcrafted features, of which pipeline is as
follows: firstly, the detector leverages the pre-trained segment anything model
to obtain masks; then, the vectorizer converts the masks to polygons and
graphic structure; secondly, the global matcher addresses challenges from
global viewpoint changes and scale variation based on bidirectional-pyramid
strategy with pre-trained LoFTR; finally, the local matcher further overcomes
local disparity discontinuity and topology inconsistency of polygon matching by
local-joint geometry and multi-feature matching strategy with Hungarian
algorithm. We benchmark our U(PM)$^2$ on the ScanNet and SceneFlow datasets
using our proposed new metric, which achieved state-of-the-art accuracy at a
competitive speed and satisfactory generalization performance at low cost
without any training requirement.
\\ ( https://arxiv.org/abs/2511.05949 ,  7909kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05955
Date: Sat, 8 Nov 2025 10:07:45 GMT   (30722kb)

Title: CSGaze: Context-aware Social Gaze Prediction
Authors: Surbhi Madan, Shreya Ghosh, Ramanathan Subramanian, Abhinav Dhall and
 Tom Gedeon
Categories: cs.CV cs.LG
\\
 A person's gaze offers valuable insights into their focus of attention, level
of social engagement, and confidence. In this work, we investigate how
contextual cues combined with visual scene and facial information can be
effectively utilized to predict and interpret social gaze patterns during
conversational interactions. We introduce CSGaze, a context aware multimodal
approach that leverages facial, scene information as complementary inputs to
enhance social gaze pattern prediction from multi-person images. The model also
incorporates a fine-grained attention mechanism centered on the principal
speaker, which helps in better modeling social gaze dynamics. Experimental
results show that CSGaze performs competitively with state-of-the-art methods
on GP-Static, UCO-LAEO and AVA-LAEO. Our findings highlight the role of
contextual cues in improving social gaze prediction. Additionally, we provide
initial explainability through generated attention scores, offering insights
into the model's decision-making process. We also demonstrate our model's
generalizability by testing our model on open set datasets that demonstrating
its robustness across diverse scenarios.
\\ ( https://arxiv.org/abs/2511.05955 ,  30722kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05965
Date: Sat, 8 Nov 2025 10:50:43 GMT   (5203kb)

Title: Adaptive Agent Selection and Interaction Network for Image-to-point
 cloud Registration
Authors: Zhixin Cheng, Xiaotian Yin, Jiacheng Deng, Bohao Liao, Yujia Chen, Xu
 Zhou, Baoqun Yin, Tianzhu Zhang
Categories: cs.CV cs.AI
Comments: Accepted by AAAI2026
\\
 Typical detection-free methods for image-to-point cloud registration leverage
transformer-based architectures to aggregate cross-modal features and establish
correspondences. However, they often struggle under challenging conditions,
where noise disrupts similarity computation and leads to incorrect
correspondences. Moreover, without dedicated designs, it remains difficult to
effectively select informative and correlated representations across
modalities, thereby limiting the robustness and accuracy of registration. To
address these challenges, we propose a novel cross-modal registration framework
composed of two key modules: the Iterative Agents Selection (IAS) module and
the Reliable Agents Interaction (RAI) module. IAS enhances structural feature
awareness with phase maps and employs reinforcement learning principles to
efficiently select reliable agents. RAI then leverages these selected agents to
guide cross-modal interactions, effectively reducing mismatches and improving
overall robustness. Extensive experiments on the RGB-D Scenes v2 and 7-Scenes
benchmarks demonstrate that our method consistently achieves state-of-the-art
performance.
\\ ( https://arxiv.org/abs/2511.05965 ,  5203kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05966
Date: Sat, 8 Nov 2025 10:55:46 GMT   (3763kb)

Title: Commonality in Few: Few-Shot Multimodal Anomaly Detection via
 Hypergraph-Enhanced Memory
Authors: Yuxuan Lin, Hanjing Yan, Xuan Tong, Yang Chang, Huanzhen Wang, Ziheng
 Zhou, Shuyong Gao, Yan Wang, Wenqiang Zhang
Categories: cs.CV
Comments: Accepted by AAAI 2026
\\
 Few-shot multimodal industrial anomaly detection is a critical yet
underexplored task, offering the ability to quickly adapt to complex industrial
scenarios. In few-shot settings, insufficient training samples often fail to
cover the diverse patterns present in test samples. This challenge can be
mitigated by extracting structural commonality from a small number of training
samples. In this paper, we propose a novel few-shot unsupervised multimodal
industrial anomaly detection method based on structural commonality, CIF
(Commonality In Few). To extract intra-class structural information, we employ
hypergraphs, which are capable of modeling higher-order correlations, to
capture the structural commonality within training samples, and use a memory
bank to store this intra-class structural prior. Firstly, we design a
semantic-aware hypergraph construction module tailored for single-semantic
industrial images, from which we extract common structures to guide the
construction of the memory bank. Secondly, we use a training-free hypergraph
message passing module to update the visual features of test samples, reducing
the distribution gap between test features and features in the memory bank. We
further propose a hyperedge-guided memory search module, which utilizes
structural information to assist the memory search process and reduce the false
positive rate. Experimental results on the MVTec 3D-AD dataset and the
Eyecandies dataset show that our method outperforms the state-of-the-art (SOTA)
methods in few-shot settings. Code is available at
https://github.com/Sunny5250/CIF.
\\ ( https://arxiv.org/abs/2511.05966 ,  3763kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05967
Date: Sat, 8 Nov 2025 11:01:22 GMT   (762kb)

Title: Adapted Foundation Models for Breast MRI Triaging in Contrast-Enhanced
 and Non-Contrast Enhanced Protocols
Authors: Tri-Thien Nguyen, Lorenz A. Kapsner, Tobias Hepp, Shirin
 Heidarikahkesh, Hannes Schreiter, Luise Brock, Dominika Skwierawska,
 Dominique Hadler, Julian Hossbach, Evelyn Wenkel, Sabine Ohlmeyer, Frederik
 B. Laun, Andrzej Liebert, Andreas Maier, Michael Uder, and Sebastian
 Bickelhaupt
Categories: cs.CV cs.AI
Comments: 23 pages, 6 figures, 4 tables. Originally submitted to Radiology
 (RAD-25-2541); under consideration for transfer to Radiology: Artificial
 Intelligence (RSNA Portfolio Journal)
\\
 Background: Magnetic resonance imaging (MRI) has high sensitivity for breast
cancer detection, but interpretation is time-consuming. Artificial intelligence
may aid in pre-screening. Purpose: To evaluate the DINOv2-based Medical Slice
Transformer (MST) for ruling out significant findings (Breast Imaging Reporting
and Data System [BI-RADS] >=4) in contrast-enhanced and non-contrast-enhanced
abbreviated breast MRI. Materials and Methods: This institutional review board
approved retrospective study included 1,847 single-breast MRI examinations (377
BI-RADS >=4) from an in-house dataset and 924 from an external validation
dataset (Duke). Four abbreviated protocols were tested: T1-weighted early
subtraction (T1sub), diffusion-weighted imaging with b=1500 s/mm2 (DWI1500),
DWI1500+T2-weighted (T2w), and T1sub+T2w. Performance was assessed at 90%, 95%,
and 97.5% sensitivity using five-fold cross-validation and area under the
receiver operating characteristic curve (AUC) analysis. AUC differences were
compared with the DeLong test. False negatives were characterized, and
attention maps of true positives were rated in the external dataset. Results: A
total of 1,448 female patients (mean age, 49 +/- 12 years) were included.
T1sub+T2w achieved an AUC of 0.77 +/- 0.04; DWI1500+T2w, 0.74 +/- 0.04
(p=0.15). At 97.5% sensitivity, T1sub+T2w had the highest specificity (19% +/-
7%), followed by DWI1500+T2w (17% +/- 11%). Missed lesions had a mean diameter
<10 mm at 95% and 97.5% thresholds for both T1sub and DWI1500, predominantly
non-mass enhancements. External validation yielded an AUC of 0.77, with 88% of
attention maps rated good or moderate. Conclusion: At 97.5% sensitivity, the
MST framework correctly triaged cases without BI-RADS >=4, achieving 19%
specificity for contrast-enhanced and 17% for non-contrast-enhanced MRI.
Further research is warranted before clinical implementation.
\\ ( https://arxiv.org/abs/2511.05967 ,  762kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05968
Date: Sat, 8 Nov 2025 11:08:27 GMT   (10128kb)

Title: DiA-gnostic VLVAE: Disentangled Alignment-Constrained Vision Language
 Variational AutoEncoder for Robust Radiology Reporting with Missing
 Modalities
Authors: Nagur Shareef Shaik, Teja Krishna Cherukuri, Adnan Masood and Dong Hye
 Ye
Categories: cs.CV cs.AI cs.LG
Comments: Accepted for Oral Presentation at the 40th AAAI Conference on
 Artificial Intelligence (AAAI-26), Main Technical Track
\\
 The integration of medical images with clinical context is essential for
generating accurate and clinically interpretable radiology reports. However,
current automated methods often rely on resource-heavy Large Language Models
(LLMs) or static knowledge graphs and struggle with two fundamental challenges
in real-world clinical data: (1) missing modalities, such as incomplete
clinical context , and (2) feature entanglement, where mixed modality-specific
and shared information leads to suboptimal fusion and clinically unfaithful
hallucinated findings. To address these challenges, we propose the DiA-gnostic
VLVAE, which achieves robust radiology reporting through Disentangled
Alignment. Our framework is designed to be resilient to missing modalities by
disentangling shared and modality-specific features using a Mixture-of-Experts
(MoE) based Vision-Language Variational Autoencoder (VLVAE). A constrained
optimization objective enforces orthogonality and alignment between these
latent representations to prevent suboptimal fusion. A compact LLaMA-X decoder
then uses these disentangled representations to generate reports efficiently.
On the IU X-Ray and MIMIC-CXR datasets, DiA has achieved competetive BLEU@4
scores of 0.266 and 0.134, respectively. Experimental results show that the
proposed method significantly outperforms state-of-the-art models.
\\ ( https://arxiv.org/abs/2511.05968 ,  10128kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05982
Date: Sat, 8 Nov 2025 12:06:54 GMT   (87kb)

Title: Runtime Safety Monitoring of Deep Neural Networks for Perception: A
 Survey
Authors: Albert Schotschneider, Svetlana Pavlitska, J. Marius Z\"ollner
Categories: cs.CV cs.AI cs.LG cs.RO
Comments: 6 pages, 1 figure, 2 tables, accepted at IEEE SMC 2025 in Vienna,
 presented on 8th October 2025
\\
 Deep neural networks (DNNs) are widely used in perception systems for
safety-critical applications, such as autonomous driving and robotics. However,
DNNs remain vulnerable to various safety concerns, including generalization
errors, out-of-distribution (OOD) inputs, and adversarial attacks, which can
lead to hazardous failures. This survey provides a comprehensive overview of
runtime safety monitoring approaches, which operate in parallel to DNNs during
inference to detect these safety concerns without modifying the DNN itself. We
categorize existing methods into three main groups: Monitoring inputs, internal
representations, and outputs. We analyze the state-of-the-art for each
category, identify strengths and limitations, and map methods to the safety
concerns they address. In addition, we highlight open challenges and future
research directions.
\\ ( https://arxiv.org/abs/2511.05982 ,  87kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05989
Date: Sat, 8 Nov 2025 12:33:18 GMT   (822kb)

Title: A Dual-Mode ViT-Conditioned Diffusion Framework with an Adaptive
 Conditioning Bridge for Breast Cancer Segmentation
Authors: Prateek Singh, Moumita Dholey, P.K. Vinod
Categories: cs.CV
Comments: 5 pages, 2 figures, 3 tables, submitted to ISBI 2026
\\
 In breast ultrasound images, precise lesion segmentation is essential for
early diagnosis; however, low contrast, speckle noise, and unclear boundaries
make this difficult. Even though deep learning models have demonstrated
potential, standard convolutional architectures frequently fall short in
capturing enough global context, resulting in segmentations that are
anatomically inconsistent. To overcome these drawbacks, we suggest a flexible,
conditional Denoising Diffusion Model that combines an enhanced UNet-based
generative decoder with a Vision Transformer (ViT) encoder for global feature
extraction. We introduce three primary innovations: 1) an Adaptive Conditioning
Bridge (ACB) for efficient, multi-scale fusion of semantic features; 2) a novel
Topological Denoising Consistency (TDC) loss component that regularizes
training by penalizing structural inconsistencies during denoising; and 3) a
dual-head architecture that leverages the denoising objective as a powerful
regularizer, enabling a lightweight auxiliary head to perform rapid and
accurate inference on smaller datasets and a noise prediction head. Our
framework establishes a new state-of-the-art on public breast ultrasound
datasets, achieving Dice scores of 0.96 on BUSI, 0.90 on BrEaST and 0.97 on
BUS-UCLM. Comprehensive ablation studies empirically validate that the model
components are critical for achieving these results and for producing
segmentations that are not only accurate but also anatomically plausible.
\\ ( https://arxiv.org/abs/2511.05989 ,  822kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05996
Date: Sat, 8 Nov 2025 12:56:21 GMT   (19041kb)

Title: Exploring Category-level Articulated Object Pose Tracking on SE(3)
 Manifolds
Authors: Xianhui Meng, Yukang Huo, Li Zhang, Liu Liu, Haonan Jiang, Yan Zhong,
 Pingrui Zhang, Cewu Lu, Jun Liu
Categories: cs.CV cs.AI
\\
 Articulated objects are prevalent in daily life and robotic manipulation
tasks. However, compared to rigid objects, pose tracking for articulated
objects remains an underexplored problem due to their inherent kinematic
constraints. To address these challenges, this work proposes a novel
point-pair-based pose tracking framework, termed \textbf{PPF-Tracker}. The
proposed framework first performs quasi-canonicalization of point clouds in the
SE(3) Lie group space, and then models articulated objects using Point Pair
Features (PPF) to predict pose voting parameters by leveraging the invariance
properties of SE(3). Finally, semantic information of joint axes is
incorporated to impose unified kinematic constraints across all parts of the
articulated object. PPF-Tracker is systematically evaluated on both synthetic
datasets and real-world scenarios, demonstrating strong generalization across
diverse and challenging environments. Experimental results highlight the
effectiveness and robustness of PPF-Tracker in multi-frame pose tracking of
articulated objects. We believe this work can foster advances in robotics,
embodied intelligence, and augmented reality. Codes are available at
https://github.com/mengxh20/PPFTracker.
\\ ( https://arxiv.org/abs/2511.05996 ,  19041kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06002
Date: Sat, 8 Nov 2025 13:16:19 GMT   (32859kb)

Title: MALeR: Improving Compositional Fidelity in Layout-Guided Generation
Authors: Shivank Saxena and Dhruv Srivastava and Makarand Tapaswi
Categories: cs.CV
Comments: ACM TOG Dec 2025, Siggraph Asia, Project page:
 https://katha-ai.github.io/projects/maler/
\\
 Recent advances in text-to-image models have enabled a new era of creative
and controllable image generation. However, generating compositional scenes
with multiple subjects and attributes remains a significant challenge. To
enhance user control over subject placement, several layout-guided methods have
been proposed. However, these methods face numerous challenges, particularly in
compositional scenes. Unintended subjects often appear outside the layouts,
generated images can be out-of-distribution and contain unnatural artifacts, or
attributes bleed across subjects, leading to incorrect visual outputs. In this
work, we propose MALeR, a method that addresses each of these challenges. Given
a text prompt and corresponding layouts, our method prevents subjects from
appearing outside the given layouts while being in-distribution. Additionally,
we propose a masked, attribute-aware binding mechanism that prevents attribute
leakage, enabling accurate rendering of subjects with multiple attributes, even
in complex compositional scenes. Qualitative and quantitative evaluation
demonstrates that our method achieves superior performance in compositional
accuracy, generation consistency, and attribute binding compared to previous
work. MALeR is particularly adept at generating images of scenes with multiple
subjects and multiple attributes per subject.
\\ ( https://arxiv.org/abs/2511.06002 ,  32859kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06005
Date: Sat, 8 Nov 2025 13:25:04 GMT   (381kb)

Title: How Reasoning Influences Intersectional Biases in Vision Language Models
Authors: Adit Desai, Sudipta Roy, Mohna Chakraborty
Categories: cs.CV
\\
 Vision Language Models (VLMs) are increasingly deployed across downstream
tasks, yet their training data often encode social biases that surface in
outputs. Unlike humans, who interpret images through contextual and social
cues, VLMs process them through statistical associations, often leading to
reasoning that diverges from human reasoning. By analyzing how a VLM reasons,
we can understand how inherent biases are perpetuated and can adversely affect
downstream performance. To examine this gap, we systematically analyze social
biases in five open-source VLMs for an occupation prediction task, on the
FairFace dataset. Across 32 occupations and three different prompting styles,
we elicit both predictions and reasoning. Our findings reveal that the biased
reasoning patterns systematically underlie intersectional disparities,
highlighting the need to align VLM reasoning with human values prior to its
downstream deployment.
\\ ( https://arxiv.org/abs/2511.06005 ,  381kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06006
Date: Sat, 8 Nov 2025 13:27:12 GMT   (634kb)

Title: Distributed Deep Learning for Medical Image Denoising with Data
 Obfuscation
Authors: Sulaimon Oyeniyi Adebayo, Ayaz H. Khan
Categories: cs.CV cs.DC
\\
 Medical image denoising is essential for improving image quality while
minimizing the exposure of sensitive information, particularly when working
with large-scale clinical datasets. This study explores distributed deep
learning for denoising chest X-ray images from the NIH Chest X-ray14 dataset,
using additive Gaussian noise as a lightweight obfuscation technique. We
implement and evaluate U-Net and U-Net++ architectures under single-GPU,
standard multi-GPU (DataParallel), and optimized multi-GPU training
configurations using PyTorch's DistributedDataParallel (DDP) and Automatic
Mixed Precision (AMP). Our results show that U-Net++ consistently delivers
superior denoising performance, achieving competitive Peak Signal to Noise
Ratio (PSNR) and Structured Similarity Index Method (SSIM) scores, though with
less performance in Learned Perceptual Image Patch Similarity (LPIPS) compared
to U-Net under low and moderate noise levels. This indicates U-Net++'s enhanced
structural fidelity and low perceptual similarity. Meanwhile, our optimized
training pipeline reduces training time by over 60% for both models compared to
single-GPU training, and outperforms standard DataParallel by over 40%, with
only a minor accuracy drop for both models (trading some accuracy for speed).
These findings highlight the effectiveness of software-level optimization in
distributed learning for medical imaging. This work demonstrates the practical
viability of combining architectural design, lightweight obfuscation, and
advanced distributed training strategies to accelerate and enhance medical
image processing pipelines in real-world clinical and research environments.
The full implementation is publicly available at:
https://github.com/Suadey/medical-image-denoising-ddp.
\\ ( https://arxiv.org/abs/2511.06006 ,  634kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06016
Date: Sat, 8 Nov 2025 14:06:23 GMT   (749kb)

Title: One-Shot Knowledge Transfer for Scalable Person Re-Identification
Authors: Longhua Li, Lei Qi, Xin Geng
Categories: cs.CV cs.AI
Comments: Accepted by ICCV 2025
Journal-ref: Proceedings of the IEEE/CVF International Conference on Computer
 Vision (ICCV), 2025
\\
 Edge computing in person re-identification (ReID) is crucial for reducing the
load on central cloud servers and ensuring user privacy. Conventional
compression methods for obtaining compact models require computations for each
individual student model. When multiple models of varying sizes are needed to
accommodate different resource conditions, this leads to repetitive and
cumbersome computations. To address this challenge, we propose a novel
knowledge inheritance approach named OSKT (One-Shot Knowledge Transfer), which
consolidates the knowledge of the teacher model into an intermediate carrier
called a weight chain. When a downstream scenario demands a model that meets
specific resource constraints, this weight chain can be expanded to the target
model size without additional computation. OSKT significantly outperforms
state-of-the-art compression methods, with the added advantage of one-time
knowledge transfer that eliminates the need for frequent computations for each
target model.
\\ ( https://arxiv.org/abs/2511.06016 ,  749kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06019
Date: Sat, 8 Nov 2025 14:10:04 GMT   (4864kb)

Title: MiVID: Multi-Strategic Self-Supervision for Video Frame Interpolation
 using Diffusion Model
Authors: Priyansh Srivastava, Romit Chatterjee, Abir Sen, Aradhana Behura,
 Ratnakar Dash
Categories: cs.CV cs.AI
\\
 Video Frame Interpolation (VFI) remains a cornerstone in video enhancement,
enabling temporal upscaling for tasks like slow-motion rendering, frame rate
conversion, and video restoration. While classical methods rely on optical flow
and learning-based models assume access to dense ground-truth, both struggle
with occlusions, domain shifts, and ambiguous motion. This article introduces
MiVID, a lightweight, self-supervised, diffusion-based framework for video
interpolation. Our model eliminates the need for explicit motion estimation by
combining a 3D U-Net backbone with transformer-style temporal attention,
trained under a hybrid masking regime that simulates occlusions and motion
uncertainty. The use of cosine-based progressive masking and adaptive loss
scheduling allows our network to learn robust spatiotemporal representations
without any high-frame-rate supervision. Our framework is evaluated on UCF101-7
and DAVIS-7 datasets. MiVID is trained entirely on CPU using the datasets and
9-frame video segments, making it a low-resource yet highly effective pipeline.
Despite these constraints, our model achieves optimal results at just 50
epochs, competitive with several supervised baselines.This work demonstrates
the power of self-supervised diffusion priors for temporally coherent frame
synthesis and provides a scalable path toward accessible and generalizable VFI
systems.
\\ ( https://arxiv.org/abs/2511.06019 ,  4864kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06024
Date: Sat, 8 Nov 2025 14:35:11 GMT   (15910kb)

Title: Towards Implicit Aggregation: Robust Image Representation for Place
 Recognition in the Transformer Era
Authors: Feng Lu, Tong Jin, Canming Ye, Yunpeng Liu, Xiangyuan Lan, Chun Yuan
Categories: cs.CV
Comments: Accepted by NeurIPS 2025
\\
 Visual place recognition (VPR) is typically regarded as a specific image
retrieval task, whose core lies in representing images as global descriptors.
Over the past decade, dominant VPR methods (e.g., NetVLAD) have followed a
paradigm that first extracts the patch features/tokens of the input image using
a backbone, and then aggregates these patch features into a global descriptor
via an aggregator. This backbone-plus-aggregator paradigm has achieved
overwhelming dominance in the CNN era and remains widely used in
transformer-based models. In this paper, however, we argue that a dedicated
aggregator is not necessary in the transformer era, that is, we can obtain
robust global descriptors only with the backbone. Specifically, we introduce
some learnable aggregation tokens, which are prepended to the patch tokens
before a particular transformer block. All these tokens will be jointly
processed and interact globally via the intrinsic self-attention mechanism,
implicitly aggregating useful information within the patch tokens to the
aggregation tokens. Finally, we only take these aggregation tokens from the
last output tokens and concatenate them as the global representation. Although
implicit aggregation can provide robust global descriptors in an extremely
simple manner, where and how to insert additional tokens, as well as the
initialization of tokens, remains an open issue worthy of further exploration.
To this end, we also propose the optimal token insertion strategy and token
initialization method derived from empirical studies. Experimental results show
that our method outperforms state-of-the-art methods on several VPR datasets
with higher efficiency and ranks 1st on the MSLS challenge leaderboard. The
code is available at https://github.com/lu-feng/image.
\\ ( https://arxiv.org/abs/2511.06024 ,  15910kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06033
Date: Sat, 8 Nov 2025 15:01:55 GMT   (8244kb)

Title: S2ML: Spatio-Spectral Mutual Learning for Depth Completion
Authors: Zihui Zhao, Yifei Zhang, Zheng Wang, Yang Li, Kui Jiang, Zihan Geng,
 Chia-Wen Lin
Categories: cs.CV cs.AI
\\
 The raw depth images captured by RGB-D cameras using Time-of-Flight (TOF) or
structured light often suffer from incomplete depth values due to weak
reflections, boundary shadows, and artifacts, which limit their applications in
downstream vision tasks. Existing methods address this problem through depth
completion in the image domain, but they overlook the physical characteristics
of raw depth images. It has been observed that the presence of invalid depth
areas alters the frequency distribution pattern. In this work, we propose a
Spatio-Spectral Mutual Learning framework (S2ML) to harmonize the advantages of
both spatial and frequency domains for depth completion. Specifically, we
consider the distinct properties of amplitude and phase spectra and devise a
dedicated spectral fusion module. Meanwhile, the local and global correlations
between spatial-domain and frequency-domain features are calculated in a
unified embedding space. The gradual mutual representation and refinement
encourage the network to fully explore complementary physical characteristics
and priors for more accurate depth completion. Extensive experiments
demonstrate the effectiveness of our proposed S2ML method, outperforming the
state-of-the-art method CFormer by 0.828 dB and 0.834 dB on the NYU-Depth V2
and SUN RGB-D datasets, respectively.
\\ ( https://arxiv.org/abs/2511.06033 ,  8244kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06046
Date: Sat, 8 Nov 2025 15:35:43 GMT   (39270kb)

Title: StreamSTGS: Streaming Spatial and Temporal Gaussian Grids for Real-Time
 Free-Viewpoint Video
Authors: Zhihui Ke, Yuyang Liu, Xiaobo Zhou, Tie Qiu
Categories: cs.CV
Comments: Accepted by AAAI 2026. Code will be released at
 https://www.github.com/kkkzh/StreamSTGS
\\
 Streaming free-viewpoint video~(FVV) in real-time still faces significant
challenges, particularly in training, rendering, and transmission efficiency.
Harnessing superior performance of 3D Gaussian Splatting~(3DGS), recent
3DGS-based FVV methods have achieved notable breakthroughs in both training and
rendering. However, the storage requirements of these methods can reach up to
$10$MB per frame, making stream FVV in real-time impossible. To address this
problem, we propose a novel FVV representation, dubbed StreamSTGS, designed for
real-time streaming. StreamSTGS represents a dynamic scene using canonical 3D
Gaussians, temporal features, and a deformation field. For high compression
efficiency, we encode canonical Gaussian attributes as 2D images and temporal
features as a video. This design not only enables real-time streaming, but also
inherently supports adaptive bitrate control based on network condition without
any extra training. Moreover, we propose a sliding window scheme to aggregate
adjacent temporal features to learn local motions, and then introduce a
transformer-guided auxiliary training module to learn global motions. On
diverse FVV benchmarks, StreamSTGS demonstrates competitive performance on all
metrics compared to state-of-the-art methods. Notably, StreamSTGS increases the
PSNR by an average of $1$dB while reducing the average frame size to just
$170$KB. The code is publicly available on https://github.com/kkkzh/StreamSTGS.
\\ ( https://arxiv.org/abs/2511.06046 ,  39270kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06055
Date: Sat, 8 Nov 2025 15:54:32 GMT   (30686kb)

Title: Neodragon: Mobile Video Generation using Diffusion Transformer
Authors: Animesh Karnewar, Denis Korzhenkov, Ioannis Lelekas, Adil Karjauv,
 Noor Fathima, Hanwen Xiong, Vancheeswaran Vaidyanathan, Will Zeng, Rafael
 Esteves, Tushar Singhal, Fatih Porikli, Mohsen Ghafoorian, Amirhossein
 Habibian
Categories: cs.CV
\\
 We introduce Neodragon, a text-to-video system capable of generating 2s (49
frames @24 fps) videos at the 640x1024 resolution directly on a Qualcomm
Hexagon NPU in a record 6.7s (7 FPS). Differing from existing transformer-based
offline text-to-video generation models, Neodragon is the first to have been
specifically optimised for mobile hardware to achieve efficient and
high-fidelity video synthesis. We achieve this through four key technical
contributions: (1) Replacing the original large 4.762B T5xxl Text-Encoder with
a much smaller 0.2B DT5 (DistilT5) with minimal quality loss, enabled through a
novel Text-Encoder Distillation procedure. (2) Proposing an Asymmetric Decoder
Distillation approach allowing us to replace the native codec-latent-VAE
decoder with a more efficient one, without disturbing the generative
latent-space of the generation pipeline. (3) Pruning of MMDiT blocks within the
denoiser backbone based on their relative importance, with recovery of original
performance through a two-stage distillation process. (4) Reducing the NFE
(Neural Functional Evaluation) requirement of the denoiser by performing step
distillation using DMD adapted for pyramidal flow-matching, thereby
substantially accelerating video generation. When paired with an optimised
SSD1B first-frame image generator and QuickSRNet for 2x super-resolution, our
end-to-end Neodragon system becomes a highly parameter (4.945B full model),
memory (3.5GB peak RAM usage), and runtime (6.7s E2E latency) efficient
mobile-friendly model, while achieving a VBench total score of 81.61. By
enabling low-cost, private, and on-device text-to-video synthesis, Neodragon
democratizes AI-based video content creation, empowering creators to generate
high-quality videos without reliance on cloud services. Code and model will be
made publicly available at our website:
https://qualcomm-ai-research.github.io/neodragon
\\ ( https://arxiv.org/abs/2511.06055 ,  30686kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06066
Date: Sat, 8 Nov 2025 16:36:52 GMT   (40662kb)

Title: LoopExpose: An Unsupervised Framework for Arbitrary-Length Exposure
 Correction
Authors: Ao Li, Chen Chen, Zhenyu Wang, Tao Huang, Fangfang Wu, Weisheng Dong
Categories: cs.CV
\\
 Exposure correction is essential for enhancing image quality under
challenging lighting conditions. While supervised learning has achieved
significant progress in this area, it relies heavily on large-scale labeled
datasets, which are difficult to obtain in practical scenarios. To address this
limitation, we propose a pseudo label-based unsupervised method called
LoopExpose for arbitrary-length exposure correction. A nested loop optimization
strategy is proposed to address the exposure correction problem, where the
correction model and pseudo-supervised information are jointly optimized in a
two-level framework. Specifically, the upper-level trains a correction model
using pseudo-labels generated through multi-exposure fusion at the lower level.
A feedback mechanism is introduced where corrected images are fed back into the
fusion process to refine the pseudo-labels, creating a self-reinforcing
learning loop. Considering the dominant role of luminance calibration in
exposure correction, a Luminance Ranking Loss is introduced to leverage the
relative luminance ordering across the input sequence as a self-supervised
constraint. Extensive experiments on different benchmark datasets demonstrate
that LoopExpose achieves superior exposure correction and fusion performance,
outperforming existing state-of-the-art unsupervised methods. Code is available
at https://github.com/FALALAS/LoopExpose.
\\ ( https://arxiv.org/abs/2511.06066 ,  40662kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06080
Date: Sat, 8 Nov 2025 17:23:51 GMT   (13684kb)

Title: An Artificial Intelligence-based Assistant for the Visually Impaired
Authors: Luis Marquez-Carpintero, Francisco Gomez-Donoso, Zuria Bauer, Bessie
 Dominguez-Dager, Alvaro Belmonte-Baeza, M\'onica Pina-Navarro, Francisco
 Morillas-Espejo, Felix Escalona, Miguel Cazorla
Categories: cs.CV cs.CY cs.HC
\\
 This paper describes an artificial intelligence-based assistant application,
AIDEN, developed during 2023 and 2024, aimed at improving the quality of life
for visually impaired individuals. Visually impaired individuals face
challenges in identifying objects, reading text, and navigating unfamiliar
environments, which can limit their independence and reduce their quality of
life. Although solutions such as Braille, audio books, and screen readers
exist, they may not be effective in all situations. This application leverages
state-of-the-art machine learning algorithms to identify and describe objects,
read text, and answer questions about the environment. Specifically, it uses
You Only Look Once architectures and a Large Language and Vision Assistant. The
system incorporates several methods to facilitate the user's interaction with
the system and access to textual and visual information in an appropriate
manner. AIDEN aims to enhance user autonomy and access to information,
contributing to an improved perception of daily usability, as supported by user
feedback.
\\ ( https://arxiv.org/abs/2511.06080 ,  13684kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06087
Date: Sat, 8 Nov 2025 17:48:58 GMT   (6147kb)

Title: Hybrid CNN-ViT Framework for Motion-Blurred Scene Text Restoration
Authors: Umar Rashid (1), Muhammad Arslan Arshad (1), Ghulam Ahmad (1),
 Muhammad Zeeshan Anjum (1), Rizwan Khan (1), Muhammad Akmal (2) ((1)
 University of Engineering & Technology, New Campus, Lahore, Pakistan, (2)
 Sheffield Hallam University, Sheffield, UK)
Categories: cs.CV cs.AI
\\
 Motion blur in scene text images severely impairs readability and hinders the
reliability of computer vision tasks, including autonomous driving, document
digitization, and visual information retrieval. Conventional deblurring
approaches are often inadequate in handling spatially varying blur and
typically fall short in modeling the long-range dependencies necessary for
restoring textual clarity. To overcome these limitations, we introduce a hybrid
deep learning framework that combines convolutional neural networks (CNNs) with
vision transformers (ViTs), thereby leveraging both local feature extraction
and global contextual reasoning. The architecture employs a CNN-based
encoder-decoder to preserve structural details, while a transformer module
enhances global awareness through self-attention. Training is conducted on a
curated dataset derived from TextOCR, where sharp scene-text samples are paired
with synthetically blurred versions generated using realistic motion-blur
kernels of multiple sizes and orientations. Model optimization is guided by a
composite loss that incorporates mean absolute error (MAE), squared error
(MSE), perceptual similarity, and structural similarity (SSIM). Quantitative
eval- uations show that the proposed method attains 32.20 dB in PSNR and 0.934
in SSIM, while remaining lightweight with 2.83 million parameters and an
average inference time of 61 ms. These results highlight the effectiveness and
computational efficiency of the CNN-ViT hybrid design, establishing its
practicality for real-world motion-blurred scene-text restoration.
\\ ( https://arxiv.org/abs/2511.06087 ,  6147kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06115
Date: Sat, 8 Nov 2025 19:50:53 GMT   (4451kb)

Title: DiLO: Disentangled Latent Optimization for Learning Shape and
 Deformation in Grouped Deforming 3D Objects
Authors: Mostofa Rafid Uddin, Jana Armouti, Umong Sain, Md Asib Rahman,
 Xingjian Li, and Min Xu
Categories: cs.CV
\\
 In this work, we propose a disentangled latent optimization-based method for
parameterizing grouped deforming 3D objects into shape and deformation factors
in an unsupervised manner. Our approach involves the joint optimization of a
generator network along with the shape and deformation factors, supported by
specific regularization techniques. For efficient amortized inference of
disentangled shape and deformation codes, we train two order-invariant
PoinNet-based encoder networks in the second stage of our method. We
demonstrate several significant downstream applications of our method,
including unsupervised deformation transfer, deformation classification, and
explainability analysis. Extensive experiments conducted on 3D human, animal,
and facial expression datasets demonstrate that our simple approach is highly
effective in these downstream tasks, comparable or superior to existing methods
with much higher complexity.
\\ ( https://arxiv.org/abs/2511.06115 ,  4451kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06138
Date: Sat, 8 Nov 2025 21:20:59 GMT   (35356kb)

Title: Latent Refinement via Flow Matching for Training-free Linear Inverse
 Problem Solving
Authors: Hossein Askari, Yadan Luo, Hongfu Sun, Fred Roosta
Categories: cs.CV
Comments: 37 pages, 16 figures,
\\
 Recent advances in inverse problem solving have increasingly adopted flow
priors over diffusion models due to their ability to construct straight
probability paths from noise to data, thereby enhancing efficiency in both
training and inference. However, current flow-based inverse solvers face two
primary limitations: (i) they operate directly in pixel space, which demands
heavy computational resources for training and restricts scalability to
high-resolution images, and (ii) they employ guidance strategies with
prior-agnostic posterior covariances, which can weaken alignment with the
generative trajectory and degrade posterior coverage. In this paper, we propose
LFlow (Latent Refinement via Flows), a training-free framework for solving
linear inverse problems via pretrained latent flow priors. LFlow leverages the
efficiency of flow matching to perform ODE sampling in latent space along an
optimal path. This latent formulation further allows us to introduce a
theoretically grounded posterior covariance, derived from the optimal vector
field, enabling effective flow guidance. Experimental results demonstrate that
our proposed method outperforms state-of-the-art latent diffusion solvers in
reconstruction quality across most tasks. The code will be publicly available
at https://github.com/hosseinaskari-cs/LFlow .
\\ ( https://arxiv.org/abs/2511.06138 ,  35356kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06152
Date: Sat, 8 Nov 2025 22:09:32 GMT   (10662kb)

Title: Real-Time Bundle Adjustment for Ultra-High-Resolution UAV Imagery Using
 Adaptive Patch-Based Feature Tracking
Authors: Selim Ahmet Iz, Francesco Nex, Norman Kerle, Henry Meissner, Ralf
 Berger
Categories: cs.CV math.OC
DOI: 10.5194/isprs-annals-X-2-W2-2025-73-2025
\\
 Real-time processing of UAV imagery is crucial for applications requiring
urgent geospatial information, such as disaster response, where rapid
decision-making and accurate spatial data are essential. However, processing
high-resolution imagery in real time presents significant challenges due to the
computational demands of feature extraction, matching, and bundle adjustment
(BA). Conventional BA methods either downsample images, sacrificing important
details, or require extensive processing time, making them unsuitable for
time-critical missions. To overcome these limitations, we propose a novel
real-time BA framework that operates directly on fullresolution UAV imagery
without downsampling. Our lightweight, onboard-compatible approach divides each
image into user-defined patches (e.g., NxN grids, default 150x150 pixels) and
dynamically tracks them across frames using UAV GNSS/IMU data and a coarse,
globally available digital surface model (DSM). This ensures spatial
consistency for robust feature extraction and matching between patches.
Overlapping relationships between images are determined in real time using UAV
navigation system, enabling the rapid selection of relevant neighbouring images
for localized BA. By limiting optimization to a sliding cluster of overlapping
images, including those from adjacent flight strips, the method achieves
real-time performance while preserving the accuracy of global BA. The proposed
algorithm is designed for seamless integration into the DLR Modular Aerial
Camera System (MACS), supporting largearea mapping in real time for disaster
response, infrastructure monitoring, and coastal protection. Validation on MACS
datasets with 50MP images demonstrates that the method maintains precise camera
orientations and high-fidelity mapping across multiple strips, running full
bundle adjustment in under 2 seconds without GPU acceleration.
\\ ( https://arxiv.org/abs/2511.06152 ,  10662kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06172
Date: Sun, 9 Nov 2025 00:53:58 GMT   (6834kb)

Title: MambaOVSR: Multiscale Fusion with Global Motion Modeling for Chinese
 Opera Video Super-Resolution
Authors: Hua Chang, Xin Xu, Wei Liu, Wei Wang, Xin Yuan, Kui Jiang
Categories: cs.CV cs.AI
\\
 Chinese opera is celebrated for preserving classical art. However, early
filming equipment limitations have degraded videos of last-century performances
by renowned artists (e.g., low frame rates and resolution), hindering archival
efforts. Although space-time video super-resolution (STVSR) has advanced
significantly, applying it directly to opera videos remains challenging. The
scarcity of datasets impedes the recovery of high frequency details, and
existing STVSR methods lack global modeling capabilities, compromising visual
quality when handling opera's characteristic large motions. To address these
challenges, we pioneer a large scale Chinese Opera Video Clip (COVC) dataset
and propose the Mamba-based multiscale fusion network for space-time Opera
Video Super-Resolution (MambaOVSR). Specifically, MambaOVSR involves three
novel components: the Global Fusion Module (GFM) for motion modeling through a
multiscale alternating scanning mechanism, and the Multiscale Synergistic Mamba
Module (MSMM) for alignment across different sequence lengths. Additionally,
our MambaVR block resolves feature artifacts and positional information loss
during alignment. Experimental results on the COVC dataset show that MambaOVSR
significantly outperforms the SOTA STVSR method by an average of 1.86 dB in
terms of PSNR. Dataset and Code will be publicly released.
\\ ( https://arxiv.org/abs/2511.06172 ,  6834kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06194
Date: Sun, 9 Nov 2025 02:45:12 GMT   (30421kb)

Title: NURBGen: High-Fidelity Text-to-CAD Generation through LLM-Driven NURBS
 Modeling
Authors: Muhammad Usama, Mohammad Sadil Khan, Didier Stricker, Muhammad Zeshan
 Afzal
Categories: cs.CV
Comments: Accepted in AAAI 2026
\\
 Generating editable 3D CAD models from natural language remains challenging,
as existing text-to-CAD systems either produce meshes or rely on scarce
design-history data. We present NURBGen, the first framework to generate
high-fidelity 3D CAD models directly from text using Non-Uniform Rational
B-Splines (NURBS). To achieve this, we fine-tune a large language model (LLM)
to translate free-form texts into JSON representations containing NURBS surface
parameters (\textit{i.e}, control points, knot vectors, degrees, and rational
weights) which can be directly converted into BRep format using Python. We
further propose a hybrid representation that combines untrimmed NURBS with
analytic primitives to handle trimmed surfaces and degenerate regions more
robustly, while reducing token complexity. Additionally, we introduce partABC,
a curated subset of the ABC dataset consisting of individual CAD components,
annotated with detailed captions using an automated annotation pipeline.
NURBGen demonstrates strong performance on diverse prompts, surpassing prior
methods in geometric fidelity and dimensional accuracy, as confirmed by expert
evaluations. Code and dataset will be released publicly.
\\ ( https://arxiv.org/abs/2511.06194 ,  30421kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06201
Date: Sun, 9 Nov 2025 03:24:10 GMT   (26523kb)

Title: Scene-Aware Urban Design: A Human-AI Recommendation Framework Using
 Co-Occurrence Embeddings and Vision-Language Models
Authors: Rodrigo Gallardo, Oz Fishman, Alexander Htet Kyaw
Categories: cs.CV cs.HC
Comments: Accepted to NEURIPS 2025 Creative AI Track
\\
 This paper introduces a human-in-the-loop computer vision framework that uses
generative AI to propose micro-scale design interventions in public space and
support more continuous, local participation. Using Grounding DINO and a
curated subset of the ADE20K dataset as a proxy for the urban built
environment, the system detects urban objects and builds co-occurrence
embeddings that reveal common spatial configurations. From this analysis, the
user receives five statistically likely complements to a chosen anchor object.
A vision language model then reasons over the scene image and the selected pair
to suggest a third object that completes a more complex urban tactic. The
workflow keeps people in control of selection and refinement and aims to move
beyond top-down master planning by grounding choices in everyday patterns and
lived experience.
\\ ( https://arxiv.org/abs/2511.06201 ,  26523kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06225
Date: Sun, 9 Nov 2025 04:52:42 GMT   (457kb)

Title: MoRA: Missing Modality Low-Rank Adaptation for Visual Recognition
Authors: Shu Zhao, Nilesh Ahuja, Tan Yu, Tianyi Shen, Vijaykrishnan Narayanan
Categories: cs.CV
\\
 Pre-trained vision language models have shown remarkable performance on
visual recognition tasks, but they typically assume the availability of
complete multimodal inputs during both training and inference. In real-world
scenarios, however, modalities may be missing due to privacy constraints,
collection difficulties, or resource limitations. While previous approaches
have addressed this challenge using prompt learning techniques, they fail to
capture the cross-modal relationships necessary for effective multimodal visual
recognition and suffer from inevitable computational overhead. In this paper,
we introduce MoRA, a parameter-efficient fine-tuning method that explicitly
models cross-modal interactions while maintaining modality-specific
adaptations. MoRA introduces modality-common parameters between text and vision
encoders, enabling bidirectional knowledge transfer. Additionally, combined
with the modality-specific parameters, MoRA allows the backbone model to
maintain inter-modality interaction and enable intra-modality flexibility.
Extensive experiments on standard benchmarks demonstrate that MoRA achieves an
average performance improvement in missing-modality scenarios by 5.24% and uses
only 25.90% of the inference time compared to the SOTA method while requiring
only 0.11% of trainable parameters compared to full fine-tuning.
\\ ( https://arxiv.org/abs/2511.06225 ,  457kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06238
Date: Sun, 9 Nov 2025 05:45:25 GMT   (8687kb)

Title: Temporal-Guided Visual Foundation Models for Event-Based Vision
Authors: Ruihao Xia, Junhong Cai, Luziwei Leng, Liuyi Wang, Chengju Liu, Ran
 Cheng, Yang Tang, Pan Zhou
Categories: cs.CV
\\
 Event cameras offer unique advantages for vision tasks in challenging
environments, yet processing asynchronous event streams remains an open
challenge. While existing methods rely on specialized architectures or
resource-intensive training, the potential of leveraging modern Visual
Foundation Models (VFMs) pretrained on image data remains under-explored for
event-based vision. To address this, we propose Temporal-Guided VFM (TGVFM), a
novel framework that integrates VFMs with our temporal context fusion block
seamlessly to bridge this gap. Our temporal block introduces three key
components: (1) Long-Range Temporal Attention to model global temporal
dependencies, (2) Dual Spatiotemporal Attention for multi-scale frame
correlation, and (3) Deep Feature Guidance Mechanism to fuse semantic-temporal
features. By retraining event-to-video models on real-world data and leveraging
transformer-based VFMs, TGVFM preserves spatiotemporal dynamics while
harnessing pretrained representations. Experiments demonstrate SoTA performance
across semantic segmentation, depth estimation, and object detection, with
improvements of 16%, 21%, and 16% over existing methods, respectively. Overall,
this work unlocks the cross-modality potential of image-based VFMs for
event-based vision with temporal reasoning. Code is available at
https://github.com/XiaRho/TGVFM.
\\ ( https://arxiv.org/abs/2511.06238 ,  8687kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06244
Date: Sun, 9 Nov 2025 06:10:20 GMT   (1480kb)

Title: Physics-Informed Image Restoration via Progressive PDE Integration
Authors: Shamika Likhite, Santiago L\'opez-Tapia, Aggelos K. Katsaggelos
Categories: cs.CV
\\
 Motion blur, caused by relative movement between camera and scene during
exposure, significantly degrades image quality and impairs downstream computer
vision tasks such as object detection, tracking, and recognition in dynamic
environments. While deep learning-based motion deblurring methods have achieved
remarkable progress, existing approaches face fundamental challenges in
capturing the long-range spatial dependencies inherent in motion blur patterns.
Traditional convolutional methods rely on limited receptive fields and require
extremely deep networks to model global spatial relationships. These
limitations motivate the need for alternative approaches that incorporate
physical priors to guide feature evolution during restoration. In this paper,
we propose a progressive training framework that integrates physics-informed
PDE dynamics into state-of-the-art restoration architectures. By leveraging
advection-diffusion equations to model feature evolution, our approach
naturally captures the directional flow characteristics of motion blur while
enabling principled global spatial modeling. Our PDE-enhanced deblurring models
achieve superior restoration quality with minimal overhead, adding only
approximately 1\% to inference GMACs while providing consistent improvements in
perceptual quality across multiple state-of-the-art architectures.
Comprehensive experiments on standard motion deblurring benchmarks demonstrate
that our physics-informed approach improves PSNR and SSIM significantly across
four diverse architectures, including FFTformer, NAFNet, Restormer, and
Stripformer. These results validate that incorporating mathematical physics
principles through PDE-based global layers can enhance deep learning-based
image restoration, establishing a promising direction for physics-informed
neural network design in computer vision applications.
\\ ( https://arxiv.org/abs/2511.06244 ,  1480kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06245
Date: Sun, 9 Nov 2025 06:10:35 GMT   (326kb)

Title: Gait Recognition via Collaborating Discriminative and Generative
 Diffusion Models
Authors: Haijun Xiong, Bin Feng, Bang Wang, Xinggang Wang, Wenyu Liu
Categories: cs.CV
Comments: 14 pages, 4figures
\\
 Gait recognition offers a non-intrusive biometric solution by identifying
individuals through their walking patterns. Although discriminative models have
achieved notable success in this domain, the full potential of generative
models remains largely underexplored. In this paper, we introduce
\textbf{CoD$^2$}, a novel framework that combines the data distribution
modeling capabilities of diffusion models with the semantic representation
learning strengths of discriminative models to extract robust gait features. We
propose a Multi-level Conditional Control strategy that incorporates both
high-level identity-aware semantic conditions and low-level visual details.
Specifically, the high-level condition, extracted by the discriminative
extractor, guides the generation of identity-consistent gait sequences, whereas
low-level visual details, such as appearance and motion, are preserved to
enhance consistency. Furthermore, the generated sequences facilitate the
discriminative extractor's learning, enabling it to capture more comprehensive
high-level semantic features. Extensive experiments on four datasets
(SUSTech1K, CCPG, GREW, and Gait3D) demonstrate that CoD$^2$ achieves
state-of-the-art performance and can be seamlessly integrated with existing
discriminative methods, yielding consistent improvements.
\\ ( https://arxiv.org/abs/2511.06245 ,  326kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06253
Date: Sun, 9 Nov 2025 07:05:03 GMT   (1578kb)

Title: AdaDrive: Self-Adaptive Slow-Fast System for Language-Grounded
 Autonomous Driving
Authors: Ruifei Zhang, Junlin Xie, Wei Zhang, Weikai Chen, Xiao Tan, Xiang Wan,
 Guanbin Li
Categories: cs.CV
Comments: Accepted by ICCV2025
\\
 Effectively integrating Large Language Models (LLMs) into autonomous driving
requires a balance between leveraging high-level reasoning and maintaining
real-time efficiency. Existing approaches either activate LLMs too frequently,
causing excessive computational overhead, or use fixed schedules, failing to
adapt to dynamic driving conditions. To address these challenges, we propose
AdaDrive, an adaptively collaborative slow-fast framework that optimally
determines when and how LLMs contribute to decision-making. (1) When to
activate the LLM: AdaDrive employs a novel adaptive activation loss that
dynamically determines LLM invocation based on a comparative learning
mechanism, ensuring activation only in complex or critical scenarios. (2) How
to integrate LLM assistance: Instead of rigid binary activation, AdaDrive
introduces an adaptive fusion strategy that modulates a continuous, scaled LLM
influence based on scene complexity and prediction confidence, ensuring
seamless collaboration with conventional planners. Through these strategies,
AdaDrive provides a flexible, context-aware framework that maximizes decision
accuracy without compromising real-time performance. Extensive experiments on
language-grounded autonomous driving benchmarks demonstrate that AdaDrive
state-of-the-art performance in terms of both driving accuracy and
computational efficiency. Code is available at
https://github.com/ReaFly/AdaDrive.
\\ ( https://arxiv.org/abs/2511.06253 ,  1578kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06256
Date: Sun, 9 Nov 2025 07:14:53 GMT   (897kb)

Title: VLDrive: Vision-Augmented Lightweight MLLMs for Efficient
 Language-grounded Autonomous Driving
Authors: Ruifei Zhang, Wei Zhang, Xiao Tan, Sibei Yang, Xiang Wan, Xiaonan Luo,
 Guanbin Li
Categories: cs.CV
Comments: Accepted by ICCV2025
\\
 Recent advancements in language-grounded autonomous driving have been
significantly promoted by the sophisticated cognition and reasoning
capabilities of large language models (LLMs). However, current LLM-based
approaches encounter critical challenges: (1) Failure analysis reveals that
frequent collisions and obstructions, stemming from limitations in visual
representations, remain primary obstacles to robust driving performance. (2)
The substantial parameters of LLMs pose considerable deployment hurdles. To
address these limitations, we introduce VLDrive, a novel approach featuring a
lightweight MLLM architecture with enhanced vision components. VLDrive achieves
compact visual tokens through innovative strategies, including cycle-consistent
dynamic visual pruning and memory-enhanced feature aggregation. Furthermore, we
propose a distance-decoupled instruction attention mechanism to improve joint
visual-linguistic feature learning, particularly for long-range visual tokens.
Extensive experiments conducted in the CARLA simulator demonstrate VLDrive`s
effectiveness. Notably, VLDrive achieves state-of-the-art driving performance
while reducing parameters by 81% (from 7B to 1.3B), yielding substantial
driving score improvements of 15.4%, 16.8%, and 7.6% at tiny, short, and long
distances, respectively, in closed-loop evaluations. Code is available at
https://github.com/ReaFly/VLDrive.
\\ ( https://arxiv.org/abs/2511.06256 ,  897kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06261
Date: Sun, 9 Nov 2025 07:37:05 GMT   (4116kb)

Title: Robust Nearest Neighbour Retrieval Using Targeted Manifold Manipulation
Authors: B. Ghosh, H. Harikumar, S. Rana
Categories: cs.CV
\\
 Nearest-neighbour retrieval is central to classification and explainable-AI
pipelines, but current practice relies on hand-tuning feature layers and
distance metrics. We propose Targeted Manifold Manipulation-Nearest Neighbour
(TMM-NN), which reconceptualises retrieval by assessing how readily each sample
can be nudged into a designated region of the feature manifold; neighbourhoods
are defined by a sample's responsiveness to a targeted perturbation rather than
absolute geometric distance. TMM-NN implements this through a lightweight,
query-specific trigger patch. The patch is added to the query image, and the
network is weakly ``backdoored'' so that any input with the patch is steered
toward a dummy class. Images similar to the query need only a slight shift and
are classified as the dummy class with high probability, while dissimilar ones
are less affected. By ranking candidates by this confidence, TMM-NN retrieves
the most semantically related neighbours. Robustness analysis and benchmark
experiments confirm this trigger-based ranking outperforms traditional metrics
under noise and across diverse tasks.
\\ ( https://arxiv.org/abs/2511.06261 ,  4116kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06266
Date: Sun, 9 Nov 2025 08:02:15 GMT   (2005kb)

Title: A Mixture-of-Experts Framework with Log-Logistic Components for Survival
 Analysis on Histopathology Images
Authors: Ardhendu Sekhar, Vasu Soni, Keshav Aske, Shivam Madnoorkar, Pranav
 Jeevan, Amit Sethi
Categories: cs.CV
\\
 We propose a modular framework for predicting cancer specific survival from
whole slide pathology images (WSIs). The method integrates four components: (i)
Quantile Gated Patch Selection via quantile based thresholding to isolate
prognostically informative tissue regions; (ii) Graph Guided Clustering using a
k nearest neighbor graph to capture phenotype level heterogeneity through
spatial and morphological coherence; (iii) Hierarchical Context Attention to
learn intra and inter cluster interactions; and (iv) an Expert Driven Mixture
of Log logistics framework to estimate complex survival distributions using Log
logistics distributions. The model attains a concordance index of 0.644 on TCGA
LUAD, 0.751 on TCGA KIRC, and 0.752 on TCGA BRCA respectively, outperforming
existing state of the art approaches.
\\ ( https://arxiv.org/abs/2511.06266 ,  2005kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06268
Date: Sun, 9 Nov 2025 08:05:40 GMT   (1423kb)

Title: LLM-Driven Completeness and Consistency Evaluation for Cultural Heritage
 Data Augmentation in Cross-Modal Retrieval
Authors: Jian Zhang, Junyi Guo, Junyi Yuan, Huanda Lu, Yanlin Zhou, Fangyu Wu,
 Qiufeng Wang, Dongming Lu
Categories: cs.CV cs.CY
\\
 Cross-modal retrieval is essential for interpreting cultural heritage data,
but its effectiveness is often limited by incomplete or inconsistent textual
descriptions, caused by historical data loss and the high cost of expert
annotation. While large language models (LLMs) offer a promising solution by
enriching textual descriptions, their outputs frequently suffer from
hallucinations or miss visually grounded details. To address these challenges,
we propose $C^3$, a data augmentation framework that enhances cross-modal
retrieval performance by improving the completeness and consistency of
LLM-generated descriptions. $C^3$ introduces a completeness evaluation module
to assess semantic coverage using both visual cues and language-model outputs.
Furthermore, to mitigate factual inconsistencies, we formulate a Markov
Decision Process to supervise Chain-of-Thought reasoning, guiding consistency
evaluation through adaptive query control. Experiments on the cultural heritage
datasets CulTi and TimeTravel, as well as on general benchmarks MSCOCO and
Flickr30K, demonstrate that $C^3$ achieves state-of-the-art performance in both
fine-tuned and zero-shot settings.
\\ ( https://arxiv.org/abs/2511.06268 ,  1423kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06271
Date: Sun, 9 Nov 2025 08:12:09 GMT   (6525kb)

Title: RelightMaster: Precise Video Relighting with Multi-plane Light Images
Authors: Weikang Bian, Xiaoyu Shi, Zhaoyang Huang, Jianhong Bai, Qinghe Wang,
 Xintao Wang, Pengfei Wan, Kun Gai, Hongsheng Li
Categories: cs.CV
Comments: Project Page: https://wkbian.github.io/Projects/RelightMaster/
\\
 Recent advances in diffusion models enable high-quality video generation and
editing, but precise relighting with consistent video contents, which is
critical for shaping scene atmosphere and viewer attention, remains unexplored.
Mainstream text-to-video (T2V) models lack fine-grained lighting control due to
text's inherent limitation in describing lighting details and insufficient
pre-training on lighting-related prompts. Additionally, constructing
high-quality relighting training data is challenging, as real-world
controllable lighting data is scarce. To address these issues, we propose
RelightMaster, a novel framework for accurate and controllable video
relighting. First, we build RelightVideo, the first dataset with identical
dynamic content under varying precise lighting conditions based on the Unreal
Engine. Then, we introduce Multi-plane Light Image (MPLI), a novel visual
prompt inspired by Multi-Plane Image (MPI). MPLI models lighting via K
depth-aligned planes, representing 3D light source positions, intensities, and
colors while supporting multi-source scenarios and generalizing to unseen light
setups. Third, we design a Light Image Adapter that seamlessly injects MPLI
into pre-trained Video Diffusion Transformers (DiT): it compresses MPLI via a
pre-trained Video VAE and injects latent light features into DiT blocks,
leveraging the base model's generative prior without catastrophic forgetting.
Experiments show that RelightMaster generates physically plausible lighting and
shadows and preserves original scene content. Demos are available at
https://wkbian.github.io/Projects/RelightMaster/.
\\ ( https://arxiv.org/abs/2511.06271 ,  6525kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06272
Date: Sun, 9 Nov 2025 08:15:58 GMT   (6691kb)

Title: LaneDiffusion: Improving Centerline Graph Learning via Prior Injected
 BEV Feature Generation
Authors: Zijie Wang, Weiming Zhang, Wei Zhang, Xiao Tan, Hongxing Liu, Yaowei
 Wang, Guanbin Li
Categories: cs.CV cs.AI
Comments: Accepted by ICCV 2025
\\
 Centerline graphs, crucial for path planning in autonomous driving, are
traditionally learned using deterministic methods. However, these methods often
lack spatial reasoning and struggle with occluded or invisible centerlines.
Generative approaches, despite their potential, remain underexplored in this
domain. We introduce LaneDiffusion, a novel generative paradigm for centerline
graph learning. LaneDiffusion innovatively employs diffusion models to generate
lane centerline priors at the Bird's Eye View (BEV) feature level, instead of
directly predicting vectorized centerlines. Our method integrates a Lane Prior
Injection Module (LPIM) and a Lane Prior Diffusion Module (LPDM) to effectively
construct diffusion targets and manage the diffusion process. Furthermore,
vectorized centerlines and topologies are then decoded from these
prior-injected BEV features. Extensive evaluations on the nuScenes and
Argoverse2 datasets demonstrate that LaneDiffusion significantly outperforms
existing methods, achieving improvements of 4.2%, 4.6%, 4.7%, 6.4% and 1.8% on
fine-grained point-level metrics (GEO F1, TOPO F1, JTOPO F1, APLS and SDA) and
2.3%, 6.4%, 6.8% and 2.1% on segment-level metrics (IoU, mAP_cf, DET_l and
TOP_ll). These results establish state-of-the-art performance in centerline
graph learning, offering new insights into generative models for this task.
\\ ( https://arxiv.org/abs/2511.06272 ,  6691kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06281
Date: Sun, 9 Nov 2025 08:36:40 GMT   (21644kb)

Title: VideoSSR: Video Self-Supervised Reinforcement Learning
Authors: Zefeng He, Xiaoye Qu, Yafu Li, Siyuan Huang, Daizong Liu, Yu Cheng
Categories: cs.CV
\\
 Reinforcement Learning with Verifiable Rewards (RLVR) has substantially
advanced the video understanding capabilities of Multimodal Large Language
Models (MLLMs). However, the rapid progress of MLLMs is outpacing the
complexity of existing video datasets, while the manual annotation of new,
high-quality data remains prohibitively expensive. This work investigates a
pivotal question: Can the rich, intrinsic information within videos be
harnessed to self-generate high-quality, verifiable training data? To
investigate this, we introduce three self-supervised pretext tasks: Anomaly
Grounding, Object Counting, and Temporal Jigsaw. We construct the Video
Intrinsic Understanding Benchmark (VIUBench) to validate their difficulty,
revealing that current state-of-the-art MLLMs struggle significantly on these
tasks. Building upon these pretext tasks, we develop the VideoSSR-30K dataset
and propose VideoSSR, a novel video self-supervised reinforcement learning
framework for RLVR. Extensive experiments across 17 benchmarks, spanning four
major video domains (General Video QA, Long Video QA, Temporal Grounding, and
Complex Reasoning), demonstrate that VideoSSR consistently enhances model
performance, yielding an average improvement of over 5\%. These results
establish VideoSSR as a potent foundational framework for developing more
advanced video understanding in MLLMs. The code is available at
https://github.com/lcqysl/VideoSSR.
\\ ( https://arxiv.org/abs/2511.06281 ,  21644kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06282
Date: Sun, 9 Nov 2025 08:36:42 GMT   (1263kb)

Title: From ACR O-RADS 2022 to Explainable Deep Learning: Comparative
 Performance of Expert Radiologists, Convolutional Neural Networks, Vision
 Transformers, and Fusion Models in Ovarian Masses
Authors: Ali Abbasian Ardakani, Afshin Mohammadi, Alisa Mohebbi, Anushya
 Vijayananthan, Sook Sam Leong, Lim Yi Ting, Mohd Kamil Bin Mohamad Fabell, U
 Rajendra Acharya, Sepideh Hatamikia
Categories: cs.CV
Comments: 18 pages, 4 figures
\\
 Background: The 2022 update of the Ovarian-Adnexal Reporting and Data System
(O-RADS) ultrasound classification refines risk stratification for adnexal
lesions, yet human interpretation remains subject to variability and
conservative thresholds. Concurrently, deep learning (DL) models have
demonstrated promise in image-based ovarian lesion characterization. This study
evaluates radiologist performance applying O-RADS v2022, compares it to leading
convolutional neural network (CNN) and Vision Transformer (ViT) models, and
investigates the diagnostic gains achieved by hybrid human-AI frameworks.
Methods: In this single-center, retrospective cohort study, a total of 512
adnexal mass images from 227 patients (110 with at least one malignant cyst)
were included. Sixteen DL models, including DenseNets, EfficientNets, ResNets,
VGGs, Xception, and ViTs, were trained and validated. A hybrid model
integrating radiologist O-RADS scores with DL-predicted probabilities was also
built for each scheme. Results: Radiologist-only O-RADS assessment achieved an
AUC of 0.683 and an overall accuracy of 68.0%. CNN models yielded AUCs of 0.620
to 0.908 and accuracies of 59.2% to 86.4%, while ViT16-384 reached the best
performance, with an AUC of 0.941 and an accuracy of 87.4%. Hybrid human-AI
frameworks further significantly enhanced the performance of CNN models;
however, the improvement for ViT models was not statistically significant
(P-value >0.05). Conclusions: DL models markedly outperform radiologist-only
O-RADS v2022 assessment, and the integration of expert scores with AI yields
the highest diagnostic accuracy and discrimination. Hybrid human-AI paradigms
hold substantial potential to standardize pelvic ultrasound interpretation,
reduce false positives, and improve detection of high-risk lesions.
\\ ( https://arxiv.org/abs/2511.06282 ,  1263kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06283
Date: Sun, 9 Nov 2025 08:37:18 GMT   (463kb)

Title: TinyChemVL: Advancing Chemical Vision-Language Models via Efficient
 Visual Token Reduction and Complex Reaction Tasks
Authors: Xuanle Zhao, Shuxin Zeng, Yinyuan Cai, Xiang Cheng, Duzhen Zhang,
 Xiuyi Chen, Bo Xu
Categories: cs.CV
Comments: Accepted by AAAI 2026, Preprint Version
\\
 While Vision Language Models (VLMs) have demonstrated remarkable capabilities
in general visual understanding, their application in the chemical domain has
been limited, with previous works predominantly focusing on text and thus
overlooking critical visual information, such as molecular structures. Current
approaches that directly adopt standard VLMs for chemical tasks suffer from two
primary issues: (i) computational inefficiency of processing entire chemical
images with non-informative backgrounds. (ii) a narrow scope on molecular-level
tasks that restricts progress in chemical reasoning. In this work, we propose
\textbf{TinyChemVL}, an efficient and powerful chemical VLM that leverages
visual token reduction and reaction-level tasks to improve model efficiency and
reasoning capacity. Also, we propose \textbf{ChemRxn-V}, a reaction-level
benchmark for assessing vision-based reaction recognition and prediction tasks.
Directly predicting reaction products from molecular images poses a non-trivial
challenge, as it requires models to integrate both recognition and reasoning
capacities. Our results demonstrate that with only 4B parameters, TinyChemVL
achieves superior performance on both molecular and reaction tasks while
demonstrating faster inference and training speeds compared to existing models.
Notably, TinyChemVL outperforms ChemVLM while utilizing only 1/16th of the
visual tokens. This work builds efficient yet powerful VLMs for chemical
domains by co-designing model architecture and task complexity.
\\ ( https://arxiv.org/abs/2511.06283 ,  463kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06284
Date: Sun, 9 Nov 2025 08:37:46 GMT   (951kb)

Title: Enhancing Multimodal Misinformation Detection by Replaying the Whole
 Story from Image Modality Perspective
Authors: Bing Wang, Ximing Li, Yanjun Wang, Changchun Li, Lin Yuanbo Wu, Buyu
 Wang, Shengsheng Wang
Categories: cs.CV cs.CL cs.MM
Comments: Accepted by AAAI 2026. 13 pages, 6 figures. Code:
 https://github.com/wangbing1416/RETSIMD
\\
 Multimodal Misinformation Detection (MMD) refers to the task of detecting
social media posts involving misinformation, where the post often contains text
and image modalities. However, by observing the MMD posts, we hold that the
text modality may be much more informative than the image modality because the
text generally describes the whole event/story of the current post but the
image often presents partial scenes only. Our preliminary empirical results
indicate that the image modality exactly contributes less to MMD. Upon this
idea, we propose a new MMD method named RETSIMD. Specifically, we suppose that
each text can be divided into several segments, and each text segment describes
a partial scene that can be presented by an image. Accordingly, we split the
text into a sequence of segments, and feed these segments into a pre-trained
text-to-image generator to augment a sequence of images. We further incorporate
two auxiliary objectives concerning text-image and image-label mutual
information, and further post-train the generator over an auxiliary
text-to-image generation benchmark dataset. Additionally, we propose a graph
structure by defining three heuristic relationships between images, and use a
graph neural network to generate the fused features. Extensive empirical
results validate the effectiveness of RETSIMD.
\\ ( https://arxiv.org/abs/2511.06284 ,  951kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06295
Date: Sun, 9 Nov 2025 09:13:22 GMT   (3587kb)

Title: Learning-Based Vision Systems for Semi-Autonomous Forklift Operation in
 Industrial Warehouse Environments
Authors: Vamshika Sutar, Mahek Maheshwari, Archak Mittal
Categories: cs.CV
\\
 The automation of material handling in warehouses increasingly relies on
robust, low cost perception systems for forklifts and Automated Guided Vehicles
(AGVs). This work presents a vision based framework for pallet and pallet hole
detection and mapping using a single standard camera. We utilized YOLOv8 and
YOLOv11 architectures, enhanced through Optuna driven hyperparameter
optimization and spatial post processing. An innovative pallet hole mapping
module converts the detections into actionable spatial representations,
enabling accurate pallet and pallet hole association for forklift operation.
Experiments on a custom dataset augmented with real warehouse imagery show that
YOLOv8 achieves high pallet and pallet hole detection accuracy, while YOLOv11,
particularly under optimized configurations, offers superior precision and
stable convergence. The results demonstrate the feasibility of a cost
effective, retrofittable visual perception module for forklifts. This study
proposes a scalable approach to advancing warehouse automation, promoting
safer, economical, and intelligent logistics operations.
\\ ( https://arxiv.org/abs/2511.06295 ,  3587kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06298
Date: Sun, 9 Nov 2025 09:34:10 GMT   (1191kb)

Title: SFFR: Spatial-Frequency Feature Reconstruction for Multispectral Aerial
 Object Detection
Authors: Xin Zuo, Yuchen Qu, Haibo Zhan, Jifeng Shen and Wankou Yang
Categories: cs.CV
Comments: 11 pages,8 figures, accepted by IEEE TGRS
\\
 Recent multispectral object detection methods have primarily focused on
spatial-domain feature fusion based on CNNs or Transformers, while the
potential of frequency-domain feature remains underexplored. In this work, we
propose a novel Spatial and Frequency Feature Reconstruction method (SFFR)
method, which leverages the spatial-frequency feature representation mechanisms
of the Kolmogorov-Arnold Network (KAN) to reconstruct complementary
representations in both spatial and frequency domains prior to feature fusion.
The core components of SFFR are the proposed Frequency Component Exchange KAN
(FCEKAN) module and Multi-Scale Gaussian KAN (MSGKAN) module. The FCEKAN
introduces an innovative selective frequency component exchange strategy that
effectively enhances the complementarity and consistency of cross-modal
features based on the frequency feature of RGB and IR images. The MSGKAN module
demonstrates excellent nonlinear feature modeling capability in the spatial
domain. By leveraging multi-scale Gaussian basis functions, it effectively
captures the feature variations caused by scale changes at different UAV flight
altitudes, significantly enhancing the model's adaptability and robustness to
scale variations. It is experimentally validated that our proposed FCEKAN and
MSGKAN modules are complementary and can effectively capture the frequency and
spatial semantic features respectively for better feature fusion. Extensive
experiments on the SeaDroneSee, DroneVehicle and DVTOD datasets demonstrate the
superior performance and significant advantages of the proposed method in UAV
multispectral object perception task. Code will be available at
https://github.com/qchenyu1027/SFFR.
\\ ( https://arxiv.org/abs/2511.06298 ,  1191kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06299
Date: Sun, 9 Nov 2025 09:35:03 GMT   (29642kb)

Title: Physics-Informed Deformable Gaussian Splatting: Towards Unified
 Constitutive Laws for Time-Evolving Material Field
Authors: Haoqin Hong, Ding Fan, Fubin Dou, Zhi-Li Zhou, Haoran Sun, Congcong
 Zhu, Jingrun Chen
Categories: cs.CV
Comments: Accepted by AAAI-26
\\
 Recently, 3D Gaussian Splatting (3DGS), an explicit scene representation
technique, has shown significant promise for dynamic novel-view synthesis from
monocular video input. However, purely data-driven 3DGS often struggles to
capture the diverse physics-driven motion patterns in dynamic scenes. To fill
this gap, we propose Physics-Informed Deformable Gaussian Splatting (PIDG),
which treats each Gaussian particle as a Lagrangian material point with
time-varying constitutive parameters and is supervised by 2D optical flow via
motion projection. Specifically, we adopt static-dynamic decoupled 4D
decomposed hash encoding to reconstruct geometry and motion efficiently.
Subsequently, we impose the Cauchy momentum residual as a physics constraint,
enabling independent prediction of each particle's velocity and constitutive
stress via a time-evolving material field. Finally, we further supervise data
fitting by matching Lagrangian particle flow to camera-compensated optical
flow, which accelerates convergence and improves generalization. Experiments on
a custom physics-driven dataset as well as on standard synthetic and real-world
datasets demonstrate significant gains in physical consistency and monocular
dynamic reconstruction quality.
\\ ( https://arxiv.org/abs/2511.06299 ,  29642kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06310
Date: Sun, 9 Nov 2025 10:14:14 GMT   (6543kb)

Title: Adaptive 3D Reconstruction via Diffusion Priors and Forward
 Curvature-Matching Likelihood Updates
Authors: Seunghyeok Shin, Dabin Kim, Hongki Lim
Categories: cs.CV
\\
 Reconstructing high-quality point clouds from images remains challenging in
computer vision. Existing generative-model-based approaches, particularly
diffusion-model approaches that directly learn the posterior, may suffer from
inflexibility -- they require conditioning signals during training, support
only a fixed number of input views, and need complete retraining for different
measurements. Recent diffusion-based methods have attempted to address this by
combining prior models with likelihood updates, but they rely on heuristic
fixed step sizes for the likelihood update that lead to slow convergence and
suboptimal reconstruction quality. We advance this line of approach by
integrating our novel Forward Curvature-Matching (FCM) update method with
diffusion sampling. Our method dynamically determines optimal step sizes using
only forward automatic differentiation and finite-difference curvature
estimates, enabling precise optimization of the likelihood update. This
formulation enables high-fidelity reconstruction from both single-view and
multi-view inputs, and supports various input modalities through simple
operator substitution -- all without retraining. Experiments on ShapeNet and
CO3D datasets demonstrate that our method achieves superior reconstruction
quality at matched or lower NFEs, yielding higher F-score and lower CD and EMD,
validating its efficiency and adaptability for practical applications. Code is
available at https://github.com/Seunghyeok0715/FCM
\\ ( https://arxiv.org/abs/2511.06310 ,  6543kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06315
Date: Sun, 9 Nov 2025 10:43:16 GMT   (2116kb)

Title: Seq2Seq Models Reconstruct Visual Jigsaw Puzzles without Seeing Them
Authors: Gur Elkn, Ofir Itzhak Shahar, Ohad Ben-Shahar
Categories: cs.CV
\\
 Jigsaw puzzles are primarily visual objects, whose algorithmic solutions have
traditionally been framed from a visual perspective. In this work, however, we
explore a fundamentally different approach: solving square jigsaw puzzles using
language models, without access to raw visual input. By introducing a
specialized tokenizer that converts each puzzle piece into a discrete sequence
of tokens, we reframe puzzle reassembly as a sequence-to-sequence prediction
task. Treated as "blind" solvers, encoder-decoder transformers accurately
reconstruct the original layout by reasoning over token sequences alone.
Despite being deliberately restricted from accessing visual input, our models
achieve state-of-the-art results across multiple benchmarks, often
outperforming vision-based methods. These findings highlight the surprising
capability of language models to solve problems beyond their native domain, and
suggest that unconventional approaches can inspire promising directions for
puzzle-solving research.
\\ ( https://arxiv.org/abs/2511.06315 ,  2116kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06325
Date: Sun, 9 Nov 2025 11:05:45 GMT   (1301kb)

Title: CINEMAE: Leveraging Frozen Masked Autoencoders for Cross-Generator AI
 Image Detection
Authors: Minsuk Jang, Hyeonseo Jeong, Minseok Son and Changick Kim
Categories: cs.CV cs.AI cs.CY
MSC-class: 68T07
ACM-class: I.4.8
\\
 While context-based detectors have achieved strong generalization for
AI-generated text by measuring distributional inconsistencies, image-based
detectors still struggle with overfitting to generator-specific artifacts. We
introduce CINEMAE, a novel paradigm for AIGC image detection that adapts the
core principles of text detection methods to the visual domain. Our key insight
is that Masked AutoEncoder (MAE), trained to reconstruct masked patches
conditioned on visible context, naturally encodes semantic consistency
expectations. We formalize this reconstruction process probabilistically,
computing conditional Negative Log-Likelihood (NLL, p(masked | visible)) to
quantify local semantic anomalies. By aggregating these patch-level statistics
with global MAE features through learned fusion, CINEMAE achieves strong
cross-generator generalization. Trained exclusively on Stable Diffusion v1.4,
our method achieves over 95% accuracy on all eight unseen generators in the
GenImage benchmark, substantially outperforming state-of-the-art detectors.
This demonstrates that context-conditional reconstruction uncertainty provides
a robust, transferable signal for AIGC detection.
\\ ( https://arxiv.org/abs/2511.06325 ,  1301kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06328
Date: Sun, 9 Nov 2025 11:13:32 GMT   (1361kb)

Title: Improving Multimodal Sentiment Analysis via Modality Optimization and
 Dynamic Primary Modality Selection
Authors: Dingkang Yang, Mingcheng Li, Xuecheng Wu, Zhaoyu Chen, Kaixun Jiang,
 Keliang Liu, Peng Zhai, Lihua Zhang
Categories: cs.CV
Comments: Accepted by AAAI 2026
\\
 Multimodal Sentiment Analysis (MSA) aims to predict sentiment from language,
acoustic, and visual data in videos. However, imbalanced unimodal performance
often leads to suboptimal fused representations. Existing approaches typically
adopt fixed primary modality strategies to maximize dominant modality
advantages, yet fail to adapt to dynamic variations in modality importance
across different samples. Moreover, non-language modalities suffer from
sequential redundancy and noise, degrading model performance when they serve as
primary inputs. To address these issues, this paper proposes a modality
optimization and dynamic primary modality selection framework (MODS). First, a
Graph-based Dynamic Sequence Compressor (GDC) is constructed, which employs
capsule networks and graph convolution to reduce sequential redundancy in
acoustic/visual modalities. Then, we develop a sample-adaptive Primary Modality
Selector (MSelector) for dynamic dominance determination. Finally, a
Primary-modality-Centric Cross-Attention (PCCA) module is designed to enhance
dominant modalities while facilitating cross-modal interaction. Extensive
experiments on four benchmark datasets demonstrate that MODS outperforms
state-of-the-art methods, achieving superior performance by effectively
balancing modality contributions and eliminating redundant noise.
\\ ( https://arxiv.org/abs/2511.06328 ,  1361kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06331
Date: Sun, 9 Nov 2025 11:16:20 GMT   (3806kb)

Title: Label-Efficient 3D Forest Mapping: Self-Supervised and Transfer Learning
 for Individual, Structural, and Species Analysis
Authors: Aldino Rizaldy, Fabian Ewald Fassnacht, Ahmed Jamal Afifi, Hua Jiang,
 Richard Gloaguen, Pedram Ghamisi
Categories: cs.CV
\\
 Detailed structural and species information on individual tree level is
increasingly important to support precision forestry, biodiversity
conservation, and provide reference data for biomass and carbon mapping. Point
clouds from airborne and ground-based laser scanning are currently the most
suitable data source to rapidly derive such information at scale. Recent
advancements in deep learning improved segmenting and classifying individual
trees and identifying semantic tree components. However, deep learning models
typically require large amounts of annotated training data which limits further
improvement. Producing dense, high-quality annotations for 3D point clouds,
especially in complex forests, is labor-intensive and challenging to scale. We
explore strategies to reduce dependence on large annotated datasets using
self-supervised and transfer learning architectures. Our objective is to
improve performance across three tasks: instance segmentation, semantic
segmentation, and tree classification using realistic and operational training
sets. Our findings indicate that combining self-supervised learning with domain
adaptation significantly enhances instance segmentation compared to training
from scratch (AP50 +16.98%), self-supervised learning suffices for semantic
segmentation (mIoU +1.79%), and hierarchical transfer learning enables accurate
classification of unseen species (Jaccard +6.07%). To simplify use and
encourage uptake, we integrated the tasks into a unified framework,
streamlining the process from raw point clouds to tree delineation, structural
analysis, and species classification. Pretrained models reduce energy
consumption and carbon emissions by ~21%. This open-source contribution aims to
accelerate operational extraction of individual tree information from laser
scanning point clouds to support forestry, biodiversity, and carbon mapping.
\\ ( https://arxiv.org/abs/2511.06331 ,  3806kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06337
Date: Sun, 9 Nov 2025 11:40:34 GMT   (1879kb)

Title: BuildingWorld: A Structured 3D Building Dataset for Urban Foundation
 Models
Authors: Shangfeng Huang and Ruisheng Wang and Xin Wang
Categories: cs.CV
\\
 As digital twins become central to the transformation of modern cities,
accurate and structured 3D building models emerge as a key enabler of
high-fidelity, updatable urban representations. These models underpin diverse
applications including energy modeling, urban planning, autonomous navigation,
and real-time reasoning. Despite recent advances in 3D urban modeling, most
learning-based models are trained on building datasets with limited
architectural diversity, which significantly undermines their generalizability
across heterogeneous urban environments. To address this limitation, we present
BuildingWorld, a comprehensive and structured 3D building dataset designed to
bridge the gap in stylistic diversity. It encompasses buildings from
geographically and architecturally diverse regions -- including North America,
Europe, Asia, Africa, and Oceania -- offering a globally representative dataset
for urban-scale foundation modeling and analysis. Specifically, BuildingWorld
provides about five million LOD2 building models collected from diverse
sources, accompanied by real and simulated airborne LiDAR point clouds. This
enables comprehensive research on 3D building reconstruction, detection and
segmentation. Cyber City, a virtual city model, is introduced to enable the
generation of unlimited training data with customized and structurally diverse
point cloud distributions. Furthermore, we provide standardized evaluation
metrics tailored for building reconstruction, aiming to facilitate the
training, evaluation, and comparison of large-scale vision models and
foundation models in structured 3D urban environments.
\\ ( https://arxiv.org/abs/2511.06337 ,  1879kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06348
Date: Sun, 9 Nov 2025 12:07:40 GMT   (10243kb)

Title: GazeVLM: A Vision-Language Model for Multi-Task Gaze Understanding
Authors: Athul M. Mathew, Haithem Hermassi, Thariq Khalid, Arshad Ali Khan,
 Riad Souissi
Categories: cs.CV cs.AI
\\
 Gaze understanding unifies the detection of people, their gaze targets, and
objects of interest into a single framework, offering critical insight into
visual attention and intent estimation. Although prior research has modelled
gaze cues in visual scenes, a unified system is still needed for gaze
understanding using both visual and language prompts. This paper introduces
GazeVLM, a novel Vision-Language Model (VLM) for multi-task gaze understanding
in images, addressing person detection, gaze target detection, and gaze object
identification. While other transformer-based methods exist for gaze analysis,
GazeVLM represents, to our knowledge, the first application of a VLM to these
combined tasks, allowing for selective execution of each task. Through the
integration of visual (RGB and depth) and textual modalities, our ablation
study on visual input combinations revealed that a fusion of RGB images with
HHA-encoded depth maps, guided by text prompts, yields superior performance. We
also introduce an object-level gaze detection metric for gaze object
identification ($AP_{ob}$). Through experiments, GazeVLM demonstrates
significant improvements, notably achieving state-of-the-art evaluation scores
on GazeFollow and VideoAttentionTarget datasets.
\\ ( https://arxiv.org/abs/2511.06348 ,  10243kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06360
Date: Sun, 9 Nov 2025 12:44:10 GMT   (516kb)

Title: AesTest: Measuring Aesthetic Intelligence from Perception to Production
Authors: Guolong Wang, Heng Huang, Zhiqiang Zhang, Wentian Li, Feilong Ma, Xin
 Jin
Categories: cs.CV
Comments: 10 pages, 9 figures
\\
 Perceiving and producing aesthetic judgments is a fundamental yet
underexplored capability for multimodal large language models (MLLMs). However,
existing benchmarks for image aesthetic assessment (IAA) are narrow in
perception scope or lack the diversity needed to evaluate systematic aesthetic
production. To address this gap, we introduce AesTest, a comprehensive
benchmark for multimodal aesthetic perception and production, distinguished by
the following features: 1) It consists of curated multiple-choice questions
spanning ten tasks, covering perception, appreciation, creation, and
photography. These tasks are grounded in psychological theories of generative
learning. 2) It integrates data from diverse sources, including professional
editing workflows, photographic composition tutorials, and crowdsourced
preferences. It ensures coverage of both expert-level principles and real-world
variation. 3) It supports various aesthetic query types, such as
attribute-based analysis, emotional resonance, compositional choice, and
stylistic reasoning. We evaluate both instruction-tuned IAA MLLMs and general
MLLMs on AesTest, revealing significant challenges in building aesthetic
intelligence. We will publicly release AesTest to support future research in
this area.
\\ ( https://arxiv.org/abs/2511.06360 ,  516kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06365
Date: Sun, 9 Nov 2025 13:07:23 GMT   (19737kb)

Title: V-Shuffle: Zero-Shot Style Transfer via Value Shuffle
Authors: Haojun Tang, Qiwei Lin, Tongda Xu, Lida Huang, Yan Wang
Categories: cs.CV
\\
 Attention injection-based style transfer has achieved remarkable progress in
recent years. However, existing methods often suffer from content leakage,
where the undesired semantic content of the style image mistakenly appears in
the stylized output. In this paper, we propose V-Shuffle, a zero-shot style
transfer method that leverages multiple style images from the same style domain
to effectively navigate the trade-off between content preservation and style
fidelity. V-Shuffle implicitly disrupts the semantic content of the style
images by shuffling the value features within the self-attention layers of the
diffusion model, thereby preserving low-level style representations. We further
introduce a Hybrid Style Regularization that complements these low-level
representations with high-level style textures to enhance style fidelity.
Empirical results demonstrate that V-Shuffle achieves excellent performance
when utilizing multiple style images. Moreover, when applied to a single style
image, V-Shuffle outperforms previous state-of-the-art methods.
\\ ( https://arxiv.org/abs/2511.06365 ,  19737kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06404
Date: Sun, 9 Nov 2025 14:35:59 GMT   (2032kb)

Title: InfoAffect: A Dataset for Affective Analysis of Infographics
Authors: Zihang Fu, Yunchao Wang, Chenyu Huang, Guodao Sun, Ronghua Liang
Categories: cs.CV
\\
 Infographics are widely used to convey complex information, yet their
affective dimensions remain underexplored due to the scarcity of data
resources. We introduce a 3.5k-sample affect-annotated InfoAffect dataset,
which combines textual content with real-world infographics. We first collect
the raw data from six domains and aligned them via preprocessing, the
accompanied-text-priority method, and three strategies to guarantee the quality
and compliance. After that we construct an affect table and use it to constrain
annotation. Five state-of-the-art multimodal large language models (MLLMs) then
analyze both modalities, and their outputs are fused with Reciprocal Rank
Fusion (RRF) algorithm to yield robust affects and confidences. We conducted a
user study with two experiments to validate usability and assess InfoAffect
dataset using the Composite Affect Consistency Index (CACI), achieving an
overall score of 0.986, which indicates high accuracy.
\\ ( https://arxiv.org/abs/2511.06404 ,  2032kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06406
Date: Sun, 9 Nov 2025 14:38:32 GMT   (11150kb)

Title: On Modality Incomplete Infrared-Visible Object Detection: An
 Architecture Compatibility Perspective
Authors: Shuo Yang, Yinghui Xing, Shizhou Zhang, Zhilong Niu
Categories: cs.CV cs.AI
\\
 Infrared and visible object detection (IVOD) is essential for numerous
around-the-clock applications. Despite notable advancements, current IVOD
models exhibit notable performance declines when confronted with incomplete
modality data, particularly if the dominant modality is missing. In this paper,
we take a thorough investigation on modality incomplete IVOD problem from an
architecture compatibility perspective. Specifically, we propose a
plug-and-play Scarf Neck module for DETR variants, which introduces a
modality-agnostic deformable attention mechanism to enable the IVOD detector to
flexibly adapt to any single or double modalities during training and
inference. When training Scarf-DETR, we design a pseudo modality dropout
strategy to fully utilize the multi-modality information, making the detector
compatible and robust to both working modes of single and double modalities.
Moreover, we introduce a comprehensive benchmark for the modality-incomplete
IVOD task aimed at thoroughly assessing situations where the absent modality is
either dominant or secondary. Our proposed Scarf-DETR not only performs
excellently in missing modality scenarios but also achieves superior
performances on the standard IVOD modality complete benchmarks. Our code will
be available at https://github.com/YinghuiXing/Scarf-DETR.
\\ ( https://arxiv.org/abs/2511.06406 ,  11150kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06408
Date: Sun, 9 Nov 2025 14:45:08 GMT   (12748kb)

Title: VDNeRF: Vision-only Dynamic Neural Radiance Field for Urban Scenes
Authors: Zhengyu Zou, Jingfeng Li, Hao Li, Xiaolei Hou, Jinwen Hu, Jingkun
 Chen, Lechao Cheng, Dingwen Zhang
Categories: cs.CV
\\
 Neural Radiance Fields (NeRFs) implicitly model continuous three-dimensional
scenes using a set of images with known camera poses, enabling the rendering of
photorealistic novel views. However, existing NeRF-based methods encounter
challenges in applications such as autonomous driving and robotic perception,
primarily due to the difficulty of capturing accurate camera poses and
limitations in handling large-scale dynamic environments. To address these
issues, we propose Vision-only Dynamic NeRF (VDNeRF), a method that accurately
recovers camera trajectories and learns spatiotemporal representations for
dynamic urban scenes without requiring additional camera pose information or
expensive sensor data. VDNeRF employs two separate NeRF models to jointly
reconstruct the scene. The static NeRF model optimizes camera poses and static
background, while the dynamic NeRF model incorporates the 3D scene flow to
ensure accurate and consistent reconstruction of dynamic objects. To address
the ambiguity between camera motion and independent object motion, we design an
effective and powerful training framework to achieve robust camera pose
estimation and self-supervised decomposition of static and dynamic elements in
a scene. Extensive evaluations on mainstream urban driving datasets demonstrate
that VDNeRF surpasses state-of-the-art NeRF-based pose-free methods in both
camera pose estimation and dynamic novel view synthesis.
\\ ( https://arxiv.org/abs/2511.06408 ,  12748kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06422
Date: Sun, 9 Nov 2025 15:27:17 GMT   (4410kb)

Title: DiffusionUavLoc: Visually Prompted Diffusion for Cross-View UAV
 Localization
Authors: Tao Liu, Kan Ren and Qian Chen
Categories: cs.CV
\\
 With the rapid growth of the low-altitude economy, unmanned aerial vehicles
(UAVs) have become key platforms for measurement and tracking in intelligent
patrol systems. However, in GNSS-denied environments, localization schemes that
rely solely on satellite signals are prone to failure. Cross-view image
retrieval-based localization is a promising alternative, yet substantial
geometric and appearance domain gaps exist between oblique UAV views and nadir
satellite orthophotos. Moreover, conventional approaches often depend on
complex network architectures, text prompts, or large amounts of annotation,
which hinders generalization. To address these issues, we propose
DiffusionUavLoc, a cross-view localization framework that is image-prompted,
text-free, diffusion-centric, and employs a VAE for unified representation. We
first use training-free geometric rendering to synthesize pseudo-satellite
images from UAV imagery as structural prompts. We then design a text-free
conditional diffusion model that fuses multimodal structural cues to learn
features robust to viewpoint changes. At inference, descriptors are computed at
a fixed time step t and compared using cosine similarity. On University-1652
and SUES-200, the method performs competitively for cross-view localization,
especially for satellite-to-drone in University-1652.Our data and code will be
published at the following URL:
https://github.com/liutao23/DiffusionUavLoc.git.
\\ ( https://arxiv.org/abs/2511.06422 ,  4410kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06433
Date: Sun, 9 Nov 2025 16:02:13 GMT   (1250kb)

Title: Diagnose Like A REAL Pathologist: An Uncertainty-Focused Approach for
 Trustworthy Multi-Resolution Multiple Instance Learning
Authors: Sungrae Hong, Sol Lee, Jisu Shin, Mun Yong Yi
Categories: cs.CV
Comments: Accepted by IEEE/CVF Winter Conference on Applications of Computer
 Vision (WACV) 2026
\\
 With the increasing demand for histopathological specimen examination and
diagnostic reporting, Multiple Instance Learning (MIL) has received heightened
research focus as a viable solution for AI-centric diagnostic aid. Recently, to
improve its performance and make it work more like a pathologist, several MIL
approaches based on the use of multiple-resolution images have been proposed,
delivering often higher performance than those that use single-resolution
images. Despite impressive recent developments of multiple-resolution MIL,
previous approaches only focus on improving performance, thereby lacking
research on well-calibrated MIL that clinical experts can rely on for
trustworthy diagnostic results. In this study, we propose Uncertainty-Focused
Calibrated MIL (UFC-MIL), which more closely mimics the pathologists'
examination behaviors while providing calibrated diagnostic predictions, using
multiple images with different resolutions. UFC-MIL includes a novel patch-wise
loss that learns the latent patterns of instances and expresses their
uncertainty for classification. Also, the attention-based architecture with a
neighbor patch aggregation module collects features for the classifier. In
addition, aggregated predictions are calibrated through patch-level uncertainty
without requiring multiple iterative inferences, which is a key practical
advantage. Against challenging public datasets, UFC-MIL shows superior
performance in model calibration while achieving classification accuracy
comparable to that of state-of-the-art methods.
\\ ( https://arxiv.org/abs/2511.06433 ,  1250kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06450
Date: Sun, 9 Nov 2025 16:34:19 GMT   (11747kb)

Title: Countering Multi-modal Representation Collapse through Rank-targeted
 Fusion
Authors: Seulgi Kim, Kiran Kokilepersaud, Mohit Prabhushankar, Ghassan AlRegib
Categories: cs.CV cs.LG
Comments: Accepted in 2026 IEEE/CVF Winter Conference on Applications of
 Computer Vision (WACV)
\\
 Multi-modal fusion methods often suffer from two types of representation
collapse: feature collapse where individual dimensions lose their
discriminative power (as measured by eigenspectra), and modality collapse where
one dominant modality overwhelms the other. Applications like human action
anticipation that require fusing multifarious sensor data are hindered by both
feature and modality collapse. However, existing methods attempt to counter
feature collapse and modality collapse separately. This is because there is no
unifying framework that efficiently addresses feature and modality collapse in
conjunction. In this paper, we posit the utility of effective rank as an
informative measure that can be utilized to quantify and counter both the
representation collapses. We propose \textit{Rank-enhancing Token Fuser}, a
theoretically grounded fusion framework that selectively blends less
informative features from one modality with complementary features from another
modality. We show that our method increases the effective rank of the fused
representation. To address modality collapse, we evaluate modality combinations
that mutually increase each others' effective rank. We show that depth
maintains representational balance when fused with RGB, avoiding modality
collapse. We validate our method on action anticipation, where we present
\texttt{R3D}, a depth-informed fusion framework. Extensive experiments on
NTURGBD, UTKinect, and DARai demonstrate that our approach significantly
outperforms prior state-of-the-art methods by up to 3.74\%. Our code is
available at:
\href{https://github.com/olivesgatech/R3D}{https://github.com/olivesgatech/R3D}.
\\ ( https://arxiv.org/abs/2511.06450 ,  11747kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06456
Date: Sun, 9 Nov 2025 16:42:36 GMT   (10300kb)

Title: EIDSeg: A Pixel-Level Semantic Segmentation Dataset for Post-Earthquake
 Damage Assessment from Social Media Images
Authors: Huili Huang, Chengeng Liu, Danrong Zhang, Shail Patel, Anastasiya
 Masalava, Sagar Sadak, Parisa Babolhavaeji, WeiHong Low, Max Mahdi
 Roozbahani, J. David Frost
Categories: cs.CV
Comments: Camera-Ready for AAAI-AISI26
\\
 Rapid post-earthquake damage assessment is crucial for rescue and resource
planning. Still, existing remote sensing methods depend on costly aerial
images, expert labeling, and produce only binary damage maps for early-stage
evaluation. Although ground-level images from social networks provide a
valuable source to fill this gap, a large pixel-level annotated dataset for
this task is still unavailable. We introduce EIDSeg, the first large-scale
semantic segmentation dataset specifically for post-earthquake social media
imagery. The dataset comprises 3,266 images from nine major earthquakes
(2008-2023), annotated across five classes of infrastructure damage: Undamaged
Building, Damaged Building, Destroyed Building, Undamaged Road, and Damaged
Road. We propose a practical three-phase cross-disciplinary annotation protocol
with labeling guidelines that enables consistent segmentation by non-expert
annotators, achieving over 70% inter-annotator agreement. We benchmark several
state-of-the-art segmentation models, identifying Encoder-only Mask Transformer
(EoMT) as the top-performing method with a Mean Intersection over Union (mIoU)
of 80.8%. By unlocking social networks' rich ground-level perspective, our work
paves the way for a faster, finer-grained damage assessment in the
post-earthquake scenario.
\\ ( https://arxiv.org/abs/2511.06456 ,  10300kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06457
Date: Sun, 9 Nov 2025 16:47:30 GMT   (26938kb)

Title: Inpaint360GS: Efficient Object-Aware 3D Inpainting via Gaussian
 Splatting for 360{\deg} Scenes
Authors: Shaoxiang Wang, Shihong Zhang, Christen Millerdurai, R\"udiger
 Westermann, Didier Stricker, Alain Pagani
Categories: cs.CV
Comments: WACV 2026, project page: https://dfki-av.github.io/inpaint360gs/
\\
 Despite recent advances in single-object front-facing inpainting using NeRF
and 3D Gaussian Splatting (3DGS), inpainting in complex 360{\deg} scenes
remains largely underexplored. This is primarily due to three key challenges:
(i) identifying target objects in the 3D field of 360{\deg} environments, (ii)
dealing with severe occlusions in multi-object scenes, which makes it hard to
define regions to inpaint, and (iii) maintaining consistent and high-quality
appearance across views effectively. To tackle these challenges, we propose
Inpaint360GS, a flexible 360{\deg} editing framework based on 3DGS that
supports multi-object removal and high-fidelity inpainting in 3D space. By
distilling 2D segmentation into 3D and leveraging virtual camera views for
contextual guidance, our method enables accurate object-level editing and
consistent scene completion. We further introduce a new dataset tailored for
360{\deg} inpainting, addressing the lack of ground truth object-free scenes.
Experiments demonstrate that Inpaint360GS outperforms existing baselines and
achieves state-of-the-art performance. Project page:
https://dfki-av.github.io/inpaint360gs/
\\ ( https://arxiv.org/abs/2511.06457 ,  26938kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06475
Date: Sun, 9 Nov 2025 17:41:11 GMT   (5063kb)

Title: NOAH: Benchmarking Narrative Prior driven Hallucination and Omission in
 Video Large Language Models
Authors: Kyuho Lee, Euntae Kim, Jinwoo Choi, and Buru Chang
Categories: cs.CV
Comments: 18 pages, 9 figures. Preprint
ACM-class: I.2.10; I.4.8
\\
 Video large language models (Video LLMs) have recently achieved strong
performance on tasks such as captioning, summarization, and question answering.
Many models and training methods explicitly encourage continuity across events
to enhance narrative coherence. While this improves fluency, it also introduces
an inductive bias that prioritizes storyline consistency over strict grounding
in visual evidence. We identify this bias, which we call narrative prior, as a
key driver of two errors: hallucinations, where non-existent events are
introduced or existing ones are misinterpreted, and omissions, where factual
events are suppressed because they are misaligned with surrounding context. To
systematically evaluate narrative prior-induced errors, we introduce NOAH, a
large-scale benchmark that constructs composite videos by inserting clips from
other sources into target videos. By varying semantic similarity and insertion
position, our benchmark enables controlled and scalable analysis of narrative
priors. We design one captioning task with tailored metrics and three QA tasks
- Existence, Temporal, and Narrative - yielding more than 60K evaluation
samples. Extensive experiments yield three key findings: (i) most Video LLMs
exhibit hallucinations and omissions driven by narrative priors, (ii) the
patterns of these errors vary across architectures and depend on event
similarity and insertion position, and (iii) reliance on narrative priors
intensifies under sampling with fewer frames, amplifying errors when event
continuity is weak. We establish NOAH as the first standardized evaluation of
narrative prior-induced hallucination and omission in Video LLMs, providing a
foundation for developing more reliable and trustworthy models. Our benchmark
and code are available at https://anonymous550520.github.io/.
\\ ( https://arxiv.org/abs/2511.06475 ,  5063kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06490
Date: Sun, 9 Nov 2025 18:27:45 GMT   (5857kb)

Title: Zooming into Comics: Region-Aware RL Improves Fine-Grained Comic
 Understanding in Vision-Language Models
Authors: Yule Chen, Yufan Ren, Sabine S\"usstrunk
Categories: cs.CV cs.AI
\\
 Complex visual narratives, such as comics, present a significant challenge to
Vision-Language Models (VLMs). Despite excelling on natural images, VLMs often
struggle with stylized line art, onomatopoeia, and densely packed multi-panel
layouts. To address this gap, we introduce AI4VA-FG, the first fine-grained and
comprehensive benchmark for VLM-based comic understanding. It spans tasks from
foundational recognition and detection to high-level character reasoning and
narrative construction, supported by dense annotations for characters, poses,
and depth. Beyond that, we evaluate state-of-the-art proprietary models,
including GPT-4o and Gemini-2.5, and open-source models such as Qwen2.5-VL,
revealing substantial performance deficits across core tasks of our benchmarks
and underscoring that comic understanding remains an unsolved challenge. To
enhance VLMs' capabilities in this domain, we systematically investigate
post-training strategies, including supervised fine-tuning on solutions
(SFT-S), supervised fine-tuning on reasoning trajectories (SFT-R), and
reinforcement learning (RL). Beyond that, inspired by the emerging "Thinking
with Images" paradigm, we propose Region-Aware Reinforcement Learning (RARL)
for VLMs, which trains models to dynamically attend to relevant regions through
zoom-in operations. We observe that when applied to the Qwen2.5-VL model, RL
and RARL yield significant gains in low-level entity recognition and high-level
storyline ordering, paving the way for more accurate and efficient VLM
applications in the comics domain.
\\ ( https://arxiv.org/abs/2511.06490 ,  5857kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06499
Date: Sun, 9 Nov 2025 18:55:20 GMT   (9535kb)

Title: SportR: A Benchmark for Multimodal Large Language Model Reasoning in
 Sports
Authors: Haotian Xia, Haonan Ge, Junbo Zou, Hyun Woo Choi, Xuebin Zhang, Danny
 Suradja, Botao Rui, Ethan Tran, Wendy Jin, Zhen Ye, Xiyang Lin, Christopher
 Lai, Shengjie Zhang, Junwen Miao, Shichao Chen, Rhys Tracy, Vicente Ordonez,
 Weining Shen, Hanjie Chen
Categories: cs.CV
\\
 Deeply understanding sports requires an intricate blend of fine-grained
visual perception and rule-based reasoning - a challenge that pushes the limits
of current multimodal models. To succeed, models must master three critical
capabilities: perceiving nuanced visual details, applying abstract sport rule
knowledge, and grounding that knowledge in specific visual evidence. Current
sports benchmarks either cover single sports or lack the detailed reasoning
chains and precise visual grounding needed to robustly evaluate these core
capabilities in a multi-sport context. To address this gap, we introduce
SportR, the first multi-sports large-scale benchmark designed to train and
evaluate MLLMs on the fundamental reasoning required for sports intelligence.
Our benchmark provides a dataset of 5,017 images and 2,101 videos. To enable
granular evaluation, we structure our benchmark around a progressive hierarchy
of question-answer (QA) pairs designed to probe reasoning at increasing depths
- from simple infraction identification to complex penalty prediction. For the
most advanced tasks requiring multi-step reasoning, such as determining
penalties or explaining tactics, we provide 7,118 high-quality, human-authored
Chain of Thought (CoT) annotations. In addition, our benchmark incorporates
both image and video modalities and provides manual bounding box annotations to
test visual grounding in the image part directly. Extensive experiments
demonstrate the profound difficulty of our benchmark. State-of-the-art baseline
models perform poorly on our most challenging tasks. While training on our data
via Supervised Fine-Tuning and Reinforcement Learning improves these scores,
they remain relatively low, highlighting a significant gap in current model
capabilities. SportR presents a new challenge for the community, providing a
critical resource to drive future research in multimodal sports reasoning.
\\ ( https://arxiv.org/abs/2511.06499 ,  9535kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06549
Date: Sun, 9 Nov 2025 21:29:33 GMT   (4552kb)

Title: Video Dataset for Surgical Phase, Keypoint, and Instrument Recognition
 in Laparoscopic Surgery (PhaKIR)
Authors: Tobias Rueckert, Raphaela Maerkl, David Rauber, Leonard Klausmann, Max
 Gutbrod, Daniel Rueckert, Hubertus Feussner, Dirk Wilhelm, Christoph Palm
Categories: cs.CV
Comments: 9 pages, 5 figures, 4 tables
\\
 Robotic- and computer-assisted minimally invasive surgery (RAMIS) is
increasingly relying on computer vision methods for reliable instrument
recognition and surgical workflow understanding. Developing such systems often
requires large, well-annotated datasets, but existing resources often address
isolated tasks, neglect temporal dependencies, or lack multi-center
variability. We present the Surgical Procedure Phase, Keypoint, and Instrument
Recognition (PhaKIR) dataset, comprising eight complete laparoscopic
cholecystectomy videos recorded at three medical centers. The dataset provides
frame-level annotations for three interconnected tasks: surgical phase
recognition (485,875 frames), instrument keypoint estimation (19,435 frames),
and instrument instance segmentation (19,435 frames). PhaKIR is, to our
knowledge, the first multi-institutional dataset to jointly provide phase
labels, instrument pose information, and pixel-accurate instrument
segmentations, while also enabling the exploitation of temporal context since
full surgical procedure sequences are available. It served as the basis for the
PhaKIR Challenge as part of the Endoscopic Vision (EndoVis) Challenge at MICCAI
2024 to benchmark methods in surgical scene understanding, thereby further
validating the dataset's quality and relevance. The dataset is publicly
available upon request via the Zenodo platform.
\\ ( https://arxiv.org/abs/2511.06549 ,  4552kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06593
Date: Mon, 10 Nov 2025 00:44:49 GMT   (38226kb)

Title: Spatial-Frequency Enhanced Mamba for Multi-Modal Image Fusion
Authors: Hui Sun and Long Lv and Pingping Zhang and Tongdan Tang and Feng Tian
 and Weibing Sun and Huchuan Lu
Categories: cs.CV
Comments: This work is accepted by IEEE Transactions on Image Processing. More
 modifications may be performed
\\
 Multi-Modal Image Fusion (MMIF) aims to integrate complementary image
information from different modalities to produce informative images. Previous
deep learning-based MMIF methods generally adopt Convolutional Neural Networks
(CNNs) or Transformers for feature extraction. However, these methods deliver
unsatisfactory performances due to the limited receptive field of CNNs and the
high computational cost of Transformers. Recently, Mamba has demonstrated a
powerful potential for modeling long-range dependencies with linear complexity,
providing a promising solution to MMIF. Unfortunately, Mamba lacks full spatial
and frequency perceptions, which are very important for MMIF. Moreover,
employing Image Reconstruction (IR) as an auxiliary task has been proven
beneficial for MMIF. However, a primary challenge is how to leverage IR
efficiently and effectively. To address the above issues, we propose a novel
framework named Spatial-Frequency Enhanced Mamba Fusion (SFMFusion) for MMIF.
More specifically, we first propose a three-branch structure to couple MMIF and
IR, which can retain complete contents from source images. Then, we propose the
Spatial-Frequency Enhanced Mamba Block (SFMB), which can enhance Mamba in both
spatial and frequency domains for comprehensive feature extraction. Finally, we
propose the Dynamic Fusion Mamba Block (DFMB), which can be deployed across
different branches for dynamic feature fusion. Extensive experiments show that
our method achieves better results than most state-of-the-art methods on six
MMIF datasets. The source code is available at
https://github.com/SunHui1216/SFMFusion.
\\ ( https://arxiv.org/abs/2511.06593 ,  38226kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06611
Date: Mon, 10 Nov 2025 01:43:42 GMT   (8646kb)

Title: On Accurate and Robust Estimation of 3D and 2D Circular Center: Method
 and Application to Camera-Lidar Calibration
Authors: Jiajun Jiang, Xiao Hu, Wancheng Liu, and Wei Jiang
Categories: cs.CV cs.RO
\\
 Circular targets are widely used in LiDAR-camera extrinsic calibration due to
their geometric consistency and ease of detection. However, achieving accurate
3D-2D circular center correspondence remains challenging. Existing methods
often fail due to decoupled 3D fitting and erroneous 2D ellipse-center
estimation. To address this, we propose a geometrically principled framework
featuring two innovations: (i) a robust 3D circle center estimator based on
conformal geometric algebra and RANSAC; and (ii) a chord-length variance
minimization method to recover the true 2D projected center, resolving its
dual-minima ambi- guity via homography validation or a quasi-RANSAC fallback.
Evaluated on synthetic and real-world datasets, our framework significantly
outperforms state-of-the-art approaches. It reduces extrinsic estimation error
and enables robust calibration across diverse sensors and target types,
including natural circular objects. Our code will be publicly released for
reproducibility.
\\ ( https://arxiv.org/abs/2511.06611 ,  8646kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06625
Date: Mon, 10 Nov 2025 02:04:46 GMT   (3461kb)

Title: Explainable Cross-Disease Reasoning for Cardiovascular Risk Assessment
 from LDCT
Authors: Yifei Zhang, Jiashuo Zhang, Xiaofeng Yang, Liang Zhao
Categories: cs.CV cs.AI cs.LG
\\
 Low-dose chest computed tomography (LDCT) inherently captures both pulmonary
and cardiac structures, offering a unique opportunity for joint assessment of
lung and cardiovascular health. However, most existing approaches treat these
domains as independent tasks, overlooking their physiological interplay and
shared imaging biomarkers. We propose an Explainable Cross-Disease Reasoning
Framework that enables interpretable cardiopulmonary risk assessment from a
single LDCT scan. The framework introduces an agentic reasoning process that
emulates clinical diagnostic thinking-first perceiving pulmonary findings, then
reasoning through established medical knowledge, and finally deriving a
cardiovascular judgment with explanatory rationale. It integrates three
synergistic components: a pulmonary perception module that summarizes lung
abnormalities, a knowledge-guided reasoning module that infers their
cardiovascular implications, and a cardiac representation module that encodes
structural biomarkers. Their outputs are fused to produce a holistic
cardiovascular risk prediction that is both accurate and physiologically
grounded. Experiments on the NLST cohort demonstrate that the proposed
framework achieves state-of-the-art performance for CVD screening and mortality
prediction, outperforming single-disease and purely image-based baselines.
Beyond quantitative gains, the framework provides human-verifiable reasoning
that aligns with cardiological understanding, revealing coherent links between
pulmonary abnormalities and cardiac stress mechanisms. Overall, this work
establishes a unified and explainable paradigm for cardiovascular analysis from
LDCT, bridging the gap between image-based prediction and mechanism-based
medical interpretation.
\\ ( https://arxiv.org/abs/2511.06625 ,  3461kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06632
Date: Mon, 10 Nov 2025 02:18:40 GMT   (31072kb)

Title: DIAL-GS: Dynamic Instance Aware Reconstruction for Label-free Street
 Scenes with 4D Gaussian Splatting
Authors: Chenpeng Su, Wenhua Wu, Chensheng Peng, Tianchen Deng, Zhe Liu,
 Hesheng Wang
Categories: cs.CV
\\
 Urban scene reconstruction is critical for autonomous driving, enabling
structured 3D representations for data synthesis and closed-loop testing.
Supervised approaches rely on costly human annotations and lack scalability,
while current self-supervised methods often confuse static and dynamic elements
and fail to distinguish individual dynamic objects, limiting fine-grained
editing. We propose DIAL-GS, a novel dynamic instance-aware reconstruction
method for label-free street scenes with 4D Gaussian Splatting. We first
accurately identify dynamic instances by exploiting appearance-position
inconsistency between warped rendering and actual observation. Guided by
instance-level dynamic perception, we employ instance-aware 4D Gaussians as the
unified volumetric representation, realizing dynamic-adaptive and
instance-aware reconstruction. Furthermore, we introduce a reciprocal mechanism
through which identity and dynamics reinforce each other, enhancing both
integrity and consistency. Experiments on urban driving scenarios show that
DIAL-GS surpasses existing self-supervised baselines in reconstruction quality
and instance-level editing, offering a concise yet powerful solution for urban
scene modeling.
\\ ( https://arxiv.org/abs/2511.06632 ,  31072kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06644
Date: Mon, 10 Nov 2025 02:42:08 GMT   (15931kb)

Title: UniADC: A Unified Framework for Anomaly Detection and Classification
Authors: Ximiao Zhang, Min Xu, Zheng Zhang, Junlin Hu, Xiuzhuang Zhou
Categories: cs.CV
\\
 In this paper, we introduce the task of unified anomaly detection and
classification, which aims to simultaneously detect anomalous regions in images
and identify their specific categories. Existing methods typically treat
anomaly detection and classification as separate tasks, thereby neglecting
their inherent correlation, limiting information sharing, and resulting in
suboptimal performance. To address this, we propose UniADC, a unified anomaly
detection and classification model that can effectively perform both tasks with
only a few or even no anomaly images. Specifically, UniADC consists of two key
components: a training-free controllable inpainting network and a multi-task
discriminator. The inpainting network can synthesize anomaly images of specific
categories by repainting normal regions guided by anomaly priors, and can also
repaint few-shot anomaly samples to augment the available anomaly data. The
multi-task discriminator is then trained on these synthesized samples, enabling
precise anomaly detection and classification by aligning fine-grained image
features with anomaly-category embeddings. We conduct extensive experiments on
three anomaly detection and classification datasets, including MVTec-FS, MTD,
and WFDD, and the results demonstrate that UniADC consistently outperforms
existing methods in anomaly detection, localization, and classification. The
code is available at https://github.com/cnulab/UniADC.
\\ ( https://arxiv.org/abs/2511.06644 ,  15931kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06648
Date: Mon, 10 Nov 2025 02:56:09 GMT   (1953kb)

Title: FreqGRL: Suppressing Low-Frequency Bias and Mining High-Frequency
 Knowledge for Cross-Domain Few-Shot Learning
Authors: Siqi Hui, Sanping Zhou, Ye deng, Wenli Huang, Jinjun Wang
Categories: cs.CV
\\
 Cross-domain few-shot learning (CD-FSL) aims to recognize novel classes with
only a few labeled examples under significant domain shifts. While recent
approaches leverage a limited amount of labeled target-domain data to improve
performance, the severe imbalance between abundant source data and scarce
target data remains a critical challenge for effective representation learning.
We present the first frequency-space perspective to analyze this issue and
identify two key challenges: (1) models are easily biased toward
source-specific knowledge encoded in the low-frequency components of source
data, and (2) the sparsity of target data hinders the learning of
high-frequency, domain-generalizable features. To address these challenges, we
propose \textbf{FreqGRL}, a novel CD-FSL framework that mitigates the impact of
data imbalance in the frequency space. Specifically, we introduce a
Low-Frequency Replacement (LFR) module that substitutes the low-frequency
components of source tasks with those from the target domain to create new
source tasks that better align with target characteristics, thus reducing
source-specific biases and promoting generalizable representation learning. We
further design a High-Frequency Enhancement (HFE) module that filters out
low-frequency components and performs learning directly on high-frequency
features in the frequency space to improve cross-domain generalization.
Additionally, a Global Frequency Filter (GFF) is incorporated to suppress noisy
or irrelevant frequencies and emphasize informative ones, mitigating
overfitting risks under limited target supervision. Extensive experiments on
five standard CD-FSL benchmarks demonstrate that our frequency-guided framework
achieves state-of-the-art performance.
\\ ( https://arxiv.org/abs/2511.06648 ,  1953kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06651
Date: Mon, 10 Nov 2025 02:58:32 GMT   (2354kb)

Title: NOVO: Bridging LLaVA and SAM with Visual-only Prompts for Reasoning
 Segmentation
Authors: Kyung-Yoon Yoon and Yeong-Jun Cho
Categories: cs.CV
\\
 In this study, we propose NOVO (NO text, Visual-Only prompts), a novel
framework that bridges vision-language models (VLMs) and segmentation models
through visual-only prompts. Unlike prior approaches that feed text-derived SEG
token embeddings into segmentation models, NOVO instead generates a coarse mask
and point prompts from the VLM output. These visual prompts are compatible with
the Segment Anything Model (SAM), preserving alignment with its pretrained
capabilities. To further enhance boundary quality and enable instance-level
segmentation, we introduce a training-free refinement module that reduces
visual artifacts and improves the quality of segmentation masks. We also
present RISeg, a new benchmark comprising 918 images, 2,533 instance-level
masks, and diverse reasoning queries to evaluate this task. Experiments
demonstrate that NOVO achieves state-of-the-art performance across multiple
metrics and model sizes, demonstrating its effectiveness and scalability in
reasoning segmentation.
\\ ( https://arxiv.org/abs/2511.06651 ,  2354kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06653
Date: Mon, 10 Nov 2025 03:04:36 GMT   (5159kb)

Title: HiMo-CLIP: Modeling Semantic Hierarchy and Monotonicity in
 Vision-Language Alignment
Authors: Ruijia Wu, Ping Chen, Fei Shen, Shaoan Zhao, Qiang Hui, Huanlin Gao,
 Ting Lu, Zhaoxiang Liu, Fang Zhao, Kai Wang, Shiguo Lian
Categories: cs.CV cs.CL
Comments: Accepted by AAAI 2026 as an Oral Presentation (13 pages, 7 figures, 7
 tables)
Journal-ref: AAAI2026
\\
 Contrastive vision-language models like CLIP have achieved impressive results
in image-text retrieval by aligning image and text representations in a shared
embedding space. However, these models often treat text as flat sequences,
limiting their ability to handle complex, compositional, and long-form
descriptions. In particular, they fail to capture two essential properties of
language: semantic hierarchy, which reflects the multi-level compositional
structure of text, and semantic monotonicity, where richer descriptions should
result in stronger alignment with visual content.To address these limitations,
we propose HiMo-CLIP, a representation-level framework that enhances CLIP-style
models without modifying the encoder architecture. HiMo-CLIP introduces two key
components: a hierarchical decomposition (HiDe) module that extracts latent
semantic components from long-form text via in-batch PCA, enabling flexible,
batch-aware alignment across different semantic granularities, and a
monotonicity-aware contrastive loss (MoLo) that jointly aligns global and
component-level representations, encouraging the model to internalize semantic
ordering and alignment strength as a function of textual completeness.These
components work in concert to produce structured, cognitively-aligned
cross-modal representations. Experiments on multiple image-text retrieval
benchmarks show that HiMo-CLIP consistently outperforms strong baselines,
particularly under long or compositional descriptions. The code is available at
https://github.com/UnicomAI/HiMo-CLIP.
\\ ( https://arxiv.org/abs/2511.06653 ,  5159kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06658
Date: Mon, 10 Nov 2025 03:13:40 GMT   (567kb)

Title: Active Learning for Animal Re-Identification with Ambiguity-Aware
 Sampling
Authors: Depanshu Sani, Mehar Khurana and Saket Anand
Categories: cs.CV cs.AI
Comments: In Proceedings of AAAI Conference on Artificial Intelligence 2026
\\
 Animal Re-ID has recently gained substantial attention in the AI research
community due to its high impact on biodiversity monitoring and unique research
challenges arising from environmental factors. The subtle distinguishing
patterns, handling new species and the inherent open-set nature make the
problem even harder. To address these complexities, foundation models trained
on labeled, large-scale and multi-species animal Re-ID datasets have recently
been introduced to enable zero-shot Re-ID. However, our benchmarking reveals
significant gaps in their zero-shot Re-ID performance for both known and
unknown species. While this highlights the need for collecting labeled data in
new domains, exhaustive annotation for Re-ID is laborious and requires domain
expertise. Our analyses show that existing unsupervised (USL) and AL Re-ID
methods underperform for animal Re-ID. To address these limitations, we
introduce a novel AL Re-ID framework that leverages complementary clustering
methods to uncover and target structurally ambiguous regions in the embedding
space for mining pairs of samples that are both informative and broadly
representative. Oracle feedback on these pairs, in the form of must-link and
cannot-link constraints, facilitates a simple annotation interface, which
naturally integrates with existing USL methods through our proposed constrained
clustering refinement algorithm. Through extensive experiments, we demonstrate
that, by utilizing only 0.033% of all annotations, our approach consistently
outperforms existing foundational, USL and AL baselines. Specifically, we
report an average improvement of 10.49%, 11.19% and 3.99% (mAP) on 13 wildlife
datasets over foundational, USL and AL methods, respectively, while attaining
state-of-the-art performance on each dataset. Furthermore, we also show an
improvement of 11.09%, 8.2% and 2.06% for unknown individuals in an open-world
setting.
\\ ( https://arxiv.org/abs/2511.06658 ,  567kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06665
Date: Mon, 10 Nov 2025 03:22:42 GMT   (803kb)

Title: Sim4Seg: Boosting Multimodal Multi-disease Medical Diagnosis
 Segmentation with Region-Aware Vision-Language Similarity Masks
Authors: Lingran Song, Yucheng Zhou, Jianbing Shen
Categories: cs.CV cs.AI
Comments: AAAI 2026
\\
 Despite significant progress in pixel-level medical image analysis, existing
medical image segmentation models rarely explore medical segmentation and
diagnosis tasks jointly. However, it is crucial for patients that models can
provide explainable diagnoses along with medical segmentation results. In this
paper, we introduce a medical vision-language task named Medical Diagnosis
Segmentation (MDS), which aims to understand clinical queries for medical
images and generate the corresponding segmentation masks as well as diagnostic
results. To facilitate this task, we first present the Multimodal Multi-disease
Medical Diagnosis Segmentation (M3DS) dataset, containing diverse multimodal
multi-disease medical images paired with their corresponding segmentation masks
and diagnosis chain-of-thought, created via an automated diagnosis
chain-of-thought generation pipeline. Moreover, we propose Sim4Seg, a novel
framework that improves the performance of diagnosis segmentation by taking
advantage of the Region-Aware Vision-Language Similarity to Mask (RVLS2M)
module. To improve overall performance, we investigate a test-time scaling
strategy for MDS tasks. Experimental results demonstrate that our method
outperforms the baselines in both segmentation and diagnosis.
\\ ( https://arxiv.org/abs/2511.06665 ,  803kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06666
Date: Mon, 10 Nov 2025 03:23:52 GMT   (999kb)

Title: REOcc: Camera-Radar Fusion with Radar Feature Enrichment for 3D
 Occupancy Prediction
Authors: Chaehee Song, Sanmin Kim, Hyeonjun Jeong, Juyeb Shin, Joonhee Lim and
 Dongsuk Kum
Categories: cs.CV
Comments: IROS 2025
\\
 Vision-based 3D occupancy prediction has made significant advancements, but
its reliance on cameras alone struggles in challenging environments. This
limitation has driven the adoption of sensor fusion, among which camera-radar
fusion stands out as a promising solution due to their complementary strengths.
However, the sparsity and noise of the radar data limits its effectiveness,
leading to suboptimal fusion performance. In this paper, we propose REOcc, a
novel camera-radar fusion network designed to enrich radar feature
representations for 3D occupancy prediction. Our approach introduces two main
components, a Radar Densifier and a Radar Amplifier, which refine radar
features by integrating spatial and contextual information, effectively
enhancing spatial density and quality. Extensive experiments on the
Occ3D-nuScenes benchmark demonstrate that REOcc achieves significant
performance gains over the camera-only baseline model, particularly in dynamic
object classes. These results underscore REOcc's capability to mitigate the
sparsity and noise of the radar data. Consequently, radar complements camera
data more effectively, unlocking the full potential of camera-radar fusion for
robust and reliable 3D occupancy prediction.
\\ ( https://arxiv.org/abs/2511.06666 ,  999kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06678
Date: Mon, 10 Nov 2025 03:50:57 GMT   (2089kb)

Title: Flexible Concept Bottleneck Model
Authors: Xingbo Du, Qiantong Dou, Lei Fan, Rui Zhang
Categories: cs.CV cs.LG
Comments: To appear in AAAI 2026
\\
 Concept bottleneck models (CBMs) improve neural network interpretability by
introducing an intermediate layer that maps human-understandable concepts to
predictions. Recent work has explored the use of vision-language models (VLMs)
to automate concept selection and annotation. However, existing VLM-based CBMs
typically require full model retraining when new concepts are involved, which
limits their adaptability and flexibility in real-world scenarios, especially
considering the rapid evolution of vision-language foundation models. To
address these issues, we propose Flexible Concept Bottleneck Model (FCBM),
which supports dynamic concept adaptation, including complete replacement of
the original concept set. Specifically, we design a hypernetwork that generates
prediction weights based on concept embeddings, allowing seamless integration
of new concepts without retraining the entire model. In addition, we introduce
a modified sparsemax module with a learnable temperature parameter that
dynamically selects the most relevant concepts, enabling the model to focus on
the most informative features. Extensive experiments on five public benchmarks
demonstrate that our method achieves accuracy comparable to state-of-the-art
baselines with a similar number of effective concepts. Moreover, the model
generalizes well to unseen concepts with just a single epoch of fine-tuning,
demonstrating its strong adaptability and flexibility.
\\ ( https://arxiv.org/abs/2511.06678 ,  2089kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06687
Date: Mon, 10 Nov 2025 04:20:31 GMT   (4603kb)

Title: AnoStyler: Text-Driven Localized Anomaly Generation via Lightweight
 Style Transfer
Authors: Yulim So, Seokho Kang
Categories: cs.CV
Comments: Accepted to AAAI 2026
\\
 Anomaly generation has been widely explored to address the scarcity of
anomaly images in real-world data. However, existing methods typically suffer
from at least one of the following limitations, hindering their practical
deployment: (1) lack of visual realism in generated anomalies; (2) dependence
on large amounts of real images; and (3) use of memory-intensive, heavyweight
model architectures. To overcome these limitations, we propose AnoStyler, a
lightweight yet effective method that frames zero-shot anomaly generation as
text-guided style transfer. Given a single normal image along with its category
label and expected defect type, an anomaly mask indicating the localized
anomaly regions and two-class text prompts representing the normal and anomaly
states are generated using generalizable category-agnostic procedures. A
lightweight U-Net model trained with CLIP-based loss functions is used to
stylize the normal image into a visually realistic anomaly image, where
anomalies are localized by the anomaly mask and semantically aligned with the
text prompts. Extensive experiments on the MVTec-AD and VisA datasets show that
AnoStyler outperforms existing anomaly generation methods in generating
high-quality and diverse anomaly images. Furthermore, using these generated
anomalies helps enhance anomaly detection performance.
\\ ( https://arxiv.org/abs/2511.06687 ,  4603kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06702
Date: Mon, 10 Nov 2025 04:48:48 GMT   (9211kb)

Title: SPAN: Spatial-Projection Alignment for Monocular 3D Object Detection
Authors: Yifan Wang, Yian Zhao, Fanqi Pu, Xiaochen Yang, Yang Tang, Xi Chen and
 Wenming Yang
Categories: cs.CV
\\
 Existing monocular 3D detectors typically tame the pronounced nonlinear
regression of 3D bounding box through decoupled prediction paradigm, which
employs multiple branches to estimate geometric center, depth, dimensions, and
rotation angle separately. Although this decoupling strategy simplifies the
learning process, it inherently ignores the geometric collaborative constraints
between different attributes, resulting in the lack of geometric consistency
prior, thereby leading to suboptimal performance. To address this issue, we
propose novel Spatial-Projection Alignment (SPAN) with two pivotal components:
(i). Spatial Point Alignment enforces an explicit global spatial constraint
between the predicted and ground-truth 3D bounding boxes, thereby rectifying
spatial drift caused by decoupled attribute regression. (ii). 3D-2D Projection
Alignment ensures that the projected 3D box is aligned tightly within its
corresponding 2D detection bounding box on the image plane, mitigating
projection misalignment overlooked in previous works. To ensure training
stability, we further introduce a Hierarchical Task Learning strategy that
progressively incorporates spatial-projection alignment as 3D attribute
predictions refine, preventing early stage error propagation across attributes.
Extensive experiments demonstrate that the proposed method can be easily
integrated into any established monocular 3D detector and delivers significant
performance improvements.
\\ ( https://arxiv.org/abs/2511.06702 ,  9211kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06709
Date: Mon, 10 Nov 2025 05:04:59 GMT   (1099kb)

Title: K-Stain: Keypoint-Driven Correspondence for H&E-to-IHC Virtual Staining
Authors: Sicheng Yang, Zhaohu Xing, Haipeng Zhou, and Lei Zhu
Categories: cs.CV
\\
 Virtual staining offers a promising method for converting Hematoxylin and
Eosin (H&E) images into Immunohistochemical (IHC) images, eliminating the need
for costly chemical processes. However, existing methods often struggle to
utilize spatial information effectively due to misalignment in tissue slices.
To overcome this challenge, we leverage keypoints as robust indicators of
spatial correspondence, enabling more precise alignment and integration of
structural details in synthesized IHC images. We introduce K-Stain, a novel
framework that employs keypoint-based spatial and semantic relationships to
enhance synthesized IHC image fidelity. K-Stain comprises three main
components: (1) a Hierarchical Spatial Keypoint Detector (HSKD) for identifying
keypoints in stain images, (2) a Keypoint-aware Enhancement Generator (KEG)
that integrates these keypoints during image generation, and (3) a Keypoint
Guided Discriminator (KGD) that improves the discriminator's sensitivity to
spatial details. Our approach leverages contextual information from adjacent
slices, resulting in more accurate and visually consistent IHC images.
Extensive experiments show that K-Stain outperforms state-of-the-art methods in
quantitative metrics and visual quality.
\\ ( https://arxiv.org/abs/2511.06709 ,  1099kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06716
Date: Mon, 10 Nov 2025 05:18:14 GMT   (4946kb)

Title: MirrorMamba: Towards Scalable and Robust Mirror Detection in Videos
Authors: Rui Song, Jiaying Lin, Rynson W.H. Lau
Categories: cs.CV cs.AI
\\
 Video mirror detection has received significant research attention, yet
existing methods suffer from limited performance and robustness. These
approaches often over-rely on single, unreliable dynamic features, and are
typically built on CNNs with limited receptive fields or Transformers with
quadratic computational complexity. To address these limitations, we propose a
new effective and scalable video mirror detection method, called MirrorMamba.
Our approach leverages multiple cues to adapt to diverse conditions,
incorporating perceived depth, correspondence and optical. We also introduce an
innovative Mamba-based Multidirection Correspondence Extractor, which benefits
from the global receptive field and linear complexity of the emerging Mamba
spatial state model to effectively capture correspondence properties.
Additionally, we design a Mamba-based layer-wise boundary enforcement decoder
to resolve the unclear boundary caused by the blurred depth map. Notably, this
work marks the first successful application of the Mamba-based architecture in
the field of mirror detection. Extensive experiments demonstrate that our
method outperforms existing state-of-the-art approaches for video mirror
detection on the benchmark datasets. Furthermore, on the most challenging and
representative image-based mirror detection dataset, our approach achieves
state-of-the-art performance, proving its robustness and generalizability.
\\ ( https://arxiv.org/abs/2511.06716 ,  4946kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06717
Date: Mon, 10 Nov 2025 05:23:00 GMT   (2009kb)

Title: MRT: Learning Compact Representations with Mixed RWKV-Transformer for
 Extreme Image Compression
Authors: Han Liu, Hengyu Man, Xingtao Wang, Wenrui Li, Debin Zhao
Categories: cs.CV
\\
 Recent advances in extreme image compression have revealed that mapping pixel
data into highly compact latent representations can significantly improve
coding efficiency. However, most existing methods compress images into 2-D
latent spaces via convolutional neural networks (CNNs) or Swin Transformers,
which tend to retain substantial spatial redundancy, thereby limiting overall
compression performance. In this paper, we propose a novel Mixed
RWKV-Transformer (MRT) architecture that encodes images into more compact 1-D
latent representations by synergistically integrating the complementary
strengths of linear-attention-based RWKV and self-attention-based Transformer
models. Specifically, MRT partitions each image into fixed-size windows,
utilizing RWKV modules to capture global dependencies across windows and
Transformer blocks to model local redundancies within each window. The
hierarchical attention mechanism enables more efficient and compact
representation learning in the 1-D domain. To further enhance compression
efficiency, we introduce a dedicated RWKV Compression Model (RCM) tailored to
the structure characteristics of the intermediate 1-D latent features in MRT.
Extensive experiments on standard image compression benchmarks validate the
effectiveness of our approach. The proposed MRT framework consistently achieves
superior reconstruction quality at bitrates below 0.02 bits per pixel (bpp).
Quantitative results based on the DISTS metric show that MRT significantly
outperforms the state-of-the-art 2-D architecture GLC, achieving bitrate
savings of 43.75%, 30.59% on the Kodak and CLIC2020 test datasets,
respectively.
\\ ( https://arxiv.org/abs/2511.06717 ,  2009kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06720
Date: Mon, 10 Nov 2025 05:29:18 GMT   (6938kb)

Title: Relative Energy Learning for LiDAR Out-of-Distribution Detection
Authors: Zizhao Li, Zhengkang Xiang, Jiayang Ao, Joseph West, Kourosh
 Khoshelham
Categories: cs.CV
\\
 Out-of-distribution (OOD) detection is a critical requirement for reliable
autonomous driving, where safety depends on recognizing road obstacles and
unexpected objects beyond the training distribution. Despite extensive research
on OOD detection in 2D images, direct transfer to 3D LiDAR point clouds has
been proven ineffective. Current LiDAR OOD methods struggle to distinguish rare
anomalies from common classes, leading to high false-positive rates and
overconfident errors in safety-critical settings. We propose Relative Energy
Learning (REL), a simple yet effective framework for OOD detection in LiDAR
point clouds. REL leverages the energy gap between positive (in-distribution)
and negative logits as a relative scoring function, mitigating calibration
issues in raw energy values and improving robustness across various scenes. To
address the absence of OOD samples during training, we propose a lightweight
data synthesis strategy called Point Raise, which perturbs existing point
clouds to generate auxiliary anomalies without altering the inlier semantics.
Evaluated on SemanticKITTI and the Spotting the Unexpected (STU) benchmark, REL
consistently outperforms existing methods by a large margin. Our results
highlight that modeling relative energy, combined with simple synthetic
outliers, provides a principled and scalable solution for reliable OOD
detection in open-world autonomous driving.
\\ ( https://arxiv.org/abs/2511.06720 ,  6938kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06721
Date: Mon, 10 Nov 2025 05:31:15 GMT   (3555kb)

Title: AvatarTex: High-Fidelity Facial Texture Reconstruction from Single-Image
 Stylized Avatars
Authors: Yuda Qiu, Zitong Xiao, Yiwei Zuo, Zisheng Ye, Weikai Chen, Xiaoguang
 Han
Categories: cs.CV
Comments: 3DV 2026 Accepted
\\
 We present AvatarTex, a high-fidelity facial texture reconstruction framework
capable of generating both stylized and photorealistic textures from a single
image. Existing methods struggle with stylized avatars due to the lack of
diverse multi-style datasets and challenges in maintaining geometric
consistency in non-standard textures. To address these limitations, AvatarTex
introduces a novel three-stage diffusion-to-GAN pipeline. Our key insight is
that while diffusion models excel at generating diversified textures, they lack
explicit UV constraints, whereas GANs provide a well-structured latent space
that ensures style and topology consistency. By integrating these strengths,
AvatarTex achieves high-quality topology-aligned texture synthesis with both
artistic and geometric coherence. Specifically, our three-stage pipeline first
completes missing texture regions via diffusion-based inpainting, refines style
and structure consistency using GAN-based latent optimization, and enhances
fine details through diffusion-based repainting. To address the need for a
stylized texture dataset, we introduce TexHub, a high-resolution collection of
20,000 multi-style UV textures with precise UV-aligned layouts. By leveraging
TexHub and our structured diffusion-to-GAN pipeline, AvatarTex establishes a
new state-of-the-art in multi-style facial texture reconstruction. TexHub will
be released upon publication to facilitate future research in this field.
\\ ( https://arxiv.org/abs/2511.06721 ,  3555kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06722
Date: Mon, 10 Nov 2025 05:31:59 GMT   (2176kb)

Title: Revisiting the Data Sampling in Multimodal Post-training from a
 Difficulty-Distinguish View
Authors: Jianyu Qi, Ding Zou, Wenrui Yan, Rui Ma, Jiaxu Li, Zhijie Zheng,
 Zhiguo Yang, Rongchang Zhao
Categories: cs.CV cs.AI cs.CL
Comments: Accpeted by AAAI 2026
\\
 Recent advances in Multimodal Large Language Models (MLLMs) have spurred
significant progress in Chain-of-Thought (CoT) reasoning. Building on the
success of Deepseek-R1, researchers extended multimodal reasoning to
post-training paradigms based on reinforcement learning (RL), focusing
predominantly on mathematical datasets. However, existing post-training
paradigms tend to neglect two critical aspects: (1) The lack of quantifiable
difficulty metrics capable of strategically screening samples for post-training
optimization. (2) Suboptimal post-training paradigms that fail to jointly
optimize perception and reasoning capabilities. To address this gap, we propose
two novel difficulty-aware sampling strategies: Progressive Image Semantic
Masking (PISM) quantifies sample hardness through systematic image degradation,
while Cross-Modality Attention Balance (CMAB) assesses cross-modal interaction
complexity via attention distribution analysis. Leveraging these metrics, we
design a hierarchical training framework that incorporates both GRPO-only and
SFT+GRPO hybrid training paradigms, and evaluate them across six benchmark
datasets. Experiments demonstrate consistent superiority of GRPO applied to
difficulty-stratified samples compared to conventional SFT+GRPO pipelines,
indicating that strategic data sampling can obviate the need for supervised
fine-tuning while improving model accuracy. Our code will be released at
https://github.com/qijianyu277/DifficultySampling.
\\ ( https://arxiv.org/abs/2511.06722 ,  2176kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06724
Date: Mon, 10 Nov 2025 05:34:39 GMT   (7698kb)

Title: Argus: Quality-Aware High-Throughput Text-to-Image Inference Serving
 System
Authors: Shubham Agarwal, Subrata Mitra, Saud Iqbal
Categories: cs.CV cs.DC
Comments: Accepted at Middleware 2025
\\
 Text-to-image (T2I) models have gained significant popularity. Most of these
are diffusion models with unique computational characteristics, distinct from
both traditional small-scale ML models and large language models. They are
highly compute-bound and use an iterative denoising process to generate images,
leading to very high inference time. This creates significant challenges in
designing a high-throughput system. We discovered that a large fraction of
prompts can be served using faster, approximated models. However, the
approximation setting must be carefully calibrated for each prompt to avoid
quality degradation. Designing a high-throughput system that assigns each
prompt to the appropriate model and compatible approximation setting remains a
challenging problem. We present Argus, a high-throughput T2I inference system
that selects the right level of approximation for each prompt to maintain
quality while meeting throughput targets on a fixed-size cluster. Argus
intelligently switches between different approximation strategies to satisfy
both throughput and quality requirements. Overall, Argus achieves 10x fewer
latency service-level objective (SLO) violations, 10% higher average quality,
and 40% higher throughput compared to baselines on two real-world workload
traces.
\\ ( https://arxiv.org/abs/2511.06724 ,  7698kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06734
Date: Mon, 10 Nov 2025 05:57:55 GMT   (17120kb)

Title: Rethinking Rainy 3D Scene Reconstruction via Perspective Transforming
 and Brightness Tuning
Authors: Qianfeng Yang, Xiang Chen, Pengpeng Li, Qiyuan Guan, Guiyue Jin, Jiyu
 Jin
Categories: cs.CV
Comments: Accepted by AAAI 2026 (Oral)
\\
 Rain degrades the visual quality of multi-view images, which are essential
for 3D scene reconstruction, resulting in inaccurate and incomplete
reconstruction results. Existing datasets often overlook two critical
characteristics of real rainy 3D scenes: the viewpoint-dependent variation in
the appearance of rain streaks caused by their projection onto 2D images, and
the reduction in ambient brightness resulting from cloud coverage during
rainfall. To improve data realism, we construct a new dataset named OmniRain3D
that incorporates perspective heterogeneity and brightness dynamicity, enabling
more faithful simulation of rain degradation in 3D scenes. Based on this
dataset, we propose an end-to-end reconstruction framework named REVR-GSNet
(Rain Elimination and Visibility Recovery for 3D Gaussian Splatting).
Specifically, REVR-GSNet integrates recursive brightness enhancement, Gaussian
primitive optimization, and GS-guided rain elimination into a unified
architecture through joint alternating optimization, achieving high-fidelity
reconstruction of clean 3D scenes from rain-degraded inputs. Extensive
experiments show the effectiveness of our dataset and method. Our dataset and
method provide a foundation for future research on multi-view image deraining
and rainy 3D scene reconstruction.
\\ ( https://arxiv.org/abs/2511.06734 ,  17120kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06740
Date: Mon, 10 Nov 2025 06:01:10 GMT   (516kb)

Title: SinSEMI: A One-Shot Image Generation Model and Data-Efficient Evaluation
 Framework for Semiconductor Inspection Equipment
Authors: ChunLiang Wu, Xiaochun Li
Categories: cs.CV
\\
 In the early stages of semiconductor equipment development, obtaining large
quantities of raw optical images poses a significant challenge. This data
scarcity hinder the advancement of AI-powered solutions in semiconductor
manufacturing. To address this challenge, we introduce SinSEMI, a novel
one-shot learning approach that generates diverse and highly realistic images
from single optical image. SinSEMI employs a multi-scale flow-based model
enhanced with LPIPS (Learned Perceptual Image Patch Similarity) energy guidance
during sampling, ensuring both perceptual realism and output variety. We also
introduce a comprehensive evaluation framework tailored for this application,
which enables a thorough assessment using just two reference images. Through
the evaluation against multiple one-shot generation techniques, we demonstrate
SinSEMI's superior performance in visual quality, quantitative measures, and
downstream tasks. Our experimental results demonstrate that SinSEMI-generated
images achieve both high fidelity and meaningful diversity, making them
suitable as training data for semiconductor AI applications.
\\ ( https://arxiv.org/abs/2511.06740 ,  516kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06741
Date: Mon, 10 Nov 2025 06:05:56 GMT   (2590kb)

Title: Otter: Mitigating Background Distractions of Wide-Angle Few-Shot Action
 Recognition with Enhanced RWKV
Authors: Wenbo Huang, Jinghui Zhang, Zhenghao Chen, Guang Li, Lei Zhang, Yang
 Cao, Fang Dong, Takahiro Ogawa, Miki Haseyama
Categories: cs.CV
Comments: Accepted by AAAI 2026 Oral
\\
 Wide-angle videos in few-shot action recognition (FSAR) effectively express
actions within specific scenarios. However, without a global understanding of
both subjects and background, recognizing actions in such samples remains
challenging because of the background distractions. Receptance Weighted Key
Value (RWKV), which learns interaction between various dimensions, shows
promise for global modeling. While directly applying RWKV to wide-angle FSAR
may fail to highlight subjects due to excessive background information.
Additionally, temporal relation degraded by frames with similar backgrounds is
difficult to reconstruct, further impacting performance. Therefore, we design
the CompOund SegmenTation and Temporal REconstructing RWKV (Otter).
Specifically, the Compound Segmentation Module~(CSM) is devised to segment and
emphasize key patches in each frame, effectively highlighting subjects against
background information. The Temporal Reconstruction Module (TRM) is
incorporated into the temporal-enhanced prototype construction to enable
bidirectional scanning, allowing better reconstruct temporal relation.
Furthermore, a regular prototype is combined with the temporal-enhanced
prototype to simultaneously enhance subject emphasis and temporal modeling,
improving wide-angle FSAR performance. Extensive experiments on benchmarks such
as SSv2, Kinetics, UCF101, and HMDB51 demonstrate that Otter achieves
state-of-the-art performance. Extra evaluation on the VideoBadminton dataset
further validates the superiority of Otter in wide-angle FSAR.
\\ ( https://arxiv.org/abs/2511.06741 ,  2590kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06744
Date: Mon, 10 Nov 2025 06:16:07 GMT   (6224kb)

Title: PointCubeNet: 3D Part-level Reasoning with 3x3x3 Point Cloud Blocks
Authors: Da-Yeong Kim and Yeong-Jun Cho
Categories: cs.CV
\\
 In this paper, we propose PointCubeNet, a novel multi-modal 3D understanding
framework that achieves part-level reasoning without requiring any part
annotations. PointCubeNet comprises global and local branches. The proposed
local branch, structured into 3x3x3 local blocks, enables part-level analysis
of point cloud sub-regions with the corresponding local text labels. Leveraging
the proposed pseudo-labeling method and local loss function, PointCubeNet is
effectively trained in an unsupervised manner. The experimental results
demonstrate that understanding 3D object parts enhances the understanding of
the overall 3D object. In addition, this is the first attempt to perform
unsupervised 3D part-level reasoning and achieves reliable and meaningful
results.
\\ ( https://arxiv.org/abs/2511.06744 ,  6224kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06748
Date: Mon, 10 Nov 2025 06:26:36 GMT   (17969kb)

Title: Image Restoration via Primal Dual Hybrid Gradient and Flow Generative
 Model
Authors: Ji Li and Chao Wang
Categories: cs.CV
Comments: 13 pages; AAAI26 version with appendix
\\
 Regularized optimization has been a classical approach to solving imaging
inverse problems, where the regularization term enforces desirable properties
of the unknown image. Recently, the integration of flow matching generative
models into image restoration has garnered significant attention, owing to
their powerful prior modeling capabilities. In this work, we incorporate such
generative priors into a Plug-and-Play (PnP) framework based on proximal
splitting, where the proximal operator associated with the regularizer is
replaced by a time-dependent denoiser derived from the generative model. While
existing PnP methods have achieved notable success in inverse problems with
smooth squared $\ell_2$ data fidelity--typically associated with Gaussian
noise--their applicability to more general data fidelity terms remains
underexplored. To address this, we propose a general and efficient PnP
algorithm inspired by the primal-dual hybrid gradient (PDHG) method. Our
approach is computationally efficient, memory-friendly, and accommodates a wide
range of fidelity terms. In particular, it supports both $\ell_1$ and $\ell_2$
norm-based losses, enabling robustness to non-Gaussian noise types such as
Poisson and impulse noise. We validate our method on several image restoration
tasks, including denoising, super-resolution, deblurring, and inpainting, and
demonstrate that $\ell_1$ and $\ell_2$ fidelity terms outperform the
conventional squared $\ell_2$ loss in the presence of non-Gaussian noise.
\\ ( https://arxiv.org/abs/2511.06748 ,  17969kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06752
Date: Mon, 10 Nov 2025 06:30:51 GMT   (6958kb)

Title: Med-SORA: Symptom to Organ Reasoning in Abdomen CT Images
Authors: You-Kyoung Na, Yeong-Jun Cho
Categories: cs.CV
Comments: 9 pages
\\
 Understanding symptom-image associations is crucial for clinical reasoning.
However, existing medical multimodal models often rely on simple one-to-one
hard labeling, oversimplifying clinical reality where symptoms relate to
multiple organs. In addition, they mainly use single-slice 2D features without
incorporating 3D information, limiting their ability to capture full anatomical
context. In this study, we propose Med-SORA, a framework for symptom-to-organ
reasoning in abdominal CT images. Med-SORA introduces RAG-based dataset
construction, soft labeling with learnable organ anchors to capture one-to-many
symptom-organ relationships, and a 2D-3D cross-attention architecture to fuse
local and global image features. To our knowledge, this is the first work to
address symptom-to-organ reasoning in medical multimodal learning. Experimental
results show that Med-SORA outperforms existing medical multimodal models and
enables accurate 3D clinical reasoning.
\\ ( https://arxiv.org/abs/2511.06752 ,  6958kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06764
Date: Mon, 10 Nov 2025 06:45:03 GMT   (23061kb)

Title: CAST-LUT: Tokenizer-Guided HSV Look-Up Tables for Purple Flare Removal
Authors: Pu Wang, Shuning Sun, Jialang Lu, Chen Wu, Zhihua Zhang, Youshan
 Zhang, Chenggang Shan, Dianjie Lu, Guijuan Zhang, Zhuoran Zheng
Categories: cs.CV
\\
 Purple flare, a diffuse chromatic aberration artifact commonly found around
highlight areas, severely degrades the tone transition and color of the image.
Existing traditional methods are based on hand-crafted features, which lack
flexibility and rely entirely on fixed priors, while the scarcity of paired
training data critically hampers deep learning. To address this issue, we
propose a novel network built upon decoupled HSV Look-Up Tables (LUTs). The
method aims to simplify color correction by adjusting the Hue (H), Saturation
(S), and Value (V) components independently. This approach resolves the
inherent color coupling problems in traditional methods. Our model adopts a
two-stage architecture: First, a Chroma-Aware Spectral Tokenizer (CAST)
converts the input image from RGB space to HSV space and independently encodes
the Hue (H) and Value (V) channels into a set of semantic tokens describing the
Purple flare status; second, the HSV-LUT module takes these tokens as input and
dynamically generates independent correction curves (1D-LUTs) for the three
channels H, S, and V. To effectively train and validate our model, we built the
first large-scale purple flare dataset with diverse scenes. We also proposed
new metrics and a loss function specifically designed for this task. Extensive
experiments demonstrate that our model not only significantly outperforms
existing methods in visual effects but also achieves state-of-the-art
performance on all quantitative metrics.
\\ ( https://arxiv.org/abs/2511.06764 ,  23061kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06765
Date: Mon, 10 Nov 2025 06:45:08 GMT   (2333kb)

Title: Robust and High-Fidelity 3D Gaussian Splatting: Fusing Pose Priors and
 Geometry Constraints for Texture-Deficient Outdoor Scenes
Authors: Meijun Guo, Yongliang Shi, Caiyun Liu, Yixiao Feng, Ming Ma, Tinghai
 Yan, Weining Lu, Bin Liang
Categories: cs.CV cs.GR
Comments: 7 pages, 3 figures. Accepted by IROS 2025
\\
 3D Gaussian Splatting (3DGS) has emerged as a key rendering pipeline for
digital asset creation due to its balance between efficiency and visual
quality. To address the issues of unstable pose estimation and scene
representation distortion caused by geometric texture inconsistency in large
outdoor scenes with weak or repetitive textures, we approach the problem from
two aspects: pose estimation and scene representation. For pose estimation, we
leverage LiDAR-IMU Odometry to provide prior poses for cameras in large-scale
environments. These prior pose constraints are incorporated into COLMAP's
triangulation process, with pose optimization performed via bundle adjustment.
Ensuring consistency between pixel data association and prior poses helps
maintain both robustness and accuracy. For scene representation, we introduce
normal vector constraints and effective rank regularization to enforce
consistency in the direction and shape of Gaussian primitives. These
constraints are jointly optimized with the existing photometric loss to enhance
the map quality. We evaluate our approach using both public and self-collected
datasets. In terms of pose optimization, our method requires only one-third of
the time while maintaining accuracy and robustness across both datasets. In
terms of scene representation, the results show that our method significantly
outperforms conventional 3DGS pipelines. Notably, on self-collected datasets
characterized by weak or repetitive textures, our approach demonstrates
enhanced visualization capabilities and achieves superior overall performance.
Codes and data will be publicly available at
https://github.com/justinyeah/normal_shape.git.
\\ ( https://arxiv.org/abs/2511.06765 ,  2333kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06810
Date: Mon, 10 Nov 2025 07:54:58 GMT   (6159kb)

Title: ConeGS: Error-Guided Densification Using Pixel Cones for Improved
 Reconstruction with Fewer Primitives
Authors: Bart{\l}omiej Baranowski, Stefano Esposito, Patricia Gscho{\ss}mann,
 Anpei Chen, Andreas Geiger
Categories: cs.CV
\\
 3D Gaussian Splatting (3DGS) achieves state-of-the-art image quality and
real-time performance in novel view synthesis but often suffers from a
suboptimal spatial distribution of primitives. This issue stems from
cloning-based densification, which propagates Gaussians along existing
geometry, limiting exploration and requiring many primitives to adequately
cover the scene. We present ConeGS, an image-space-informed densification
framework that is independent of existing scene geometry state. ConeGS first
creates a fast Instant Neural Graphics Primitives (iNGP) reconstruction as a
geometric proxy to estimate per-pixel depth. During the subsequent 3DGS
optimization, it identifies high-error pixels and inserts new Gaussians along
the corresponding viewing cones at the predicted depth values, initializing
their size according to the cone diameter. A pre-activation opacity penalty
rapidly removes redundant Gaussians, while a primitive budgeting strategy
controls the total number of primitives, either by a fixed budget or by
adapting to scene complexity, ensuring high reconstruction quality. Experiments
show that ConeGS consistently enhances reconstruction quality and rendering
performance across Gaussian budgets, with especially strong gains under tight
primitive constraints where efficient placement is crucial.
\\ ( https://arxiv.org/abs/2511.06810 ,  6159kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06817
Date: Mon, 10 Nov 2025 08:01:26 GMT   (2623kb)

Title: TiS-TSL: Image-Label Supervised Surgical Video Stereo Matching via
 Time-Switchable Teacher-Student Learning
Authors: Rui Wang, Ying Zhou, Hao Wang, Wenwei Zhang, Qiang Li, Zhiwei Wang
Categories: cs.CV cs.AI
Comments: 8 pages, 4 figures, accepted by BiBM2025
\\
 Stereo matching in minimally invasive surgery (MIS) is essential for
next-generation navigation and augmented reality. Yet, dense disparity
supervision is nearly impossible due to anatomical constraints, typically
limiting annotations to only a few image-level labels acquired before the
endoscope enters deep body cavities. Teacher-Student Learning (TSL) offers a
promising solution by leveraging a teacher trained on sparse labels to generate
pseudo labels and associated confidence maps from abundant unlabeled surgical
videos. However, existing TSL methods are confined to image-level supervision,
providing only spatial confidence and lacking temporal consistency estimation.
This absence of spatio-temporal reliability results in unstable disparity
predictions and severe flickering artifacts across video frames. To overcome
these challenges, we propose TiS-TSL, a novel time-switchable teacher-student
learning framework for video stereo matching under minimal supervision. At its
core is a unified model that operates in three distinct modes: Image-Prediction
(IP), Forward Video-Prediction (FVP), and Backward Video-Prediction (BVP),
enabling flexible temporal modeling within a single architecture. Enabled by
this unified model, TiS-TSL adopts a two-stage learning strategy. The
Image-to-Video (I2V) stage transfers sparse image-level knowledge to initialize
temporal modeling. The subsequent Video-to-Video (V2V) stage refines temporal
disparity predictions by comparing forward and backward predictions to
calculate bidirectional spatio-temporal consistency. This consistency
identifies unreliable regions across frames, filters noisy video-level pseudo
labels, and enforces temporal coherence. Experimental results on two public
datasets demonstrate that TiS-TSL exceeds other image-based state-of-the-arts
by improving TEPE and EPE by at least 2.11% and 4.54%, respectively..
\\ ( https://arxiv.org/abs/2511.06817 ,  2623kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06823
Date: Mon, 10 Nov 2025 08:11:20 GMT   (16646kb)

Title: Integrating Reweighted Least Squares with Plug-and-Play Diffusion Priors
 for Noisy Image Restoration
Authors: Ji Li and Chao Wang
Categories: cs.CV
Comments: 12 pages
\\
 Existing plug-and-play image restoration methods typically employ
off-the-shelf Gaussian denoisers as proximal operators within classical
optimization frameworks based on variable splitting. Recently, denoisers
induced by generative priors have been successfully integrated into regularized
optimization methods for image restoration under Gaussian noise. However, their
application to non-Gaussian noise--such as impulse noise--remains largely
unexplored. In this paper, we propose a plug-and-play image restoration
framework based on generative diffusion priors for robust removal of general
noise types, including impulse noise. Within the maximum a posteriori (MAP)
estimation framework, the data fidelity term is adapted to the specific noise
model. Departing from the conventional least-squares loss used for Gaussian
noise, we introduce a generalized Gaussian scale mixture-based loss, which
approximates a wide range of noise distributions and leads to an $\ell_q$-norm
($0<q\leq2$) fidelity term. This optimization problem is addressed using an
iteratively reweighted least squares (IRLS) approach, wherein the proximal step
involving the generative prior is efficiently performed via a diffusion-based
denoiser. Experimental results on benchmark datasets demonstrate that the
proposed method effectively removes non-Gaussian impulse noise and achieves
superior restoration performance.
\\ ( https://arxiv.org/abs/2511.06823 ,  16646kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06830
Date: Mon, 10 Nov 2025 08:21:11 GMT   (939kb)

Title: MUGSQA: Novel Multi-Uncertainty-Based Gaussian Splatting Quality
 Assessment Method, Dataset, and Benchmarks
Authors: Tianang Chen, Jian Jin, Shilv Cai, Zhuangzi Li, Weisi Lin
Categories: cs.CV
\\
 Gaussian Splatting (GS) has recently emerged as a promising technique for 3D
object reconstruction, delivering high-quality rendering results with
significantly improved reconstruction speed. As variants continue to appear,
assessing the perceptual quality of 3D objects reconstructed with different
GS-based methods remains an open challenge. To address this issue, we first
propose a unified multi-distance subjective quality assessment method that
closely mimics human viewing behavior for objects reconstructed with GS-based
methods in actual applications, thereby better collecting perceptual
experiences. Based on it, we also construct a novel GS quality assessment
dataset named MUGSQA, which is constructed considering multiple uncertainties
of the input data. These uncertainties include the quantity and resolution of
input views, the view distance, and the accuracy of the initial point cloud.
Moreover, we construct two benchmarks: one to evaluate the robustness of
various GS-based reconstruction methods under multiple uncertainties, and the
other to evaluate the performance of existing quality assessment metrics. Our
dataset and benchmark code will be released soon.
\\ ( https://arxiv.org/abs/2511.06830 ,  939kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06833
Date: Mon, 10 Nov 2025 08:28:13 GMT   (22423kb)

Title: ConsistTalk: Intensity Controllable Temporally Consistent Talking Head
 Generation with Diffusion Noise Search
Authors: Zhenjie Liu, Jianzhang Lu, Renjie Lu, Cong Liang, Shangfei Wang
Categories: cs.CV
Comments: AAAI26 poster
\\
 Recent advancements in video diffusion models have significantly enhanced
audio-driven portrait animation. However, current methods still suffer from
flickering, identity drift, and poor audio-visual synchronization. These issues
primarily stem from entangled appearance-motion representations and unstable
inference strategies. In this paper, we introduce \textbf{ConsistTalk}, a novel
intensity-controllable and temporally consistent talking head generation
framework with diffusion noise search inference. First, we propose \textbf{an
optical flow-guided temporal module (OFT)} that decouples motion features from
static appearance by leveraging facial optical flow, thereby reducing visual
flicker and improving temporal consistency. Second, we present an
\textbf{Audio-to-Intensity (A2I) model} obtained through multimodal
teacher-student knowledge distillation. By transforming audio and facial
velocity features into a frame-wise intensity sequence, the A2I model enables
joint modeling of audio and visual motion, resulting in more natural dynamics.
This further enables fine-grained, frame-wise control of motion dynamics while
maintaining tight audio-visual synchronization. Third, we introduce a
\textbf{diffusion noise initialization strategy (IC-Init)}. By enforcing
explicit constraints on background coherence and motion continuity during
inference-time noise search, we achieve better identity preservation and refine
motion dynamics compared to the current autoregressive strategy. Extensive
experiments demonstrate that ConsistTalk significantly outperforms prior
methods in reducing flicker, preserving identity, and delivering temporally
stable, high-fidelity talking head videos.
\\ ( https://arxiv.org/abs/2511.06833 ,  22423kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06836
Date: Mon, 10 Nov 2025 08:29:09 GMT   (1806kb)

Title: NeuroBridge: Bio-Inspired Self-Supervised EEG-to-Image Decoding via
 Cognitive Priors and Bidirectional Semantic Alignment
Authors: Wenjiang Zhang, Sifeng Wang, Yuwei Su, Xinyu Li, Chen Zhang and Suyu
 Zhong
Categories: cs.CV cs.AI
Comments: AAAI 2026
\\
 Visual neural decoding seeks to reconstruct or infer perceived visual stimuli
from brain activity patterns, providing critical insights into human cognition
and enabling transformative applications in brain-computer interfaces and
artificial intelligence. Current approaches, however, remain constrained by the
scarcity of high-quality stimulus-brain response pairs and the inherent
semantic mismatch between neural representations and visual content. Inspired
by perceptual variability and co-adaptive strategy of the biological systems,
we propose a novel self-supervised architecture, named NeuroBridge, which
integrates Cognitive Prior Augmentation (CPA) with Shared Semantic Projector
(SSP) to promote effective cross-modality alignment. Specifically, CPA
simulates perceptual variability by applying asymmetric, modality-specific
transformations to both EEG signals and images, enhancing semantic diversity.
Unlike previous approaches, SSP establishes a bidirectional alignment process
through a co-adaptive strategy, which mutually aligns features from two
modalities into a shared semantic space for effective cross-modal learning.
NeuroBridge surpasses previous state-of-the-art methods under both
intra-subject and inter-subject settings. In the intra-subject scenario, it
achieves the improvements of 12.3% in top-1 accuracy and 10.2% in top-5
accuracy, reaching 63.2% and 89.9% respectively on a 200-way zero-shot
retrieval task. Extensive experiments demonstrate the effectiveness,
robustness, and scalability of the proposed framework for neural visual
decoding.
\\ ( https://arxiv.org/abs/2511.06836 ,  1806kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06840
Date: Mon, 10 Nov 2025 08:31:32 GMT   (4667kb)

Title: PanoNav: Mapless Zero-Shot Object Navigation with Panoramic Scene
 Parsing and Dynamic Memory
Authors: Qunchao Jin, Yilin Wu, Changhao Chen
Categories: cs.CV cs.RO
Comments: Accepted as a poster in AAAI 2026
\\
 Zero-shot object navigation (ZSON) in unseen environments remains a
challenging problem for household robots, requiring strong perceptual
understanding and decision-making capabilities. While recent methods leverage
metric maps and Large Language Models (LLMs), they often depend on depth
sensors or prebuilt maps, limiting the spatial reasoning ability of Multimodal
Large Language Models (MLLMs). Mapless ZSON approaches have emerged to address
this, but they typically make short-sighted decisions, leading to local
deadlocks due to a lack of historical context. We propose PanoNav, a fully
RGB-only, mapless ZSON framework that integrates a Panoramic Scene Parsing
module to unlock the spatial parsing potential of MLLMs from panoramic RGB
inputs, and a Memory-guided Decision-Making mechanism enhanced by a Dynamic
Bounded Memory Queue to incorporate exploration history and avoid local
deadlocks. Experiments on the public navigation benchmark show that PanoNav
significantly outperforms representative baselines in both SR and SPL metrics.
\\ ( https://arxiv.org/abs/2511.06840 ,  4667kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06841
Date: Mon, 10 Nov 2025 08:33:00 GMT   (1929kb)

Title: Aerial Image Stitching Using IMU Data from a UAV
Authors: Selim Ahmet Iz, Mustafa Unel
Categories: cs.CV cs.RO cs.SY eess.SY math.DS
DOI: 10.1109/ICIVC58118.2023.10269879
\\
 Unmanned Aerial Vehicles (UAVs) are widely used for aerial photography and
remote sensing applications. One of the main challenges is to stitch together
multiple images into a single high-resolution image that covers a large area.
Featurebased image stitching algorithms are commonly used but can suffer from
errors and ambiguities in feature detection and matching. To address this,
several approaches have been proposed, including using bundle adjustment
techniques or direct image alignment. In this paper, we present a novel method
that uses a combination of IMU data and computer vision techniques for
stitching images captured by a UAV. Our method involves several steps such as
estimating the displacement and rotation of the UAV between consecutive images,
correcting for perspective distortion, and computing a homography matrix. We
then use a standard image stitching algorithm to align and blend the images
together. Our proposed method leverages the additional information provided by
the IMU data, corrects for various sources of distortion, and can be easily
integrated into existing UAV workflows. Our experiments demonstrate the
effectiveness and robustness of our method, outperforming some of the existing
feature-based image stitching algorithms in terms of accuracy and reliability,
particularly in challenging scenarios such as large displacements, rotations,
and variations in camera pose.
\\ ( https://arxiv.org/abs/2511.06841 ,  1929kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06846
Date: Mon, 10 Nov 2025 08:44:19 GMT   (1836kb)

Title: Gaussian-Augmented Physics Simulation and System Identification with
 Complex Colliders
Authors: Federico Vasile, Ri-Zhao Qiu, Lorenzo Natale, Xiaolong Wang
Categories: cs.CV
Comments: Accepted to NeurIPS 2025. Project website:
 https://as-diffmpm.github.io/
\\
 System identification involving the geometry, appearance, and physical
properties from video observations is a challenging task with applications in
robotics and graphics. Recent approaches have relied on fully differentiable
Material Point Method (MPM) and rendering for simultaneous optimization of
these properties. However, they are limited to simplified object-environment
interactions with planar colliders and fail in more challenging scenarios where
objects collide with non-planar surfaces. We propose AS-DiffMPM, a
differentiable MPM framework that enables physical property estimation with
arbitrarily shaped colliders. Our approach extends existing methods by
incorporating a differentiable collision handling mechanism, allowing the
target object to interact with complex rigid bodies while maintaining
end-to-end optimization. We show AS-DiffMPM can be easily interfaced with
various novel view synthesis methods as a framework for system identification
from visual observations.
\\ ( https://arxiv.org/abs/2511.06846 ,  1836kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06848
Date: Mon, 10 Nov 2025 08:46:30 GMT   (154kb)

Title: Distillation Dynamics: Towards Understanding Feature-Based Distillation
 in Vision Transformers
Authors: Huiyuan Tian, Bonan Xu Shijian Li
Categories: cs.CV
Comments: Accepted to AAAI 2026. Submitted version
\\
 While feature-based knowledge distillation has proven highly effective for
compressing CNNs, these techniques unexpectedly fail when applied to Vision
Transformers (ViTs), often performing worse than simple logit-based
distillation. We provide the first comprehensive analysis of this phenomenon
through a novel analytical framework termed as ``distillation dynamics",
combining frequency spectrum analysis, information entropy metrics, and
activation magnitude tracking. Our investigation reveals that ViTs exhibit a
distinctive U-shaped information processing pattern: initial compression
followed by expansion. We identify the root cause of negative transfer in
feature distillation: a fundamental representational paradigm mismatch between
teacher and student models. Through frequency-domain analysis, we show that
teacher models employ distributed, high-dimensional encoding strategies in
later layers that smaller student models cannot replicate due to limited
channel capacity. This mismatch causes late-layer feature alignment to actively
harm student performance. Our findings reveal that successful knowledge
transfer in ViTs requires moving beyond naive feature mimicry to methods that
respect these fundamental representational constraints, providing essential
theoretical guidance for designing effective ViTs compression strategies. All
source code and experimental logs are provided in the supplementary material.
\\ ( https://arxiv.org/abs/2511.06848 ,  154kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06857
Date: Mon, 10 Nov 2025 08:57:06 GMT   (6058kb)

Title: Ambiguity-aware Truncated Flow Matching for Ambiguous Medical Image
 Segmentation
Authors: Fanding Li (1), Xiangyu Li (1), Xianghe Su (1), Xingyu Qiu (1), Suyu
 Dong (2), Wei Wang (3), Kuanquan Wang (1), Gongning Luo (1), Shuo Li (4 and
 5) ((1) Faculty of Computing, Harbin Institute of Technology, Harbin, China,
 (2) College of Computer and Control Engineering, Northeast Forestry
 University, Harbin, China, (3) Faculty of Computing, Harbin Institute of
 Technology, Shenzhen, China, (4) Department of Computer and Data Science,
 Case Western Reserve University, Cleveland, Ohio 44106, United States, (5)
 Department of Biomedical Engineering, Case Western Reserve University,
 Cleveland, Ohio 44106, United States)
Categories: cs.CV
Comments: 13 pages, 10 figures, extended version of AAAI-26 paper
\\
 A simultaneous enhancement of accuracy and diversity of predictions remains a
challenge in ambiguous medical image segmentation (AMIS) due to the inherent
trade-offs. While truncated diffusion probabilistic models (TDPMs) hold strong
potential with a paradigm optimization, existing TDPMs suffer from entangled
accuracy and diversity of predictions with insufficient fidelity and
plausibility. To address the aforementioned challenges, we propose
Ambiguity-aware Truncated Flow Matching (ATFM), which introduces a novel
inference paradigm and dedicated model components. Firstly, we propose
Data-Hierarchical Inference, a redefinition of AMIS-specific inference
paradigm, which enhances accuracy and diversity at data-distribution and
data-sample level, respectively, for an effective disentanglement. Secondly,
Gaussian Truncation Representation (GTR) is introduced to enhance both fidelity
of predictions and reliability of truncation distribution, by explicitly
modeling it as a Gaussian distribution at $T_{\text{trunc}}$ instead of using
sampling-based approximations.Thirdly, Segmentation Flow Matching (SFM) is
proposed to enhance the plausibility of diverse predictions by extending
semantic-aware flow transformation in Flow Matching (FM). Comprehensive
evaluations on LIDC and ISIC3 datasets demonstrate that ATFM outperforms SOTA
methods and simultaneously achieves a more efficient inference. ATFM improves
GED and HM-IoU by up to $12\%$ and $7.3\%$ compared to advanced methods.
\\ ( https://arxiv.org/abs/2511.06857 ,  6058kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06863
Date: Mon, 10 Nov 2025 09:07:23 GMT   (1107kb)

Title: VAEVQ: Enhancing Discrete Visual Tokenization through Variational
 Modeling
Authors: Sicheng Yang, Xing Hu, Qiang Wu, Dawei Yang
Categories: cs.CV
\\
 Vector quantization (VQ) transforms continuous image features into discrete
representations, providing compressed, tokenized inputs for generative models.
However, VQ-based frameworks suffer from several issues, such as non-smooth
latent spaces, weak alignment between representations before and after
quantization, and poor coherence between the continuous and discrete domains.
These issues lead to unstable codeword learning and underutilized codebooks,
ultimately degrading the performance of both reconstruction and downstream
generation tasks. To this end, we propose VAEVQ, which comprises three key
components: (1) Variational Latent Quantization (VLQ), replacing the AE with a
VAE for quantization to leverage its structured and smooth latent space,
thereby facilitating more effective codeword activation; (2) Representation
Coherence Strategy (RCS), adaptively modulating the alignment strength between
pre- and post-quantization features to enhance consistency and prevent
overfitting to noise; and (3) Distribution Consistency Regularization (DCR),
aligning the entire codebook distribution with the continuous latent
distribution to improve utilization. Extensive experiments on two benchmark
datasets demonstrate that VAEVQ outperforms state-of-the-art methods.
\\ ( https://arxiv.org/abs/2511.06863 ,  1107kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06876
Date: Mon, 10 Nov 2025 09:25:25 GMT   (21432kb)

Title: Generating an Image From 1,000 Words: Enhancing Text-to-Image With
 Structured Captions
Authors: Eyal Gutflaish, Eliran Kachlon, Hezi Zisman, Tal Hacham, Nimrod Sarid,
 Alexander Visheratin, Saar Huberman, Gal Davidi, Guy Bukchin, Kfir Goldberg,
 Ron Mokady
Categories: cs.CV
\\
 Text-to-image models have rapidly evolved from casual creative tools to
professional-grade systems, achieving unprecedented levels of image quality and
realism. Yet, most models are trained to map short prompts into detailed
images, creating a gap between sparse textual input and rich visual outputs.
This mismatch reduces controllability, as models often fill in missing details
arbitrarily, biasing toward average user preferences and limiting precision for
professional use. We address this limitation by training the first open-source
text-to-image model on long structured captions, where every training sample is
annotated with the same set of fine-grained attributes. This design maximizes
expressive coverage and enables disentangled control over visual factors. To
process long captions efficiently, we propose DimFusion, a fusion mechanism
that integrates intermediate tokens from a lightweight LLM without increasing
token length. We also introduce the Text-as-a-Bottleneck Reconstruction (TaBR)
evaluation protocol. By assessing how well real images can be reconstructed
through a captioning-generation loop, TaBR directly measures controllability
and expressiveness, even for very long captions where existing evaluation
methods fail. Finally, we demonstrate our contributions by training the
large-scale model FIBO, achieving state-of-the-art prompt alignment among
open-source models. Model weights are publicly available at
https://huggingface.co/briaai/FIBO
\\ ( https://arxiv.org/abs/2511.06876 ,  21432kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06888
Date: Mon, 10 Nov 2025 09:40:48 GMT   (13475kb)

Title: A Two-Stage System for Layout-Controlled Image Generation using Large
 Language Models and Diffusion Models
Authors: Jan-Hendrik Koch, Jonas Krumme, Konrad Gadzicki
Categories: cs.CV
Comments: 12 pages, 5 figures
\\
 Text-to-image diffusion models exhibit remarkable generative capabilities,
but lack precise control over object counts and spatial arrangements. This work
introduces a two-stage system to address these compositional limitations. The
first stage employs a Large Language Model (LLM) to generate a structured
layout from a list of objects. The second stage uses a layout-conditioned
diffusion model to synthesize a photorealistic image adhering to this layout.
We find that task decomposition is critical for LLM-based spatial planning; by
simplifying the initial generation to core objects and completing the layout
with rule-based insertion, we improve object recall from 57.2% to 99.9% for
complex scenes. For image synthesis, we compare two leading conditioning
methods: ControlNet and GLIGEN. After domain-specific finetuning on
table-setting datasets, we identify a key trade-off: ControlNet preserves
text-based stylistic control but suffers from object hallucination, while
GLIGEN provides superior layout fidelity at the cost of reduced prompt-based
controllability. Our end-to-end system successfully generates images with
specified object counts and plausible spatial arrangements, demonstrating the
viability of a decoupled approach for compositionally controlled synthesis.
\\ ( https://arxiv.org/abs/2511.06888 ,  13475kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06897
Date: Mon, 10 Nov 2025 09:46:04 GMT   (1975kb)

Title: Adaptive Morph-Patch Transformer for Arotic Vessel Segmentation
Authors: Zhenxi Zhang, Fuchen Zheng, Adnan Iltaf, Yifei Han, Zhenyu Cheng, Yue
 Du, Bin Li, Tianyong Liu, Shoujun Zhou
Categories: cs.CV
Comments: This is the preprint version of a paper accepted by AAAI 2026. The
 final version will appear in the AAAI Proceedings
\\
 Accurate segmentation of aortic vascular structures is critical for
diagnosing and treating cardiovascular diseases.Traditional Transformer-based
models have shown promise in this domain by capturing long-range dependencies
between vascular features. However, their reliance on fixed-size rectangular
patches often influences the integrity of complex vascular structures, leading
to suboptimal segmentation accuracy. To address this challenge, we propose the
adaptive Morph Patch Transformer (MPT), a novel architecture specifically
designed for aortic vascular segmentation. Specifically, MPT introduces an
adaptive patch partitioning strategy that dynamically generates
morphology-aware patches aligned with complex vascular structures. This
strategy can preserve semantic integrity of complex vascular structures within
individual patches. Moreover, a Semantic Clustering Attention (SCA) method is
proposed to dynamically aggregate features from various patches with similar
semantic characteristics. This method enhances the model's capability to
segment vessels of varying sizes, preserving the integrity of vascular
structures. Extensive experiments on three open-source dataset(AVT, AortaSeg24
and TBAD) demonstrate that MPT achieves state-of-the-art performance, with
improvements in segmenting intricate vascular structures.
\\ ( https://arxiv.org/abs/2511.06897 ,  1975kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06901
Date: Mon, 10 Nov 2025 09:51:15 GMT   (895kb)

Title: Classification of Microplastic Particles in Water using Polarized Light
 Scattering and Machine Learning Methods
Authors: Leonard Saur, Marc von Pawlowski, Ulrich Gengenbach, Ingo Sieber,
 Hossein Shirali, Lorenz W\"uhrl, Rainer Kiko, Christian Pylatiuk
Categories: cs.CV
Comments: 20 pages, 6 figures
\\
 Facing the critical need for continuous, large-scale microplastic monitoring,
which is hindered by the limitations of gold-standard methods in aquatic
environments, this paper introduces and validates a novel, reflection-based
approach for the in-situ classification and identification of microplastics
directly in water bodies, which is based on polarized light scattering. In this
experiment, we classify colorless microplastic particles (50-300 $\mu$m) by
illuminating them with linearly polarized laser light and capturing their
reflected signals using a polarization-sensitive camera. This reflection-based
technique successfully circumvents the transmission-based interference issues
that plague many conventional methods when applied in water. Using a deep
convolutional neural network (CNN) for image-based classification, we
successfully identified three common polymer types, high-density polyethylene,
low-density polyethylene, and polypropylene, achieving a peak mean
classification accuracy of 80% on the test dataset. A subsequent feature
hierarchy analysis demonstrated that the CNN's decision-making process relies
mainly on the microstructural integrity and internal texture (polarization
patterns) of the particle rather than its macroshape. Critically, we found that
the Angle of Linear Polarization (AOLP) signal is significantly more robust
against contextual noise than the Degree of Linear Polarization (DOLP) signal.
While the AOLP-based classification achieved superior overall performance, its
strength lies in distinguishing between the two polyethylene plastics, showing
a lower confusion rate between high-density and low-density polyethylene.
Conversely, the DOLP signal demonstrated slightly worse overall classification
results but excels at accurately identifying the polypropylene class, which it
isolated with greater success than AOLP.
\\ ( https://arxiv.org/abs/2511.06901 ,  895kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06908
Date: Mon, 10 Nov 2025 10:02:30 GMT   (2952kb)

Title: Mono3DVG-EnSD: Enhanced Spatial-aware and Dimension-decoupled Text
 Encoding for Monocular 3D Visual Grounding
Authors: Yuzhen Li, Min Liu, Zhaoyang Li, Yuan Bian, Xueping Wang, Erbo Zhai,
 Yaonan Wang
Categories: cs.CV cs.MM
Comments: 10 pages
\\
 Monocular 3D Visual Grounding (Mono3DVG) is an emerging task that locates 3D
objects in RGB images using text descriptions with geometric cues. However,
existing methods face two key limitations. Firstly, they often over-rely on
high-certainty keywords that explicitly identify the target object while
neglecting critical spatial descriptions. Secondly, generalized textual
features contain both 2D and 3D descriptive information, thereby capturing an
additional dimension of details compared to singular 2D or 3D visual features.
This characteristic leads to cross-dimensional interference when refining
visual features under text guidance. To overcome these challenges, we propose
Mono3DVG-EnSD, a novel framework that integrates two key components: the
CLIP-Guided Lexical Certainty Adapter (CLIP-LCA) and the Dimension-Decoupled
Module (D2M). The CLIP-LCA dynamically masks high-certainty keywords while
retaining low-certainty implicit spatial descriptions, thereby forcing the
model to develop a deeper understanding of spatial relationships in captions
for object localization. Meanwhile, the D2M decouples dimension-specific
(2D/3D) textual features from generalized textual features to guide
corresponding visual features at same dimension, which mitigates
cross-dimensional interference by ensuring dimensionally-consistent cross-modal
interactions. Through comprehensive comparisons and ablation studies on the
Mono3DRefer dataset, our method achieves state-of-the-art (SOTA) performance
across all metrics. Notably, it improves the challenging Far(Acc@0.5) scenario
by a significant +13.54%.
\\ ( https://arxiv.org/abs/2511.06908 ,  2952kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06925
Date: Mon, 10 Nov 2025 10:18:26 GMT   (3052kb)

Title: DTTNet: Improving Video Shadow Detection via Dark-Aware Guidance and
 Tokenized Temporal Modeling
Authors: Zhicheng Li, Kunyang Sun, Rui Yao, Hancheng Zhu, Fuyuan Hu, Jiaqi
 Zhao, Zhiwen Shao, Yong Zhou
Categories: cs.CV
\\
 Video shadow detection confronts two entwined difficulties: distinguishing
shadows from complex backgrounds and modeling dynamic shadow deformations under
varying illumination. To address shadow-background ambiguity, we leverage
linguistic priors through the proposed Vision-language Match Module (VMM) and a
Dark-aware Semantic Block (DSB), extracting text-guided features to explicitly
differentiate shadows from dark objects. Furthermore, we introduce adaptive
mask reweighting to downweight penumbra regions during training and apply edge
masks at the final decoder stage for better supervision. For temporal modeling
of variable shadow shapes, we propose a Tokenized Temporal Block (TTB) that
decouples spatiotemporal learning. TTB summarizes cross-frame shadow semantics
into learnable temporal tokens, enabling efficient sequence encoding with
minimal computation overhead. Comprehensive Experiments on multiple benchmark
datasets demonstrate state-of-the-art accuracy and real-time inference
efficiency. Codes are available at https://github.com/city-cheng/DTTNet.
\\ ( https://arxiv.org/abs/2511.06925 ,  3052kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06943
Date: Mon, 10 Nov 2025 10:51:04 GMT   (46718kb)

Title: PlantTraitNet: An Uncertainty-Aware Multimodal Framework for
 Global-Scale Plant Trait Inference from Citizen Science Data
Authors: Ayushi Sharma, Johanna Trost, Daniel Lusk, Johannes Dollinger, Julian
 Schrader, Christian Rossi, Javier Lopatin, Etienne Lalibert\'e, Simon
 Haberstroh, Jana Eichel, Daniel Mederer, Jose Miguel Cerda-Paredes, Shyam S.
 Phartyal, Lisa-Maricia Schwarz, Anja Linst\"adter, Maria Concei\c{c}\~ao
 Caldeira, Teja Kattenborn
Categories: cs.CV cs.AI
Comments: Preprint version of the paper accepted at the 40th AAAI Conference on
 Artificial Intelligence (AAAI-26), organized by the Association for the
 Advancement of Artificial Intelligence
\\
 Global plant maps of plant traits, such as leaf nitrogen or plant height, are
essential for understanding ecosystem processes, including the carbon and
energy cycles of the Earth system. However, existing trait maps remain limited
by the high cost and sparse geographic coverage of field-based measurements.
Citizen science initiatives offer a largely untapped resource to overcome these
limitations, with over 50 million geotagged plant photographs worldwide
capturing valuable visual information on plant morphology and physiology. In
this study, we introduce PlantTraitNet, a multi-modal, multi-task
uncertainty-aware deep learning framework that predictsfour key plant traits
(plant height, leaf area, specific leaf area, and nitrogen content) from
citizen science photos using weak supervision. By aggregating individual trait
predictions across space, we generate global maps of trait distributions. We
validate these maps against independent vegetation survey data (sPlotOpen) and
benchmark them against leading global trait products. Our results show that
PlantTraitNet consistently outperforms existing trait maps across all evaluated
traits, demonstrating that citizen science imagery, when integrated with
computer vision and geospatial AI, enables not only scalable but also more
accurate global trait mapping. This approach offers a powerful new pathway for
ecological research and Earth system modeling.
\\ ( https://arxiv.org/abs/2511.06943 ,  46718kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06944
Date: Mon, 10 Nov 2025 10:52:17 GMT   (3161kb)

Title: From Attribution to Action: Jointly ALIGNing Predictions and
 Explanations
Authors: Dongsheng Hong, Chao Chen, Yanhui Chen, Shanshan Lin, Zhihao Chen,
 Xiangwen Liao
Categories: cs.CV cs.AI
Comments: Accepted in AAAI 2026
\\
 Explanation-guided learning (EGL) has shown promise in aligning model
predictions with interpretable reasoning, particularly in computer vision
tasks. However, most approaches rely on external annotations or heuristic-based
segmentation to supervise model explanations, which can be noisy, imprecise and
difficult to scale. In this work, we provide both empirical and theoretical
evidence that low-quality supervision signals can degrade model performance
rather than improve it. In response, we propose ALIGN, a novel framework that
jointly trains a classifier and a masker in an iterative manner. The masker
learns to produce soft, task-relevant masks that highlight informative regions,
while the classifier is optimized for both prediction accuracy and alignment
between its saliency maps and the learned masks. By leveraging high-quality
masks as guidance, ALIGN improves both interpretability and generalizability,
showing its superiority across various settings. Experiments on the two domain
generalization benchmarks, VLCS and Terra Incognita, show that ALIGN
consistently outperforms six strong baselines in both in-distribution and
out-of-distribution settings. Besides, ALIGN also yields superior explanation
quality concerning sufficiency and comprehensiveness, highlighting its
effectiveness in producing accurate and interpretable models.
\\ ( https://arxiv.org/abs/2511.06944 ,  3161kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06947
Date: Mon, 10 Nov 2025 10:54:35 GMT   (3732kb)

Title: FoCLIP: A Feature-Space Misalignment Framework for CLIP-Based Image
 Manipulation and Detection
Authors: Yulin Chen, Zeyuan Wang, Tianyuan Yu, Yingmei Wei, Liang Bai
Categories: cs.CV cs.AI
Comments: 15 page, 9 figures, published to PRCV
\\
 The well-aligned attribute of CLIP-based models enables its effective
application like CLIPscore as a widely adopted image quality assessment metric.
However, such a CLIP-based metric is vulnerable for its delicate multimodal
alignment. In this work, we propose \textbf{FoCLIP}, a feature-space
misalignment framework for fooling CLIP-based image quality metric. Based on
the stochastic gradient descent technique, FoCLIP integrates three key
components to construct fooling examples: feature alignment as the core module
to reduce image-text modality gaps, the score distribution balance module and
pixel-guard regularization, which collectively optimize multimodal output
equilibrium between CLIPscore performance and image quality. Such a design can
be engineered to maximize the CLIPscore predictions across diverse input
prompts, despite exhibiting either visual unrecognizability or semantic
incongruence with the corresponding adversarial prompts from human perceptual
perspectives. Experiments on ten artistic masterpiece prompts and ImageNet
subsets demonstrate that optimized images can achieve significant improvement
in CLIPscore while preserving high visual fidelity. In addition, we found that
grayscale conversion induces significant feature degradation in fooling images,
exhibiting noticeable CLIPscore reduction while preserving statistical
consistency with original images. Inspired by this phenomenon, we propose a
color channel sensitivity-driven tampering detection mechanism that achieves
91% accuracy on standard benchmarks. In conclusion, this work establishes a
practical pathway for feature misalignment in CLIP-based multimodal systems and
the corresponding defense method.
\\ ( https://arxiv.org/abs/2511.06947 ,  3732kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06948
Date: Mon, 10 Nov 2025 10:54:46 GMT   (1185kb)

Title: PADM: A Physics-aware Diffusion Model for Attenuation Correction
Authors: Trung Kien Pham, Hoang Minh Vu, Anh Duc Chu, Dac Thai Nguyen, Trung
 Thanh Nguyen, Thao Nguyen Truong, Mai Hong Son, Thanh Trung Nguyen, Phi Le
 Nguyen
Categories: cs.CV
Comments: IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)
 2026
\\
 Attenuation artifacts remain a significant challenge in cardiac Myocardial
Perfusion Imaging (MPI) using Single-Photon Emission Computed Tomography
(SPECT), often compromising diagnostic accuracy and reducing clinical
interpretability. While hybrid SPECT/CT systems mitigate these artifacts
through CT-derived attenuation maps, their high cost, limited accessibility,
and added radiation exposure hinder widespread clinical adoption. In this
study, we propose a novel CT-free solution to attenuation correction in cardiac
SPECT. Specifically, we introduce Physics-aware Attenuation Correction
Diffusion Model (PADM), a diffusion-based generative method that incorporates
explicit physics priors via a teacher--student distillation mechanism. This
approach enables attenuation artifact correction using only
Non-Attenuation-Corrected (NAC) input, while still benefiting from
physics-informed supervision during training. To support this work, we also
introduce CardiAC, a comprehensive dataset comprising 424 patient studies with
paired NAC and Attenuation-Corrected (AC) reconstructions, alongside
high-resolution CT-based attenuation maps. Extensive experiments demonstrate
that PADM outperforms state-of-the-art generative models, delivering superior
reconstruction fidelity across both quantitative metrics and visual assessment.
\\ ( https://arxiv.org/abs/2511.06948 ,  1185kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06953
Date: Mon, 10 Nov 2025 11:03:30 GMT   (9575kb)

Title: GFix: Perceptually Enhanced Gaussian Splatting Video Compression
Authors: Siyue Teng, Ge Gao, Duolikun Danier, Yuxuan Jiang, Fan Zhang, Thomas
 Davis, Zoe Liu, David Bull
Categories: cs.CV
\\
 3D Gaussian Splatting (3DGS) enhances 3D scene reconstruction through
explicit representation and fast rendering, demonstrating potential benefits
for various low-level vision tasks, including video compression. However,
existing 3DGS-based video codecs generally exhibit more noticeable visual
artifacts and relatively low compression ratios. In this paper, we specifically
target the perceptual enhancement of 3DGS-based video compression, based on the
assumption that artifacts from 3DGS rendering and quantization resemble noisy
latents sampled during diffusion training. Building on this premise, we propose
a content-adaptive framework, GFix, comprising a streamlined, single-step
diffusion model that serves as an off-the-shelf neural enhancer. Moreover, to
increase compression efficiency, We propose a modulated LoRA scheme that
freezes the low-rank decompositions and modulates the intermediate hidden
states, thereby achieving efficient adaptation of the diffusion backbone with
highly compressible updates. Experimental results show that GFix delivers
strong perceptual quality enhancement, outperforming GSVC with up to 72.1%
BD-rate savings in LPIPS and 21.4% in FID.
\\ ( https://arxiv.org/abs/2511.06953 ,  9575kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06958
Date: Mon, 10 Nov 2025 11:06:25 GMT   (25425kb)

Title: Learning from the Right Patches: A Two-Stage Wavelet-Driven Masked
 Autoencoder for Histopathology Representation Learning
Authors: Raneen Younis, Louay Hamdi, Lukas Chavez, Zahra Ahmadi
Categories: cs.CV
\\
 Whole-slide images are central to digital pathology, yet their extreme size
and scarce annotations make self-supervised learning essential. Masked
Autoencoders (MAEs) with Vision Transformer backbones have recently shown
strong potential for histopathology representation learning. However,
conventional random patch sampling during MAE pretraining often includes
irrelevant or noisy regions, limiting the model's ability to capture meaningful
tissue patterns. In this paper, we present a lightweight and domain-adapted
framework that brings structure and biological relevance into MAE-based
learning through a wavelet-informed patch selection strategy. WISE-MAE applies
a two-step coarse-to-fine process: wavelet-based screening at low magnification
to locate structurally rich regions, followed by high-resolution extraction for
detailed modeling. This approach mirrors the diagnostic workflow of
pathologists and improves the quality of learned representations. Evaluations
across multiple cancer datasets, including lung, renal, and colorectal tissues,
show that WISE-MAE achieves competitive representation quality and downstream
classification performance while maintaining efficiency under weak supervision.
\\ ( https://arxiv.org/abs/2511.06958 ,  25425kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07004
Date: Mon, 10 Nov 2025 11:56:58 GMT   (3937kb)

Title: Exploring the "Great Unseen" in Medieval Manuscripts: Instance-Level
 Labeling of Legacy Image Collections with Zero-Shot Models
Authors: Christofer Meinecke, Estelle Gu\'eville, David Joseph Wrisley
Categories: cs.CV cs.HC
\\
 We aim to theorize the medieval manuscript page and its contents more
holistically, using state-of-the-art techniques to segment and describe the
entire manuscript folio, for the purpose of creating richer training data for
computer vision techniques, namely instance segmentation, and multimodal models
for medieval-specific visual content.
\\ ( https://arxiv.org/abs/2511.07004 ,  3937kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07007
Date: Mon, 10 Nov 2025 11:57:50 GMT   (9072kb)

Title: TrueCity: Real and Simulated Urban Data for Cross-Domain 3D Scene
 Understanding
Authors: Duc Nguyen, Yan-Ling Lai, Qilin Zhang, Prabin Gyawali, Benedikt
 Schwab, Olaf Wysocki, Thomas H. Kolbe
Categories: cs.CV cs.AI cs.LG
Comments: The paper accepted for 3DV 2026 (International Conference on 3D
 Vision 2026)
\\
 3D semantic scene understanding remains a long-standing challenge in the 3D
computer vision community. One of the key issues pertains to limited real-world
annotated data to facilitate generalizable models. The common practice to
tackle this issue is to simulate new data. Although synthetic datasets offer
scalability and perfect labels, their designer-crafted scenes fail to capture
real-world complexity and sensor noise, resulting in a synthetic-to-real domain
gap. Moreover, no benchmark provides synchronized real and simulated point
clouds for segmentation-oriented domain shift analysis. We introduce TrueCity,
the first urban semantic segmentation benchmark with cm-accurate annotated
real-world point clouds, semantic 3D city models, and annotated simulated point
clouds representing the same city. TrueCity proposes segmentation classes
aligned with international 3D city modeling standards, enabling consistent
evaluation of synthetic-to-real gap. Our extensive experiments on common
baselines quantify domain shift and highlight strategies for exploiting
synthetic data to enhance real-world 3D scene understanding. We are convinced
that the TrueCity dataset will foster further development of sim-to-real gap
quantification and enable generalizable data-driven models. The data, code, and
3D models are available online: https://tum-gis.github.io/TrueCity/
\\ ( https://arxiv.org/abs/2511.07007 ,  9072kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07009
Date: Mon, 10 Nov 2025 11:58:34 GMT   (657kb)

Title: Performance Decay in Deepfake Detection: The Limitations of Training on
 Outdated Data
Authors: Jack Richings, Margaux Leblanc, Ian Groves, Victoria Nockles
Categories: cs.CV
MSC-class: 68T07, 68T45
\\
 The continually advancing quality of deepfake technology exacerbates the
threats of disinformation, fraud, and harassment by making
maliciously-generated synthetic content increasingly difficult to distinguish
from reality. We introduce a simple yet effective two-stage detection method
that achieves an AUROC of over 99.8% on contemporary deepfakes. However, this
high performance is short-lived. We show that models trained on this data
suffer a recall drop of over 30% when evaluated on deepfakes created with
generation techniques from just six months later, demonstrating significant
decay as threats evolve. Our analysis reveals two key insights for robust
detection. Firstly, continued performance requires the ongoing curation of
large, diverse datasets. Second, predictive power comes primarily from static,
frame-level artifacts, not temporal inconsistencies. The future of effective
deepfake detection therefore depends on rapid data collection and the
development of advanced frame-level feature detectors.
\\ ( https://arxiv.org/abs/2511.07009 ,  657kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07029
Date: Mon, 10 Nov 2025 12:24:35 GMT   (683kb)

Title: Certified L2-Norm Robustness of 3D Point Cloud Recognition in the
 Frequency Domain
Authors: Liang Zhou, Qiming Wang, Tianze Chen
Categories: cs.CV
Comments: Accepted by AAAI26
\\
 3D point cloud classification is a fundamental task in safety-critical
applications such as autonomous driving, robotics, and augmented reality.
However, recent studies reveal that point cloud classifiers are vulnerable to
structured adversarial perturbations and geometric corruptions, posing risks to
their deployment in safety-critical scenarios. Existing certified defenses
limit point-wise perturbations but overlook subtle geometric distortions that
preserve individual points yet alter the overall structure, potentially leading
to misclassification. In this work, we propose FreqCert, a novel certification
framework that departs from conventional spatial domain defenses by shifting
robustness analysis to the frequency domain, enabling structured certification
against global L2-bounded perturbations. FreqCert first transforms the input
point cloud via the graph Fourier transform (GFT), then applies structured
frequency-aware subsampling to generate multiple sub-point clouds. Each
sub-cloud is independently classified by a standard model, and the final
prediction is obtained through majority voting, where sub-clouds are
constructed based on spectral similarity rather than spatial proximity, making
the partitioning more stable under L2 perturbations and better aligned with the
object's intrinsic structure. We derive a closed-form lower bound on the
certified L2 robustness radius and prove its tightness under minimal and
interpretable assumptions, establishing a theoretical foundation for frequency
domain certification. Extensive experiments on the ModelNet40 and ScanObjectNN
datasets demonstrate that FreqCert consistently achieves higher certified
accuracy and empirical accuracy under strong perturbations. Our results suggest
that spectral representations provide an effective pathway toward certifiable
robustness in 3D point cloud recognition.
\\ ( https://arxiv.org/abs/2511.07029 ,  683kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07040
Date: Mon, 10 Nov 2025 12:37:00 GMT   (2590kb)

Title: 3D-ANC: Adaptive Neural Collapse for Robust 3D Point Cloud Recognition
Authors: Yuanmin Huang, Wenxuan Li, Mi Zhang, Xiaohan Zhang, Xiaoyu You, Min
 Yang
Categories: cs.CV cs.CR
Comments: AAAI 2026
\\
 Deep neural networks have recently achieved notable progress in 3D point
cloud recognition, yet their vulnerability to adversarial perturbations poses
critical security challenges in practical deployments. Conventional defense
mechanisms struggle to address the evolving landscape of multifaceted attack
patterns. Through systematic analysis of existing defenses, we identify that
their unsatisfactory performance primarily originates from an entangled feature
space, where adversarial attacks can be performed easily. To this end, we
present 3D-ANC, a novel approach that capitalizes on the Neural Collapse (NC)
mechanism to orchestrate discriminative feature learning. In particular, NC
depicts where last-layer features and classifier weights jointly evolve into a
simplex equiangular tight frame (ETF) arrangement, establishing maximally
separable class prototypes. However, leveraging this advantage in 3D
recognition confronts two substantial challenges: (1) prevalent class imbalance
in point cloud datasets, and (2) complex geometric similarities between object
categories. To tackle these obstacles, our solution combines an ETF-aligned
classification module with an adaptive training framework consisting of
representation-balanced learning (RBL) and dynamic feature direction loss
(FDL). 3D-ANC seamlessly empowers existing models to develop disentangled
feature spaces despite the complexity in 3D data distribution. Comprehensive
evaluations state that 3D-ANC significantly improves the robustness of models
with various structures on two datasets. For instance, DGCNN's classification
accuracy is elevated from 27.2% to 80.9% on ModelNet40 -- a 53.7% absolute gain
that surpasses leading baselines by 34.0%.
\\ ( https://arxiv.org/abs/2511.07040 ,  2590kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07049
Date: Mon, 10 Nov 2025 12:42:32 GMT   (11989kb)

Title: From Pretrain to Pain: Adversarial Vulnerability of Video Foundation
 Models Without Task Knowledge
Authors: Hui Lu, Yi Yu, Song Xia, Yiming Yang, Deepu Rajan, Boon Poh Ng, Alex
 Kot, Xudong Jiang
Categories: cs.CV cs.CR
Comments: AAAI 2026 (Oral presentation)
\\
 Large-scale Video Foundation Models (VFMs) has significantly advanced various
video-related tasks, either through task-specific models or Multi-modal Large
Language Models (MLLMs). However, the open accessibility of VFMs also
introduces critical security risks, as adversaries can exploit full knowledge
of the VFMs to launch potent attacks. This paper investigates a novel and
practical adversarial threat scenario: attacking downstream models or MLLMs
fine-tuned from open-source VFMs, without requiring access to the victim task,
training data, model query, and architecture. In contrast to conventional
transfer-based attacks that rely on task-aligned surrogate models, we
demonstrate that adversarial vulnerabilities can be exploited directly from the
VFMs. To this end, we propose the Transferable Video Attack (TVA), a
temporal-aware adversarial attack method that leverages the temporal
representation dynamics of VFMs to craft effective perturbations. TVA
integrates a bidirectional contrastive learning mechanism to maximize the
discrepancy between the clean and adversarial features, and introduces a
temporal consistency loss that exploits motion cues to enhance the sequential
impact of perturbations. TVA avoids the need to train expensive surrogate
models or access to domain-specific data, thereby offering a more practical and
efficient attack strategy. Extensive experiments across 24 video-related tasks
demonstrate the efficacy of TVA against downstream models and MLLMs, revealing
a previously underexplored security vulnerability in the deployment of video
models.
\\ ( https://arxiv.org/abs/2511.07049 ,  11989kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07051
Date: Mon, 10 Nov 2025 12:45:52 GMT   (2686kb)

Title: Improving Deepfake Detection with Reinforcement Learning-Based Adaptive
 Data Augmentation
Authors: Yuxuan Zhou, Tao Yu, Wen Huang, Yuheng Zhang, Tao Dai, Shu-Tao Xia
Categories: cs.CV cs.CR
\\
 The generalization capability of deepfake detectors is critical for
real-world use. Data augmentation via synthetic fake face generation
effectively enhances generalization, yet current SoTA methods rely on fixed
strategies-raising a key question: Is a single static augmentation sufficient,
or does the diversity of forgery features demand dynamic approaches? We argue
existing methods overlook the evolving complexity of real-world forgeries
(e.g., facial warping, expression manipulation), which fixed policies cannot
fully simulate. To address this, we propose CRDA (Curriculum
Reinforcement-Learning Data Augmentation), a novel framework guiding detectors
to progressively master multi-domain forgery features from simple to complex.
CRDA synthesizes augmented samples via a configurable pool of forgery
operations and dynamically generates adversarial samples tailored to the
detector's current learning state. Central to our approach is integrating
reinforcement learning (RL) and causal inference. An RL agent dynamically
selects augmentation actions based on detector performance to efficiently
explore the vast augmentation space, adapting to increasingly challenging
forgeries. Simultaneously, the agent introduces action space variations to
generate heterogeneous forgery patterns, guided by causal inference to mitigate
spurious correlations-suppressing task-irrelevant biases and focusing on
causally invariant features. This integration ensures robust generalization by
decoupling synthetic augmentation patterns from the model's learned
representations. Extensive experiments show our method significantly improves
detector generalizability, outperforming SOTA methods across multiple
cross-domain datasets.
\\ ( https://arxiv.org/abs/2511.07051 ,  2686kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07067
Date: Mon, 10 Nov 2025 13:03:58 GMT   (2940kb)

Title: RaLD: Generating High-Resolution 3D Radar Point Clouds with Latent
 Diffusion
Authors: Ruijie Zhang, Bixin Zeng, Shengpeng Wang, Fuhui Zhou, Wei Wang
Categories: cs.CV
\\
 Millimeter-wave radar offers a promising sensing modality for autonomous
systems thanks to its robustness in adverse conditions and low cost. However,
its utility is significantly limited by the sparsity and low resolution of
radar point clouds, which poses challenges for tasks requiring dense and
accurate 3D perception. Despite that recent efforts have shown great potential
by exploring generative approaches to address this issue, they often rely on
dense voxel representations that are inefficient and struggle to preserve
structural detail. To fill this gap, we make the key observation that latent
diffusion models (LDMs), though successful in other modalities, have not been
effectively leveraged for radar-based 3D generation due to a lack of compatible
representations and conditioning strategies. We introduce RaLD, a framework
that bridges this gap by integrating scene-level frustum-based LiDAR
autoencoding, order-invariant latent representations, and direct radar spectrum
conditioning. These insights lead to a more compact and expressive generation
process. Experiments show that RaLD produces dense and accurate 3D point clouds
from raw radar spectrums, offering a promising solution for robust perception
in challenging environments.
\\ ( https://arxiv.org/abs/2511.07067 ,  2940kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07068
Date: Mon, 10 Nov 2025 13:04:01 GMT   (2372kb)

Title: ClusterMine: Robust Label-Free Visual Out-Of-Distribution Detection via
 Concept Mining from Text Corpora
Authors: Nikolas Adaloglou, Diana Petrusheva, Mohamed Asker, Felix Michels and
 Markus Kollmann
Categories: cs.CV cs.LG
Comments: Accepted in WACV 2026. Code in
 https://github.com/HHU-MMBS/clustermine_wacv_official 9 Tables, 11 Figures
\\
 Large-scale visual out-of-distribution (OOD) detection has witnessed
remarkable progress by leveraging vision-language models such as CLIP. However,
a significant limitation of current methods is their reliance on a pre-defined
set of in-distribution (ID) ground-truth label names (positives). These fixed
label names can be unavailable, unreliable at scale, or become less relevant
due to in-distribution shifts after deployment. Towards truly unsupervised OOD
detection, we utilize widely available text corpora for positive label mining,
bypassing the need for positives. In this paper, we utilize widely available
text corpora for positive label mining under a general concept mining paradigm.
Within this framework, we propose ClusterMine, a novel positive label mining
method. ClusterMine is the first method to achieve state-of-the-art OOD
detection performance without access to positive labels. It extracts positive
concepts from a large text corpus by combining visual-only sample consistency
(via clustering) and zero-shot image-text consistency. Our experimental study
reveals that ClusterMine is scalable across a plethora of CLIP models and
achieves state-of-the-art robustness to covariate in-distribution shifts. The
code is available at https://github.com/HHU-MMBS/clustermine_wacv_official.
\\ ( https://arxiv.org/abs/2511.07068 ,  2372kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07078
Date: Mon, 10 Nov 2025 13:08:15 GMT   (7695kb)

Title: LeCoT: revisiting network architecture for two-view correspondence
 pruning
Authors: Luanyuan Dai, Xiaoyu Du, Jinhui Tang
Categories: cs.CV
Comments: Just accepted at SCIENCE CHINA Information Sciences
DOI: 10.1007/s11432-024-4555-x
\\
 Two-view correspondence pruning aims to accurately remove incorrect
correspondences (outliers) from initial ones and is widely applied to various
computer vision tasks. Current popular strategies adopt multilayer perceptron
(MLP) as the backbone, supplemented by additional modules to enhance the
network ability to handle context information, which is a known limitation of
MLPs. In contrast, we introduce a novel perspective for capturing
correspondence context information without extra design modules. To this end,
we design a two-view correspondence pruning network called LeCoT, which can
naturally leverage global context information at different stages.
Specifically, the core design of LeCoT is the Spatial-Channel Fusion
Transformer block, a newly proposed component that efficiently utilizes both
spatial and channel global context information among sparse correspondences. In
addition, we integrate the proposed prediction block that utilizes
correspondence features from intermediate stages to generate a probability set,
which acts as guiding information for subsequent learning phases, allowing the
network to more effectively capture robust global context information. Notably,
this prediction block progressively refines the probability set, thereby
mitigating the issue of information loss that is common in the traditional one.
Extensive experiments prove that the proposed LeCoT outperforms
state-of-the-art methods in correspondence pruning, relative pose estimation,
homography estimation, visual localization, and $3$D~reconstruction tasks. The
code is provided in
https://github.com/Dailuanyuan2024/LeCoT-Revisiting-Network-Architecture-for-Two-View-Correspondence-Pruning.
\\ ( https://arxiv.org/abs/2511.07078 ,  7695kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07084
Date: Mon, 10 Nov 2025 13:18:36 GMT   (3457kb)

Title: Pandar128 dataset for lane line detection
Authors: Filip Ber\'anek, V\'aclav Divi\v{s}, Ivan Gruber
Categories: cs.CV cs.AI
\\
 We present Pandar128, the largest public dataset for lane line detection
using a 128-beam LiDAR. It contains over 52,000 camera frames and 34,000 LiDAR
scans, captured in diverse real-world conditions in Germany. The dataset
includes full sensor calibration (intrinsics, extrinsics) and synchronized
odometry, supporting tasks such as projection, fusion, and temporal modeling.
 To complement the dataset, we also introduce SimpleLidarLane, a light-weight
baseline method for lane line reconstruction that combines BEV segmentation,
clustering, and polyline fitting. Despite its simplicity, our method achieves
strong performance under challenging various conditions (e.g., rain, sparse
returns), showing that modular pipelines paired with high-quality data and
principled evaluation can compete with more complex approaches.
 Furthermore, to address the lack of standardized evaluation, we propose a
novel polyline-based metric - Interpolation-Aware Matching F1 (IAM-F1) - that
employs interpolation-aware lateral matching in BEV space.
 All data and code are publicly released to support reproducibility in
LiDAR-based lane detection.
\\ ( https://arxiv.org/abs/2511.07084 ,  3457kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07091
Date: Mon, 10 Nov 2025 13:27:05 GMT   (5682kb)

Title: How Bias Binds: Measuring Hidden Associations for Bias Control in
 Text-to-Image Compositions
Authors: Jeng-Lin Li, Ming-Ching Chang, Wei-Chao Chen
Categories: cs.CV cs.AI
Comments: Accepted for publication at the Alignment Track of The 40th Annual
 AAAI Conference on Artificial Intelligence (AAAI 2026)
\\
 Text-to-image generative models often exhibit bias related to sensitive
attributes. However, current research tends to focus narrowly on single-object
prompts with limited contextual diversity. In reality, each object or attribute
within a prompt can contribute to bias. For example, the prompt "an assistant
wearing a pink hat" may reflect female-inclined biases associated with a pink
hat. The neglected joint effects of the semantic binding in the prompts cause
significant failures in current debiasing approaches. This work initiates a
preliminary investigation on how bias manifests under semantic binding, where
contextual associations between objects and attributes influence generative
outcomes. We demonstrate that the underlying bias distribution can be amplified
based on these associations. Therefore, we introduce a bias adherence score
that quantifies how specific object-attribute bindings activate bias. To delve
deeper, we develop a training-free context-bias control framework to explore
how token decoupling can facilitate the debiasing of semantic bindings. This
framework achieves over 10% debiasing improvement in compositional generation
tasks. Our analysis of bias scores across various attribute-object bindings and
token decorrelation highlights a fundamental challenge: reducing bias without
disrupting essential semantic relationships. These findings expose critical
limitations in current debiasing approaches when applied to semantically bound
contexts, underscoring the need to reassess prevailing bias mitigation
strategies.
\\ ( https://arxiv.org/abs/2511.07091 ,  5682kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07103
Date: Mon, 10 Nov 2025 13:44:16 GMT   (14887kb)

Title: GEWDiff: Geometric Enhanced Wavelet-based Diffusion Model for
 Hyperspectral Image Super-resolution
Authors: Sirui Wang, Jiang He, Nat\`alia Blasco Andreo, Xiao Xiang Zhu
Categories: cs.CV cs.AI
Comments: This manuscript has been accepted for publication in AAAI 2026
\\
 Improving the quality of hyperspectral images (HSIs), such as through
super-resolution, is a crucial research area. However, generative modeling for
HSIs presents several challenges. Due to their high spectral dimensionality,
HSIs are too memory-intensive for direct input into conventional diffusion
models. Furthermore, general generative models lack an understanding of the
topological and geometric structures of ground objects in remote sensing
imagery. In addition, most diffusion models optimize loss functions at the
noise level, leading to a non-intuitive convergence behavior and suboptimal
generation quality for complex data. To address these challenges, we propose a
Geometric Enhanced Wavelet-based Diffusion Model (GEWDiff), a novel framework
for reconstructing hyperspectral images at 4-times super-resolution. A
wavelet-based encoder-decoder is introduced that efficiently compresses HSIs
into a latent space while preserving spectral-spatial information. To avoid
distortion during generation, we incorporate a geometry-enhanced diffusion
process that preserves the geometric features. Furthermore, a multi-level loss
function was designed to guide the diffusion process, promoting stable
convergence and improved reconstruction fidelity. Our model demonstrated
state-of-the-art results across multiple dimensions, including fidelity,
spectral accuracy, visual realism, and clarity.
\\ ( https://arxiv.org/abs/2511.07103 ,  14887kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07106
Date: Mon, 10 Nov 2025 13:49:59 GMT   (2087kb)

Title: HENet++: Hybrid Encoding and Multi-task Learning for 3D Perception and
 End-to-end Autonomous Driving
Authors: Zhongyu Xia, Zhiwei Lin, Yongtao Wang, Ming-Hsuan Yang
Categories: cs.CV
Comments: Preliminary version, 19 pages
\\
 Three-dimensional feature extraction is a critical component of autonomous
driving systems, where perception tasks such as 3D object detection,
bird's-eye-view (BEV) semantic segmentation, and occupancy prediction serve as
important constraints on 3D features. While large image encoders,
high-resolution images, and long-term temporal inputs can significantly enhance
feature quality and deliver remarkable performance gains, these techniques are
often incompatible in both training and inference due to computational resource
constraints. Moreover, different tasks favor distinct feature representations,
making it difficult for a single model to perform end-to-end inference across
multiple tasks while maintaining accuracy comparable to that of single-task
models. To alleviate these issues, we present the HENet and HENet++ framework
for multi-task 3D perception and end-to-end autonomous driving. Specifically,
we propose a hybrid image encoding network that uses a large image encoder for
short-term frames and a small one for long-term frames. Furthermore, our
framework simultaneously extracts both dense and sparse features, providing
more suitable representations for different tasks, reducing cumulative errors,
and delivering more comprehensive information to the planning module. The
proposed architecture maintains compatibility with various existing 3D feature
extraction methods and supports multimodal inputs. HENet++ achieves
state-of-the-art end-to-end multi-task 3D perception results on the nuScenes
benchmark, while also attaining the lowest collision rate on the nuScenes
end-to-end autonomous driving benchmark.
\\ ( https://arxiv.org/abs/2511.07106 ,  2087kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07122
Date: Mon, 10 Nov 2025 14:10:43 GMT   (5802kb)

Title: Sparse4DGS: 4D Gaussian Splatting for Sparse-Frame Dynamic Scene
 Reconstruction
Authors: Changyue Shi, Chuxiao Yang, Xinyuan Hu, Minghao Chen, Wenwen Pan, Yan
 Yang, Jiajun Ding, Zhou Yu, Jun Yu
Categories: cs.CV
Comments: AAAI 2026
\\
 Dynamic Gaussian Splatting approaches have achieved remarkable performance
for 4D scene reconstruction. However, these approaches rely on dense-frame
video sequences for photorealistic reconstruction. In real-world scenarios, due
to equipment constraints, sometimes only sparse frames are accessible. In this
paper, we propose Sparse4DGS, the first method for sparse-frame dynamic scene
reconstruction. We observe that dynamic reconstruction methods fail in both
canonical and deformed spaces under sparse-frame settings, especially in areas
with high texture richness. Sparse4DGS tackles this challenge by focusing on
texture-rich areas. For the deformation network, we propose Texture-Aware
Deformation Regularization, which introduces a texture-based depth alignment
loss to regulate Gaussian deformation. For the canonical Gaussian field, we
introduce Texture-Aware Canonical Optimization, which incorporates
texture-based noise into the gradient descent process of canonical Gaussians.
Extensive experiments show that when taking sparse frames as inputs, our method
outperforms existing dynamic or few-shot techniques on NeRF-Synthetic,
HyperNeRF, NeRF-DS, and our iPhone-4D datasets.
\\ ( https://arxiv.org/abs/2511.07122 ,  5802kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07137
Date: Mon, 10 Nov 2025 14:18:27 GMT   (12328kb)

Title: MPJudge: Towards Perceptual Assessment of Music-Induced Paintings
Authors: Shiqi Jiang, Tianyi Liang, Changbo Wang, Chenhui Li
Categories: cs.CV
Journal-ref: AAAI 2026
\\
 Music induced painting is a unique artistic practice, where visual artworks
are created under the influence of music. Evaluating whether a painting
faithfully reflects the music that inspired it poses a challenging perceptual
assessment task. Existing methods primarily rely on emotion recognition models
to assess the similarity between music and painting, but such models introduce
considerable noise and overlook broader perceptual cues beyond emotion. To
address these limitations, we propose a novel framework for music induced
painting assessment that directly models perceptual coherence between music and
visual art. We introduce MPD, the first large scale dataset of music painting
pairs annotated by domain experts based on perceptual coherence. To better
handle ambiguous cases, we further collect pairwise preference annotations.
Building on this dataset, we present MPJudge, a model that integrates music
features into a visual encoder via a modulation based fusion mechanism. To
effectively learn from ambiguous cases, we adopt Direct Preference Optimization
for training. Extensive experiments demonstrate that our method outperforms
existing approaches. Qualitative results further show that our model more
accurately identifies music relevant regions in paintings.
\\ ( https://arxiv.org/abs/2511.07137 ,  12328kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07142
Date: Mon, 10 Nov 2025 14:23:55 GMT   (25784kb)

Title: ProcGen3D: Learning Neural Procedural Graph Representations for
 Image-to-3D Reconstruction
Authors: Xinyi Zhang, Daoyi Gao, Naiqi Li, Angela Dai
Categories: cs.CV
Comments: Project Page: https://xzhang-t.github.io/project/ProcGen3D/
\\
 We introduce ProcGen3D, a new approach for 3D content creation by generating
procedural graph abstractions of 3D objects, which can then be decoded into
rich, complex 3D assets. Inspired by the prevalent use of procedural generators
in production 3D applications, we propose a sequentialized, graph-based
procedural graph representation for 3D assets. We use this to learn to
approximate the landscape of a procedural generator for image-based 3D
reconstruction. We employ edge-based tokenization to encode the procedural
graphs, and train a transformer prior to predict the next token conditioned on
an input RGB image. Crucially, to enable better alignment of our generated
outputs to an input image, we incorporate Monte Carlo Tree Search (MCTS) guided
sampling into our generation process, steering output procedural graphs towards
more image-faithful reconstructions. Our approach is applicable across a
variety of objects that can be synthesized with procedural generators.
Extensive experiments on cacti, trees, and bridges show that our neural
procedural graph generation outperforms both state-of-the-art generative 3D
methods and domain-specific modeling techniques. Furthermore, this enables
improved generalization on real-world input images, despite training only on
synthetic data.
\\ ( https://arxiv.org/abs/2511.07142 ,  25784kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07171
Date: Mon, 10 Nov 2025 15:01:51 GMT   (662kb)

Title: Federated Learning for Video Violence Detection: Complementary Roles of
 Lightweight CNNs and Vision-Language Models for Energy-Efficient Use
Authors: S\'ebastien Thuau, Siba Haidar, Rachid Chelouah
Categories: cs.CV cs.AI cs.LG
Comments: 5 pages, 3 figures, ICTAI 2025
\\
 Deep learning-based video surveillance increasingly demands
privacy-preserving architectures with low computational and environmental
overhead. Federated learning preserves privacy but deploying large
vision-language models (VLMs) introduces major energy and sustainability
challenges. We compare three strategies for federated violence detection under
realistic non-IID splits on the RWF-2000 and RLVS datasets: zero-shot inference
with pretrained VLMs, LoRA-based fine-tuning of LLaVA-NeXT-Video-7B, and
personalized federated learning of a 65.8M-parameter 3D CNN. All methods exceed
90% accuracy in binary violence detection. The 3D CNN achieves superior
calibration (ROC AUC 92.59%) at roughly half the energy cost (240 Wh vs. 570
Wh) of federated LoRA, while VLMs provide richer multimodal reasoning.
Hierarchical category grouping (based on semantic similarity and class
exclusion) boosts VLM multiclass accuracy from 65.31% to 81% on the UCF-Crime
dataset. To our knowledge, this is the first comparative simulation study of
LoRA-tuned VLMs and personalized CNNs for federated violence detection, with
explicit energy and CO2e quantification. Our results inform hybrid deployment
strategies that default to efficient CNNs for routine inference and selectively
engage VLMs for complex contextual reasoning.
\\ ( https://arxiv.org/abs/2511.07171 ,  662kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07192
Date: Mon, 10 Nov 2025 15:22:28 GMT   (2749kb)

Title: LiteUpdate: A Lightweight Framework for Updating AI-Generated Image
 Detectors
Authors: Jiajie Lu, Zhenkan Fu, Na Zhao, Long Xing, Kejiang Chen, Weiming
 Zhang, Nenghai Yu
Categories: cs.CV cs.CR
\\
 The rapid progress of generative AI has led to the emergence of new
generative models, while existing detection methods struggle to keep pace,
resulting in significant degradation in the detection performance. This
highlights the urgent need for continuously updating AI-generated image
detectors to adapt to new generators. To overcome low efficiency and
catastrophic forgetting in detector updates, we propose LiteUpdate, a
lightweight framework for updating AI-generated image detectors. LiteUpdate
employs a representative sample selection module that leverages image
confidence and gradient-based discriminative features to precisely select
boundary samples. This approach improves learning and detection accuracy on new
distributions with limited generated images, significantly enhancing detector
update efficiency. Additionally, LiteUpdate incorporates a model merging module
that fuses weights from multiple fine-tuning trajectories, including
pre-trained, representative, and random updates. This balances the adaptability
to new generators and mitigates the catastrophic forgetting of prior knowledge.
Experiments demonstrate that LiteUpdate substantially boosts detection
performance in various detectors. Specifically, on AIDE, the average detection
accuracy on Midjourney improved from 87.63% to 93.03%, a 6.16% relative
increase.
\\ ( https://arxiv.org/abs/2511.07192 ,  2749kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07199
Date: Mon, 10 Nov 2025 15:28:02 GMT   (5105kb)

Title: Automated Estimation of Anatomical Risk Metrics for Endoscopic Sinus
 Surgery Using Deep Learning
Authors: Konrad Reuter, Lennart Thaysen, Bilkay Doruk, Sarah Latus, Brigitte
 Holst, Benjamin Becker, Dennis Eggert, Christian Betz, Anna-Sophie Hoffmann,
 Alexander Schlaefer
Categories: cs.CV
Comments: Accepted to SPIE Medical Imaging conference 2026
\\
 Endoscopic sinus surgery requires careful preoperative assessment of the
skull base anatomy to minimize risks such as cerebrospinal fluid leakage.
Anatomical risk scores like the Keros, Gera and Thailand-Malaysia-Singapore
score offer a standardized approach but require time-consuming manual
measurements on coronal CT or CBCT scans. We propose an automated deep learning
pipeline that estimates these risk scores by localizing key anatomical
landmarks via heatmap regression. We compare a direct approach to a specialized
global-to-local learning strategy and find mean absolute errors on the relevant
anatomical measurements of 0.506mm for the Keros, 4.516{\deg} for the Gera and
0.802mm / 0.777mm for the TMS classification.
\\ ( https://arxiv.org/abs/2511.07199 ,  5105kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07206
Date: Mon, 10 Nov 2025 15:33:02 GMT   (21749kb)

Title: Geometric implicit neural representations for signed distance functions
Authors: Luiz Schirmer, Tiago Novello, Vin\'icius da Silva, Guilherme
 Schardong, Daniel Perazzo, H\'elio Lopes, Nuno Gon\c{c}alves, Luiz Velho
Categories: cs.CV cs.CG cs.GR
DOI: 10.1016/j.cag.2024.104085
\\
 \textit{Implicit neural representations} (INRs) have emerged as a promising
framework for representing signals in low-dimensional spaces. This survey
reviews the existing literature on the specialized INR problem of approximating
\textit{signed distance functions} (SDFs) for surface scenes, using either
oriented point clouds or a set of posed images. We refer to neural SDFs that
incorporate differential geometry tools, such as normals and curvatures, in
their loss functions as \textit{geometric} INRs. The key idea behind this 3D
reconstruction approach is to include additional \textit{regularization} terms
in the loss function, ensuring that the INR satisfies certain global properties
that the function should hold -- such as having unit gradient in the case of
SDFs. We explore key methodological components, including the definition of
INR, the construction of geometric loss functions, and sampling schemes from a
differential geometry perspective. Our review highlights the significant
advancements enabled by geometric INRs in surface reconstruction from oriented
point clouds and posed images.
\\ ( https://arxiv.org/abs/2511.07206 ,  21749kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07210
Date: Mon, 10 Nov 2025 15:37:44 GMT   (6081kb)

Title: Breaking the Stealth-Potency Trade-off in Clean-Image Backdoors with
 Generative Trigger Optimization
Authors: Binyan Xu, Fan Yang, Di Tang, Xilin Dai, Kehuan Zhang
Categories: cs.CV cs.CR cs.LG
Comments: 19 pages, 22 figures, 15 tables. To appear in AAAI '26 (Oral). This
 paper extends the AAAI-2026 version by including the Appendix
MSC-class: 68T07
ACM-class: I.2.6
\\
 Clean-image backdoor attacks, which use only label manipulation in training
datasets to compromise deep neural networks, pose a significant threat to
security-critical applications. A critical flaw in existing methods is that the
poison rate required for a successful attack induces a proportional, and thus
noticeable, drop in Clean Accuracy (CA), undermining their stealthiness. This
paper presents a new paradigm for clean-image attacks that minimizes this
accuracy degradation by optimizing the trigger itself. We introduce Generative
Clean-Image Backdoors (GCB), a framework that uses a conditional InfoGAN to
identify naturally occurring image features that can serve as potent and
stealthy triggers. By ensuring these triggers are easily separable from benign
task-related features, GCB enables a victim model to learn the backdoor from an
extremely small set of poisoned examples, resulting in a CA drop of less than
1%. Our experiments demonstrate GCB's remarkable versatility, successfully
adapting to six datasets, five architectures, and four tasks, including the
first demonstration of clean-image backdoors in regression and segmentation.
GCB also exhibits resilience against most of the existing backdoor defenses.
\\ ( https://arxiv.org/abs/2511.07210 ,  6081kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07222
Date: Mon, 10 Nov 2025 15:44:48 GMT   (7491kb)

Title: Omni-View: Unlocking How Generation Facilitates Understanding in Unified
 3D Model based on Multiview images
Authors: JiaKui Hu, Shanshan Zhao, Qing-Guo Chen, Xuerui Qiu, Jialun Liu, Zhao
 Xu, Weihua Luo, Kaifu Zhang, Yanye Lu
Categories: cs.CV
Comments: Under review
\\
 This paper presents Omni-View, which extends the unified multimodal
understanding and generation to 3D scenes based on multiview images, exploring
the principle that "generation facilitates understanding". Consisting of
understanding model, texture module, and geometry module, Omni-View jointly
models scene understanding, novel view synthesis, and geometry estimation,
enabling synergistic interaction between 3D scene understanding and generation
tasks. By design, it leverages the spatiotemporal modeling capabilities of its
texture module responsible for appearance synthesis, alongside the explicit
geometric constraints provided by its dedicated geometry module, thereby
enriching the model's holistic understanding of 3D scenes. Trained with a
two-stage strategy, Omni-View achieves a state-of-the-art score of 55.4 on the
VSI-Bench benchmark, outperforming existing specialized 3D understanding
models, while simultaneously delivering strong performance in both novel view
synthesis and 3D scene generation.
\\ ( https://arxiv.org/abs/2511.07222 ,  7491kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07231
Date: Mon, 10 Nov 2025 15:48:04 GMT   (7350kb)

Title: Mapping Reduced Accessibility to WASH Facilities in Rohingya Refugee
 Camps with Sub-Meter Imagery
Authors: Kyeongjin Ahn and YongHun Suh and Sungwon Han and Jeasurk Yang and
 Hannes Taubenb\"ock and Meeyoung Cha
Categories: cs.CV
Comments: 23 pages, 13 figures, 2 tables
\\
 Access to Water, Sanitation, and Hygiene (WASH) services remains a major
public health concern in refugee camps. This study introduces a remote
sensing-driven framework to quantify WASH accessibility-specifically to water
pumps, latrines, and bathing cubicles-in the Rohingya camps of Cox's Bazar, one
of the world's most densely populated displacement settings. Detecting refugee
shelters in such emergent camps presents substantial challenges, primarily due
to their dense spatial configuration and irregular geometric patterns. Using
sub-meter satellite images, we develop a semi-supervised segmentation framework
that achieves an F1-score of 76.4% in detecting individual refugee shelters.
Applying the framework across multi-year data reveals declining WASH
accessibility, driven by rapid refugee population growth and reduced facility
availability, rising from 25 people per facility in 2022 to 29.4 in 2025.
Gender-disaggregated analysis further shows that women and girls experience
reduced accessibility, in scenarios with inadequate safety-related segregation
in WASH facilities. These findings suggest the importance of demand-responsive
allocation strategies that can identify areas with under-served
populations-such as women and girls-and ensure that limited infrastructure
serves the greatest number of people in settings with fixed or shrinking
budgets. We also discuss the value of high-resolution remote sensing and
machine learning to detect inequality and inform equitable resource planning in
complex humanitarian environments.
\\ ( https://arxiv.org/abs/2511.07231 ,  7350kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07233
Date: Mon, 10 Nov 2025 15:48:50 GMT   (21697kb)

Title: Noise & pattern: identity-anchored Tikhonov regularization for robust
 structural anomaly detection
Authors: Alexander Bauer and Klaus-Robert M\"uller
Categories: cs.CV cs.LG
\\
 Anomaly detection plays a pivotal role in automated industrial inspection,
aiming to identify subtle or rare defects in otherwise uniform visual patterns.
As collecting representative examples of all possible anomalies is infeasible,
we tackle structural anomaly detection using a self-supervised autoencoder that
learns to repair corrupted inputs. To this end, we introduce a corruption model
that injects artificial disruptions into training images to mimic structural
defects. While reminiscent of denoising autoencoders, our approach differs in
two key aspects. First, instead of unstructured i.i.d.\ noise, we apply
structured, spatially coherent perturbations that make the task a hybrid of
segmentation and inpainting. Second, and counterintuitively, we add and
preserve Gaussian noise on top of the occlusions, which acts as a Tikhonov
regularizer anchoring the Jacobian of the reconstruction function toward
identity. This identity-anchored regularization stabilizes reconstruction and
further improves both detection and segmentation accuracy. On the MVTec AD
benchmark, our method achieves state-of-the-art results (I/P-AUROC: 99.9/99.4),
supporting our theoretical framework and demonstrating its practical relevance
for automatic inspection.
\\ ( https://arxiv.org/abs/2511.07233 ,  21697kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07238
Date: Mon, 10 Nov 2025 15:54:23 GMT   (3281kb)

Title: Leveraging Text-Driven Semantic Variation for Robust OOD Segmentation
Authors: Seungheon Song and Jaekoo Lee
Categories: cs.CV cs.AI
Comments: 8 pages, 5 figure references, 2025 IEEE/RSJ International Conference
 on Intelligent Robots and Systems (IROS) submission
\\
 In autonomous driving and robotics, ensuring road safety and reliable
decision-making critically depends on out-of-distribution (OOD) segmentation.
While numerous methods have been proposed to detect anomalous objects on the
road, leveraging the vision-language space-which provides rich linguistic
knowledge-remains an underexplored field. We hypothesize that incorporating
these linguistic cues can be especially beneficial in the complex contexts
found in real-world autonomous driving scenarios.
 To this end, we present a novel approach that trains a Text-Driven OOD
Segmentation model to learn a semantically diverse set of objects in the
vision-language space. Concretely, our approach combines a vision-language
model's encoder with a transformer decoder, employs Distance-Based OOD prompts
located at varying semantic distances from in-distribution (ID) classes, and
utilizes OOD Semantic Augmentation for OOD representations. By aligning visual
and textual information, our approach effectively generalizes to unseen objects
and provides robust OOD segmentation in diverse driving environments.
 We conduct extensive experiments on publicly available OOD segmentation
datasets such as Fishyscapes, Segment-Me-If-You-Can, and Road Anomaly datasets,
demonstrating that our approach achieves state-of-the-art performance across
both pixel-level and object-level evaluations. This result underscores the
potential of vision-language-based OOD segmentation to bolster the safety and
reliability of future autonomous driving systems.
\\ ( https://arxiv.org/abs/2511.07238 ,  3281kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07241
Date: Mon, 10 Nov 2025 15:57:03 GMT   (1365kb)

Title: 4DSTR: Advancing Generative 4D Gaussians with Spatial-Temporal
 Rectification for High-Quality and Consistent 4D Generation
Authors: Mengmeng Liu, Jiuming Liu, Yunpeng Zhang, Jiangtao Li, Michael Ying
 Yang, Francesco Nex, Hao Cheng
Categories: cs.CV
Comments: Accepted by AAAI 2026.The first two authors contributed equally
\\
 Remarkable advances in recent 2D image and 3D shape generation have induced a
significant focus on dynamic 4D content generation. However, previous 4D
generation methods commonly struggle to maintain spatial-temporal consistency
and adapt poorly to rapid temporal variations, due to the lack of effective
spatial-temporal modeling. To address these problems, we propose a novel 4D
generation network called 4DSTR, which modulates generative 4D Gaussian
Splatting with spatial-temporal rectification. Specifically, temporal
correlation across generated 4D sequences is designed to rectify deformable
scales and rotations and guarantee temporal consistency. Furthermore, an
adaptive spatial densification and pruning strategy is proposed to address
significant temporal variations by dynamically adding or deleting Gaussian
points with the awareness of their pre-frame movements. Extensive experiments
demonstrate that our 4DSTR achieves state-of-the-art performance in video-to-4D
generation, excelling in reconstruction quality, spatial-temporal consistency,
and adaptation to rapid temporal movements.
\\ ( https://arxiv.org/abs/2511.07241 ,  1365kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07250
Date: Mon, 10 Nov 2025 16:02:33 GMT   (4276kb)

Title: MVU-Eval: Towards Multi-Video Understanding Evaluation for Multimodal
 LLMs
Authors: Tianhao Peng, Haochen Wang, Yuanxing Zhang, Zekun Wang, Zili Wang, Ge
 Zhang, Jian Yang, Shihao Li, Yanghai Wang, Xintao Wang, Houyi Li, Wei Ji,
 Pengfei Wan, Wenhao Huang, Zhaoxiang Zhang, Jiaheng Liu
Categories: cs.CV cs.AI
Journal-ref: The Thirty-Ninth Annual Conference on Neural Information
 Processing Systems (NeurIPS 2025)
\\
 The advent of Multimodal Large Language Models (MLLMs) has expanded AI
capabilities to visual modalities, yet existing evaluation benchmarks remain
limited to single-video understanding, overlooking the critical need for
multi-video understanding in real-world scenarios (e.g., sports analytics and
autonomous driving). To address this significant gap, we introduce MVU-Eval,
the first comprehensive benchmark for evaluating Multi-Video Understanding for
MLLMs. Specifically, our MVU-Eval mainly assesses eight core competencies
through 1,824 meticulously curated question-answer pairs spanning 4,959 videos
from diverse domains, addressing both fundamental perception tasks and
high-order reasoning tasks. These capabilities are rigorously aligned with
real-world applications such as multi-sensor synthesis in autonomous systems
and cross-angle sports analytics. Through extensive evaluation of
state-of-the-art open-source and closed-source models, we reveal significant
performance discrepancies and limitations in current MLLMs' ability to perform
understanding across multiple videos. The benchmark will be made publicly
available to foster future research.
\\ ( https://arxiv.org/abs/2511.07250 ,  4276kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07278
Date: Mon, 10 Nov 2025 16:25:03 GMT   (11453kb)

Title: StreamKV: Streaming Video Question-Answering with Segment-based KV Cache
 Retrieval and Compression
Authors: Yilong Chen, Xiang Bai, Zhibin Wang, Chengyu Bai, Yuhan Dai, Ming Lu,
 Shanghang Zhang
Categories: cs.CV
\\
 Video Large Language Models (Video-LLMs) have demonstrated significant
potential in the areas of video captioning, search, and summarization. However,
current Video-LLMs still face challenges with long real-world videos. Recent
methods have introduced a retrieval mechanism that retrieves query-relevant KV
caches for question answering, enhancing the efficiency and accuracy of long
real-world videos. However, the compression and retrieval of KV caches are
still not fully explored. In this paper, we propose \textbf{StreamKV}, a
training-free framework that seamlessly equips Video-LLMs with advanced KV
cache retrieval and compression. Compared to previous methods that used uniform
partitioning, StreamKV dynamically partitions video streams into semantic
segments, which better preserves semantic information. For KV cache retrieval,
StreamKV calculates a summary vector for each segment to retain segment-level
information essential for retrieval. For KV cache compression, StreamKV
introduces a guidance prompt designed to capture the key semantic elements
within each segment, ensuring only the most informative KV caches are retained
for answering questions. Moreover, StreamKV unifies KV cache retrieval and
compression within a single module, performing both in a layer-adaptive manner,
thereby further improving the effectiveness of streaming video question
answering. Extensive experiments on public StreamingVQA benchmarks demonstrate
that StreamKV significantly outperforms existing Online Video-LLMs, achieving
superior accuracy while substantially improving both memory efficiency and
computational latency. The code has been released at
https://github.com/sou1p0wer/StreamKV.
\\ ( https://arxiv.org/abs/2511.07278 ,  11453kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07281
Date: Mon, 10 Nov 2025 16:27:25 GMT   (798kb)

Title: Segmentation of Ischemic Stroke Lesions using Transfer Learning on
 Multi-sequence MRI
Authors: R. P. Chowdhury, T. Rahman
Categories: cs.CV
Comments: Ischemic Stroke, Segmentation, Transfer Learning, Magnetic Resonance
 Imaging, Deep Learning, Res-UNet
\\
 The accurate understanding of ischemic stroke lesions is critical for
efficient therapy and prognosis of stroke patients. Magnetic resonance imaging
(MRI) is sensitive to acute ischemic stroke and is a common diagnostic method
for stroke. However, manual lesion segmentation performed by experts is
tedious, time-consuming, and prone to observer inconsistency. Automatic medical
image analysis methods have been proposed to overcome this challenge. However,
previous approaches have relied on hand-crafted features that may not capture
the irregular and physiologically complex shapes of ischemic stroke lesions. In
this study, we present a novel framework for quickly and automatically
segmenting ischemic stroke lesions on various MRI sequences, including
T1-weighted, T2-weighted, DWI, and FLAIR. The proposed methodology is validated
on the ISLES 2015 Brain Stroke sequence dataset, where we trained our model
using the Res-Unet architecture twice: first, with pre-existing weights, and
then without, to explore the benefits of transfer learning. Evaluation metrics,
including the Dice score and sensitivity, were computed across 3D volumes.
Finally, a Majority Voting Classifier was integrated to amalgamate the outcomes
from each axis, resulting in a comprehensive segmentation method. Our efforts
culminated in achieving a Dice score of 80.5\% and an accuracy of 74.03\%,
showcasing the efficacy of our segmentation approach.
\\ ( https://arxiv.org/abs/2511.07281 ,  798kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07286
Date: Mon, 10 Nov 2025 16:33:34 GMT   (7025kb)

Title: Glioma C6: A Novel Dataset for Training and Benchmarking Cell
 Segmentation
Authors: Roman Malashin, Svetlana Pashkevich, Daniil Ilyukhin, Arseniy Volkov,
 Valeria Yachnaya, Andrey Denisov, and Maria Mikhalkova
Categories: cs.CV cs.AI
\\
 We present Glioma C6, a new open dataset for instance segmentation of glioma
C6 cells, designed as both a benchmark and a training resource for deep
learning models. The dataset comprises 75 high-resolution phase-contrast
microscopy images with over 12,000 annotated cells, providing a realistic
testbed for biomedical image analysis. It includes soma annotations and
morphological cell categorization provided by biologists. Additional
categorization of cells, based on morphology, aims to enhance the utilization
of image data for cancer cell research. Glioma C6 consists of two parts: the
first is curated with controlled parameters for benchmarking, while the second
supports generalization testing under varying conditions. We evaluate the
performance of several generalist segmentation models, highlighting their
limitations on our dataset. Our experiments demonstrate that training on Glioma
C6 significantly enhances segmentation performance, reinforcing its value for
developing robust and generalizable models. The dataset is publicly available
for researchers.
\\ ( https://arxiv.org/abs/2511.07286 ,  7025kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07298
Date: Mon, 10 Nov 2025 16:56:11 GMT   (406kb)

Title: LMM-IQA: Image Quality Assessment for Low-Dose CT Imaging
Authors: Kagan Celik, Mehmet Ozan Unal, Metin Ertas, Isa Yildirim
Categories: cs.CV cs.AI
\\
 Low-dose computed tomography (CT) represents a significant improvement in
patient safety through lower radiation doses, but increased noise, blur, and
contrast loss can diminish diagnostic quality. Therefore, consistency and
robustness in image quality assessment become essential for clinical
applications. In this study, we propose an LLM-based quality assessment system
that generates both numerical scores and textual descriptions of degradations
such as noise, blur, and contrast loss. Furthermore, various inference
strategies - from the zero-shot approach to metadata integration and error
feedback - are systematically examined, demonstrating the progressive
contribution of each method to overall performance. The resultant assessments
yield not only highly correlated scores but also interpretable output, thereby
adding value to clinical workflows. The source codes of our study are available
at https://github.com/itu-biai/lmms_ldct_iqa.
\\ ( https://arxiv.org/abs/2511.07298 ,  406kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07299
Date: Mon, 10 Nov 2025 16:56:11 GMT   (33610kb)

Title: VADER: Towards Causal Video Anomaly Understanding with Relation-Aware
 Large Language Models
Authors: Ying Cheng, Yu-Ho Lin, Min-Hung Chen, Fu-En Yang and Shang-Hong Lai
Categories: cs.CV
\\
 Video anomaly understanding (VAU) aims to provide detailed interpretation and
semantic comprehension of anomalous events within videos, addressing
limitations of traditional methods that focus solely on detecting and
localizing anomalies. However, existing approaches often neglect the deeper
causal relationships and interactions between objects, which are critical for
understanding anomalous behaviors. In this paper, we propose VADER, an
LLM-driven framework for Video Anomaly unDErstanding, which integrates keyframe
object Relation features with visual cues to enhance anomaly comprehension from
video. Specifically, VADER first applies an Anomaly Scorer to assign per-frame
anomaly scores, followed by a Context-AwarE Sampling (CAES) strategy to capture
the causal context of each anomalous event. A Relation Feature Extractor and a
COntrastive Relation Encoder (CORE) jointly model dynamic object interactions,
producing compact relational representations for downstream reasoning. These
visual and relational cues are integrated with LLMs to generate detailed,
causally grounded descriptions and support robust anomaly-related question
answering. Experiments on multiple real-world VAU benchmarks demonstrate that
VADER achieves strong results across anomaly description, explanation, and
causal reasoning tasks, advancing the frontier of explainable video anomaly
analysis.
\\ ( https://arxiv.org/abs/2511.07299 ,  33610kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07301
Date: Mon, 10 Nov 2025 17:06:01 GMT   (11723kb)

Title: Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free
 Object Detection
Authors: Huizai Yao, Sicheng Zhao, Pengteng Li, Yi Cui, Shuo Lu, Weiyu Guo,
 Yunfan Lu, Yijie Xu, Hui Xiong
Categories: cs.CV cs.AI
Comments: Accepted to AAAI 2026. Extended version with full Appendix
\\
 Source-Free Object Detection (SFOD) aims to adapt a source-pretrained object
detector to a target domain without access to source data. However, existing
SFOD methods predominantly rely on internal knowledge from the source model,
which limits their capacity to generalize across domains and often results in
biased pseudo-labels, thereby hindering both transferability and
discriminability. In contrast, Vision Foundation Models (VFMs), pretrained on
massive and diverse data, exhibit strong perception capabilities and broad
generalization, yet their potential remains largely untapped in the SFOD
setting. In this paper, we propose a novel SFOD framework that leverages VFMs
as external knowledge sources to jointly enhance feature alignment and label
quality. Specifically, we design three VFM-based modules: (1) Patch-weighted
Global Feature Alignment (PGFA) distills global features from VFMs using
patch-similarity-based weighting to enhance global feature transferability; (2)
Prototype-based Instance Feature Alignment (PIFA) performs instance-level
contrastive learning guided by momentum-updated VFM prototypes; and (3)
Dual-source Enhanced Pseudo-label Fusion (DEPF) fuses predictions from
detection VFMs and teacher models via an entropy-aware strategy to yield more
reliable supervision. Extensive experiments on six benchmarks demonstrate that
our method achieves state-of-the-art SFOD performance, validating the
effectiveness of integrating VFMs to simultaneously improve transferability and
discriminability.
\\ ( https://arxiv.org/abs/2511.07301 ,  11723kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07321
Date: Mon, 10 Nov 2025 17:21:54 GMT   (2204kb)

Title: YoNoSplat: You Only Need One Model for Feedforward 3D Gaussian Splatting
Authors: Botao Ye, Boqi Chen, Haofei Xu, Daniel Barath, and Marc Pollefeys
Categories: cs.CV
\\
 Fast and flexible 3D scene reconstruction from unstructured image collections
remains a significant challenge. We present YoNoSplat, a feedforward model that
reconstructs high-quality 3D Gaussian Splatting representations from an
arbitrary number of images. Our model is highly versatile, operating
effectively with both posed and unposed, calibrated and uncalibrated inputs.
YoNoSplat predicts local Gaussians and camera poses for each view, which are
aggregated into a global representation using either predicted or provided
poses. To overcome the inherent difficulty of jointly learning 3D Gaussians and
camera parameters, we introduce a novel mixing training strategy. This approach
mitigates the entanglement between the two tasks by initially using
ground-truth poses to aggregate local Gaussians and gradually transitioning to
a mix of predicted and ground-truth poses, which prevents both training
instability and exposure bias. We further resolve the scale ambiguity problem
by a novel pairwise camera-distance normalization scheme and by embedding
camera intrinsics into the network. Moreover, YoNoSplat also predicts intrinsic
parameters, making it feasible for uncalibrated inputs. YoNoSplat demonstrates
exceptional efficiency, reconstructing a scene from 100 views (at 280x518
resolution) in just 2.69 seconds on an NVIDIA GH200 GPU. It achieves
state-of-the-art performance on standard benchmarks in both pose-free and
pose-dependent settings. Our project page is at
https://botaoye.github.io/yonosplat/.
\\ ( https://arxiv.org/abs/2511.07321 ,  2204kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07325
Date: Mon, 10 Nov 2025 17:27:51 GMT   (9765kb)

Title: Garbage Vulnerable Point Monitoring using IoT and Computer Vision
Authors: R. Kumar, A. Lall, S. Chaudhari, M. Kale, A. Vattem
Categories: cs.CV cs.LG
\\
 This paper proposes a smart way to manage municipal solid waste by using the
Internet of Things (IoT) and computer vision (CV) to monitor illegal waste
dumping at garbage vulnerable points (GVPs) in urban areas. The system can
quickly detect and monitor dumped waste using a street-level camera and object
detection algorithm. Data was collected from the Sangareddy district in
Telangana, India. A series of comprehensive experiments was carried out using
the proposed dataset to assess the accuracy and overall performance of various
object detection models. Specifically, we performed an in-depth evaluation of
YOLOv8, YOLOv10, YOLO11m, and RT-DETR on our dataset. Among these models,
YOLO11m achieved the highest accuracy of 92.39\% in waste detection,
demonstrating its effectiveness in detecting waste. Additionally, it attains an
mAP@50 of 0.91, highlighting its high precision. These findings confirm that
the object detection model is well-suited for monitoring and tracking waste
dumping events at GVP locations. Furthermore, the system effectively captures
waste disposal patterns, including hourly, daily, and weekly dumping trends,
ensuring comprehensive daily and nightly monitoring.
\\ ( https://arxiv.org/abs/2511.07325 ,  9765kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07362
Date: Mon, 10 Nov 2025 18:18:38 GMT   (218kb)

Title: Inference-Time Scaling of Diffusion Models for Infrared Data Generation
Authors: Kai A. Horstmann, Maxim Clouser, Kia Khezeli
Categories: cs.CV cs.AI cs.LG
Comments: Peer-reviewed workshop paper
Journal-ref: 39th Conference on Neural Information Processing Systems (NeurIPS
 2025) Workshop: Learning to Sense
\\
 Infrared imagery enables temperature-based scene understanding using passive
sensors, particularly under conditions of low visibility where traditional RGB
imaging fails. Yet, developing downstream vision models for infrared
applications is hindered by the scarcity of high-quality annotated data, due to
the specialized expertise required for infrared annotation. While synthetic
infrared image generation has the potential to accelerate model development by
providing large-scale, diverse training data, training foundation-level
generative diffusion models in the infrared domain has remained elusive due to
limited datasets. In light of such data constraints, we explore an
inference-time scaling approach using a domain-adapted CLIP-based verifier for
enhanced infrared image generation quality. We adapt FLUX.1-dev, a
state-of-the-art text-to-image diffusion model, to the infrared domain by
finetuning it on a small sample of infrared images using parameter-efficient
techniques. The trained verifier is then employed during inference to guide the
diffusion sampling process toward higher quality infrared generations that
better align with input text prompts. Empirically, we find that our approach
leads to consistent improvements in generation quality, reducing FID scores on
the KAIST Multispectral Pedestrian Detection Benchmark dataset by 10% compared
to unguided baseline samples. Our results suggest that inference-time guidance
offers a promising direction for bridging the domain gap in low-data infrared
settings.
\\ ( https://arxiv.org/abs/2511.07362 ,  218kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07377
Date: Mon, 10 Nov 2025 18:38:15 GMT   (3260kb)

Title: Real-Time LiDAR Super-Resolution via Frequency-Aware Multi-Scale Fusion
Authors: June Moh Goo, Zichao Zeng, Jan Boehm
Categories: cs.CV cs.AI cs.RO
\\
 LiDAR super-resolution addresses the challenge of achieving high-quality 3D
perception from cost-effective, low-resolution sensors. While recent
transformer-based approaches like TULIP show promise, they remain limited to
spatial-domain processing with restricted receptive fields. We introduce FLASH
(Frequency-aware LiDAR Adaptive Super-resolution with Hierarchical fusion), a
novel framework that overcomes these limitations through dual-domain
processing. FLASH integrates two key innovations: (i) Frequency-Aware Window
Attention that combines local spatial attention with global frequency-domain
analysis via FFT, capturing both fine-grained geometry and periodic scanning
patterns at log-linear complexity. (ii) Adaptive Multi-Scale Fusion that
replaces conventional skip connections with learned position-specific feature
aggregation, enhanced by CBAM attention for dynamic feature selection.
Extensive experiments on KITTI demonstrate that FLASH achieves state-of-the-art
performance across all evaluation metrics, surpassing even uncertainty-enhanced
baselines that require multiple forward passes. Notably, FLASH outperforms
TULIP with Monte Carlo Dropout while maintaining single-pass efficiency, which
enables real-time deployment. The consistent superiority across all distance
ranges validates that our dual-domain approach effectively handles uncertainty
through architectural design rather than computationally expensive stochastic
inference, making it practical for autonomous systems.
\\ ( https://arxiv.org/abs/2511.07377 ,  3260kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07399
Date: Mon, 10 Nov 2025 18:51:28 GMT   (10210kb)

Title: StreamDiffusionV2: A Streaming System for Dynamic and Interactive Video
 Generation
Authors: Tianrui Feng, Zhi Li, Shuo Yang, Haocheng Xi, Muyang Li, Xiuyu Li,
 Lvmin Zhang, Keting Yang, Kelly Peng, Song Han, Maneesh Agrawala, Kurt
 Keutzer, Akio Kodaira, Chenfeng Xu
Categories: cs.CV cs.LG
Comments: Project Page: http://streamdiffusionv2.github.io
\\
 Generative models are reshaping the live-streaming industry by redefining how
content is created, styled, and delivered. Previous image-based streaming
diffusion models have powered efficient and creative live streaming products
but have hit limits on temporal consistency due to the foundation of
image-based designs. Recent advances in video diffusion have markedly improved
temporal consistency and sampling efficiency for offline generation. However,
offline generation systems primarily optimize throughput by batching large
workloads. In contrast, live online streaming operates under strict
service-level objectives (SLOs): time-to-first-frame must be minimal, and every
frame must meet a per-frame deadline with low jitter. Besides, scalable
multi-GPU serving for real-time streams remains largely unresolved so far. To
address this, we present StreamDiffusionV2, a training-free pipeline for
interactive live streaming with video diffusion models. StreamDiffusionV2
integrates an SLO-aware batching scheduler and a block scheduler, together with
a sink-token--guided rolling KV cache, a motion-aware noise controller, and
other system-level optimizations. Moreover, we introduce a scalable pipeline
orchestration that parallelizes the diffusion process across denoising steps
and network layers, achieving near-linear FPS scaling without violating latency
guarantees. The system scales seamlessly across heterogeneous GPU environments
and supports flexible denoising steps (e.g., 1--4), enabling both
ultra-low-latency and higher-quality modes. Without TensorRT or quantization,
StreamDiffusionV2 renders the first frame within 0.5s and attains 58.28 FPS
with a 14B-parameter model and 64.52 FPS with a 1.3B-parameter model on four
H100 GPUs, making state-of-the-art generative live streaming practical and
accessible--from individual creators to enterprise-scale platforms.
\\ ( https://arxiv.org/abs/2511.07399 ,  10210kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07403
Date: Mon, 10 Nov 2025 18:52:47 GMT   (16997kb)

Title: SpatialThinker: Reinforcing 3D Reasoning in Multimodal LLMs via Spatial
 Rewards
Authors: Hunar Batra, Haoqin Tu, Hardy Chen, Yuanze Lin, Cihang Xie, Ronald
 Clark
Categories: cs.CV cs.AI cs.CL cs.LG
Comments: Preprint. Accepted at NeurIPS 2025 Workshops on SPACE in Vision,
 Language, and Embodied AI (SpaVLE), Embodied World Models for Decision Making
 (EWM), Aligning Reinforcement Learning Experimentalists and Theorists
 (ARLET), and Scaling Environments for Agents (SEA)
\\
 Multimodal large language models (MLLMs) have achieved remarkable progress in
vision-language tasks, but they continue to struggle with spatial
understanding. Existing spatial MLLMs often rely on explicit 3D inputs or
architecture-specific modifications, and remain constrained by large-scale
datasets or sparse supervision. To address these limitations, we introduce
SpatialThinker, a 3D-aware MLLM trained with RL to integrate structured spatial
grounding with multi-step reasoning. The model simulates human-like spatial
perception by constructing a scene graph of task-relevant objects and spatial
relations, and reasoning towards an answer via dense spatial rewards.
SpatialThinker consists of two key contributions: (1) a data synthesis pipeline
that generates STVQA-7K, a high-quality spatial VQA dataset, and (2) online RL
with a multi-objective dense spatial reward enforcing spatial grounding.
SpatialThinker-7B outperforms supervised fine-tuning and the sparse RL baseline
on spatial understanding and real-world VQA benchmarks, nearly doubling the
base-model gain compared to sparse RL, and surpassing GPT-4o. These results
showcase the effectiveness of combining spatial supervision with reward-aligned
reasoning in enabling robust 3D spatial understanding with limited data and
advancing MLLMs towards human-level visual reasoning.
\\ ( https://arxiv.org/abs/2511.07403 ,  16997kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07409
Date: Mon, 10 Nov 2025 18:56:49 GMT   (5803kb)

Title: DIMO: Diverse 3D Motion Generation for Arbitrary Objects
Authors: Linzhan Mou and Jiahui Lei and Chen Wang and Lingjie Liu and Kostas
 Daniilidis
Categories: cs.CV
Comments: Published in ICCV 2025, project page https://linzhanm.github.io/dimo
\\
 We present DIMO, a generative approach capable of generating diverse 3D
motions for arbitrary objects from a single image. The core idea of our work is
to leverage the rich priors in well-trained video models to extract the common
motion patterns and then embed them into a shared low-dimensional latent space.
Specifically, we first generate multiple videos of the same object with diverse
motions. We then embed each motion into a latent vector and train a shared
motion decoder to learn the distribution of motions represented by a structured
and compact motion representation, i.e., neural key point trajectories. The
canonical 3D Gaussians are then driven by these key points and fused to model
the geometry and appearance. During inference time with learned latent space,
we can instantly sample diverse 3D motions in a single-forward pass and support
several interesting applications including 3D motion interpolation and
language-guided motion generation. Our project page is available at
https://linzhanm.github.io/dimo.
\\ ( https://arxiv.org/abs/2511.07409 ,  5803kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07412
Date: Mon, 10 Nov 2025 18:57:09 GMT   (3302kb)

Title: TwinOR: Photorealistic Digital Twins of Dynamic Operating Rooms for
 Embodied AI Research
Authors: Han Zhang, Yiqing Shen, Roger D. Soberanis-Mukul, Ankita Ghosh, Hao
 Ding, Lalithkumar Seenivasan, Jose L. Porras, Zhekai Mao, Chenjia Li, Wenjie
 Xiao, Lonny Yarmus, Angela Christine Argento, Masaru Ishii, and Mathias
 Unberath
Categories: cs.CV cs.RO
\\
 Developing embodied AI for intelligent surgical systems requires safe,
controllable environments for continual learning and evaluation. However,
safety regulations and operational constraints in operating rooms (ORs) limit
embodied agents from freely perceiving and interacting in realistic settings.
Digital twins provide high-fidelity, risk-free environments for exploration and
training. How we may create photorealistic and dynamic digital representations
of ORs that capture relevant spatial, visual, and behavioral complexity remains
unclear. We introduce TwinOR, a framework for constructing photorealistic,
dynamic digital twins of ORs for embodied AI research. The system reconstructs
static geometry from pre-scan videos and continuously models human and
equipment motion through multi-view perception of OR activities. The static and
dynamic components are fused into an immersive 3D environment that supports
controllable simulation and embodied exploration. The proposed framework
reconstructs complete OR geometry with centimeter level accuracy while
preserving dynamic interaction across surgical workflows, enabling realistic
renderings and a virtual playground for embodied AI systems. In our
experiments, TwinOR simulates stereo and monocular sensor streams for geometry
understanding and visual localization tasks. Models such as FoundationStereo
and ORB-SLAM3 on TwinOR-synthesized data achieve performance within their
reported accuracy on real indoor datasets, demonstrating that TwinOR provides
sensor-level realism sufficient for perception and localization challenges. By
establishing a real-to-sim pipeline for constructing dynamic, photorealistic
digital twins of OR environments, TwinOR enables the safe, scalable, and
data-efficient development and benchmarking of embodied AI, ultimately
accelerating the deployment of embodied AI from sim-to-real.
\\ ( https://arxiv.org/abs/2511.07412 ,  3302kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05493
Date: Wed, 10 Sep 2025 07:57:00 GMT   (553kb)

Title: GreyShot: Zeroshot and Privacy-preserving Recommender System by GM(1,1)
 Model
Authors: Hao Wang
Categories: cs.IR
Journal-ref: The Journal of Grey System, 2025, 37(2): 16-22
\\
 Every recommendation engineer needs to face the cold start problem when
building his system. During the past decades, most scientists adopted transfer
learning and meta learning to solve the problem. Although notable exceptions
such as ZeroMat etc. have been invented in recent years, cold-start problem
remains a challenging problem for many researchers. In this paper, we build a
zeroshot and privacy-preserving recommender system algorithm GreyShot using
GM(1,1) model by taking advantage of the Poisson-Pareto property of the online
rating data. Our approach relies on no input data and is effective in
generating both accurate and fair results. In conclusion, zeroshot problem of
recommender systems could be effectively solved by grey system methods such as
GM(1,1).
\\ ( https://arxiv.org/abs/2511.05493 ,  553kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05494
Date: Wed, 10 Sep 2025 08:49:58 GMT   (821kb)

Title: Customized Retrieval-Augmented Generation with LLM for Debiasing
 Recommendation Unlearning
Authors: Haichao Zhang, Chong Zhang, Peiyu Hu, Shi Qiu, Jia Wang
Categories: cs.IR cs.AI
Comments: 10 pages, 4 figures. Accepted ICDM 2025 (IEEE International
 Conference on Data Mining)
\\
 Modern recommender systems face a critical challenge in complying with
privacy regulations like the 'right to be forgotten': removing a user's data
without disrupting recommendations for others. Traditional unlearning methods
address this by partial model updates, but introduce propagation bias--where
unlearning one user's data distorts recommendations for behaviorally similar
users, degrading system accuracy. While retraining eliminates bias, it is
computationally prohibitive for large-scale systems. To address this challenge,
we propose CRAGRU, a novel framework leveraging Retrieval-Augmented Generation
(RAG) for efficient, user-specific unlearning that mitigates bias while
preserving recommendation quality. CRAGRU decouples unlearning into distinct
retrieval and generation stages. In retrieval, we employ three tailored
strategies designed to precisely isolate the target user's data influence,
minimizing collateral impact on unrelated users and enhancing unlearning
efficiency. Subsequently, the generation stage utilizes an LLM, augmented with
user profiles integrated into prompts, to reconstruct accurate and personalized
recommendations without needing to retrain the entire base model. Experiments
on three public datasets demonstrate that CRAGRU effectively unlearns targeted
user data, significantly mitigating unlearning bias by preventing adverse
impacts on non-target users, while maintaining recommendation performance
comparable to fully trained original models. Our work highlights the promise of
RAG-based architectures for building robust and privacy-preserving recommender
systems. The source code is available at:
https://github.com/zhanghaichao520/LLM_rec_unlearning.
\\ ( https://arxiv.org/abs/2511.05494 ,  821kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05495
Date: Wed, 10 Sep 2025 23:53:40 GMT   (2672kb)

Title: IMDMR: An Intelligent Multi-Dimensional Memory Retrieval System for
 Enhanced Conversational AI
Authors: Tejas Pawar, Sarika Patil, Om Tilekar, Rushikesh Janwade, Vaibhav
 Helambe
Categories: cs.IR cs.AI
Comments: 28 pages, 8 figures, submitted to arXiv for open access publication
ACM-class: I.2.7; I.2.6; H.3.3; I.2.1; I.2.4; H.3.1; I.2.8; H.3.4
\\
 Conversational AI systems often struggle with maintaining coherent,
contextual memory across extended interactions, limiting their ability to
provide personalized and contextually relevant responses. This paper presents
IMDMR (Intelligent Multi-Dimensional Memory Retrieval), a novel system that
addresses these limitations through a multi-dimensional search architecture.
Unlike existing memory systems that rely on single-dimensional approaches,
IMDMR leverages six distinct memory dimensions-semantic, entity, category,
intent, context, and temporal-to provide comprehensive memory retrieval
capabilities. Our system incorporates intelligent query processing with dynamic
strategy selection, cross-memory entity resolution, and advanced memory
integration techniques. Through comprehensive evaluation against five baseline
systems including LangChain RAG, LlamaIndex, MemGPT, and spaCy + RAG, IMDMR
achieves a 3.8x improvement in overall performance (0.792 vs 0.207 for the best
baseline). We present both simulated (0.314) and production (0.792)
implementations, demonstrating the importance of real technology integration
while maintaining superiority over all baseline systems. Ablation studies
demonstrate the effectiveness of multi-dimensional search, with the full system
outperforming individual dimension approaches by 23.3%. Query-type analysis
reveals superior performance across all categories, particularly for
preferences/interests (0.630) and goals/aspirations (0.630) queries.
Comprehensive visualizations and statistical analysis confirm the significance
of these improvements with p < 0.001 across all metrics. The results establish
IMDMR as a significant advancement in conversational AI memory systems,
providing a robust foundation for enhanced user interactions and personalized
experiences.
\\ ( https://arxiv.org/abs/2511.05495 ,  2672kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05496
Date: Fri, 12 Sep 2025 08:09:09 GMT   (346kb)

Title: DOCUEVAL: An LLM-based AI Engineering Tool for Building Customisable
 Document Evaluation Workflows
Authors: Hao Zhang, Qinghua Lu, and Liming Zhu
Categories: cs.IR cs.AI
\\
 Foundation models, such as large language models (LLMs), have the potential
to streamline evaluation workflows and improve their performance. However,
practical adoption faces challenges, such as customisability, accuracy, and
scalability. In this paper, we present DOCUEVAL, an AI engineering tool for
building customisable DOCUment EVALuation workflows. DOCUEVAL supports advanced
document processing and customisable workflow design which allow users to
define theory-grounded reviewer roles, specify evaluation criteria, experiment
with different reasoning strategies and choose the assessment style. To ensure
traceability, DOCUEVAL provides comprehensive logging of every run, along with
source attribution and configuration management, allowing systematic comparison
of results across alternative setups. By integrating these capabilities,
DOCUEVAL directly addresses core software engineering challenges, including how
to determine whether evaluators are "good enough" for deployment and how to
empirically compare different evaluation strategies. We demonstrate the
usefulness of DOCUEVAL through a real-world academic peer review case, showing
how DOCUEVAL enables both the engineering of evaluators and scalable, reliable
document evaluation.
\\ ( https://arxiv.org/abs/2511.05496 ,  346kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05497
Date: Sat, 13 Sep 2025 02:04:39 GMT   (541kb)

Title: Socially Aware Music Recommendation: A Multi-Modal Graph Neural Networks
 for Collaborative Music Consumption and Community-Based Engagement
Authors: Kajwan Ziaoddini
Categories: cs.IR cs.LG cs.MM
\\
 This study presents a novel Multi-Modal Graph Neural Network (MM-GNN)
framework for socially aware music recommendation, designed to enhance
personalization and foster community-based engagement. The proposed model
introduces a fusion-free deep mutual learning strategy that aligns
modality-specific representations from lyrics, audio, and visual data while
maintaining robustness against missing modalities. A heterogeneous graph
structure is constructed to capture both user-song interactions and user-user
social relationships, enabling the integration of individual preferences with
social influence. Furthermore, emotion-aware embeddings derived from acoustic
and textual signals contribute to emotionally aligned recommendations.
Experimental evaluations on benchmark datasets demonstrate that MM-GNN
significantly outperforms existing state-of-the-art methods across various
performance metrics. Ablation studies further validate the critical impact of
each model component, confirming the effectiveness of the framework in
delivering accurate and socially contextualized music recommendations.
\\ ( https://arxiv.org/abs/2511.05497 ,  541kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05498
Date: Mon, 15 Sep 2025 09:50:51 GMT   (3212kb)

Title: Biomedical Hypothesis Explainability with Graph-Based Context Retrieval
Authors: Ilya Tyagin, Saeideh Valipour, Aliaksandra Sikirzhytskaya, Michael
 Shtutman, Ilya Safro
Categories: cs.IR cs.AI
Comments: 30 pages, 10 figures,
\\
 We introduce an explainability method for biomedical hypothesis generation
systems, built on top of the novel Hypothesis Generation Context Retriever
framework. Our approach combines semantic graph-based retrieval and relevant
data-restrictive training to simulate real-world discovery constraints.
Integrated with large language models (LLMs) via retrieval-augmented
generation, the system explains hypotheses with contextual evidence using
published scientific literature. We also propose a novel feedback loop
approach, which iteratively identifies and corrects flawed parts of
LLM-generated explanations, refining both the evidence paths and supporting
context. We demonstrate the performance of our method with multiple large
language models and evaluate the explanation and context retrieval quality
through both expert-curated assessment and large-scale automated analysis. Our
code is available at: https://github.com/IlyaTyagin/HGCR.
\\ ( https://arxiv.org/abs/2511.05498 ,  3212kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05499
Date: Mon, 15 Sep 2025 23:51:12 GMT   (391kb)

Title: Weightless Neural Networks for Continuously Trainable Personalized
 Recommendation Systems
Authors: Rafayel Latif, Satwik Behera, Ali Al-Ebrahim
Categories: cs.IR cs.AI cs.LG
\\
 Given that conventional recommenders, while deeply effective, rely on large
distributed systems pre-trained on aggregate user data, incorporating new data
necessitates large training cycles, making them slow to adapt to real-time user
feedback and often lacking transparency in recommendation rationale. We explore
the performance of smaller personal models trained on per-user data using
weightless neural networks (WNNs), an alternative to neural backpropagation
that enable continuous learning by using neural networks as a state machine
rather than a system with pretrained weights. We contrast our approach against
a classic weighted system, also on a per-user level, and standard collaborative
filtering, achieving competitive levels of accuracy on a subset of the
MovieLens dataset. We close with a discussion of how weightless systems can be
developed to augment centralized systems to achieve higher subjective accuracy
through recommenders more directly tunable by end-users.
\\ ( https://arxiv.org/abs/2511.05499 ,  391kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05500
Date: Mon, 29 Sep 2025 15:25:02 GMT   (46kb)

Title: Predicting Oscar-Nominated Screenplays with Sentence Embeddings
Authors: Francis Gross
Categories: cs.IR cs.AI cs.CL
\\
 Oscar nominations are an important factor in the movie industry because they
can boost both the visibility and the commercial success. This work explores
whether it is possible to predict Oscar nominations for screenplays using
modern language models. Since no suitable dataset was available, a new one
called Movie-O-Label was created by combining the MovieSum collection of movie
scripts with curated Oscar records. Each screenplay was represented by its
title, Wikipedia summary, and full script. Long scripts were split into
overlapping text chunks and encoded with the E5 sentence em bedding model.
Then, the screenplay embed dings were classified using a logistic regression
model. The best results were achieved when three feature inputs related to
screenplays (script, summary, and title) were combined. The best-performing
model reached a macro F1 score of 0.66, a precision recall AP of 0.445 with
baseline 0.19 and a ROC-AUC of 0.79. The results suggest that even simple
models based on modern text embeddings demonstrate good prediction performance
and might be a starting point for future research.
\\ ( https://arxiv.org/abs/2511.05500 ,  46kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05667
Date: Fri, 7 Nov 2025 19:09:57 GMT   (11935kb)

Title: SARCH: Multimodal Search for Archaeological Archives
Authors: Nivedita Sinha, Bharati Khanijo, Sanskar Singh, Priyansh Mahant,
 Ashutosh Roy, Saubhagya Singh Bhadouria, Arpan Jain, Maya Ramanath
Categories: cs.IR
\\
 In this paper, we describe a multi-modal search system designed to search old
archaeological books and reports. This corpus is digitally available as scanned
PDFs, but varies widely in the quality of scans. Our pipeline, designed for
multi-modal archaeological documents, extracts and indexes text, images
(classified into maps, photos, layouts, and others), and tables. We evaluated
different retrieval strategies, including keyword-based search, embedding-
based models, and a hybrid approach that selects optimal results from both
modalities. We report and analyze our preliminary results and discuss future
work in this exciting vertical.
\\ ( https://arxiv.org/abs/2511.05667 ,  11935kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05684
Date: Fri, 7 Nov 2025 20:07:46 GMT   (384kb)

Title: A Representation Sharpening Framework for Zero Shot Dense Retrieval
Authors: Dhananjay Ashok, Suraj Nair, Mutasem Al-Darabsah, Choon Hui Teo, Tarun
 Agarwal, Jonathan May
Categories: cs.IR cs.CL
Comments: 15 pages, 4 figures
\\
 Zero-shot dense retrieval is a challenging setting where a document corpus is
provided without relevant queries, necessitating a reliance on pretrained dense
retrievers (DRs). However, since these DRs are not trained on the target
corpus, they struggle to represent semantic differences between similar
documents. To address this failing, we introduce a training-free representation
sharpening framework that augments a document's representation with information
that helps differentiate it from similar documents in the corpus. On over
twenty datasets spanning multiple languages, the representation sharpening
framework proves consistently superior to traditional retrieval, setting a new
state-of-the-art on the BRIGHT benchmark. We show that representation
sharpening is compatible with prior approaches to zero-shot dense retrieval and
consistently improves their performance. Finally, we address the
performance-cost tradeoff presented by our framework and devise an
indexing-time approximation that preserves the majority of our performance
gains over traditional retrieval, yet suffers no additional inference-time
cost.
\\ ( https://arxiv.org/abs/2511.05684 ,  384kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05808
Date: Sat, 8 Nov 2025 02:45:32 GMT   (874kb)

Title: User Hesitation and Negative Transfer in Multi-Behavior Recommendation
Authors: Cheng Li, Yong Xu, Suhua Tang, Wenqiang Lin, Xin He, Jinde Cao
Categories: cs.IR
\\
 Multi-behavior recommendation aims to integrate users' interactions across
various behavior types (e.g., view, favorite, add-to-cart, purchase) to more
comprehensively characterize user preferences. However, existing methods lack
in-depth modeling when dealing with interactions that generate only auxiliary
behaviors without triggering the target behavior. In fact, these weak signals
contain rich latent information and can be categorized into two types: (1)
positive weak signals-items that have not triggered the target behavior but
exhibit frequent auxiliary interactions, reflecting users' hesitation
tendencies toward these items; and (2) negative weak signals-auxiliary
behaviors that result from misoperations or interaction noise, which deviate
from true preferences and may cause negative transfer effects. To more
effectively identify and utilize these weak signals, we propose a
recommendation framework focused on weak signal learning, termed HNT.
Specifically, HNT models weak signal features from two dimensions: positive and
negative effects. By learning the characteristics of auxiliary behaviors that
lead to target behaviors, HNT identifies similar auxiliary behaviors that did
not trigger the target behavior and constructs a hesitation set of related
items as weak positive samples to enhance preference modeling, thereby
capturing users' latent hesitation intentions. Meanwhile, during auxiliary
feature fusion, HNT incorporates latent negative transfer effect modeling to
distinguish and suppress interference caused by negative representations
through item similarity learning. Experiments on three real-world datasets
demonstrate that HNT improves HR@10 and NDCG@10 by 12.57% and 14.37%,
respectively, compared to the best baseline methods.
\\ ( https://arxiv.org/abs/2511.05808 ,  874kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05850
Date: Sat, 8 Nov 2025 04:54:29 GMT   (108kb)

Title: Retrieval Quality at Context Limit
Authors: Max McKinnon
Categories: cs.IR cs.AI
Comments: 3 pages, 0 figures
MSC-class: 68P20 (Primary), 68T07 (Secondary)
\\
 The ability of large language models (LLMs) to recall and retrieve
information from long contexts is critical for many real-world applications.
Prior work (Liu et al., 2023) reported that LLMs suffer significant drops in
retrieval accuracy for facts placed in the middle of large contexts, an effect
known as "Lost in the Middle" (LITM). We find the model Gemini 2.5 Flash can
answer needle-in-a-haystack questions with great accuracy regardless of
document position including when the document is nearly at the input context
limit. Our results suggest that the "Lost in the Middle" effect is not present
for simple factoid Q\&A in Gemini 2.5 Flash, indicating substantial
improvements in long-context retrieval.
\\ ( https://arxiv.org/abs/2511.05850 ,  108kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05885
Date: Sat, 8 Nov 2025 06:51:38 GMT   (1857kb)

Title: A Remarkably Efficient Paradigm to Multimodal Large Language Models for
 Sequential Recommendation
Authors: Qiyong Zhong, Jiajie Su, Ming Yang, Yunshan Ma, Xiaolin Zheng,
 Chaochao Chen
Categories: cs.IR cs.AI
\\
 In this paper, we proposed Speeder, a remarkably efficient paradigm to
multimodal large language models for sequential recommendation. Speeder
introduces 3 key components: (1) Multimodal Representation Compression (MRC),
which efficiently reduces redundancy in item descriptions; (2) Sequential
Position Awareness Enhancement (SPAE), which strengthens the model's ability to
capture complex sequential dependencies; (3) Modality-aware Progressive
Optimization (MPO), which progressively integrates different modalities to
improve the model's understanding and reduce cognitive biases. Through
extensive experiments, Speeder demonstrates superior performance over baselines
in terms of VHR@1 and computational efficiency. Specifically, Speeder achieved
250% of the training speed and 400% of the inference speed compared to the
state-of-the-art MLLM-based SR models. Future work could focus on incorporating
real-time feedback from real-world systems.
\\ ( https://arxiv.org/abs/2511.05885 ,  1857kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05991
Date: Sat, 8 Nov 2025 12:38:45 GMT   (3200kb)

Title: Ontology Learning and Knowledge Graph Construction: A Comparison of
 Approaches and Their Impact on RAG Performance
Authors: Tiago da Cruz, Bernardo Tavares, Francisco Belo
Categories: cs.IR cs.AI
Comments: 12 pages, 8 Figures
\\
 Retrieval-Augmented Generation (RAG) systems combine Large Language Models
(LLMs) with external knowledge, and their performance depends heavily on how
that knowledge is represented. This study investigates how different Knowledge
Graph (KG) construction strategies influence RAG performance. We compare a
variety of approaches: standard vector-based RAG, GraphRAG, and retrieval over
KGs built from ontologies derived either from relational databases or textual
corpora. Results show that ontology-guided KGs incorporating chunk information
achieve competitive performance with state-of-the-art frameworks, substantially
outperforming vector retrieval baselines. Moreover, the findings reveal that
ontology-guided KGs built from relational databases perform competitively to
ones built with ontologies extracted from text, with the benefit of offering a
dual advantage: they require a one-time-only ontology learning process,
substantially reducing LLM usage costs; and avoid the complexity of ontology
merging inherent to text-based approaches.
\\ ( https://arxiv.org/abs/2511.05991 ,  3200kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06213
Date: Sun, 9 Nov 2025 03:55:14 GMT   (888kb)

Title: Time Matters: A Novel Real-Time Long- and Short-term User Interest Model
 for Click-Through Rate Prediction
Authors: Xian-Jin Gui
Categories: cs.IR cs.LG
Comments: This work was doned when the first author interned at Alibaba Group
\\
 Click-Through Rate (CTR) prediction is a core task in online personalization
platform. A key step for CTR prediction is to learn accurate user
representation to capture their interests. Generally, the interest expressed by
a user is time-variant, i.e., a user activates different interests at different
time. However, most previous CTR prediction methods overlook the correlation
between the activated interest and the occurrence time, resulting in what they
actually learn is the mixture of the interests expressed by the user at all
time, rather than the real-time interest at the certain prediction time. To
capture the correlation between the activated interest and the occurrence time,
in this paper we investigate users' interest evolution from the perspective of
the whole time line and develop two regular patterns: periodic pattern and
time-point pattern. Based on the two patterns, we propose a novel time-aware
long- and short-term user interest modeling method to model users' dynamic
interests at different time. Extensive experiments on public datasets as well
as an industrial dataset verify the effectiveness of exploiting the two
patterns and demonstrate the superiority of our proposed method compared with
other state-of-the-art ones.
\\ ( https://arxiv.org/abs/2511.06213 ,  888kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06254
Date: Sun, 9 Nov 2025 07:12:15 GMT   (449kb)

Title: LLaDA-Rec: Discrete Diffusion for Parallel Semantic ID Generation in
 Generative Recommendation
Authors: Teng Shi, Chenglei Shen, Weijie Yu, Shen Nie, Chongxuan Li, Xiao
 Zhang, Ming He, Yan Han, Jun Xu
Categories: cs.IR
\\
 Generative recommendation represents each item as a semantic ID, i.e., a
sequence of discrete tokens, and generates the next item through autoregressive
decoding. While effective, existing autoregressive models face two intrinsic
limitations: (1) unidirectional constraints, where causal attention restricts
each token to attend only to its predecessors, hindering global semantic
modeling; and (2) error accumulation, where the fixed left-to-right generation
order causes prediction errors in early tokens to propagate to the predictions
of subsequent token. To address these issues, we propose LLaDA-Rec, a discrete
diffusion framework that reformulates recommendation as parallel semantic ID
generation. By combining bidirectional attention with the adaptive generation
order, the approach models inter-item and intra-item dependencies more
effectively and alleviates error accumulation. Specifically, our approach
comprises three key designs: (1) a parallel tokenization scheme that produces
semantic IDs for bidirectional modeling, addressing the mismatch between
residual quantization and bidirectional architectures; (2) two masking
mechanisms at the user-history and next-item levels to capture both inter-item
sequential dependencies and intra-item semantic relationships; and (3) an
adapted beam search strategy for adaptive-order discrete diffusion decoding,
resolving the incompatibility of standard beam search with diffusion-based
generation. Experiments on three real-world datasets show that LLaDA-Rec
consistently outperforms both ID-based and state-of-the-art generative
recommenders, establishing discrete diffusion as a new paradigm for generative
recommendation.
\\ ( https://arxiv.org/abs/2511.06254 ,  449kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06285
Date: Sun, 9 Nov 2025 08:39:26 GMT   (2627kb)

Title: Exploiting Inter-Session Information with Frequency-enhanced Dual-Path
 Networks for Sequential Recommendation
Authors: Peng He, Yanglei Gan, Tingting Dai, Run Lin, Xuexin Li, Yao Liu, Qiao
 Liu
Categories: cs.IR cs.AI
\\
 Sequential recommendation (SR) aims to predict a user's next item preference
by modeling historical interaction sequences. Recent advances often integrate
frequency-domain modules to compensate for self-attention's low-pass nature by
restoring the high-frequency signals critical for personalized recommendations.
Nevertheless, existing frequency-aware solutions process each session in
isolation and optimize exclusively with time-domain objectives. Consequently,
they overlook cross-session spectral dependencies and fail to enforce alignment
between predicted and actual spectral signatures, leaving valuable frequency
information under-exploited. To this end, we propose FreqRec, a
Frequency-Enhanced Dual-Path Network for sequential Recommendation that jointly
captures inter-session and intra-session behaviors via a learnable
Frequency-domain Multi-layer Perceptrons. Moreover, FreqRec is optimized under
a composite objective that combines cross entropy with a frequency-domain
consistency loss, explicitly aligning predicted and true spectral signatures.
Extensive experiments on three benchmarks show that FreqRec surpasses strong
baselines and remains robust under data sparsity and noisy-log conditions.
\\ ( https://arxiv.org/abs/2511.06285 ,  2627kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06388
Date: Sun, 9 Nov 2025 13:52:48 GMT   (123kb)

Title: HyMoERec: Hybrid Mixture-of-Experts for Sequential Recommendation
Authors: Kunrong Li, Zhu Sun, Kwan Hui Lim
Categories: cs.IR cs.AI
Comments: AAAI 2026 Student Abstract
\\
 We propose HyMoERec, a novel sequential recommendation framework that
addresses the limitations of uniform Position-wise Feed-Forward Networks in
existing models. Current approaches treat all user interactions and items
equally, overlooking the heterogeneity in user behavior patterns and diversity
in item complexity. HyMoERec initially introduces a hybrid mixture-of-experts
architecture that combines shared and specialized expert branches with an
adaptive expert fusion mechanism for the sequential recommendation task. This
design captures diverse reasoning for varied users and items while ensuring
stable training. Experiments on MovieLens-1M and Beauty datasets demonstrate
that HyMoERec consistently outperforms state-of-the-art baselines.
\\ ( https://arxiv.org/abs/2511.06388 ,  123kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06405
Date: Sun, 9 Nov 2025 14:37:11 GMT   (422kb)

Title: TOOL4POI: A Tool-Augmented LLM Framework for Next POI Recommendation
Authors: Dongsheng Wang, Shen Gao, Chengrui Huang, Yuxi Huang, Ruixiang Feng,
 Shuo Shang
Categories: cs.IR
Comments: Accepted by AAAI2026
\\
 Next Point-of-Interest (POI) recommendation is a fundamental task in
location-based services. While recent advances leverage Large Language Model
(LLM) for sequential modeling, existing LLM-based approaches face two key
limitations: (i) strong reliance on the contextual completeness of user
histories, resulting in poor performance on out-of-history (OOH) scenarios;
(ii) limited scalability, due to the restricted context window of LLMs, which
limits their ability to access and process a large number of candidate POIs. To
address these challenges, we propose Tool4POI, a novel tool-augmented framework
that enables LLMs to perform open-set POI recommendation through external
retrieval and reasoning. Tool4POI consists of three key modules: preference
extraction module, multi-turn candidate retrieval module, and reranking module,
which together summarize long-term user interests, interact with external tools
to retrieve relevant POIs, and refine final recommendations based on recent
behaviors. Unlike existing methods, Tool4POI requires no task-specific
fine-tuning and is compatible with off-the-shelf LLMs in a plug-and-play
manner. Extensive experiments on three real-world datasets show that Tool4POI
substantially outperforms state-of-the-art baselines, achieving up to 40%
accuracy on challenging OOH scenarios where existing methods fail, and
delivering average improvements of 20% and 30% on Acc@5 and Acc@10,
respectively.
\\ ( https://arxiv.org/abs/2511.06405 ,  422kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06635
Date: Mon, 10 Nov 2025 02:26:14 GMT   (1449kb)

Title: Can LLM Annotations Replace User Clicks for Learning to Rank?
Authors: Lulu Yu, Keping Bi, Jiafeng Guo, Shihao Liu, Shuaiqiang Wang, Dawei
 Yin, Xueqi Cheng
Categories: cs.IR
Comments: 12 pages, 7 figures
\\
 Large-scale supervised data is essential for training modern ranking models,
but obtaining high-quality human annotations is costly. Click data has been
widely used as a low-cost alternative, and with recent advances in large
language models (LLMs), LLM-based relevance annotation has emerged as another
promising annotation. This paper investigates whether LLM annotations can
replace click data for learning to rank (LTR) by conducting a comprehensive
comparison across multiple dimensions. Experiments on both a public dataset,
TianGong-ST, and an industrial dataset, Baidu-Click, show that click-supervised
models perform better on high-frequency queries, while LLM
annotation-supervised models are more effective on medium- and low-frequency
queries. Further analysis shows that click-supervised models are better at
capturing document-level signals such as authority or quality, while LLM
annotation-supervised models are more effective at modeling semantic matching
between queries and documents and at distinguishing relevant from non-relevant
documents. Motivated by these observations, we explore two training strategies
-- data scheduling and frequency-aware multi-objective learning -- that
integrate both supervision signals. Both approaches enhance ranking performance
across queries at all frequency levels, with the latter being more effective.
Our code is available at
https://github.com/Trustworthy-Information-Access/LLMAnn_Click.
\\ ( https://arxiv.org/abs/2511.06635 ,  1449kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06668
Date: Mon, 10 Nov 2025 03:27:54 GMT   (1337kb)

Title: When Evidence Contradicts: Toward Safer Retrieval-Augmented Generation
 in Healthcare
Authors: Saeedeh Javadi, Sara Mirabi, Manan Gangar, Bahadorreza Ofoghi
Categories: cs.IR cs.LG
\\
 In high-stakes information domains such as healthcare, where large language
models (LLMs) can produce hallucinations or misinformation, retrieval-augmented
generation (RAG) has been proposed as a mitigation strategy, grounding model
outputs in external, domain-specific documents. Yet, this approach can
introduce errors when source documents contain outdated or contradictory
information. This work investigates the performance of five LLMs in generating
RAG-based responses to medicine-related queries. Our contributions are
three-fold: i) the creation of a benchmark dataset using consumer medicine
information documents from the Australian Therapeutic Goods Administration
(TGA), where headings are repurposed as natural language questions, ii) the
retrieval of PubMed abstracts using TGA headings, stratified across multiple
publication years, to enable controlled temporal evaluation of outdated
evidence, and iii) a comparative analysis of the frequency and impact of
outdated or contradictory content on model-generated responses, assessing how
LLMs integrate and reconcile temporally inconsistent information. Our findings
show that contradictions between highly similar abstracts do, in fact, degrade
performance, leading to inconsistencies and reduced factual accuracy in model
answers. These results highlight that retrieval similarity alone is
insufficient for reliable medical RAG and underscore the need for
contradiction-aware filtering strategies to ensure trustworthy responses in
high-stakes domains.
\\ ( https://arxiv.org/abs/2511.06668 ,  1337kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06803
Date: Mon, 10 Nov 2025 07:45:15 GMT   (2161kb)

Title: Learning to Fast Unrank in Collaborative Filtering Recommendation
Authors: Junpeng Zhao, Lin Li, Ming Li, Amran Bhuiyan, Jimmy Huang
Categories: cs.IR cs.AI cs.LG
\\
 Modern data-driven recommendation systems risk memorizing sensitive user
behavioral patterns, raising privacy concerns. Existing recommendation
unlearning methods, while capable of removing target data influence, suffer
from inefficient unlearning speed and degraded performance, failing to meet
real-time unlearning demands. Considering the ranking-oriented nature of
recommendation systems, we present unranking, the process of reducing the
ranking positions of target items while ensuring the formal guarantees of
recommendation unlearning. To achieve efficient unranking, we propose Learning
to Fast Unrank in Collaborative Filtering Recommendation (L2UnRank), which
operates through three key stages: (a) identifying the influenced scope via
interaction-based p-hop propagation, (b) computing structural and semantic
influences for entities within this scope, and (c) performing efficient,
ranking-aware parameter updates guided by influence information. Extensive
experiments across multiple datasets and backbone models demonstrate L2UnRank's
model-agnostic nature, achieving state-of-the-art unranking effectiveness and
maintaining recommendation quality comparable to retraining, while also
delivering a 50x speedup over existing methods. Codes are available at
https://github.com/Juniper42/L2UnRank.
\\ ( https://arxiv.org/abs/2511.06803 ,  2161kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06905
Date: Mon, 10 Nov 2025 10:00:26 GMT   (412kb)

Title: Have We Really Understood Collaborative Information? An Empirical
 Investigation
Authors: Xiaokun Zhang, Zhaochun Ren, Bowei He, Ziqiang Cui, Chen Ma
Categories: cs.IR
Comments: This work has been accepted by WSDM 2026
\\
 Collaborative information serves as the cornerstone of recommender systems
which typically focus on capturing it from user-item interactions to deliver
personalized services. However, current understanding of this crucial resource
remains limited. Specifically, a quantitative definition of collaborative
information is missing, its manifestation within user-item interactions remains
unclear, and its impact on recommendation performance is largely unknown. To
bridge this gap, this work conducts a systematic investigation of collaborative
information. We begin by clarifying collaborative information in terms of item
co-occurrence patterns, identifying its main characteristics, and presenting a
quantitative definition. We then estimate the distribution of collaborative
information from several aspects, shedding light on how collaborative
information is structured in practice. Furthermore, we evaluate the impact of
collaborative information on the performance of various recommendation
algorithms. Finally, we highlight challenges in effectively capturing
collaborative information and outlook promising directions for future research.
By establishing an empirical framework, we uncover many insightful observations
that advance our understanding of collaborative information and offer valuable
guidelines for developing more effective recommender systems.
\\ ( https://arxiv.org/abs/2511.06905 ,  412kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06937
Date: Mon, 10 Nov 2025 10:38:16 GMT   (4011kb)

Title: Fine-Tuning Diffusion-Based Recommender Systems via Reinforcement
 Learning with Reward Function Optimization
Authors: Yu Hou, Hua Li, Ha Young Kim, Won-Yong Shin
Categories: cs.IR cs.AI cs.LG cs.NI cs.SI
Comments: 14 pages, 12 figures, 9 tables
\\
 Diffusion models recently emerged as a powerful paradigm for recommender
systems, offering state-of-the-art performance by modeling the generative
process of user-item interactions. However, training such models from scratch
is both computationally expensive and yields diminishing returns once
convergence is reached. To remedy these challenges, we propose ReFiT, a new
framework that integrates Reinforcement learning (RL)-based Fine-Tuning into
diffusion-based recommender systems. In contrast to prior RL approaches for
diffusion models depending on external reward models, ReFiT adopts a
task-aligned design: it formulates the denoising trajectory as a Markov
decision process (MDP) and incorporates a collaborative signal-aware reward
function that directly reflects recommendation quality. By tightly coupling the
MDP structure with this reward signal, ReFiT empowers the RL agent to exploit
high-order connectivity for fine-grained optimization, while avoiding the noisy
or uninformative feedback common in naive reward designs. Leveraging policy
gradient optimization, ReFiT maximizes exact log-likelihood of observed
interactions, thereby enabling effective post hoc fine-tuning of diffusion
recommenders. Comprehensive experiments on wide-ranging real-world datasets
demonstrate that the proposed ReFiT framework (a) exhibits substantial
performance gains over strong competitors (up to 36.3% on sequential
recommendation), (b) demonstrates strong efficiency with linear complexity in
the number of users or items, and (c) generalizes well across multiple
diffusion-based recommendation scenarios. The source code and datasets are
publicly available at https://anonymous.4open.science/r/ReFiT-4C60.
\\ ( https://arxiv.org/abs/2511.06937 ,  4011kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07028
Date: Mon, 10 Nov 2025 12:22:33 GMT   (555kb)

Title: Wavelet Enhanced Adaptive Frequency Filter for Sequential Recommendation
Authors: Huayang Xu, Huanhuan Yuan, Guanfeng Liu, Junhua Fang, Lei Zhao,
 Pengpeng Zhao
Categories: cs.IR
\\
 Sequential recommendation has garnered significant attention for its ability
to capture dynamic preferences by mining users' historical interaction data.
Given that users' complex and intertwined periodic preferences are difficult to
disentangle in the time domain, recent research is exploring frequency domain
analysis to identify these hidden patterns. However, current
frequency-domain-based methods suffer from two key limitations: (i) They
primarily employ static filters with fixed characteristics, overlooking the
personalized nature of behavioral patterns; (ii) While the global discrete
Fourier transform excels at modeling long-range dependencies, it can blur
non-stationary signals and short-term fluctuations. To overcome these
limitations, we propose a novel method called Wavelet Enhanced Adaptive
Frequency Filter for Sequential Recommendation. Specifically, it consists of
two vital modules: dynamic frequency-domain filtering and wavelet feature
enhancement. The former is used to dynamically adjust filtering operations
based on behavioral sequences to extract personalized global information, and
the latter integrates wavelet transform to reconstruct sequences, enhancing
blurred non-stationary signals and short-term fluctuations. Finally, these two
modules work to achieve comprehensive performance and efficiency optimization
in long sequential recommendation scenarios. Extensive experiments on four
widely-used benchmark datasets demonstrate the superiority of our work.
\\ ( https://arxiv.org/abs/2511.07028 ,  555kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07295
Date: Mon, 10 Nov 2025 16:51:03 GMT   (2464kb)

Title: Hard vs. Noise: Resolving Hard-Noisy Sample Confusion in Recommender
 Systems via Large Language Models
Authors: Tianrui Song, Wen-Shuo Chao, Hao Liu
Categories: cs.IR cs.AI
Comments: Accepted by AAAI2026
\\
 Implicit feedback, employed in training recommender systems, unavoidably
confronts noise due to factors such as misclicks and position bias. Previous
studies have attempted to identify noisy samples through their diverged data
patterns, such as higher loss values, and mitigate their influence through
sample dropping or reweighting. However, we observed that noisy samples and
hard samples display similar patterns, leading to hard-noisy confusion issue.
Such confusion is problematic as hard samples are vital for modeling user
preferences. To solve this problem, we propose LLMHNI framework, leveraging two
auxiliary user-item relevance signals generated by Large Language Models (LLMs)
to differentiate hard and noisy samples. LLMHNI obtains user-item semantic
relevance from LLM-encoded embeddings, which is used in negative sampling to
select hard negatives while filtering out noisy false negatives. An objective
alignment strategy is proposed to project LLM-encoded embeddings, originally
for general language tasks, into a representation space optimized for user-item
relevance modeling. LLMHNI also exploits LLM-inferred logical relevance within
user-item interactions to identify hard and noisy samples. These LLM-inferred
interactions are integrated into the interaction graph and guide denoising with
cross-graph contrastive alignment. To eliminate the impact of unreliable
interactions induced by LLM hallucination, we propose a graph contrastive
learning strategy that aligns representations from randomly edge-dropped views
to suppress unreliable edges. Empirical results demonstrate that LLMHNI
significantly improves denoising and recommendation performance.
\\ ( https://arxiv.org/abs/2511.07295 ,  2464kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05549
Date: Sun, 2 Nov 2025 06:13:06 GMT   (624kb)

Title: AGRAG: Advanced Graph-based Retrieval-Augmented Generation for LLMs
Authors: Yubo Wang, Haoyang Li, Fei Teng and Lei Chen
Categories: cs.LG cs.AI cs.IR
\\
 Graph-based retrieval-augmented generation (Graph-based RAG) has demonstrated
significant potential in enhancing Large Language Models (LLMs) with structured
knowledge. However, existing methods face three critical challenges: Inaccurate
Graph Construction, caused by LLM hallucination; Poor Reasoning Ability, caused
by failing to generate explicit reasons telling LLM why certain chunks were
selected; and Inadequate Answering, which only partially answers the query due
to the inadequate LLM reasoning, making their performance lag behind NaiveRAG
on certain tasks. To address these issues, we propose AGRAG, an advanced
graph-based retrieval-augmented generation framework. When constructing the
graph, AGRAG substitutes the widely used LLM entity extraction method with a
statistics-based method, avoiding hallucination and error propagation. When
retrieval, AGRAG formulates the graph reasoning procedure as the Minimum Cost
Maximum Influence (MCMI) subgraph generation problem, where we try to include
more nodes with high influence score, but with less involving edge cost, to
make the generated reasoning paths more comprehensive. We prove this problem to
be NP-hard, and propose a greedy algorithm to solve it. The MCMI subgraph
generated can serve as explicit reasoning paths to tell LLM why certain chunks
were retrieved, thereby making the LLM better focus on the query-related part
contents of the chunks, reducing the impact of noise, and improving AGRAG's
reasoning ability. Furthermore, compared with the simple tree-structured
reasoning paths, our MCMI subgraph can allow more complex graph structures,
such as cycles, and improve the comprehensiveness of the generated reasoning
paths.
\\ ( https://arxiv.org/abs/2511.05549 ,  624kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05552
Date: Sun, 2 Nov 2025 21:12:38 GMT   (283kb)

Title: Deep one-gate per layer networks with skip connections are universal
 classifiers
Authors: Raul Rojas
Categories: cs.LG cs.AI
Comments: 5 pages, 6 figures
ACM-class: I.2.0
\\
 This paper shows how a multilayer perceptron with two hidden layers, which
has been designed to classify two classes of data points, can easily be
transformed into a deep neural network with one-gate layers and skip
connections.
\\ ( https://arxiv.org/abs/2511.05552 ,  283kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05556
Date: Mon, 3 Nov 2025 18:20:54 GMT   (819kb)

Title: Daily Forecasting for Annual Time Series Datasets Using Similarity-Based
 Machine Learning Methods: A Case Study in the Energy Market
Authors: Mahdi Goldani
Categories: cs.LG econ.GN q-fin.EC
\\
 The policy environment of countries changes rapidly, influencing macro-level
indicators such as the Energy Security Index. However, this index is only
reported annually, limiting its responsiveness to short-term fluctuations. To
address this gap, the present study introduces a daily proxy for the Energy
Security Index and applies it to forecast energy security at a daily
frequency.The study employs a two stage approach first, a suitable daily proxy
for the annual Energy Security Index is identified by applying six time series
similarity measures to key energy related variables. Second, the selected proxy
is modeled using the XGBoost algorithm to generate 15 day ahead forecasts,
enabling high frequency monitoring of energy security dynamics.As the result of
proxy choosing, Volume Brent consistently emerged as the most suitable proxy
across the majority of methods. The model demonstrated strong performance, with
an R squared of 0.981 on the training set and 0.945 on the test set, and
acceptable error metrics . The 15 day forecast of Brent volume indicates short
term fluctuations, with a peak around day 4, a decline until day 8, a rise near
day 10, and a downward trend toward day 15, accompanied by prediction
intervals.By integrating time series similarity measures with machine learning
based forecasting, this study provides a novel framework for converting low
frequency macroeconomic indicators into high frequency, actionable signals. The
approach enables real time monitoring of the Energy Security Index, offering
policymakers and analysts a scalable and practical tool to respond more rapidly
to fast changing policy and market conditions, especially in data scarce
environments.
\\ ( https://arxiv.org/abs/2511.05556 ,  819kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05558
Date: Tue, 4 Nov 2025 00:12:10 GMT   (5682kb)

Title: Diversified Flow Matching with Translation Identifiability
Authors: Sagar Shrestha and Xiao Fu
Categories: cs.LG cs.AI
\\
 Diversified distribution matching (DDM) finds a unified translation function
mapping a diverse collection of conditional source distributions to their
target counterparts. DDM was proposed to resolve content misalignment issues in
unpaired domain translation, achieving translation identifiability. However,
DDM has only been implemented using GANs due to its constraints on the
translation function. GANs are often unstable to train and do not provide the
transport trajectory information -- yet such trajectories are useful in
applications such as single-cell evolution analysis and robot route planning.
This work introduces diversified flow matching (DFM), an ODE-based framework
for DDM. Adapting flow matching (FM) to enforce a unified translation function
as in DDM is challenging, as FM learns the translation function's velocity
rather than the translation function itself. A custom bilevel
optimization-based training loss, a nonlinear interpolant, and a structural
reformulation are proposed to address these challenges, offering a tangible
implementation. To our knowledge, DFM is the first ODE-based approach
guaranteeing translation identifiability. Experiments on synthetic and
real-world datasets validate the proposed method.
\\ ( https://arxiv.org/abs/2511.05558 ,  5682kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05562
Date: Tue, 4 Nov 2025 02:33:23 GMT   (1097kb)

Title: Effective Test-Time Scaling of Discrete Diffusion through Iterative
 Refinement
Authors: Sanghyun Lee, Sunwoo Kim, Seungryong Kim, Jongho Park, Dongmin Park
Categories: cs.LG cs.AI
\\
 Test-time scaling through reward-guided generation remains largely unexplored
for discrete diffusion models despite its potential as a promising alternative.
In this work, we introduce Iterative Reward-Guided Refinement (IterRef), a
novel test-time scaling method tailored to discrete diffusion that leverages
reward- guided noising-denoising transitions to progressively refine misaligned
intermediate states. We formalize this process within a Multiple-Try Metropolis
(MTM) framework, proving convergence to the reward-aligned distribution. Unlike
prior methods that assume the current state is already aligned with the reward
distribution and only guide the subsequent transition, our approach explicitly
refines each state in situ, progressively steering it toward the optimal
intermediate distribution. Across both text and image domains, we evaluate
IterRef on diverse discrete diffusion models and observe consistent
improvements in reward-guided generation quality. In particular, IterRef
achieves striking gains under low compute budgets, far surpassing prior
state-of-the-art baselines.
\\ ( https://arxiv.org/abs/2511.05562 ,  1097kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05563
Date: Tue, 4 Nov 2025 02:37:37 GMT   (306kb)

Title: Lookahead Unmasking Elicits Accurate Decoding in Diffusion Language
 Models
Authors: Sanghyun Lee, Seungryong Kim, Jongho Park, Dongmin Park
Categories: cs.LG cs.AI
\\
 Masked Diffusion Models (MDMs) as language models generate by iteratively
unmasking tokens, yet their performance crucially depends on the inference time
order of unmasking. Prevailing heuristics, such as confidence based sampling,
are myopic: they optimize locally, fail to leverage extra test-time compute,
and let early decoding mistakes cascade. We propose Lookahead Unmasking
(LookUM), which addresses these concerns by reformulating sampling as path
selection over all possible unmasking orders without the need for an external
reward model. Our framework couples (i) a path generator that proposes paths by
sampling from pools of unmasking sets with (ii) a verifier that computes the
uncertainty of the proposed paths and performs importance sampling to
subsequently select the final paths. Empirically, erroneous unmasking
measurably inflates sequence level uncertainty, and our method exploits this to
avoid error-prone trajectories. We validate our framework across six
benchmarks, such as mathematics, planning, and coding, and demonstrate
consistent performance improvements. LookUM requires only two to three paths to
achieve peak performance, demonstrating remarkably efficient path selection.
The consistent improvements on both LLaDA and post-trained LLaDA 1.5 are
particularly striking: base LLaDA with LookUM rivals the performance of
RL-tuned LLaDA 1.5, while LookUM further enhances LLaDA 1.5 itself showing that
uncertainty based verification provides orthogonal benefits to reinforcement
learning and underscoring the versatility of our framework. Code will be
publicly released.
\\ ( https://arxiv.org/abs/2511.05563 ,  306kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05568
Date: Tue, 4 Nov 2025 10:20:21 GMT   (818kb)

Title: Adaptive Sample-Level Framework Motivated by Distributionally Robust
 Optimization with Variance-Based Radius Assignment for Enhanced Neural
 Network Generalization Under Distribution Shift
Authors: Aheer Sravon, Devdyuti Mazumder, Md. Ibrahim
Categories: cs.LG cs.CV
Comments: Conference
\\
 Distribution shifts and minority subpopulations frequently undermine the
reliability of deep neural networks trained using Empirical Risk Minimization
(ERM). Distributionally Robust Optimization (DRO) addresses this by optimizing
for the worst-case risk within a neighborhood of the training distribution.
However, conventional methods depend on a single, global robustness budget,
which can lead to overly conservative models or a misallocation of robustness.
We propose a variance-driven, adaptive, sample-level DRO (Var-DRO) framework
that automatically identifies high-risk training samples and assigns a
personalized robustness budget to each based on its online loss variance. Our
formulation employs two-sided, KL-divergence-style bounds to constrain the
ratio between adversarial and empirical weights for every sample. This results
in a linear inner maximization problem over a convex polytope, which admits an
efficient water-filling solution. To stabilize training, we introduce a warmup
phase and a linear ramp schedule for the global cap on per-sample budgets,
complemented by label smoothing for numerical robustness. Evaluated on
CIFAR-10-C (corruptions), our method achieves the highest overall mean accuracy
compared to ERM and KL-DRO. On Waterbirds, Var-DRO improves overall performance
while matching or surpassing KL-DRO. On the original CIFAR-10 dataset, Var-DRO
remains competitive, exhibiting the modest trade-off anticipated when
prioritizing robustness. The proposed framework is unsupervised (requiring no
group labels), straightforward to implement, theoretically sound, and
computationally efficient.
\\ ( https://arxiv.org/abs/2511.05568 ,  818kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05569
Date: Tue, 4 Nov 2025 11:45:58 GMT   (3088kb)

Title: Data-driven jet fuel demand forecasting: A case study of Copenhagen
 Airport
Authors: Alessandro Contini, Davide Cacciarelli, Murat Kulahci
Categories: cs.LG
\\
 Accurate forecasting of jet fuel demand is crucial for optimizing supply
chain operations in the aviation market. Fuel distributors specifically require
precise estimates to avoid inventory shortages or excesses. However, there is a
lack of studies that analyze the jet fuel demand forecasting problem using
machine learning models. Instead, many industry practitioners rely on
deterministic or expertise-based models. In this research, we evaluate the
performance of data-driven approaches using a substantial amount of data
obtained from a major aviation fuel distributor in the Danish market. Our
analysis compares the predictive capabilities of traditional time series
models, Prophet, LSTM sequence-to-sequence neural networks, and hybrid models.
A key challenge in developing these models is the required forecasting horizon,
as fuel demand needs to be predicted for the next 30 days to optimize sourcing
strategies. To ensure the reliability of the data-driven approaches and provide
valuable insights to practitioners, we analyze three different datasets. The
primary objective of this study is to present a comprehensive case study on jet
fuel demand forecasting, demonstrating the advantages of employing data-driven
models and highlighting the impact of incorporating additional variables in the
predictive models.
\\ ( https://arxiv.org/abs/2511.05569 ,  3088kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05577
Date: Tue, 4 Nov 2025 22:32:53 GMT   (670kb)

Title: Fine-Tuning Vision-Language Models for Multimodal Polymer Property
 Prediction
Authors: An Vuong, Minh-Hao Van, Prateek Verma, Chen Zhao and Xintao Wu
Categories: cs.LG cond-mat.mtrl-sci cs.AI cs.CL
\\
 Vision-Language Models (VLMs) have shown strong performance in tasks like
visual question answering and multimodal text generation, but their
effectiveness in scientific domains such as materials science remains limited.
While some machine learning methods have addressed specific challenges in this
field, there is still a lack of foundation models designed for broad tasks like
polymer property prediction using multimodal data. In this work, we present a
multimodal polymer dataset to fine-tune VLMs through instruction-tuning pairs
and assess the impact of multimodality on prediction performance. Our
fine-tuned models, using LoRA, outperform unimodal and baseline approaches,
demonstrating the benefits of multimodal learning. Additionally, this approach
reduces the need to train separate models for different properties, lowering
deployment and maintenance costs.
\\ ( https://arxiv.org/abs/2511.05577 ,  670kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05582
Date: Wed, 5 Nov 2025 08:14:12 GMT   (1662kb)

Title: Distillation-Accelerated Uncertainty Modeling for Multi-Objective RTA
 Interception
Authors: Gaoxiang Zhao, Ruina Qiu, Pengpeng Zhao, Rongjin Wang, Zhangang Lin,
 Xiaoqiang Wang
Categories: cs.LG cs.GT
\\
 Real-Time Auction (RTA) Interception aims to filter out invalid or irrelevant
traffic to enhance the integrity and reliability of downstream data. However,
two key challenges remain: (i) the need for accurate estimation of traffic
quality together with sufficiently high confidence in the model's predictions,
typically addressed through uncertainty modeling, and (ii) the efficiency
bottlenecks that such uncertainty modeling introduces in real-time applications
due to repeated inference. To address these challenges, we propose DAUM, a
joint modeling framework that integrates multi-objective learning with
uncertainty modeling, yielding both traffic quality predictions and reliable
confidence estimates. Building on DAUM, we further apply knowledge distillation
to reduce the computational overhead of uncertainty modeling, while largely
preserving predictive accuracy and retaining the benefits of uncertainty
estimation. Experiments on the JD advertisement dataset demonstrate that DAUM
consistently improves predictive performance, with the distilled model
delivering a tenfold increase in inference speed.
\\ ( https://arxiv.org/abs/2511.05582 ,  1662kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05585
Date: Wed, 5 Nov 2025 10:00:03 GMT   (2817kb)

Title: Depth-induced NTK: Bridging Over-parameterized Neural Networks and Deep
 Neural Kernels
Authors: Yong-Ming Tian, Shuang Liang, Shao-Qun Zhang, Feng-Lei Fan
Categories: cs.LG
\\
 While deep learning has achieved remarkable success across a wide range of
applications, its theoretical understanding of representation learning remains
limited. Deep neural kernels provide a principled framework to interpret
over-parameterized neural networks by mapping hierarchical feature
transformations into kernel spaces, thereby combining the expressive power of
deep architectures with the analytical tractability of kernel methods. Recent
advances, particularly neural tangent kernels (NTKs) derived by gradient inner
products, have established connections between infinitely wide neural networks
and nonparametric Bayesian inference. However, the existing NTK paradigm has
been predominantly confined to the infinite-width regime, while overlooking the
representational role of network depth. To address this gap, we propose a
depth-induced NTK kernel based on a shortcut-related architecture, which
converges to a Gaussian process as the network depth approaches infinity. We
theoretically analyze the training invariance and spectrum properties of the
proposed kernel, which stabilizes the kernel dynamics and mitigates
degeneration. Experimental results further underscore the effectiveness of our
proposed method. Our findings significantly extend the existing landscape of
the neural kernel theory and provide an in-depth understanding of deep learning
and the scaling law.
\\ ( https://arxiv.org/abs/2511.05585 ,  2817kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05586
Date: Wed, 5 Nov 2025 10:24:21 GMT   (3678kb)

Title: Prompting Neural-Guided Equation Discovery Based on Residuals
Authors: Jannis Brugger and Viktor Pfanschilling and David Richter and Mira
 Mezini and Stefan Kramer
Categories: cs.LG
Comments: 16 pages, 7 figures, Discovery Science 2025
ACM-class: I.2.6; I.1.1
DOI: 10.1007/978-3-032-05461-6_7
\\
 Neural-guided equation discovery systems use a data set as prompt and predict
an equation that describes the data set without extensive search. However, if
the equation does not meet the user's expectations, there are few options for
getting other equation suggestions without intensive work with the system. To
fill this gap, we propose Residuals for Equation Discovery (RED), a
post-processing method that improves a given equation in a targeted manner,
based on its residuals. By parsing the initial equation to a syntax tree, we
can use node-based calculation rules to compute the residual for each
subequation of the initial equation. It is then possible to use this residual
as new target variable in the original data set and generate a new prompt. If,
with the new prompt, the equation discovery system suggests a subequation
better than the old subequation on a validation set, we replace the latter by
the former. RED is usable with any equation discovery system, is fast to
calculate, and is easy to extend for new mathematical operations. In
experiments on 53 equations from the Feynman benchmark, we show that it not
only helps to improve all tested neural-guided systems, but also all tested
classical genetic programming systems.
\\ ( https://arxiv.org/abs/2511.05586 ,  3678kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05589
Date: Wed, 5 Nov 2025 11:39:32 GMT   (218kb)

Title: CoPRIS: Efficient and Stable Reinforcement Learning via
 Concurrency-Controlled Partial Rollout with Importance Sampling
Authors: Zekai Qu, Yinxu Pan, Ao Sun, Chaojun Xiao, Xu Han
Categories: cs.LG cs.AI
Comments: 13 pages, 4 figures
\\
 Reinforcement learning (RL) post-training has become a trending paradigm for
enhancing the capabilities of large language models (LLMs). Most existing RL
systems for LLMs operate in a fully synchronous manner, where training must
wait for the rollout of an entire batch to complete. This design leads to
severe inefficiencies, as extremely long trajectories can stall the entire
rollout process and leave many GPUs idle. To address this issue, we propose
Concurrency- Controlled Partial Rollout with Importance Sampling (CoPRIS),
which mitigates long-tail inefficiencies by maintaining a fixed number of
concurrent rollouts, early-terminating once sufficient samples are collected,
and reusing unfinished trajectories in subsequent rollouts. To mitigate the
impact of off-policy trajectories, we introduce Cross-stage Importance Sampling
Correction, which concatenates buffered log probabilities from the previous
policy with those recomputed under the current policy for importance sampling
correction. Experiments on challenging mathematical reasoning benchmarks show
that CoPRIS achieves up to 1.94x faster training while maintaining comparable
or superior performance to synchronous RL systems. The code of CoPRIS is
available at https://github.com/777pomingzi/CoPRIS.
\\ ( https://arxiv.org/abs/2511.05589 ,  218kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05591
Date: Wed, 5 Nov 2025 12:38:08 GMT   (1896kb)

Title: FedSparQ: Adaptive Sparse Quantization with Error Feedback for Robust &
 Efficient Federated Learning
Authors: Chaimaa Medjadji, Sadi Alawadi, Feras M. Awaysheh, Guilain Leduc,
 Sylvain Kubler, Yves Le Traon
Categories: cs.LG
\\
 Federated Learning (FL) enables collaborative model training across
decentralized clients while preserving data privacy by keeping raw data local.
However, FL suffers from significant communication overhead due to the frequent
exchange of high-dimensional model updates over constrained networks. In this
paper, we present FedSparQ, a lightweight compression framework that
dynamically sparsifies the gradient of each client through an adaptive
threshold, applies half-precision quanti- zation to retained entries and
integrates residuals from error feedback to prevent loss of information.
FedSparQ requires no manual tuning of sparsity rates or quantization schedules,
adapts seamlessly to both homogeneous and heterogeneous data distributions, and
is agnostic to model architecture. Through extensive empirical evaluation on
vision benchmarks under independent and identically distributed (IID) and
non-IID data, we show that FedSparQ substantially reduces communication
overhead (reducing by 90% of bytes sent compared to FedAvg) while preserving or
improving model accuracy (improving by 6% compared to FedAvg non-compressed
solution or to state-of-the- art compression models) and enhancing convergence
robustness (by 50%, compared to the other baselines). Our approach provides a
practical, easy-to-deploy solution for bandwidth- constrained federated
deployments and lays the groundwork for future extensions in adaptive precision
and privacy-preserving protocols.
\\ ( https://arxiv.org/abs/2511.05591 ,  1896kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05592
Date: Wed, 5 Nov 2025 13:07:26 GMT   (4716kb)

Title: GRAVER: Generative Graph Vocabularies for Robust Graph Foundation Models
 Fine-tuning
Authors: Haonan Yuan, Qingyun Sun, Junhua Shi, Xingcheng Fu, Bryan Hooi,
 Jianxin Li, Philip S. Yu
Categories: cs.LG
Comments: Accepted by the NeurIPS 2025
\\
 Inspired by the remarkable success of foundation models in language and
vision, Graph Foundation Models (GFMs) hold significant promise for broad
applicability across diverse graph tasks and domains. However, existing GFMs
struggle with unstable few-shot fine-tuning, where both performance and
adaptation efficiency exhibit significant fluctuations caused by the randomness
in the support sample selection and structural discrepancies between the
pre-trained and target graphs. How to fine-tune GFMs robustly and efficiently
to enable trustworthy knowledge transfer across domains and tasks is the major
challenge. In this paper, we propose GRAVER, a novel Generative gRAph
VocabulariEs for Robust GFM fine-tuning framework that tackles the
aforementioned instability via generative augmentations. Specifically, to
identify transferable units, we analyze and extract key class-specific subgraph
patterns by ego-graph disentanglement and validate their transferability both
theoretically and empirically. To enable effective pre-training across diverse
domains, we leverage a universal task template based on ego-graph similarity
and construct graph vocabularies via graphon-based generative experts. To
facilitate robust and efficient prompt fine-tuning, we grave the support
samples with in-context vocabularies, where the lightweight MoE-CoE network
attentively routes knowledge from source domains. Extensive experiments
demonstrate the superiority of GRAVER over effectiveness, robustness, and
efficiency on downstream few-shot node and graph classification tasks compared
with 15 state-of-the-art baselines.
\\ ( https://arxiv.org/abs/2511.05592 ,  4716kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05593
Date: Wed, 5 Nov 2025 13:11:30 GMT   (1745kb,D)

Title: Gradient Projection onto Historical Descent Directions for
 Communication-Efficient Federated Learning
Authors: Arnaud Descours (UCBL), L\'eonard Deroose, Jan Ramon
Categories: cs.LG cs.NE math.OC math.ST stat.TH
\\
 Federated Learning (FL) enables decentralized model training across multiple
clients while optionally preserving data privacy. However, communication
efficiency remains a critical bottleneck, particularly for large-scale models.
In this work, we introduce two complementary algorithms: ProjFL, designed for
unbiased compressors, and ProjFL+EF, tailored for biased compressors through an
Error Feedback mechanism. Both methods rely on projecting local gradients onto
a shared client-server subspace spanned by historical descent directions,
enabling efficient information exchange with minimal communication overhead. We
establish convergence guarantees for both algorithms under strongly convex,
convex, and non-convex settings. Empirical evaluations on standard FL
classification benchmarks with deep neural networks show that ProjFL and
ProjFL+EF achieve accuracy comparable to existing baselines while substantially
reducing communication costs.
\\ ( https://arxiv.org/abs/2511.05593 ,  1745kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05594
Date: Wed, 5 Nov 2025 13:21:29 GMT   (2779kb)

Title: Optimizing Predictive Maintenance in Intelligent Manufacturing: An
 Integrated FNO-DAE-GNN-PPO MDP Framework
Authors: Shiqing Qiu
Categories: cs.LG cs.CE
\\
 In the era of smart manufacturing, predictive maintenance (PdM) plays a
pivotal role in improving equipment reliability and reducing operating costs.
In this paper, we propose a novel Markov Decision Process (MDP) framework that
integrates advanced soft computing techniques - Fourier Neural Operator (FNO),
Denoising Autoencoder (DAE), Graph Neural Network (GNN), and Proximal Policy
Optimisation (PPO) - to address the multidimensional challenges of predictive
maintenance in complex manufacturing systems. Specifically, the proposed
framework innovatively combines the powerful frequency-domain representation
capability of FNOs to capture high-dimensional temporal patterns; DAEs to
achieve robust, noise-resistant latent state embedding from complex
non-Gaussian sensor data; and GNNs to accurately represent inter-device
dependencies for coordinated system-wide maintenance decisions. Furthermore, by
exploiting PPO, the framework ensures stable and efficient optimisation of
long-term maintenance strategies to effectively handle uncertainty and
non-stationary dynamics. Experimental validation demonstrates that the approach
significantly outperforms multiple deep learning baseline models with up to 13%
cost reduction, as well as strong convergence and inter-module synergy. The
framework has considerable industrial potential to effectively reduce downtime
and operating expenses through data-driven strategies.
\\ ( https://arxiv.org/abs/2511.05594 ,  2779kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05595
Date: Wed, 5 Nov 2025 14:06:19 GMT   (2605kb)

Title: FlowNet: Modeling Dynamic Spatio-Temporal Systems via Flow Propagation
Authors: Yutong Feng, Xu Liu, Yutong Xia, Yuxuan Liang
Categories: cs.LG cs.AI
\\
 Accurately modeling complex dynamic spatio-temporal systems requires
capturing flow-mediated interdependencies and context-sensitive interaction
dynamics. Existing methods, predominantly graph-based or attention-driven, rely
on similarity-driven connectivity assumptions, neglecting asymmetric flow
exchanges that govern system evolution. We propose Spatio-Temporal Flow, a
physics-inspired paradigm that explicitly models dynamic node couplings through
quantifiable flow transfers governed by conservation principles. Building on
this, we design FlowNet, a novel architecture leveraging flow tokens as
information carriers to simulate source-to-destination transfers via Flow
Allocation Modules, ensuring state redistribution aligns with conservation
laws. FlowNet dynamically adjusts the interaction radius through an Adaptive
Spatial Masking module, suppressing irrelevant noise while enabling
context-aware propagation. A cascaded architecture enhances scalability and
nonlinear representation capacity. Experiments demonstrate that FlowNet
significantly outperforms existing state-of-the-art approaches on seven metrics
in the modeling of three real-world systems, validating its efficiency and
physical interpretability. We establish a principled methodology for modeling
complex systems through spatio-temporal flow interactions.
\\ ( https://arxiv.org/abs/2511.05595 ,  2605kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05596
Date: Wed, 5 Nov 2025 14:09:03 GMT   (13313kb)

Title: AutoHood3D: A Multi-Modal Benchmark for Automotive Hood Design and
 Fluid-Structure Interaction
Authors: Vansh Sharma and Harish Jai Ganesh and Maryam Akram and Wanjiao Liu
 and Venkat Raman
Categories: cs.LG physics.comp-ph physics.flu-dyn
ACM-class: I.2.0; I.2.6
Journal-ref: 39th Conference on Neural Information Processing Systems (NeurIPS
 2025)
\\
 This study presents a new high-fidelity multi-modal dataset containing 16000+
geometric variants of automotive hoods useful for machine learning (ML)
applications such as engineering component design and process optimization, and
multiphysics system surrogates. The dataset is centered on a practical
multiphysics problem-hood deformation from fluid entrapment and inertial
loading during rotary-dip painting. Each hood is numerically modeled with a
coupled Large-Eddy Simulation (LES)-Finite Element Analysis (FEA), using 1.2M
cells in total to ensure spatial and temporal accuracy. The dataset provides
time-resolved physical fields, along with STL meshes and structured natural
language prompts for text-to-geometry synthesis. Existing datasets are either
confined to 2D cases, exhibit limited geometric variations, or lack the
multi-modal annotations and data structures - shortcomings we address with
AutoHood3D. We validate our numerical methodology, establish quantitative
baselines across five neural architectures, and demonstrate systematic
surrogate errors in displacement and force predictions. These findings motivate
the design of novel approaches and multiphysics loss functions that enforce
fluid-solid coupling during model training. By providing fully reproducible
workflows, AutoHood3D enables physics-aware ML development, accelerates
generative-design iteration, and facilitates the creation of new FSI
benchmarks. Dataset and code URLs in Appendix.
\\ ( https://arxiv.org/abs/2511.05596 ,  13313kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05605
Date: Thu, 6 Nov 2025 08:34:53 GMT   (796kb)

Title: FiCABU: A Fisher-Based, Context-Adaptive Machine Unlearning Processor
 for Edge AI
Authors: Eun-Su Cho, Jongin Choi, Jeongmin Jin, Jae-Jin Lee and Woojoo Lee
Categories: cs.LG cs.AR
Comments: 8 pages, 6 figures, 4 tables, DATE 2026 accepted paper
\\
 Machine unlearning, driven by privacy regulations and the "right to be
forgotten", is increasingly needed at the edge, yet server-centric or
retraining-heavy methods are impractical under tight computation and energy
budgets. We present FiCABU (Fisher-based Context-Adaptive Balanced Unlearning),
a software-hardware co-design that brings unlearning to edge AI processors.
FiCABU combines (i) Context-Adaptive Unlearning, which begins edits from
back-end layers and halts once the target forgetting is reached, with (ii)
Balanced Dampening, which scales dampening strength by depth to preserve retain
accuracy. These methods are realized in a full RTL design of a RISC-V edge AI
processor that integrates two lightweight IPs for Fisher estimation and
dampening into a GEMM-centric streaming pipeline, validated on an FPGA
prototype and synthesized in 45 nm for power analysis. Across CIFAR-20 and
PinsFaceRecognition with ResNet-18 and ViT, FiCABU achieves random-guess forget
accuracy while matching the retraining-free Selective Synaptic Dampening (SSD)
baseline on retain accuracy, reducing computation by up to 87.52 percent
(ResNet-18) and 71.03 percent (ViT). On the INT8 hardware prototype, FiCABU
further improves retain preservation and reduces energy to 6.48 percent
(CIFAR-20) and 0.13 percent (PinsFaceRecognition) of the SSD baseline. In sum,
FiCABU demonstrates that back-end-first, depth-aware unlearning can be made
both practical and efficient for resource-constrained edge AI devices.
\\ ( https://arxiv.org/abs/2511.05605 ,  796kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05610
Date: Thu, 6 Nov 2025 09:43:34 GMT   (221kb)

Title: Conformal Prediction-Driven Adaptive Sampling for Digital Twins of Water
 Distribution Networks
Authors: Mohammadhossein Homaei, Oscar Mogollon Gutierrez, Ruben Molano, Andres
 Caro, Mar Avila
Categories: cs.LG cs.AI math.OC
Comments: 6 Pages, 7 tables, 1 Figure
\\
 Digital Twins (DTs) for Water Distribution Networks (WDNs) require accurate
state estimation with limited sensors. Uniform sampling often wastes resources
across nodes with different uncertainty. We propose an adaptive framework
combining LSTM forecasting and Conformal Prediction (CP) to estimate node-wise
uncertainty and focus sensing on the most uncertain points. Marginal CP is used
for its low computational cost, suitable for real-time DTs. Experiments on
Hanoi, Net3, and CTOWN show 33-34% lower demand error than uniform sampling at
40% coverage and maintain 89.4-90.2% empirical coverage with only 5-10% extra
computation.
\\ ( https://arxiv.org/abs/2511.05610 ,  221kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05614
Date: Thu, 6 Nov 2025 17:07:18 GMT   (405kb)

Title: An MLCommons Scientific Benchmarks Ontology
Authors: Ben Hawks, Gregor von Laszewski, Matthew D. Sinclair, Marco Colombo,
 Shivaram Venkataraman, Rutwik Jain, Yiwei Jiang, Nhan Tran, Geoffrey Fox
Categories: cs.LG cs.AI cs.PF physics.comp-ph
Comments: 16 Pages, 3 Figures
Report-no: FERMILAB-PUB-25-0701-CSAID
\\
 Scientific machine learning research spans diverse domains and data
modalities, yet existing benchmark efforts remain siloed and lack
standardization. This makes novel and transformative applications of machine
learning to critical scientific use-cases more fragmented and less clear in
pathways to impact. This paper introduces an ontology for scientific
benchmarking developed through a unified, community-driven effort that extends
the MLCommons ecosystem to cover physics, chemistry, materials science,
biology, climate science, and more. Building on prior initiatives such as
XAI-BENCH, FastML Science Benchmarks, PDEBench, and the SciMLBench framework,
our effort consolidates a large set of disparate benchmarks and frameworks into
a single taxonomy of scientific, application, and system-level benchmarks. New
benchmarks can be added through an open submission workflow coordinated by the
MLCommons Science Working Group and evaluated against a six-category rating
rubric that promotes and identifies high-quality benchmarks, enabling
stakeholders to select benchmarks that meet their specific needs. The
architecture is extensible, supporting future scientific and AI/ML motifs, and
we discuss methods for identifying emerging computing patterns for unique
scientific workloads. The MLCommons Science Benchmarks Ontology provides a
standardized, scalable foundation for reproducible, cross-domain benchmarking
in scientific machine learning. A companion webpage for this work has also been
developed as the effort evolves: https://mlcommons-science.github.io/benchmark/
\\ ( https://arxiv.org/abs/2511.05614 ,  405kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05615
Date: Thu, 6 Nov 2025 17:18:13 GMT   (10124kb)

Title: wa-hls4ml: A Benchmark and Surrogate Models for hls4ml Resource and
 Latency Estimation
Authors: Benjamin Hawks, Jason Weitz, Dmitri Demler, Karla Tame-Narvaez, Dennis
 Plotnikov, Mohammad Mehdi Rahimifar, Hamza Ezzaoui Rahali, Audrey C.
 Therrien, Donovan Sproule, Elham E Khoda, Keegan A. Smith, Russell Marroquin,
 Giuseppe Di Guglielmo, Nhan Tran, Javier Duarte, Vladimir Loncar
Categories: cs.LG cs.AI cs.AR physics.ins-det
Comments: 30 pages, 18 figures
Report-no: FERMILAB-PUB-25-0359-CSAID
\\
 As machine learning (ML) is increasingly implemented in hardware to address
real-time challenges in scientific applications, the development of advanced
toolchains has significantly reduced the time required to iterate on various
designs. These advancements have solved major obstacles, but also exposed new
challenges. For example, processes that were not previously considered
bottlenecks, such as hardware synthesis, are becoming limiting factors in the
rapid iteration of designs. To mitigate these emerging constraints, multiple
efforts have been undertaken to develop an ML-based surrogate model that
estimates resource usage of ML accelerator architectures. We introduce
wa-hls4ml, a benchmark for ML accelerator resource and latency estimation, and
its corresponding initial dataset of over 680,000 fully connected and
convolutional neural networks, all synthesized using hls4ml and targeting
Xilinx FPGAs. The benchmark evaluates the performance of resource and latency
predictors against several common ML model architectures, primarily originating
from scientific domains, as exemplar models, and the average performance across
a subset of the dataset. Additionally, we introduce GNN- and transformer-based
surrogate models that predict latency and resources for ML accelerators. We
present the architecture and performance of the models and find that the models
generally predict latency and resources for the 75% percentile within several
percent of the synthesized resources on the synthetic test dataset.
\\ ( https://arxiv.org/abs/2511.05615 ,  10124kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05619
Date: Thu, 6 Nov 2025 21:08:51 GMT   (620kb)

Title: Frequency Matters: When Time Series Foundation Models Fail Under
 Spectral Shift
Authors: Tianze Wang, Sofiane Ennadir, John Pertoft, Gabriela Zarzar Gandler,
 Lele Cao, Zineb Senane, Styliani Katsarou, Sahar Asadi, Axel Karlsson, and
 Oleg Smirnov
Categories: cs.LG cs.AI
Comments: Accepted and presented at NeurIPS 2025 Workshop on Recent Advances in
 Time Series Foundation Models (BERT2S)
\\
 Time series foundation models (TSFMs) have shown strong results on public
benchmarks, prompting comparisons to a "BERT moment" for time series. Their
effectiveness in industrial settings, however, remains uncertain. We examine
why TSFMs often struggle to generalize and highlight spectral shift (a mismatch
between the dominant frequency components in downstream tasks and those
represented during pretraining) as a key factor. We present evidence from an
industrial-scale player engagement prediction task in mobile gaming, where
TSFMs underperform domain-adapted baselines. To isolate the mechanism, we
design controlled synthetic experiments contrasting signals with seen versus
unseen frequency bands, observing systematic degradation under spectral
mismatch. These findings position frequency awareness as critical for robust
TSFM deployment and motivate new pretraining and evaluation protocols that
explicitly account for spectral diversity.
\\ ( https://arxiv.org/abs/2511.05619 ,  620kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05620
Date: Thu, 6 Nov 2025 22:16:56 GMT   (93kb)

Title: Fooling Algorithms in Non-Stationary Bandits using Belief Inertia
Authors: Gal Mendelson, Eyal Tadmor
Categories: cs.LG math.PR stat.ML
\\
 We study the problem of worst case regret in piecewise stationary multi armed
bandits. While the minimax theory for stationary bandits is well established,
understanding analogous limits in time-varying settings is challenging.
Existing lower bounds rely on what we refer to as infrequent sampling
arguments, where long intervals without exploration allow adversarial reward
changes that induce large regret.
 In this paper, we introduce a fundamentally different approach based on a
belief inertia argument. Our analysis captures how an algorithm's empirical
beliefs, encoded through historical reward averages, create momentum that
resists new evidence after a change. We show how this inertia can be exploited
to construct adversarial instances that mislead classical algorithms such as
Explore Then Commit, epsilon greedy, and UCB, causing them to suffer regret
that grows linearly with T and with a substantial constant factor, regardless
of how their parameters are tuned, even with a single change point.
 We extend the analysis to algorithms that periodically restart to handle non
stationarity and prove that, even then, the worst case regret remains linear in
T. Our results indicate that utilizing belief inertia can be a powerful method
for deriving sharp lower bounds in non stationary bandits.
\\ ( https://arxiv.org/abs/2511.05620 ,  93kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05628
Date: Fri, 7 Nov 2025 02:59:51 GMT   (312kb)

Title: Unveiling the Training Dynamics of ReLU Networks through a Linear Lens
Authors: Longqing Ye
Categories: cs.LG cs.AI
\\
 Deep neural networks, particularly those employing Rectified Linear Units
(ReLU), are often perceived as complex, high-dimensional, non-linear systems.
This complexity poses a significant challenge to understanding their internal
learning mechanisms. In this work, we propose a novel analytical framework that
recasts a multi-layer ReLU network into an equivalent single-layer linear model
with input-dependent "effective weights". For any given input sample, the
activation pattern of ReLU units creates a unique computational path,
effectively zeroing out a subset of weights in the network. By composing the
active weights across all layers, we can derive an effective weight matrix,
$W_{\text{eff}}(x)$, that maps the input directly to the output for that
specific sample. We posit that the evolution of these effective weights reveals
fundamental principles of representation learning. Our work demonstrates that
as training progresses, the effective weights corresponding to samples from the
same class converge, while those from different classes diverge. By tracking
the trajectories of these sample-wise effective weights, we provide a new lens
through which to interpret the formation of class-specific decision boundaries
and the emergence of semantic representations within the network.
\\ ( https://arxiv.org/abs/2511.05628 ,  312kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05629
Date: Fri, 7 Nov 2025 03:43:53 GMT   (8603kb)

Title: SSTODE: Ocean-Atmosphere Physics-Informed Neural ODEs for Sea Surface
 Temperature Prediction
Authors: Zheng Jiang, Wei Wang, Gaowei Zhang, Yi Wang
Categories: cs.LG cs.AI physics.ao-ph
Comments: To be published in the Proceedings of AAAI-AISI 2026
\\
 Sea Surface Temperature (SST) is crucial for understanding upper-ocean
thermal dynamics and ocean-atmosphere interactions, which have profound
economic and social impacts. While data-driven models show promise in SST
prediction, their black-box nature often limits interpretability and overlooks
key physical processes. Recently, physics-informed neural networks have been
gaining momentum but struggle with complex ocean-atmosphere dynamics due to 1)
inadequate characterization of seawater movement (e.g., coastal upwelling) and
2) insufficient integration of external SST drivers (e.g., turbulent heat
fluxes). To address these challenges, we propose SSTODE, a physics-informed
Neural Ordinary Differential Equations (Neural ODEs) framework for SST
prediction. First, we derive ODEs from fluid transport principles,
incorporating both advection and diffusion to model ocean spatiotemporal
dynamics. Through variational optimization, we recover a latent velocity field
that explicitly governs the temporal dynamics of SST. Building upon ODE, we
introduce an Energy Exchanges Integrator (EEI)-inspired by ocean heat budget
equations-to account for external forcing factors. Thus, the variations in the
components of these factors provide deeper insights into SST dynamics.
Extensive experiments demonstrate that SSTODE achieves state-of-the-art
performances in global and regional SST forecasting benchmarks. Furthermore,
SSTODE visually reveals the impact of advection dynamics, thermal diffusion
patterns, and diurnal heating-cooling cycles on SST evolution. These findings
demonstrate the model's interpretability and physical consistency.
\\ ( https://arxiv.org/abs/2511.05629 ,  8603kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05633
Date: Fri, 7 Nov 2025 07:48:12 GMT   (383kb)

Title: Physics-Guided Machine Learning for Uncertainty Quantification in
 Turbulence Models
Authors: Minghan Chu and Weicheng Qian
Categories: cs.LG physics.flu-dyn
Comments: Accepted to NeurIPS 2025 Workshop on Machine Learning and the
 Physical Sciences (ML4PS), non-archival
\\
 Predicting the evolution of turbulent flows is central across science and
engineering. Most studies rely on simulations with turbulence models, whose
empirical simplifications introduce epistemic uncertainty. The Eigenspace
Perturbation Method (EPM) is a widely used physics-based approach to quantify
model-form uncertainty, but being purely physics-based it can overpredict
uncertainty bounds. We propose a convolutional neural network (CNN)-based
modulation of EPM perturbation magnitudes to improve calibration while
preserving physical consistency. Across canonical cases, the hybrid ML-EPM
framework yields substantially tighter, better-calibrated uncertainty estimates
than baseline EPM alone.
\\ ( https://arxiv.org/abs/2511.05633 ,  383kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05640
Date: Fri, 7 Nov 2025 16:27:59 GMT   (1245kb)

Title: Blind Inverse Game Theory: Jointly Decoding Rewards and Rationality in
 Entropy-Regularized Competitive Games
Authors: Hamza Virk, Sandro Amaglobeli, Zuhayr Syed
Categories: cs.LG cs.GT stat.ML
\\
 Inverse Game Theory (IGT) methods based on the entropy-regularized Quantal
Response Equilibrium (QRE) offer a tractable approach for competitive settings,
but critically assume the agents' rationality parameter (temperature $\tau$) is
known a priori. When $\tau$ is unknown, a fundamental scale ambiguity emerges
that couples $\tau$ with the reward parameters ($\theta$), making them
statistically unidentifiable. We introduce Blind-IGT, the first statistical
framework to jointly recover both $\theta$ and $\tau$ from observed behavior.
We analyze this bilinear inverse problem and establish necessary and sufficient
conditions for unique identification by introducing a normalization constraint
that resolves the scale ambiguity. We propose an efficient Normalized Least
Squares (NLS) estimator and prove it achieves the optimal
$\mathcal{O}(N^{-1/2})$ convergence rate for joint parameter recovery. When
strong identifiability conditions fail, we provide partial identification
guarantees through confidence set construction. We extend our framework to
Markov games and demonstrate optimal convergence rates with strong empirical
performance even when transition dynamics are unknown.
\\ ( https://arxiv.org/abs/2511.05640 ,  1245kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05664
Date: Fri, 7 Nov 2025 19:05:36 GMT   (172kb)

Title: KLASS: KL-Guided Fast Inference in Masked Diffusion Models
Authors: Seo Hyun Kim, Sunwoo Hong, Hojung Jung, Youngrok Park, Se-Young Yun
Categories: cs.LG
Comments: NeurIPS 2025 Spotlight. Code: https://github.com/shkim0116/KLASS
\\
 Masked diffusion models have demonstrated competitive results on various
tasks including language generation. However, due to its iterative refinement
process, the inference is often bottlenecked by slow and static sampling speed.
To overcome this problem, we introduce `KL-Adaptive Stability Sampling'
(KLASS), a fast yet effective sampling method that exploits token-level KL
divergence to identify stable, high-confidence predictions. By unmasking
multiple tokens in each iteration without any additional model training, our
approach speeds up generation significantly while maintaining sample quality.
On reasoning benchmarks, KLASS achieves up to $2.78\times$ wall-clock speedups
while improving performance over standard greedy decoding, attaining
state-of-the-art results among diffusion-based samplers. We further validate
KLASS across diverse domains, including text, image, and molecular generation,
showing its effectiveness as a broadly applicable sampler across different
models.
\\ ( https://arxiv.org/abs/2511.05664 ,  172kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05694
Date: Fri, 7 Nov 2025 20:25:43 GMT   (7355kb)

Title: Distributionally Robust Self Paced Curriculum Reinforcement Learning
Authors: Anirudh Satheesh and Keenan Powell and Vaneet Aggarwal
Categories: cs.LG
\\
 A central challenge in reinforcement learning is that policies trained in
controlled environments often fail under distribution shifts at deployment into
real-world environments. Distributionally Robust Reinforcement Learning (DRRL)
addresses this by optimizing for worst-case performance within an uncertainty
set defined by a robustness budget $\epsilon$. However, fixing $\epsilon$
results in a tradeoff between performance and robustness: small values yield
high nominal performance but weak robustness, while large values can result in
instability and overly conservative policies. We propose Distributionally
Robust Self-Paced Curriculum Reinforcement Learning (DR-SPCRL), a method that
overcomes this limitation by treating $\epsilon$ as a continuous curriculum.
DR-SPCRL adaptively schedules the robustness budget according to the agent's
progress, enabling a balance between nominal and robust performance. Empirical
results across multiple environments demonstrate that DR-SPCRL not only
stabilizes training but also achieves a superior robustness-performance
trade-off, yielding an average 11.8\% increase in episodic return under varying
perturbations compared to fixed or heuristic scheduling strategies, and
achieving approximately 1.9$\times$ the performance of the corresponding
nominal RL algorithms.
\\ ( https://arxiv.org/abs/2511.05694 ,  7355kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05696
Date: Fri, 7 Nov 2025 20:27:05 GMT   (1836kb)

Title: AI-assisted workflow enables rapid, high-fidelity breast cancer clinical
 trial eligibility prescreening
Authors: Jacob T. Rosenthal, Emma Hahesy, Sulov Chalise, Menglei Zhu, Mert R.
 Sabuncu, Lior Z. Braunstein, Anyi Li
Categories: cs.LG
\\
 Clinical trials play an important role in cancer care and research, yet
participation rates remain low. We developed MSK-MATCH (Memorial Sloan
Kettering Multi-Agent Trial Coordination Hub), an AI system for automated
eligibility screening from clinical text. MSK-MATCH integrates a large language
model with a curated oncology trial knowledge base and retrieval-augmented
architecture providing explanations for all AI predictions grounded in source
text. In a retrospective dataset of 88,518 clinical documents from 731 patients
across six breast cancer trials, MSK-MATCH automatically resolved 61.9% of
cases and triaged 38.1% for human review. This AI-assisted workflow achieved
98.6% accuracy, 98.4% sensitivity, and 98.7% specificity for patient-level
eligibility classification, matching or exceeding performance of the human-only
and AI-only comparisons. For the triaged cases requiring manual review,
prepopulating eligibility screens with AI-generated explanations reduced
screening time from 20 minutes to 43 seconds at an average cost of $0.96 per
patient-trial pair.
\\ ( https://arxiv.org/abs/2511.05696 ,  1836kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05704
Date: Fri, 7 Nov 2025 20:46:45 GMT   (2118kb)

Title: TabDistill: Distilling Transformers into Neural Nets for Few-Shot
 Tabular Classification
Authors: Pasan Dissanayake and Sanghamitra Dutta
Categories: cs.LG cs.AI cs.CL
\\
 Transformer-based models have shown promising performance on tabular data
compared to their classical counterparts such as neural networks and Gradient
Boosted Decision Trees (GBDTs) in scenarios with limited training data. They
utilize their pre-trained knowledge to adapt to new domains, achieving
commendable performance with only a few training examples, also called the
few-shot regime. However, the performance gain in the few-shot regime comes at
the expense of significantly increased complexity and number of parameters. To
circumvent this trade-off, we introduce TabDistill, a new strategy to distill
the pre-trained knowledge in complex transformer-based models into simpler
neural networks for effectively classifying tabular data. Our framework yields
the best of both worlds: being parameter-efficient while performing well with
limited training data. The distilled neural networks surpass classical
baselines such as regular neural networks, XGBoost and logistic regression
under equal training data, and in some cases, even the original
transformer-based models that they were distilled from.
\\ ( https://arxiv.org/abs/2511.05704 ,  2118kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05716
Date: Fri, 7 Nov 2025 21:18:35 GMT   (27kb)

Title: Distributionally Robust Multimodal Machine Learning
Authors: Peilin Yang, Yu Ma
Categories: cs.LG
\\
 We consider the problem of distributionally robust multimodal machine
learning. Existing approaches often rely on merging modalities on the feature
level (early fusion) or heuristic uncertainty modeling, which downplays
modality-aware ef- fects and provide limited insights. We propose a novel
distributionally robust optimization (DRO) framework that aims to study both
the theoretical and practical insights of multimodal machine learning. We first
justify this setup and show the significance of this problem through complexity
analysis. We then establish both generalization upper bounds and minimax lower
bounds which provide perfor- mance guarantees. These results are further
extended in settings where we consider encoder-specific error propogations.
Empirically, we demonstrate that our approach improves robustness in both
simulation settings and real-world datasets. Together, these findings provide a
principled foundation for employing multimodal machine learning models in
high-stakes applications where uncertainty is unavoidable.
\\ ( https://arxiv.org/abs/2511.05716 ,  27kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05726
Date: Fri, 7 Nov 2025 21:32:58 GMT   (703kb)

Title: GastroDL-Fusion: A Dual-Modal Deep Learning Framework Integrating
 Protein-Ligand Complexes and Gene Sequences for Gastrointestinal Disease Drug
 Discovery
Authors: Ziyang Gao, Annie Cheung, Yihao Ou
Categories: cs.LG q-bio.QM
\\
 Accurate prediction of protein-ligand binding affinity plays a pivotal role
in accelerating the discovery of novel drugs and vaccines, particularly for
gastrointestinal (GI) diseases such as gastric ulcers, Crohn's disease, and
ulcerative colitis. Traditional computational models often rely on structural
information alone and thus fail to capture the genetic determinants that
influence disease mechanisms and therapeutic responses. To address this gap, we
propose GastroDL-Fusion, a dual-modal deep learning framework that integrates
protein-ligand complex data with disease-associated gene sequence information
for drug and vaccine development. In our approach, protein-ligand complexes are
represented as molecular graphs and modeled using a Graph Isomorphism Network
(GIN), while gene sequences are encoded into biologically meaningful embeddings
via a pre-trained Transformer (ProtBERT/ESM). These complementary modalities
are fused through a multi-layer perceptron to enable robust cross-modal
interaction learning. We evaluate the model on benchmark datasets of GI
disease-related targets, demonstrating that GastroDL-Fusion significantly
improves predictive performance over conventional methods. Specifically, the
model achieves a mean absolute error (MAE) of 1.12 and a root mean square error
(RMSE) of 1.75, outperforming CNN, BiLSTM, GIN, and Transformer-only baselines.
These results confirm that incorporating both structural and genetic features
yields more accurate predictions of binding affinities, providing a reliable
computational tool for accelerating the design of targeted therapies and
vaccines in the context of gastrointestinal diseases.
\\ ( https://arxiv.org/abs/2511.05726 ,  703kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05728
Date: Fri, 7 Nov 2025 21:38:04 GMT   (355kb)

Title: Compressing Chemistry Reveals Functional Groups
Authors: Ruben Sharma, Ross D. King
Categories: cs.LG cs.AI cs.IT math.IT
\\
 We introduce the first formal large-scale assessment of the utility of
traditional chemical functional groups as used in chemical explanations. Our
assessment employs a fundamental principle from computational learning theory:
a good explanation of data should also compress the data. We introduce an
unsupervised learning algorithm based on the Minimum Message Length (MML)
principle that searches for substructures that compress around three million
biologically relevant molecules. We demonstrate that the discovered
substructures contain most human-curated functional groups as well as novel
larger patterns with more specific functions. We also run our algorithm on 24
specific bioactivity prediction datasets to discover dataset-specific
functional groups. Fingerprints constructed from dataset-specific functional
groups are shown to significantly outperform other fingerprint representations,
including the MACCS and Morgan fingerprint, when training ridge regression
models on bioactivity regression tasks.
\\ ( https://arxiv.org/abs/2511.05728 ,  355kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05730
Date: Fri, 7 Nov 2025 21:44:31 GMT   (515kb)

Title: QiVC-Net: Quantum-Inspired Variational Convolutional Network, with
 Application to Biosignal Classification
Authors: Amin Golnari, Jamileh Yousefi, Reza Moheimani, Saeid Sanei
Categories: cs.LG eess.SP
\\
 This work introduces the quantum-inspired variational convolution (QiVC)
framework, a novel learning paradigm that integrates principles of
probabilistic inference, variational optimization, and quantum-inspired
transformations within convolutional architectures. The central innovation of
QiVC lies in its quantum-inspired rotated ensemble (QiRE) mechanism. QiRE
performs differentiable low-dimensional subspace rotations of convolutional
weights, analogously to quantum state evolution. This approach enables
structured uncertainty modeling while preserving the intrinsic geometry of the
parameter space, resulting in more expressive, stable, and uncertainty-aware
representations. To demonstrate its practical potential, the concept is
instantiated in a QiVC-based convolutional network (QiVC-Net) and evaluated in
the context of biosignal classification, focusing on phonocardiogram (PCG)
recordings, a challenging domain characterized by high noise, inter-subject
variability, and often imbalanced data. The proposed QiVC-Net integrates an
architecture in which the QiVC layer does not introduce additional parameters,
instead performing an ensemble rotation of the convolutional weights through a
structured mechanism ensuring robustness without added highly computational
burden. Experiments on two benchmark datasets, PhysioNet CinC 2016 and
PhysioNet CirCor DigiScope 2022, show that QiVC-Net achieves state-of-the-art
performance, reaching accuracies of 97.84% and 97.89%, respectively. These
findings highlight the versatility of the QiVC framework and its promise for
advancing uncertainty-aware modeling in real-world biomedical signal analysis.
The implementation of the QiVConv layer is openly available in GitHub.
\\ ( https://arxiv.org/abs/2511.05730 ,  515kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05736
Date: Fri, 7 Nov 2025 21:48:55 GMT   (6434kb)

Title: Near-Exponential Savings for Mean Estimation with Active Learning
Authors: Julian M. Morimoto, Jacob Goldin, and Daniel E. Ho
Categories: cs.LG
Comments: Accepted to the 39th Conference on Neural Information Processing
 Systems (NeurIPS 2025)
\\
 We study the problem of efficiently estimating the mean of a $k$-class random
variable, $Y$, using a limited number of labels, $N$, in settings where the
analyst has access to auxiliary information (i.e.: covariates) $X$ that may be
informative about $Y$. We propose an active learning algorithm ("PartiBandits")
to estimate $\mathbb{E}[Y]$. The algorithm yields an estimate,
$\widehat{\mu}_{\text{PB}}$, such that $\left( \widehat{\mu}_{\text{PB}} -
\mathbb{E}[Y]\right)^2$ is $\tilde{\mathcal{O}}\left( \frac{\nu + \exp(c \cdot
(-N/\log(N))) }{N} \right)$, where $c > 0$ is a constant and $\nu$ is the risk
of the Bayes-optimal classifier. PartiBandits is essentially a two-stage
algorithm. In the first stage, it learns a partition of the unlabeled data that
shrinks the average conditional variance of $Y$. In the second stage it uses a
UCB-style subroutine ("WarmStart-UCB") to request labels from each stratum
round-by-round. Both the main algorithm's and the subroutine's convergence
rates are minimax optimal in classical settings. PartiBandits bridges the UCB
and disagreement-based approaches to active learning despite these two
approaches being designed to tackle very different tasks. We illustrate our
methods through simulation using nationwide electronic health records. Our
methods can be implemented using the PartiBandits package in R.
\\ ( https://arxiv.org/abs/2511.05736 ,  6434kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05745
Date: Fri, 7 Nov 2025 22:19:34 GMT   (8687kb)

Title: Beyond Redundancy: Diverse and Specialized Multi-Expert Sparse
 Autoencoder
Authors: Zhen Xu, Zhen Tan, Song Wang, Kaidi Xu, Tianlong Chen
Categories: cs.LG cs.AI
\\
 Sparse autoencoders (SAEs) have emerged as a powerful tool for interpreting
large language models (LLMs) by decomposing token activations into combinations
of human-understandable features. While SAEs provide crucial insights into LLM
explanations, their practical adoption faces a fundamental challenge: better
interpretability demands that SAEs' hidden layers have high dimensionality to
satisfy sparsity constraints, resulting in prohibitive training and inference
costs. Recent Mixture of Experts (MoE) approaches attempt to address this by
partitioning SAEs into narrower expert networks with gated activation, thereby
reducing computation. In a well-designed MoE, each expert should focus on
learning a distinct set of features. However, we identify a \textit{critical
limitation} in MoE-SAE: Experts often fail to specialize, which means they
frequently learn overlapping or identical features. To deal with it, we propose
two key innovations: (1) Multiple Expert Activation that simultaneously engages
semantically weighted expert subsets to encourage specialization, and (2)
Feature Scaling that enhances diversity through adaptive high-frequency
scaling. Experiments demonstrate a 24\% lower reconstruction error and a 99\%
reduction in feature redundancy compared to existing MoE-SAE methods. This work
bridges the interpretability-efficiency gap in LLM analysis, allowing
transparent model inspection without compromising computational feasibility.
\\ ( https://arxiv.org/abs/2511.05745 ,  8687kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05758
Date: Fri, 7 Nov 2025 23:05:14 GMT   (1384kb)

Title: Primal-Only Actor Critic Algorithm for Robust Constrained Average Cost
 MDPs
Authors: Anirudh Satheesh and Sooraj Sathish and Swetha Ganesh and Keenan
 Powell and Vaneet Aggarwal
Categories: cs.LG
\\
 In this work, we study the problem of finding robust and safe policies in
Robust Constrained Average-Cost Markov Decision Processes (RCMDPs). A key
challenge in this setting is the lack of strong duality, which prevents the
direct use of standard primal-dual methods for constrained RL. Additional
difficulties arise from the average-cost setting, where the Robust Bellman
operator is not a contraction under any norm. To address these challenges, we
propose an actor-critic algorithm for Average-Cost RCMDPs. We show that our
method achieves both \(\epsilon\)-feasibility and \(\epsilon\)-optimality, and
we establish a sample complexities of \(\tilde{O}\left(\epsilon^{-4}\right)\)
and \(\tilde{O}\left(\epsilon^{-6}\right)\) with and without slackness
assumption, which is comparable to the discounted setting.
\\ ( https://arxiv.org/abs/2511.05758 ,  1384kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05770
Date: Fri, 7 Nov 2025 23:59:09 GMT   (1213kb)

Title: An Efficient Gradient-Aware Error-Bounded Lossy Compressor for Federated
 Learning
Authors: Zhijing Ye, Sheng Di, Jiamin Wang, Zhiqing Zhong, Zhaorui Zhang,
 Xiaodong Yu
Categories: cs.LG cs.DC
Comments: Preprint version
\\
 Federated learning (FL) enables collaborative model training without exposing
clients' private data, but its deployment is often constrained by the
communication cost of transmitting gradients between clients and the central
server, especially under system heterogeneity where low-bandwidth clients
bottleneck overall performance. Lossy compression of gradient data can mitigate
this overhead, and error-bounded lossy compression (EBLC) is particularly
appealing for its fine-grained utility-compression tradeoff. However, existing
EBLC methods (e.g., SZ), originally designed for smooth scientific data with
strong spatial locality, rely on generic predictors such as Lorenzo and
interpolation for entropy reduction to improve compression ratio. Gradient
tensors, in contrast, exhibit low smoothness and weak spatial correlation,
rendering these predictors ineffective and leading to poor compression ratios.
To address this limitation, we propose an EBLC framework tailored for FL
gradient data to achieve high compression ratios while preserving model
accuracy. The core of it is an innovative prediction mechanism that exploits
temporal correlations across FL training rounds and structural regularities
within convolutional kernels to reduce residual entropy. The predictor is
compatible with standard quantizers and entropy coders and comprises (1) a
cross-round magnitude predictor based on a normalized exponential moving
average, and (2) a sign predictor that leverages gradient oscillation and
kernel-level sign consistency. Experiments show that this new EBLC yields up to
1.53x higher compression ratios than SZ3 with lower accuracy loss. Integrated
into a real-world FL framework, APPFL, it reduces end-to-end communication time
by 76.1%-96.2% under various constrained-bandwidth scenarios, demonstrating
strong scalability for real-world FL deployments.
\\ ( https://arxiv.org/abs/2511.05770 ,  1213kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05773
Date: Sat, 8 Nov 2025 00:07:43 GMT   (4906kb)

Title: MARAuder's Map: Motion-Aware Real-time Activity Recognition with
 Layout-Based Trajectories
Authors: Zishuai Liu, Weihang You, Jin Lu, Fei Dou
Categories: cs.LG cs.CV
\\
 Ambient sensor-based human activity recognition (HAR) in smart homes remains
challenging due to the need for real-time inference, spatially grounded
reasoning, and context-aware temporal modeling. Existing approaches often rely
on pre-segmented, within-activity data and overlook the physical layout of the
environment, limiting their robustness in continuous, real-world deployments.
In this paper, we propose MARAuder's Map, a novel framework for real-time
activity recognition from raw, unsegmented sensor streams. Our method projects
sensor activations onto the physical floorplan to generate trajectory-aware,
image-like sequences that capture the spatial flow of human movement. These
representations are processed by a hybrid deep learning model that jointly
captures spatial structure and temporal dependencies. To enhance temporal
awareness, we introduce a learnable time embedding module that encodes
contextual cues such as hour-of-day and day-of-week. Additionally, an
attention-based encoder selectively focuses on informative segments within each
observation window, enabling accurate recognition even under cross-activity
transitions and temporal ambiguity. Extensive experiments on multiple
real-world smart home datasets demonstrate that our method outperforms strong
baselines, offering a practical solution for real-time HAR in ambient sensor
environments.
\\ ( https://arxiv.org/abs/2511.05773 ,  4906kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05790
Date: Sat, 8 Nov 2025 01:45:49 GMT   (2386kb)

Title: SymLight: Exploring Interpretable and Deployable Symbolic Policies for
 Traffic Signal Control
Authors: Xiao-Cheng Liao, Yi Mei, and Mengjie Zhang
Categories: cs.LG cs.AI
\\
 Deep Reinforcement Learning have achieved significant success in
automatically devising effective traffic signal control (TSC) policies. Neural
policies, however, tend to be over-parameterized and non-transparent, hindering
their interpretability and deployability on resource-limited edge devices. This
work presents SymLight, a priority function search framework based on Monte
Carlo Tree Search (MCTS) for discovering inherently interpretable and
deployable symbolic priority functions to serve as the TSC policies. The
priority function, in particular, accepts traffic features as input and then
outputs a priority for each traffic signal phase, which subsequently directs
the phase transition. For effective search, we propose a concise yet expressive
priority function representation. This helps mitigate the combinatorial
explosion of the action space in MCTS. Additionally, a probabilistic structural
rollout strategy is introduced to leverage structural patterns from previously
discovered high-quality priority functions, guiding the rollout process. Our
experiments on real-world datasets demonstrate SymLight's superior performance
across a range of baselines. A key advantage is SymLight's ability to produce
interpretable and deployable TSC policies while maintaining excellent
performance.
\\ ( https://arxiv.org/abs/2511.05790 ,  2386kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05802
Date: Sat, 8 Nov 2025 02:22:33 GMT   (205kb)

Title: Beyond the Lower Bound: Bridging Regret Minimization and Best Arm
 Identification in Lexicographic Bandits
Authors: Bo Xue, Yuanyu Wan, Zhichao Lu, Qingfu Zhang
Categories: cs.LG cs.AI
Comments: Accepted by AAAI 2026
\\
 In multi-objective decision-making with hierarchical preferences,
lexicographic bandits provide a natural framework for optimizing multiple
objectives in a prioritized order. In this setting, a learner repeatedly
selects arms and observes reward vectors, aiming to maximize the reward for the
highest-priority objective, then the next, and so on. While previous studies
have primarily focused on regret minimization, this work bridges the gap
between \textit{regret minimization} and \textit{best arm identification} under
lexicographic preferences. We propose two elimination-based algorithms to
address this joint objective. The first algorithm eliminates suboptimal arms
sequentially, layer by layer, in accordance with the objective priorities, and
achieves sample complexity and regret bounds comparable to those of the best
single-objective algorithms. The second algorithm simultaneously leverages
reward information from all objectives in each round, effectively exploiting
cross-objective dependencies. Remarkably, it outperforms the known lower bound
for the single-objective bandit problem, highlighting the benefit of
cross-objective information sharing in the multi-objective setting. Empirical
results further validate their superior performance over baselines.
\\ ( https://arxiv.org/abs/2511.05802 ,  205kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05804
Date: Sat, 8 Nov 2025 02:24:05 GMT   (1905kb)

Title: Catching Contamination Before Generation: Spectral Kill Switches for
 Agents
Authors: Valentin No\"el
Categories: cs.LG cs.SY eess.SP eess.SY stat.ML
Comments: Preprint under review (2025). 9 pages, 2 figures. Code and scripts:
 to be released
\\
 Agentic language models compose multi step reasoning chains, yet intermediate
steps can be corrupted by inconsistent context, retrieval errors, or
adversarial inputs, which makes post hoc evaluation too late because errors
propagate before detection. We introduce a diagnostic that requires no
additional training and uses only the forward pass to emit a binary accept or
reject signal during agent execution. The method analyzes token graphs induced
by attention and computes two spectral statistics in early layers, namely the
high frequency energy ratio and spectral entropy. We formalize these signals,
establish invariances, and provide finite sample estimators with uncertainty
quantification. Under a two regime mixture assumption with a monotone
likelihood ratio property, we show that a single threshold on the high
frequency energy ratio is optimal in the Bayes sense for detecting context
inconsistency. Empirically, the high frequency energy ratio exhibits robust
bimodality during context verification across multiple model families, which
enables gating decisions with overhead below one millisecond on our hardware
and configurations. We demonstrate integration into retrieval augmented agent
pipelines and discuss deployment as an inline safety monitor. The approach
detects contamination while the model is still processing the text, before
errors commit to the reasoning chain.
\\ ( https://arxiv.org/abs/2511.05804 ,  1905kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05805
Date: Sat, 8 Nov 2025 02:24:16 GMT   (181kb)

Title: Measuring Model Performance in the Presence of an Intervention
Authors: Winston Chen, Michael W. Sjoding, Jenna Wiens
Categories: cs.LG cs.AI
Comments: AAAI 2026
\\
 AI models are often evaluated based on their ability to predict the outcome
of interest. However, in many AI for social impact applications, the presence
of an intervention that affects the outcome can bias the evaluation. Randomized
controlled trials (RCTs) randomly assign interventions, allowing data from the
control group to be used for unbiased model evaluation. However, this approach
is inefficient because it ignores data from the treatment group. Given the
complexity and cost often associated with RCTs, making the most use of the data
is essential. Thus, we investigate model evaluation strategies that leverage
all data from an RCT. First, we theoretically quantify the estimation bias that
arises from na\"ively aggregating performance estimates from treatment and
control groups, and derive the condition under which this bias leads to
incorrect model selection. Leveraging these theoretical insights, we propose
nuisance parameter weighting (NPW), an unbiased model evaluation approach that
reweights data from the treatment group to mimic the distributions of samples
that would or would not experience the outcome under no intervention. Using
synthetic and real-world datasets, we demonstrate that our proposed evaluation
approach consistently yields better model selection than the standard approach,
which ignores data from the treatment group, across various intervention effect
and sample size settings. Our contribution represents a meaningful step towards
more efficient model evaluation in real-world contexts.
\\ ( https://arxiv.org/abs/2511.05805 ,  181kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05811
Date: Sat, 8 Nov 2025 02:51:26 GMT   (521kb)

Title: MOSS: Efficient and Accurate FP8 LLM Training with Microscaling and
 Automatic Scaling
Authors: Yu Zhang, Hui-Ling Zhen, Mingxuan Yuan, Bei Yu
Categories: cs.LG cs.AI
\\
 Training large language models with FP8 formats offers significant efficiency
gains. However, the reduced numerical precision of FP8 poses challenges for
stable and accurate training. Current frameworks preserve training performance
using mixed-granularity quantization, i.e., applying per-group quantization for
activations and per-tensor/block quantization for weights. While effective,
per-group quantization requires scaling along the inner dimension of matrix
multiplication, introducing additional dequantization overhead. Moreover, these
frameworks often rely on just-in-time scaling to dynamically adjust scaling
factors based on the current data distribution. However, this online
quantization is inefficient for FP8 training, as it involves multiple memory
reads and writes that negate the performance benefits of FP8. To overcome these
limitations, we propose MOSS, a novel FP8 training framework that ensures both
efficiency and numerical stability. MOSS introduces two key innovations: (1) a
two-level microscaling strategy for quantizing sensitive activations, which
balances precision and dequantization cost by combining a high-precision global
scale with compact, power-of-two local scales; and (2) automatic scaling for
weights in linear layers, which eliminates the need for costly max-reduction
operations by predicting and adjusting scaling factors during training.
Leveraging these techniques, MOSS enables efficient FP8 training of a 7B
parameter model, achieving performance comparable to the BF16 baseline while
achieving up to 34% higher training throughput.
\\ ( https://arxiv.org/abs/2511.05811 ,  521kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05814
Date: Sat, 8 Nov 2025 03:04:11 GMT   (1660kb)

Title: In-depth Analysis on Caching and Pre-fetching in Mixture of Experts
 Offloading
Authors: Shuning Lin, Yifan He, Yitong Chen
Categories: cs.LG cs.AI
\\
 In today's landscape, Mixture of Experts (MoE) is a crucial architecture that
has been used by many of the most advanced models. One of the major challenges
of MoE models is that they usually require much more memory than their dense
counterparts due to their unique architecture, and hence are harder to deploy
in environments with limited GPU memory, such as edge devices. MoE offloading
is a promising technique proposed to overcome this challenge, especially if it
is enhanced with caching and pre-fetching, but prior work stopped at suboptimal
caching algorithm and offered limited insights. In this work, we study MoE
offloading in depth and make the following contributions: 1. We analyze the
expert activation and LRU caching behavior in detail and provide traces. 2. We
propose LFU caching optimization based on our analysis and obtain strong
improvements from LRU. 3. We implement and experiment speculative expert
pre-fetching, providing detailed trace showing its huge potential . 4. In
addition, our study extensively covers the behavior of the MoE architecture
itself, offering information on the characteristic of the gating network and
experts. This can inspire future work on the interpretation of MoE models and
the development of pruning techniques for MoE architecture with minimal
performance loss.
\\ ( https://arxiv.org/abs/2511.05814 ,  1660kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05823
Date: Sat, 8 Nov 2025 03:14:26 GMT   (22111kb)

Title: AiEDA: An Open-Source AI-Aided Design Library for Design-to-Vector
Authors: Yihang Qiu, Zengrong Huang, Simin Tao, Hongda Zhang, Weiguo Li, Xinhua
 Lai, Rui Wang, Weiqiang Wang, Xingquan Li
Categories: cs.LG cs.AR
Comments: 18 pages, 29 figures, accepted by TCAD 2025
\\
 Recent research has demonstrated that artificial intelligence (AI) can assist
electronic design automation (EDA) in improving both the quality and efficiency
of chip design. But current AI for EDA (AI-EDA) infrastructures remain
fragmented, lacking comprehensive solutions for the entire data pipeline from
design execution to AI integration. Key challenges include fragmented flow
engines that generate raw data, heterogeneous file formats for data exchange,
non-standardized data extraction methods, and poorly organized data storage.
This work introduces a unified open-source library for EDA (AiEDA) that
addresses these issues. AiEDA integrates multiple design-to-vector data
representation techniques that transform diverse chip design data into
universal multi-level vector representations, establishing an AI-aided design
(AAD) paradigm optimized for AI-EDA workflows. AiEDA provides complete physical
design flows with programmatic data extraction and standardized Python
interfaces bridging EDA datasets and AI frameworks. Leveraging the AiEDA
library, we generate iDATA, a 600GB dataset of structured data derived from 50
real chip designs (28nm), and validate its effectiveness through seven
representative AAD tasks spanning prediction, generation, optimization and
analysis. The code is publicly available at
https://github.com/OSCC-Project/AiEDA, while the full iDATA dataset is being
prepared for public release, providing a foundation for future AI-EDA research.
\\ ( https://arxiv.org/abs/2511.05823 ,  22111kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05826
Date: Sat, 8 Nov 2025 03:24:22 GMT   (2162kb)

Title: CADM: Cluster-customized Adaptive Distance Metric for Categorical Data
 Clustering
Authors: Taixi Chen, Yiu-ming Cheung, Yiqun Zhang
Categories: cs.LG stat.ML
Comments: 5 pages
\\
 An appropriate distance metric is crucial for categorical data clustering, as
the distance between categorical data cannot be directly calculated. However,
the distances between attribute values usually vary in different clusters
induced by their different distributions, which has not been taken into
account, thus leading to unreasonable distance measurement. Therefore, we
propose a cluster-customized distance metric for categorical data clustering,
which can competitively update distances based on different distributions of
attributes in each cluster. In addition, we extend the proposed distance metric
to the mixed data that contains both numerical and categorical attributes.
Experiments demonstrate the efficacy of the proposed method, i.e., achieving an
average ranking of around first in fourteen datasets. The source code is
available at https://anonymous.4open.science/r/CADM-47D8
\\ ( https://arxiv.org/abs/2511.05826 ,  2162kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05859
Date: Sat, 8 Nov 2025 05:24:45 GMT   (858kb)

Title: Predicting the Future by Retrieving the Past
Authors: Dazhao Du, Tao Han, Song Guo
Categories: cs.LG cs.AI
Comments: Accepted by AAAI 2026
\\
 Deep learning models such as MLP, Transformer, and TCN have achieved
remarkable success in univariate time series forecasting, typically relying on
sliding window samples from historical data for training. However, while these
models implicitly compress historical information into their parameters during
training, they are unable to explicitly and dynamically access this global
knowledge during inference, relying only on the local context within the
lookback window. This results in an underutilization of rich patterns from the
global history. To bridge this gap, we propose Predicting the Future by
Retrieving the Past (PFRP), a novel approach that explicitly integrates global
historical data to enhance forecasting accuracy. Specifically, we construct a
Global Memory Bank (GMB) to effectively store and manage global historical
patterns. A retrieval mechanism is then employed to extract similar patterns
from the GMB, enabling the generation of global predictions. By adaptively
combining these global predictions with the outputs of any local prediction
model, PFRP produces more accurate and interpretable forecasts. Extensive
experiments conducted on seven real-world datasets demonstrate that PFRP
significantly enhances the average performance of advanced univariate
forecasting models by 8.4\%. Codes can be found in
https://github.com/ddz16/PFRP.
\\ ( https://arxiv.org/abs/2511.05859 ,  858kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05863
Date: Sat, 8 Nov 2025 05:37:16 GMT   (2343kb)

Title: EMOD: A Unified EEG Emotion Representation Framework Leveraging V-A
 Guided Contrastive Learning
Authors: Yuning Chen, Sha Zhao, Shijian Li, Gang Pan
Categories: cs.LG cs.AI
\\
 Emotion recognition from EEG signals is essential for affective computing and
has been widely explored using deep learning. While recent deep learning
approaches have achieved strong performance on single EEG emotion datasets,
their generalization across datasets remains limited due to the heterogeneity
in annotation schemes and data formats. Existing models typically require
dataset-specific architectures tailored to input structure and lack semantic
alignment across diverse emotion labels. To address these challenges, we
propose EMOD: A Unified EEG Emotion Representation Framework Leveraging
Valence-Arousal (V-A) Guided Contrastive Learning. EMOD learns transferable and
emotion-aware representations from heterogeneous datasets by bridging both
semantic and structural gaps. Specifically, we project discrete and continuous
emotion labels into a unified V-A space and formulate a soft-weighted
supervised contrastive loss that encourages emotionally similar samples to
cluster in the latent space. To accommodate variable EEG formats, EMOD employs
a flexible backbone comprising a Triple-Domain Encoder followed by a
Spatial-Temporal Transformer, enabling robust extraction and integration of
temporal, spectral, and spatial features. We pretrain EMOD on eight public EEG
datasets and evaluate its performance on three benchmark datasets. Experimental
results show that EMOD achieves state-of-the-art performance, demonstrating
strong adaptability and generalization across diverse EEG-based emotion
recognition scenarios.
\\ ( https://arxiv.org/abs/2511.05863 ,  2343kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05872
Date: Sat, 8 Nov 2025 06:16:11 GMT   (562kb)

Title: Adaptation and Fine-tuning with TabPFN for Travelling Salesman Problem
Authors: Nguyen Gia Hien Vu, Yifan Tang, Rey Lim, Yifan Yang, Hang Ma, Ke Wang,
 G. Gary Wang
Categories: cs.LG cs.AI math.CO
\\
 Tabular Prior-Data Fitted Network (TabPFN) is a foundation model designed for
small to medium-sized tabular data, which has attracted much attention
recently. This paper investigates the application of TabPFN in Combinatorial
Optimization (CO) problems. The aim is to lessen challenges in time and
data-intensive training requirements often observed in using traditional
methods including exact and heuristic algorithms, Machine Learning (ML)-based
models, to solve CO problems. Proposing possibly the first ever application of
TabPFN for such a purpose, we adapt and fine-tune the TabPFN model to solve the
Travelling Salesman Problem (TSP), one of the most well-known CO problems.
Specifically, we adopt the node-based approach and the node-predicting
adaptation strategy to construct the entire TSP route. Our evaluation with
varying instance sizes confirms that TabPFN requires minimal training, adapts
to TSP using a single sample, performs better generalization across varying TSP
instance sizes, and reduces performance degradation. Furthermore, the training
process with adaptation and fine-tuning is completed within minutes. The
methodology leads to strong solution quality even without post-processing and
achieves performance comparable to other models with post-processing
refinement. Our findings suggest that the TabPFN model is a promising approach
to solve structured and CO problems efficiently under training resource
constraints and rapid deployment requirements.
\\ ( https://arxiv.org/abs/2511.05872 ,  562kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05878
Date: Sat, 8 Nov 2025 06:30:50 GMT   (399kb)

Title: FusionLog: Cross-System Log-based Anomaly Detection via Fusion of
 General and Proprietary Knowledge
Authors: Xinlong Zhao, Tong Jia, Minghua He, Xixuan Yang and Ying Li
Categories: cs.LG cs.SE
Comments: 11 pages, 4 figures, and 2 tables
\\
 Log-based anomaly detection is critical for ensuring the stability and
reliability of web systems. One of the key problems in this task is the lack of
sufficient labeled logs, which limits the rapid deployment in new systems.
Existing works usually leverage large-scale labeled logs from a mature web
system and a small amount of labeled logs from a new system, using transfer
learning to extract and generalize general knowledge across both domains.
However, these methods focus solely on the transfer of general knowledge and
neglect the disparity and potential mismatch between such knowledge and the
proprietary knowledge of target system, thus constraining performance. To
address this limitation, we propose FusionLog, a novel zero-label cross-system
log-based anomaly detection method that effectively achieves the fusion of
general and proprietary knowledge, enabling cross-system generalization without
any labeled target logs. Specifically, we first design a training-free router
based on semantic similarity that dynamically partitions unlabeled target logs
into 'general logs' and 'proprietary logs.' For general logs, FusionLog employs
a small model based on system-agnostic representation meta-learning for direct
training and inference, inheriting the general anomaly patterns shared between
the source and target systems. For proprietary logs, we iteratively generate
pseudo-labels and fine-tune the small model using multi-round collaborative
knowledge distillation and fusion based on large language model (LLM) and small
model (SM) to enhance its capability to recognize anomaly patterns specific to
the target system. Experimental results on three public log datasets from
different systems show that FusionLog achieves over 90% F1-score under a fully
zero-label setting, significantly outperforming state-of-the-art cross-system
log-based anomaly detection methods.
\\ ( https://arxiv.org/abs/2511.05878 ,  399kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05879
Date: Sat, 8 Nov 2025 06:41:39 GMT   (2405kb)

Title: Physics-Informed Neural Networks for Real-Time Gas Crossover Prediction
 in PEM Electrolyzers: First Application with Multi-Membrane Validation
Authors: Yong-Woon Kim, Chulung Kang, Yung-Cheol Byun
Categories: cs.LG cs.AI
\\
 Green hydrogen production via polymer electrolyte membrane (PEM) water
electrolysis is pivotal for energy transition, yet hydrogen crossover through
membranes threatens safety and economic viability-approaching explosive limits
(4 mol% H$_2$ in O$_2$) while reducing Faradaic efficiency by 2.5%. Current
physics-based models require extensive calibration and computational resources
that preclude real-time implementation, while purely data-driven approaches
fail to extrapolate beyond training conditions-critical for dynamic
electrolyzer operation. Here we present the first application of
physics-informed neural networks (PINNs) for hydrogen crossover prediction,
integrating mass conservation, Fick's diffusion law, and Henry's solubility law
within a compact architecture (17,793 parameters). Validated across six
membranes under industrially relevant conditions (0.05-5.0 A/cm$^2$, 1-200 bar,
25-85{\deg}C), our PINN achieves exceptional accuracy (R$^2$ = 99.84%, RMSE =
0.0348%) with sub-millisecond inference times suitable for real-time control.
Remarkably, the model maintains R$^2$ > 86% when predicting crossover at
pressures 2.5x beyond training range-substantially outperforming pure neural
networks (R$^2$ = 43.4%). The hardware-agnostic deployment, from desktop CPUs
to edge devices (Raspberry Pi 4), enables distributed safety monitoring
essential for gigawatt-scale installations. By bridging physical rigor and
computational efficiency, this work establishes a new paradigm for real-time
electrolyzer monitoring, accelerating deployment of safe, efficient green
hydrogen infrastructure crucial for net-zero emissions targets.
\\ ( https://arxiv.org/abs/2511.05879 ,  2405kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05924
Date: Sat, 8 Nov 2025 08:38:37 GMT   (6794kb)

Title: From Kernels to Attention: A Transformer Framework for Density and Score
 Estimation
Authors: Vasily Ilin, Peter Sushko
Categories: cs.LG
Comments: 14 pages, 14 figures
MSC-class: 68T07, 62G07
ACM-class: I.2.6; G.3
\\
 We introduce a unified attention-based framework for joint score and density
estimation. Framing the problem as a sequence-to-sequence task, we develop a
permutation- and affine-equivariant transformer that estimates both the
probability density $f(x)$ and its score $\nabla_x \log f(x)$ directly from
i.i.d. samples. Unlike traditional score-matching methods that require training
a separate model for each distribution, our approach learns a single
distribution-agnostic operator that generalizes across densities and sample
sizes. The architecture employs cross-attention to connect observed samples
with arbitrary query points, enabling generalization beyond the training data,
while built-in symmetry constraints ensure equivariance to permutation and
affine transformations. Analytically, we show that the attention weights can
recover classical kernel density estimation (KDE), and verify it empirically,
establishing a principled link between classical KDE and the transformer
architecture. Empirically, the model achieves substantially lower error and
better scaling than KDE and score-debiased KDE (SD-KDE), while exhibiting
better runtime scaling. Together, these results establish transformers as
general-purpose, data-adaptive operators for nonparametric density and score
estimation.
\\ ( https://arxiv.org/abs/2511.05924 ,  6794kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05960
Date: Sat, 8 Nov 2025 10:31:20 GMT   (3273kb)

Title: Deep Survival Analysis of Longitudinal EHR Data for Joint Prediction of
 Hospitalization and Death in COPD Patients
Authors: Enrico Manzini, Thomas Gonzalez Saito, Joan Escudero, Ana G\'enova,
 Cristina Caso, Tomas Perez-Porcuna, Alexandre Perera-Lluna
Categories: cs.LG
ACM-class: J.3
\\
 Patients with chronic obstructive pulmonary disease (COPD) have an increased
risk of hospitalizations, strongly associated with decreased survival, yet
predicting the timing of these events remains challenging and has received
limited attention in the literature. In this study, we performed survival
analysis to predict hospitalization and death in COPD patients using
longitudinal electronic health records (EHRs), comparing statistical models,
machine learning (ML), and deep learning (DL) approaches. We analyzed data from
more than 150k patients from the SIDIAP database in Catalonia, Spain, from 2013
to 2017, modeling hospitalization as a first event and death as a
semi-competing terminal event. Multiple models were evaluated, including Cox
proportional hazards, SurvivalBoost, DeepPseudo, SurvTRACE, Dynamic Deep-Hit,
and Deep Recurrent Survival Machine. Results showed that DL models utilizing
recurrent architectures outperformed both ML and linear approaches in
concordance and time-dependent AUC, especially for hospitalization, which
proved to be the harder event to predict. This study is, to our knowledge, the
first to apply deep survival analysis on longitudinal EHR data to jointly
predict multiple time-to-event outcomes in COPD patients, highlighting the
potential of DL approaches to capture temporal patterns and improve risk
stratification.
\\ ( https://arxiv.org/abs/2511.05960 ,  3273kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05963
Date: Sat, 8 Nov 2025 10:41:26 GMT   (7302kb)

Title: Next-Latent Prediction Transformers Learn Compact World Models
Authors: Jayden Teoh, Manan Tomar, Kwangjun Ahn, Edward S. Hu, Pratyusha
 Sharma, Riashat Islam, Alex Lamb, John Langford
Categories: cs.LG
Comments: Preprint by Microsoft Research
\\
 Transformers replace recurrence with a memory that grows with sequence length
and self-attention that enables ad-hoc look ups over past tokens. Consequently,
they lack an inherent incentive to compress history into compact latent states
with consistent transition rules. This often leads to learning solutions that
generalize poorly. We introduce Next-Latent Prediction (NextLat), which extends
standard next-token training with self-supervised predictions in the latent
space. Specifically, NextLat trains a transformer to learn latent
representations that are predictive of its next latent state given the next
output token. Theoretically, we show that these latents provably converge to
belief states, compressed information of the history necessary to predict the
future. This simple auxiliary objective also injects a recurrent inductive bias
into transformers, while leaving their architecture, parallel training, and
inference unchanged. NextLat effectively encourages the transformer to form
compact internal world models with its own belief states and transition
dynamics -- a crucial property absent in standard next-token prediction
transformers. Empirically, across benchmarks targeting core sequence modeling
competencies -- world modeling, reasoning, planning, and language modeling --
NextLat demonstrates significant gains over standard next-token training in
downstream accuracy, representation compression, and lookahead planning.
NextLat stands as a simple and efficient paradigm for shaping transformer
representations toward stronger generalization.
\\ ( https://arxiv.org/abs/2511.05963 ,  7302kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05973
Date: Sat, 8 Nov 2025 11:39:59 GMT   (24567kb)

Title: Explainable Deep Learning-based Classification of Wolff-Parkinson-White
 Electrocardiographic Signals
Authors: Alice Ragonesi, Stefania Fresca, Karli Gillette, Stefan Kurath-Koller,
 Gernot Plank, Elena Zappon
Categories: cs.LG cs.NA math.NA q-bio.TO
Comments: 27 pages, 9 figures, 4 tables
MSC-class: 68T07
ACM-class: G.1.10
\\
 Wolff-Parkinson-White (WPW) syndrome is a cardiac electrophysiology (EP)
disorder caused by the presence of an accessory pathway (AP) that bypasses the
atrioventricular node, faster ventricular activation rate, and provides a
substrate for atrio-ventricular reentrant tachycardia (AVRT). Accurate
localization of the AP is critical for planning and guiding catheter ablation
procedures. While traditional diagnostic tree (DT) methods and more recent
machine learning (ML) approaches have been proposed to predict AP location from
surface electrocardiogram (ECG), they are often constrained by limited
anatomical localization resolution, poor interpretability, and the use of small
clinical datasets. In this study, we present a Deep Learning (DL) model for the
localization of single manifest APs across 24 cardiac regions, trained on a
large, physiologically realistic database of synthetic ECGs generated using a
personalized virtual heart model. We also integrate eXplainable Artificial
Intelligence (XAI) methods, Guided Backpropagation, Grad-CAM, and Guided
Grad-CAM, into the pipeline. This enables interpretation of DL decision-making
and addresses one of the main barriers to clinical adoption: lack of
transparency in ML predictions. Our model achieves localization accuracy above
95%, with a sensitivity of 94.32% and specificity of 99.78%. XAI outputs are
physiologically validated against known depolarization patterns, and a novel
index is introduced to identify the most informative ECG leads for AP
localization. Results highlight lead V2 as the most critical, followed by aVF,
V1, and aVL. This work demonstrates the potential of combining cardiac digital
twins with explainable DL to enable accurate, transparent, and non-invasive AP
localization.
\\ ( https://arxiv.org/abs/2511.05973 ,  24567kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05978
Date: Sat, 8 Nov 2025 11:53:08 GMT   (9353kb)

Title: Kunlun Anomaly Troubleshooter: Enabling Kernel-Level Anomaly Detection
 and Causal Reasoning for Large Model Distributed Inference
Authors: Yuyang Liu, Jingjing Cai, Jiayi Ren, Peng Zhou, Danyang Zhang, Yin Du,
 Shijian Li
Categories: cs.LG cs.AI cs.DC cs.PF
Comments: Preprint version, under submission
ACM-class: C.4; I.5.4
\\
 Anomaly troubleshooting for large model distributed inference (LMDI) remains
a critical challenge. Resolving anomalies such as inference performance
degradation or latency jitter in distributed system demands significant manual
efforts from domain experts, resulting in extremely time-consuming diagnosis
processes with relatively low accuracy. In this paper, we introduce Kunlun
Anomaly Troubleshooter (KAT), the first anomaly troubleshooting framework
tailored for LMDI. KAT addresses this problem through two core innovations.
First, KAT exploits the synchronicity and consistency of GPU workers,
innovatively leverages function trace data to precisely detect kernel-level
anomalies and associated hardware components at nanosecond resolution. Second,
KAT integrates these detection results into a domain-adapted LLM, delivering
systematic causal reasoning and natural language interpretation of complex
anomaly symptoms. Evaluations conducted in Alibaba Cloud Service production
environment indicate that KAT achieves over 0.884 precision and 0.936 recall in
anomaly detection, providing detail anomaly insights that significantly narrow
down the diagnostic scope and improve both the efficiency and success rate of
troubleshooting.
\\ ( https://arxiv.org/abs/2511.05978 ,  9353kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05980
Date: Sat, 8 Nov 2025 11:57:33 GMT   (485kb)

Title: Are Time-Indexed Foundation Models the Future of Time Series Imputation?
Authors: Etienne Le Naour, Tahar Nabil, Adrien Petralia, Ghislain Agoua
Categories: cs.LG
\\
 Foundation models for time series imputation remain largely unexplored.
Recently, two such models, TabPFN-TS and MoTM, have emerged. These models share
a common philosophy that places them within the family of time-indexed
foundation models. This paper presents the first large-scale empirical study of
these models for zero-shot imputation, which enables missing value recovery
without retraining across a wide range of scenarios. We conduct extensive
univariate experiments across 33 out-of-domain datasets (approximately 1.3M
imputation windows) and evaluate their ability to integrate covariates at
inference time to improve accuracy without fine-tuning. Our results demonstrate
that time-indexed foundation models are a powerful and practical step toward
achieving general-purpose, zero-shot imputation for real-world time series.
\\ ( https://arxiv.org/abs/2511.05980 ,  485kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05985
Date: Sat, 8 Nov 2025 12:17:34 GMT   (2125kb)

Title: Bespoke Co-processor for Energy-Efficient Health Monitoring on
 RISC-V-based Flexible Wearables
Authors: Theofanis Vergos, Polykarpos Vergos, Mehdi B. Tahoori, Georgios
 Zervakis
Categories: cs.LG cs.AR
Comments: Accepted for publication at IEEE Design, Automation & Test in Europe
 (DATE 2026)
\\
 Flexible electronics offer unique advantages for conformable, lightweight,
and disposable healthcare wearables. However, their limited gate count, large
feature sizes, and high static power consumption make on-body machine learning
classification highly challenging. While existing bendable RISC-V systems
provide compact solutions, they lack the energy efficiency required. We present
a mechanically flexible RISC-V that integrates a bespoke multiply-accumulate
co-processor with fixed coefficients to maximize energy efficiency and minimize
latency. Our approach formulates a constrained programming problem to jointly
determine co-processor constants and optimally map Multi-Layer Perceptron (MLP)
inference operations, enabling compact, model-specific hardware by leveraging
the low fabrication and non-recurring engineering costs of flexible
technologies. Post-layout results demonstrate near-real-time performance across
several healthcare datasets, with our circuits operating within the power
budget of existing flexible batteries and occupying only 2.42 mm^2, offering a
promising path toward accessible, sustainable, and conformable healthcare
wearables. Our microprocessors achieve an average 2.35x speedup and 2.15x lower
energy consumption compared to the state of the art.
\\ ( https://arxiv.org/abs/2511.05985 ,  2125kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06010
Date: Sat, 8 Nov 2025 13:40:16 GMT   (642kb)

Title: MoSKA: Mixture of Shared KV Attention for Efficient Long-Sequence LLM
 Inference
Authors: Myunghyun Rhee, Sookyung Choi, Euiseok Kim, Joonseop Sim, Youngpyo
 Joo, Hoshik Kim
Categories: cs.LG cs.AI cs.DC
Comments: 4 pages, 5 figures, accepted for publication at IEEE Computer
 Architecture Letters (IEEE CAL), 2025
DOI: 10.1109/LCA.2025.3627539
\\
 The escalating context length in Large Language Models (LLMs) creates a
severe performance bottleneck around the Key-Value (KV) cache, whose
memory-bound nature leads to significant GPU under-utilization. This paper
introduces Mixture of Shared KV Attention (MoSKA), an architecture that
addresses this challenge by exploiting the heterogeneity of context data. It
differentiates between per-request unique and massively reused shared
sequences. The core of MoSKA is a novel Shared KV Attention mechanism that
transforms the attention on shared data from a series of memory-bound GEMV
operations into a single, compute-bound GEMM by batching concurrent requests.
This is supported by an MoE-inspired sparse attention strategy that prunes the
search space and a tailored Disaggregated Infrastructure that specializes
hardware for unique and shared data. This comprehensive approach demonstrates a
throughput increase of up to 538.7x over baselines in workloads with high
context sharing, offering a clear architectural path toward scalable LLM
inference.
\\ ( https://arxiv.org/abs/2511.06010 ,  642kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06029
Date: Sat, 8 Nov 2025 14:52:43 GMT   (1339kb)

Title: Lethe: Layer- and Time-Adaptive KV Cache Pruning for Reasoning-Intensive
 LLM Serving
Authors: Hui Zeng, Daming Zhao, Pengfei Yang, Wenxuan Hou, Tianyang Zheng, Hui
 Li, Weiye Ji, Jidong Zhai
Categories: cs.LG
Comments: aaai26 camera-ready version, 12 pages
\\
 Generative reasoning with large language models (LLMs) often involves long
decoding sequences, leading to substantial memory and latency overheads from
accumulating key-value (KV) caches. While existing KV compression methods
primarily focus on reducing prefill memory from long input sequences, they fall
short in addressing the dynamic and layer-sensitive nature of long-form
generation, which is central to reasoning tasks. We propose Lethe, a dynamic KV
cache management framework that introduces adaptivity along both the spatial
and temporal dimensions of decoding. Along the spatial dimension, Lethe
performs layerwise sparsity-aware allocation, assigning token pruning budgets
to each transformer layer based on estimated attention redundancy. Along the
temporal dimension, Lethe conducts multi-round token pruning during generation,
driven by a Recency-Aware Selective Retention} (RASR) mechanism. RASR extends
traditional recency-based heuristics by also considering token relevance
derived from evolving attention patterns, enabling informed decisions about
which tokens to retain or evict. Empirical results demonstrate that Lethe
achieves a favorable balance between efficiency and generation quality across
diverse models and tasks, increases throughput by up to 2.56x.
\\ ( https://arxiv.org/abs/2511.06029 ,  1339kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06032
Date: Sat, 8 Nov 2025 15:00:25 GMT   (1465kb)

Title: ITPP: Learning Disentangled Event Dynamics in Marked Temporal Point
 Processes
Authors: Wang-Tao Zhou, Zhao Kang, Ke Yan, Ling Tian
Categories: cs.LG cs.AI
Comments: Accepted to AAAI'26 Poster
\\
 Marked Temporal Point Processes (MTPPs) provide a principled framework for
modeling asynchronous event sequences by conditioning on the history of past
events. However, most existing MTPP models rely on channel-mixing strategies
that encode information from different event types into a single, fixed-size
latent representation. This entanglement can obscure type-specific dynamics,
leading to performance degradation and increased risk of overfitting. In this
work, we introduce ITPP, a novel channel-independent architecture for MTPP
modeling that decouples event type information using an encoder-decoder
framework with an ODE-based backbone. Central to ITPP is a type-aware inverted
self-attention mechanism, designed to explicitly model inter-channel
correlations among heterogeneous event types. This architecture enhances
effectiveness and robustness while reducing overfitting. Comprehensive
experiments on multiple real-world and synthetic datasets demonstrate that ITPP
consistently outperforms state-of-the-art MTPP models in both predictive
accuracy and generalization.
\\ ( https://arxiv.org/abs/2511.06032 ,  1465kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06041
Date: Sat, 8 Nov 2025 15:24:23 GMT   (30850kb)

Title: Advancing Ocean State Estimation with efficient and scalable AI
Authors: Yanfei Xiang, Yuan Gao, Hao Wu, Quan Zhang, Ruiqi Shu, Xiao Zhou, Xi
 Wu, Xiaomeng Huang
Categories: cs.LG cs.AI
Comments: 29 papes, 10 Figures
\\
 Accurate and efficient global ocean state estimation remains a grand
challenge for Earth system science, hindered by the dual bottlenecks of
computational scalability and degraded data fidelity in traditional data
assimilation (DA) and deep learning (DL) approaches. Here we present an
AI-driven Data Assimilation Framework for Ocean (ADAF-Ocean) that directly
assimilates multi-source and multi-scale observations, ranging from sparse
in-situ measurements to 4 km satellite swaths, without any interpolation or
data thinning. Inspired by Neural Processes, ADAF-Ocean learns a continuous
mapping from heterogeneous inputs to ocean states, preserving native data
fidelity. Through AI-driven super-resolution, it reconstructs 0.25$^\circ$
mesoscale dynamics from coarse 1$^\circ$ fields, which ensures both efficiency
and scalability, with just 3.7\% more parameters than the 1$^\circ$
configuration. When coupled with a DL forecasting system, ADAF-Ocean extends
global forecast skill by up to 20 days compared to baselines without
assimilation. This framework establishes a computationally viable and
scientifically rigorous pathway toward real-time, high-resolution Earth system
monitoring.
\\ ( https://arxiv.org/abs/2511.06041 ,  30850kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06042
Date: Sat, 8 Nov 2025 15:30:55 GMT   (17625kb)

Title: Physics-Informed Design of Input Convex Neural Networks for Consistency
 Optimal Transport Flow Matching
Authors: Fanghui Song, Zhongjian Wang, Jiebao Sun
Categories: cs.LG
\\
 We propose a consistency model based on the optimal-transport flow. A
physics-informed design of partially input-convex neural networks (PICNN) plays
a central role in constructing the flow field that emulates the displacement
interpolation. During the training stage, we couple the Hamilton-Jacobi (HJ)
residual in the OT formulation with the original flow matching loss function.
Our approach avoids inner optimization subproblems that are present in previous
one-step OFM approaches. During the prediction stage, our approach supports
both one-step (Brenier-map) and multi-step ODE sampling from the same learned
potential, leveraging the straightness of the OT flow. We validate scalability
and performance on standard OT benchmarks.
\\ ( https://arxiv.org/abs/2511.06042 ,  17625kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06044
Date: Sat, 8 Nov 2025 15:34:15 GMT   (138kb)

Title: How Particle-System Random Batch Methods Enhance Graph Transformer:
 Memory Efficiency and Parallel Computing Strategy
Authors: Hanwen Liu, Yixuan Ma, Shi Jin and Yuguang Wang
Categories: cs.LG cs.AI math.ST stat.TH
\\
 Attention mechanism is a significant part of Transformer models. It helps
extract features from embedded vectors by adding global information and its
expressivity has been proved to be powerful. Nevertheless, the quadratic
complexity restricts its practicability. Although several researches have
provided attention mechanism in sparse form, they are lack of theoretical
analysis about the expressivity of their mechanism while reducing complexity.
In this paper, we put forward Random Batch Attention (RBA), a linear
self-attention mechanism, which has theoretical support of the ability to
maintain its expressivity. Random Batch Attention has several significant
strengths as follows: (1) Random Batch Attention has linear time complexity.
Other than this, it can be implemented in parallel on a new dimension, which
contributes to much memory saving. (2) Random Batch Attention mechanism can
improve most of the existing models by replacing their attention mechanisms,
even many previously improved attention mechanisms. (3) Random Batch Attention
mechanism has theoretical explanation in convergence, as it comes from Random
Batch Methods on computation mathematics. Experiments on large graphs have
proved advantages mentioned above. Also, the theoretical modeling of
self-attention mechanism is a new tool for future research on
attention-mechanism analysis.
\\ ( https://arxiv.org/abs/2511.06044 ,  138kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06054
Date: Sat, 8 Nov 2025 15:52:35 GMT   (1832kb)

Title: Function Based Isolation Forest (FuBIF): A Unifying Framework for
 Interpretable Isolation-Based Anomaly Detection
Authors: Alessio Arcudi, Alessandro Ferreri, Francesco Borsatti, Gian Antonio
 Susto
Categories: cs.LG stat.ML
\\
 Anomaly Detection (AD) is evolving through algorithms capable of identifying
outliers in complex datasets. The Isolation Forest (IF), a pivotal AD
technique, exhibits adaptability limitations and biases. This paper introduces
the Function-based Isolation Forest (FuBIF), a generalization of IF that
enables the use of real-valued functions for dataset branching, significantly
enhancing the flexibility of evaluation tree construction. Complementing this,
the FuBIF Feature Importance (FuBIFFI) algorithm extends the interpretability
in IF-based approaches by providing feature importance scores across possible
FuBIF models. This paper details the operational framework of FuBIF, evaluates
its performance against established methods, and explores its theoretical
contributions. An open-source implementation is provided to encourage further
research and ensure reproducibility.
\\ ( https://arxiv.org/abs/2511.06054 ,  1832kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06072
Date: Sat, 8 Nov 2025 17:02:42 GMT   (13801kb)

Title: CatBack: Universal Backdoor Attacks on Tabular Data via Categorical
 Encoding
Authors: Behrad Tajalli, Stefanos Koffas, Stjepan Picek
Categories: cs.LG cs.CR
\\
 Backdoor attacks in machine learning have drawn significant attention for
their potential to compromise models stealthily, yet most research has focused
on homogeneous data such as images. In this work, we propose a novel backdoor
attack on tabular data, which is particularly challenging due to the presence
of both numerical and categorical features. Our key idea is a novel technique
to convert categorical values into floating-point representations. This
approach preserves enough information to maintain clean-model accuracy compared
to traditional methods like one-hot or ordinal encoding. By doing this, we
create a gradient-based universal perturbation that applies to all features,
including categorical ones.
 We evaluate our method on five datasets and four popular models. Our results
show up to a 100% attack success rate in both white-box and black-box settings
(including real-world applications like Vertex AI), revealing a severe
vulnerability for tabular data. Our method is shown to surpass the previous
works like Tabdoor in terms of performance, while remaining stealthy against
state-of-the-art defense mechanisms. We evaluate our attack against Spectral
Signatures, Neural Cleanse, Beatrix, and Fine-Pruning, all of which fail to
defend successfully against it. We also verify that our attack successfully
bypasses popular outlier detection mechanisms.
\\ ( https://arxiv.org/abs/2511.06072 ,  13801kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06077
Date: Sat, 8 Nov 2025 17:22:54 GMT   (499kb)

Title: Make It Long, Keep It Fast: End-to-End 10k-Sequence Modeling at Billion
 Scale on Douyin
Authors: Lin Guan, Jia-Qi Yang, Zhishan Zhao, Beichuan Zhang, Bo Sun, Xuanyuan
 Luo, Jinan Ni, Xiaowen Li, Yuhang Qi, Zhifang Fan, Hangyu Wang, Qiwei Chen,
 Yi Cheng, Feng Zhang, Xiao Yang
Categories: cs.LG cs.IR
\\
 Short-video recommenders such as Douyin must exploit extremely long user
histories without breaking latency or cost budgets. We present an end-to-end
system that scales long-sequence modeling to 10k-length histories in
production. First, we introduce Stacked Target-to-History Cross Attention
(STCA), which replaces history self-attention with stacked cross-attention from
the target to the history, reducing complexity from quadratic to linear in
sequence length and enabling efficient end-to-end training. Second, we propose
Request Level Batching (RLB), a user-centric batching scheme that aggregates
multiple targets for the same user/request to share the user-side encoding,
substantially lowering sequence-related storage, communication, and compute
without changing the learning objective. Third, we design a
length-extrapolative training strategy -- train on shorter windows, infer on
much longer ones -- so the model generalizes to 10k histories without
additional training cost. Across offline and online experiments, we observe
predictable, monotonic gains as we scale history length and model capacity,
mirroring the scaling law behavior observed in large language models. Deployed
at full traffic on Douyin, our system delivers significant improvements on key
engagement metrics while meeting production latency, demonstrating a practical
path to scaling end-to-end long-sequence recommendation to the 10k regime.
\\ ( https://arxiv.org/abs/2511.06077 ,  499kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06083
Date: Sat, 8 Nov 2025 17:31:21 GMT   (925kb)

Title: Event-driven physics-informed operator learning for reliability analysis
Authors: Shailesh Garg and Souvik Chakraborty
Categories: cs.LG
\\
 Reliability analysis of engineering systems under uncertainty poses
significant computational challenges, particularly for problems involving
high-dimensional stochastic inputs, nonlinear system responses, and
multiphysics couplings. Traditional surrogate modeling approaches often incur
high energy consumption, which severely limits their scalability and
deployability in resource-constrained environments. We introduce NeuroPOL,
\textit{the first neuroscience-inspired physics-informed operator learning
framework} for reliability analysis. NeuroPOL incorporates Variable Spiking
Neurons into a physics-informed operator architecture, replacing continuous
activations with event-driven spiking dynamics. This innovation promotes sparse
communication, significantly reduces computational load, and enables an
energy-efficient surrogate model. The proposed framework lowers both
computational and power demands, supporting real-time reliability assessment
and deployment on edge devices and digital twins. By embedding governing
physical laws into operator learning, NeuroPOL builds physics-consistent
surrogates capable of accurate uncertainty propagation and efficient failure
probability estimation, even for high-dimensional problems. We evaluate
NeuroPOL on five canonical benchmarks, the Burgers equation, Nagumo equation,
two-dimensional Poisson equation, two-dimensional Darcy equation, and
incompressible Navier-Stokes equation with energy coupling. Results show that
NeuroPOL achieves reliability measures comparable to standard physics-informed
operators, while introducing significant communication sparsity, enabling
scalable, distributed, and energy-efficient deployment.
\\ ( https://arxiv.org/abs/2511.06083 ,  925kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06094
Date: Sat, 8 Nov 2025 18:17:18 GMT   (5181kb)

Title: Approximating Shapley Explanations in Reinforcement Learning
Authors: Daniel Beechey and \"Ozg\"ur \c{S}im\c{s}ek
Categories: cs.LG
Comments: Camera-ready version. Published at the Conference on Neural
 Information Processing Systems (NeurIPS 2025)
Journal-ref: Proceedings of the Conference on Neural Information Processing
 Systems (NeurIPS 2025)
\\
 Reinforcement learning has achieved remarkable success in complex
decision-making environments, yet its lack of transparency limits its
deployment in practice, especially in safety-critical settings. Shapley values
from cooperative game theory provide a principled framework for explaining
reinforcement learning; however, the computational cost of Shapley explanations
is an obstacle to their use. We introduce FastSVERL, a scalable method for
explaining reinforcement learning by approximating Shapley values. FastSVERL is
designed to handle the unique challenges of reinforcement learning, including
temporal dependencies across multi-step trajectories, learning from off-policy
data, and adapting to evolving agent behaviours in real time. FastSVERL
introduces a practical, scalable approach for principled and rigorous
interpretability in reinforcement learning.
\\ ( https://arxiv.org/abs/2511.06094 ,  5181kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06101
Date: Sat, 8 Nov 2025 18:45:33 GMT   (738kb)

Title: Adapting Web Agents with Synthetic Supervision
Authors: Zhaoyang Wang, Yiming Liang, Xuchao Zhang, Qianhui Wu, Siwei Han,
 Anson Bastos, Rujia Wang, Chetan Bansal, Baolin Peng, Jianfeng Gao, Saravan
 Rajmohan, Huaxiu Yao
Categories: cs.LG cs.AI cs.CL
Comments: 19 pages, 6 figures
\\
 Web agents struggle to adapt to new websites due to the scarcity of
environment specific tasks and demonstrations. Recent works have explored
synthetic data generation to address this challenge, however, they suffer from
data quality issues where synthesized tasks contain hallucinations that cannot
be executed, and collected trajectories are noisy with redundant or misaligned
actions. In this paper, we propose SynthAgent, a fully synthetic supervision
framework that aims at improving synthetic data quality via dual refinement of
both tasks and trajectories. Our approach begins by synthesizing diverse tasks
through categorized exploration of web elements, ensuring efficient coverage of
the target environment. During trajectory collection, we refine tasks when
conflicts with actual observations are detected, mitigating hallucinations
while maintaining task consistency. After collection, we conduct trajectory
refinement with a global context to mitigate potential noise or misalignments.
Finally, we fine-tune open-source web agents on the refined synthetic data to
adapt them to the target environment. Experimental results demonstrate that
SynthAgent outperforms existing synthetic data methods, validating the
importance of high-quality synthetic supervision. The code will be publicly
available at https://github.com/aiming-lab/SynthAgent.
\\ ( https://arxiv.org/abs/2511.06101 ,  738kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06111
Date: Sat, 8 Nov 2025 19:32:31 GMT   (5775kb)

Title: Guardian-regularized Safe Offline Reinforcement Learning for Smart
 Weaning of Mechanical Circulatory Devices
Authors: Aysin Tumay, Sophia Sun, Sonia Fereidooni, Aaron Dumas, Elise
 Jortberg, Rose Yu
Categories: cs.LG
\\
 We study the sequential decision-making problem for automated weaning of
mechanical circulatory support (MCS) devices in cardiogenic shock patients. MCS
devices are percutaneous micro-axial flow pumps that provide left ventricular
unloading and forward blood flow, but current weaning strategies vary
significantly across care teams and lack data-driven approaches. Offline
reinforcement learning (RL) has proven to be successful in sequential
decision-making tasks, but our setting presents challenges for training and
evaluating traditional offline RL methods: prohibition of online patient
interaction, highly uncertain circulatory dynamics due to concurrent
treatments, and limited data availability. We developed an end-to-end machine
learning framework with two key contributions (1) Clinically-aware
OOD-regularized Model-based Policy Optimization (CORMPO), a density-regularized
offline RL algorithm for out-of-distribution suppression that also incorporates
clinically-informed reward shaping and (2) a Transformer-based probabilistic
digital twin that models MCS circulatory dynamics for policy evaluation with
rich physiological and clinical metrics. We prove that \textsf{CORMPO} achieves
theoretical performance guarantees under mild assumptions. CORMPO attains a
higher reward than the offline RL baselines by 28% and higher scores in
clinical metrics by 82.6% on real and synthetic datasets. Our approach offers a
principled framework for safe offline policy learning in high-stakes medical
applications where domain expertise and safety constraints are essential.
\\ ( https://arxiv.org/abs/2511.06111 ,  5775kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06132
Date: Sat, 8 Nov 2025 20:51:02 GMT   (811kb)

Title: On the Convergence and Stability of Distributed Sub-model Training
Authors: Yuyang Deng, Fuli Qiao, Mehrdad Mahdavi
Categories: cs.LG
\\
 As learning models continue to grow in size, enabling on-device local
training of these models has emerged as a critical challenge in federated
learning. A popular solution is sub-model training, where the server only
distributes randomly sampled sub-models to the edge clients, and clients only
update these small models. However, those random sampling of sub-models may not
give satisfying convergence performance. In this paper, observing the success
of SGD with shuffling, we propose a distributed shuffled sub-model training,
where the full model is partitioned into several sub-models in advance, and the
server shuffles those sub-models, sends each of them to clients at each round,
and by the end of local updating period, clients send back the updated
sub-models, and server averages them. We establish the convergence rate of this
algorithm. We also study the generalization of distributed sub-model training
via stability analysis, and find that the sub-model training can improve the
generalization via amplifying the stability of training process. The extensive
experiments also validate our theoretical findings.
\\ ( https://arxiv.org/abs/2511.06132 ,  811kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06143
Date: Sat, 8 Nov 2025 21:36:42 GMT   (318kb)

Title: Enhancing Robustness of Graph Neural Networks through p-Laplacian
Authors: Anuj Kumar Sirohi, Subhanu Halder, Kabir Kumar, Sandeep Kumar
Categories: cs.LG
Comments: Accepted at 5th Workshop on Graphs and more Complex Structures For
 Learning and Reasoning (GCLR), The 40th AAAI Conference on Artificial
 Intelligence (AAAI-26)
\\
 With the increase of data in day-to-day life, businesses and different
stakeholders need to analyze the data for better pre- dictions. Traditionally,
relational data has been a source of various insights, but with the increase in
computational power and the need to understand deeper relationships between en-
tities, the need to design new techniques has arisen. For this graph data
analysis has become an extraordinary tool for un- derstanding the data, which
reveals more realistic and flexible modelling of complex relationships.
Recently, Graph Neural Networks (GNNs) have shown great promise in various ap-
plications, such as social network analysis, recommendation systems, drug
discovery, and more. However, many adversar- ial attacks can happen over the
data, whether during training (poisoning attack) or during testing (evasion
attack), which can adversely manipulate the desired outcome from the GNN model.
Therefore, it is crucial to make the GNNs robust to such attacks. The existing
robustness methods are computa- tionally demanding and perform poorly when the
intensity of attack increases. This paper presents a computationally ef-
ficient framework, namely, pLAPGNN, based on weighted p-Laplacian for making
GNNs robust. Empirical evaluation on real datasets establishes the efficacy and
efficiency of the proposed method.
\\ ( https://arxiv.org/abs/2511.06143 ,  318kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06157
Date: Sat, 8 Nov 2025 22:38:14 GMT   (650kb)

Title: Models Got Talent: Identifying High Performing Wearable Human Activity
 Recognition Models Without Training
Authors: Richard Goldman, Varun Komperla, Thomas Ploetz, Harish Haresamudram
Categories: cs.LG cs.AI
\\
 A promising alternative to the computationally expensive Neural Architecture
Search (NAS) involves the development of \textit{Zero Cost Proxies (ZCPs)},
which correlate well to trained performance, but can be computed through a
single forward/backward pass on a randomly sampled batch of data. In this
paper, we investigate the effectiveness of ZCPs for HAR on six benchmark
datasets, and demonstrate that they discover network architectures that obtain
within 5\% of performance attained by full scale training involving 1500
randomly sampled architectures. This results in substantial computational
savings as high performing architectures can be discovered with minimal
training. Our experiments not only introduce ZCPs to sensor-based HAR, but also
demonstrate that they are robust to data noise, further showcasing their
suitability for practical scenarios.
\\ ( https://arxiv.org/abs/2511.06157 ,  650kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06161
Date: Sat, 8 Nov 2025 23:05:31 GMT   (272kb)

Title: LLM Attention Transplant for Transfer Learning of Tabular Data Across
 Disparate Domains
Authors: Ibna Kowsar, Kazi F. Akhter, and Manar D. Samad
Categories: cs.LG cs.AI
\\
 Transfer learning of tabular data is non-trivial due to heterogeneity in the
feature space across disparate domains. The limited success of traditional deep
learning in tabular knowledge transfer can be advanced by leveraging large
language models (LLMs). However, the efficacy of LLMs often stagnates for mixed
data types structured in tables due to the limitations of text prompts and
in-context learning. We propose a lightweight transfer learning framework that
fine-tunes an LLM using source tabular data and transplants the LLM's selective
$key$ and $value$ projection weights into a gated feature tokenized transformer
(gFTT) built for tabular data. The gFTT model with cross-domain attention is
fine-tuned using target tabular data for transfer learning, eliminating the
need for shared features, LLM prompt engineering, and large-scale pretrained
models. Our experiments using ten pairs of source-target data sets and 12
baselines demonstrate the superiority of the proposed LLM-attention transplant
for transfer learning (LATTLE) method over traditional ML models,
state-of-the-art deep tabular architectures, and transfer learning models
trained on thousands to billions of tabular samples. The proposed attention
transfer demonstrates an effective solution to learning relationships between
data tables using an LLM in a low-resource learning environment. The source
code for the proposed method is publicly available.
\\ ( https://arxiv.org/abs/2511.06161 ,  272kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06164
Date: Sat, 8 Nov 2025 23:42:36 GMT   (1927kb)

Title: Learning Gaussian DAG Models without Condition Number Bounds
Authors: Constantinos Daskalakis, Vardis Kandiros, Rui Yao
Categories: cs.LG
\\
 We study the problem of learning the topology of a directed Gaussian
Graphical Model under the equal-variance assumption, where the graph has $n$
nodes and maximum in-degree $d$. Prior work has established that $O(d \log n)$
samples are sufficient for this task. However, an important factor that is
often overlooked in these analyses is the dependence on the condition number of
the covariance matrix of the model. Indeed, all algorithms from prior work
require a number of samples that grows polynomially with this condition number.
In many cases this is unsatisfactory, since the condition number could grow
polynomially with $n$, rendering these prior approaches impractical in
high-dimensional settings. In this work, we provide an algorithm that recovers
the underlying graph and prove that the number of samples required is
independent of the condition number. Furthermore, we establish lower bounds
that nearly match the upper bound up to a $d$-factor, thus providing an almost
tight characterization of the true sample complexity of the problem. Moreover,
under a further assumption that all the variances of the variables are bounded,
we design a polynomial-time algorithm that recovers the underlying graph, at
the cost of an additional polynomial dependence of the sample complexity on
$d$. We complement our theoretical findings with simulations on synthetic
datasets that confirm our predictions.
\\ ( https://arxiv.org/abs/2511.06164 ,  1927kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06169
Date: Sun, 9 Nov 2025 00:30:17 GMT   (28033kb)

Title: Local K-Similarity Constraint for Federated Learning with Label Noise
Authors: Sanskar Amgain, Prashant Shrestha, Bidur Khanal, Alina Devkota, Yash
 Raj Shrestha, Seungryul Baek, Prashnna Gyawali, Binod Bhattarai
Categories: cs.LG
\\
 Federated learning on clients with noisy labels is a challenging problem, as
such clients can infiltrate the global model, impacting the overall
generalizability of the system. Existing methods proposed to handle noisy
clients assume that a sufficient number of clients with clean labels are
available, which can be leveraged to learn a robust global model while
dampening the impact of noisy clients. This assumption fails when a high number
of heterogeneous clients contain noisy labels, making the existing approaches
ineffective. In such scenarios, it is important to locally regularize the
clients before communication with the global model, to ensure the global model
isn't corrupted by noisy clients. While pre-trained self-supervised models can
be effective for local regularization, existing centralized approaches relying
on pretrained initialization are impractical in a federated setting due to the
potentially large size of these models, which increases communication costs. In
that line, we propose a regularization objective for client models that
decouples the pre-trained and classification models by enforcing similarity
between close data points within the client. We leverage the representation
space of a self-supervised pretrained model to evaluate the closeness among
examples. This regularization, when applied with the standard objective
function for the downstream task in standard noisy federated settings,
significantly improves performance, outperforming existing state-of-the-art
federated methods in multiple computer vision and medical image classification
benchmarks. Unlike other techniques that rely on self-supervised pretrained
initialization, our method does not require the pretrained model and classifier
backbone to share the same architecture, making it architecture-agnostic.
\\ ( https://arxiv.org/abs/2511.06169 ,  28033kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06208
Date: Sun, 9 Nov 2025 03:34:45 GMT   (465kb)

Title: Resilience Inference for Supply Chains with Hypergraph Neural Network
Authors: Zetian Shen, Hongjun Wang, Jiyuan Chen, Xuan Song
Categories: cs.LG cs.AI
\\
 Supply chains are integral to global economic stability, yet disruptions can
swiftly propagate through interconnected networks, resulting in substantial
economic impacts. Accurate and timely inference of supply chain resilience the
capability to maintain core functions during disruptions is crucial for
proactive risk mitigation and robust network design. However, existing
approaches lack effective mechanisms to infer supply chain resilience without
explicit system dynamics and struggle to represent the higher-order,
multi-entity dependencies inherent in supply chain networks. These limitations
motivate the definition of a novel problem and the development of targeted
modeling solutions. To address these challenges, we formalize a novel problem:
Supply Chain Resilience Inference (SCRI), defined as predicting supply chain
resilience using hypergraph topology and observed inventory trajectories
without explicit dynamic equations. To solve this problem, we propose the
Supply Chain Resilience Inference Hypergraph Network (SC-RIHN), a novel
hypergraph-based model leveraging set-based encoding and hypergraph message
passing to capture multi-party firm-product interactions. Comprehensive
experiments demonstrate that SC-RIHN significantly outperforms traditional MLP,
representative graph neural network variants, and ResInf baselines across
synthetic benchmarks, underscoring its potential for practical, early-warning
risk assessment in complex supply chain systems.
\\ ( https://arxiv.org/abs/2511.06208 ,  465kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06211
Date: Sun, 9 Nov 2025 03:48:21 GMT   (37kb)

Title: Sparse Linear Regression is Easy on Random Supports
Authors: Gautam Chandrasekaran, Raghu Meka, Konstantinos Stavropoulos
Categories: cs.LG cs.DS math.ST stat.ML stat.TH
\\
 Sparse linear regression is one of the most basic questions in machine
learning and statistics. Here, we are given as input a design matrix $X \in
\mathbb{R}^{N \times d}$ and measurements or labels ${y} \in \mathbb{R}^N$
where ${y} = {X} {w}^* + {\xi}$, and ${\xi}$ is the noise in the measurements.
Importantly, we have the additional constraint that the unknown signal vector
${w}^*$ is sparse: it has $k$ non-zero entries where $k$ is much smaller than
the ambient dimension. Our goal is to output a prediction vector
$\widehat{{w}}$ that has small prediction error: $\frac{1}{N}\cdot \|{X} {w}^*
- {X} \widehat{{w}}\|^2_2$.
 Information-theoretically, we know what is best possible in terms of
measurements: under most natural noise distributions, we can get prediction
error at most $\epsilon$ with roughly $N = O(k \log d/\epsilon)$ samples.
Computationally, this currently needs $d^{\Omega(k)}$ run-time. Alternately,
with $N = O(d)$, we can get polynomial-time. Thus, there is an exponential gap
(in the dependence on $d$) between the two and we do not know if it is possible
to get $d^{o(k)}$ run-time and $o(d)$ samples.
 We give the first generic positive result for worst-case design matrices
${X}$: For any ${X}$, we show that if the support of ${w}^*$ is chosen at
random, we can get prediction error $\epsilon$ with $N = \text{poly}(k, \log d,
1/\epsilon)$ samples and run-time $\text{poly}(d,N)$. This run-time holds for
any design matrix ${X}$ with condition number up to $2^{\text{poly}(d)}$.
 Previously, such results were known for worst-case ${w}^*$, but only for
random design matrices from well-behaved families, matrices that have a very
low condition number ($\text{poly}(\log d)$; e.g., as studied in compressed
sensing), or those with special structural properties.
\\ ( https://arxiv.org/abs/2511.06211 ,  37kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06216
Date: Sun, 9 Nov 2025 04:01:46 GMT   (522kb)

Title: Adaptive Multi-view Graph Contrastive Learning via Fractional-order
 Neural Diffusion Networks
Authors: Yanan Zhao and Feng Ji and Jingyang Dai and Jiaze Ma and Keyue Jiang
 and Kai Zhao and Wee Peng Tay
Categories: cs.LG
Comments: Submitted to TPAMI
\\
 Graph contrastive learning (GCL) learns node and graph representations by
contrasting multiple views of the same graph. Existing methods typically rely
on fixed, handcrafted views-usually a local and a global perspective, which
limits their ability to capture multi-scale structural patterns. We present an
augmentation-free, multi-view GCL framework grounded in fractional-order
continuous dynamics. By varying the fractional derivative order $\alpha \in
(0,1]$, our encoders produce a continuous spectrum of views: small $\alpha$
yields localized features, while large $\alpha$ induces broader, global
aggregation. We treat $\alpha$ as a learnable parameter so the model can adapt
diffusion scales to the data and automatically discover informative views. This
principled approach generates diverse, complementary representations without
manual augmentations. Extensive experiments on standard benchmarks demonstrate
that our method produces more robust and expressive embeddings and outperforms
state-of-the-art GCL baselines.
\\ ( https://arxiv.org/abs/2511.06216 ,  522kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06229
Date: Sun, 9 Nov 2025 05:07:42 GMT   (9489kb)

Title: Deep Reinforcement Learning for Dynamic Origin-Destination Matrix
 Estimation in Microscopic Traffic Simulations Considering Credit Assignment
Authors: Donggyu Min, Seongjin Choi, Dong-Kyu Kim
Categories: cs.LG
Comments: 11 pages, 10 figures, 3 tables
\\
 This paper focuses on dynamic origin-destination matrix estimation (DODE), a
crucial calibration process necessary for the effective application of
microscopic traffic simulations. The fundamental challenge of the DODE problem
in microscopic simulations stems from the complex temporal dynamics and
inherent uncertainty of individual vehicle dynamics. This makes it highly
challenging to precisely determine which vehicle traverses which link at any
given moment, resulting in intricate and often ambiguous relationships between
origin-destination (OD) matrices and their contributions to resultant link
flows. This phenomenon constitutes the credit assignment problem, a central
challenge addressed in this study. We formulate the DODE problem as a Markov
Decision Process (MDP) and propose a novel framework that applies model-free
deep reinforcement learning (DRL). Within our proposed framework, the agent
learns an optimal policy to sequentially generate OD matrices, refining its
strategy through direct interaction with the simulation environment. The
proposed method is validated on the Nguyen-Dupuis network using SUMO, where its
performance is evaluated against ground-truth link flows aggregated at 5-minute
intervals over a 30-minute horizon. Experimental results demonstrate that our
approach achieves a 43.2% reduction in mean squared error (MSE) compared to the
best-performing conventional baseline. By reframing DODE as a sequential
decision-making problem, our approach addresses the credit assignment challenge
through its learned policy, thereby overcoming the limitations of conventional
methods and proposing a novel framework for calibration of microscopic traffic
simulations.
\\ ( https://arxiv.org/abs/2511.06229 ,  9489kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06231
Date: Sun, 9 Nov 2025 05:15:04 GMT   (1974kb)

Title: Synheart Emotion: Privacy-Preserving On-Device Emotion Recognition from
 Biosignals
Authors: Henok Ademtew and Israel Goytom
Categories: cs.LG
Comments: Preprint submitted to the Proceedings of the ACM on Interactive,
 Mobile, Wearable and Ubiquitous Technologies (IMWUT)
MSC-class: 68T05, 92C55
ACM-class: I.2.6; H.1.2; J.3
\\
 Human-computer interaction increasingly demands systems that recognize not
only explicit user inputs but also implicit emotional states. While substantial
progress has been made in affective computing, most emotion recognition systems
rely on cloud-based inference, introducing privacy vulnerabilities and latency
constraints unsuitable for real-time applications. This work presents a
comprehensive evaluation of machine learning architectures for on-device
emotion recognition from wrist-based photoplethysmography (PPG), systematically
comparing different models spanning classical ensemble methods, deep neural
networks, and transformers on the WESAD stress detection dataset. Results
demonstrate that classical ensemble methods substantially outperform deep
learning on small physiological datasets, with ExtraTrees achieving F1 = 0.826
on combined features and F1 = 0.623 on wrist-only features, compared to
transformers achieving only F1 = 0.509-0.577. We deploy the wrist-only
ExtraTrees model optimized via ONNX conversion, achieving a 4.08 MB footprint,
0.05 ms inference latency, and 152x speedup over the original implementation.
Furthermore, ONNX optimization yields a 30.5% average storage reduction and
40.1x inference speedup, highlighting the feasibility of privacy-preserving
on-device emotion recognition for real-world wearables.
\\ ( https://arxiv.org/abs/2511.06231 ,  1974kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06232
Date: Sun, 9 Nov 2025 05:19:14 GMT   (13kb)

Title: Scaling Laws and In-Context Learning: A Unified Theoretical Framework
Authors: Sushant Mehta, Ishan Gupta
Categories: cs.LG cs.AI
Journal-ref: Workshop on Principles of Generative Modeling (PriGM) @ EurIPS2025
\\
 In-context learning (ICL) enables large language models to adapt to new tasks
from demonstrations without parameter updates. Despite extensive empirical
studies, a principled understanding of ICL emergence at scale remains more
elusive. We present a unified theoretical framework connecting scaling laws to
ICL emergence in transformers. Our analysis establishes that ICL performance
follows power-law relationships with model depth $L$, width $d$, context length
$k$, and training data $D$, with exponents determined by task structure. We
show that under specific conditions, transformers implement gradient-based
metalearning in their forward pass, with an effective learning rate
$\eta_{\text{eff}} = \Theta(1/\sqrt{Ld})$. We demonstrate sharp phase
transitions at critical scales and derive optimal depth-width allocations
favoring $L^* \propto N^{2/3}$, $d^* \propto N^{1/3}$ for the fixed parameter
budget $N = Ld$. Systematic experiments on synthetic tasks validate our
predictions, with measured scaling exponents closely matching theory. This work
provides both necessary and sufficient conditions for the emergence of ICLs and
establishes fundamental computational limits on what transformers can learn
in-context.
\\ ( https://arxiv.org/abs/2511.06232 ,  13kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06237
Date: Sun, 9 Nov 2025 05:44:45 GMT   (277kb)

Title: Mixtures of SubExperts for Large Language Continual Learning
Authors: Haeyong Kang
Categories: cs.LG cs.AI cs.CL
\\
 Adapting Large Language Models (LLMs) to a continuous stream of tasks is a
critical yet challenging endeavor. While Parameter-Efficient Fine-Tuning (PEFT)
methods have become a standard for this, they face a fundamental dilemma in
continual learning. Reusing a single set of PEFT parameters for new tasks often
leads to catastrophic forgetting of prior knowledge. Conversely, allocating
distinct parameters for each task prevents forgetting but results in a linear
growth of the model's size and fails to facilitate knowledge transfer between
related tasks. To overcome these limitations, we propose a novel adaptive PEFT
method referred to as \textit{Mixtures of SubExperts (MoSEs)}, a novel
continual learning framework designed for minimal forgetting and efficient
scalability. MoSEs integrate a sparse Mixture of SubExperts into the
transformer layers, governed by a task-specific routing mechanism. This
architecture allows the model to isolate and protect knowledge within dedicated
SubExperts, thereby minimizing parameter interference and catastrophic
forgetting. Crucially, the router can adaptively select and combine previously
learned sparse parameters for new tasks, enabling effective knowledge transfer
while ensuring that the model's capacity grows sublinearly. We evaluate MoSEs
on the comprehensive TRACE benchmark datasets. Our experiments demonstrate that
MoSEs significantly outperform conventional continual learning approaches in
both knowledge retention and scalability to new tasks, achieving
state-of-the-art performance with substantial memory and computational savings.
\\ ( https://arxiv.org/abs/2511.06237 ,  277kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06248
Date: Sun, 9 Nov 2025 06:18:38 GMT   (3722kb)

Title: Constraint-Informed Active Learning for End-to-End ACOPF Optimization
 Proxies
Authors: Miao Li, Michael Klamkin, Pascal Van Hentenryck, Wenting Li, Russell
 Bent
Categories: cs.LG cs.AI
Comments: 8 PAGES
MSC-class: 00
\\
 This paper studies optimization proxies, machine learning (ML) models trained
to efficiently predict optimal solutions for AC Optimal Power Flow (ACOPF)
problems. While promising, optimization proxy performance heavily depends on
training data quality. To address this limitation, this paper introduces a
novel active sampling framework for ACOPF optimization proxies designed to
generate realistic and diverse training data. The framework actively explores
varied, flexible problem specifications reflecting plausible operational
realities. More importantly, the approach uses optimization-specific quantities
(active constraint sets) that better capture the salient features of an ACOPF
that lead to the optimal solution. Numerical results show superior
generalization over existing sampling methods with an equivalent training
budget, significantly advancing the state-of-practice for trustworthy ACOPF
optimization proxies.
\\ ( https://arxiv.org/abs/2511.06248 ,  3722kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06250
Date: Sun, 9 Nov 2025 06:29:22 GMT   (23235kb)

Title: Test-Time Iterative Error Correction for Efficient Diffusion Models
Authors: Yunshan Zhong, Yanwei Qi, Yuxin Zhang
Categories: cs.LG cs.CV
\\
 With the growing demand for high-quality image generation on
resource-constrained devices, efficient diffusion models have received
increasing attention. However, such models suffer from approximation errors
introduced by efficiency techniques, which significantly degrade generation
quality. Once deployed, these errors are difficult to correct, as modifying the
model is typically infeasible in deployment environments. Through an analysis
of error propagation across diffusion timesteps, we reveal that these
approximation errors can accumulate exponentially, severely impairing output
quality. Motivated by this insight, we propose Iterative Error Correction
(IEC), a novel test-time method that mitigates inference-time errors by
iteratively refining the model's output. IEC is theoretically proven to reduce
error propagation from exponential to linear growth, without requiring any
retraining or architectural changes. IEC can seamlessly integrate into the
inference process of existing diffusion models, enabling a flexible trade-off
between performance and efficiency. Extensive experiments show that IEC
consistently improves generation quality across various datasets, efficiency
techniques, and model architectures, establishing it as a practical and
generalizable solution for test-time enhancement of efficient diffusion models.
\\ ( https://arxiv.org/abs/2511.06250 ,  23235kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06252
Date: Sun, 9 Nov 2025 07:01:18 GMT   (378kb)

Title: MrCoM: A Meta-Regularized World-Model Generalizing Across
 Multi-Scenarios
Authors: Xuantang Xiong, Ni Mu, Runpeng Xie, Senhao Yang, Yaqing Wang, Lexiang
 Wang, Yao Luan, Siyuan Li, Shuang Xu, Yiqin Yang, Bo Xu
Categories: cs.LG cs.AI
\\
 Model-based reinforcement learning (MBRL) is a crucial approach to enhance
the generalization capabilities and improve the sample efficiency of RL
algorithms. However, current MBRL methods focus primarily on building world
models for single tasks and rarely address generalization across different
scenarios. Building on the insight that dynamics within the same simulation
engine share inherent properties, we attempt to construct a unified world model
capable of generalizing across different scenarios, named Meta-Regularized
Contextual World-Model (MrCoM). This method first decomposes the latent state
space into various components based on the dynamic characteristics, thereby
enhancing the accuracy of world-model prediction. Further, MrCoM adopts
meta-state regularization to extract unified representation of
scenario-relevant information, and meta-value regularization to align
world-model optimization with policy learning across diverse scenario
objectives. We theoretically analyze the generalization error upper bound of
MrCoM in multi-scenario settings. We systematically evaluate our algorithm's
generalization ability across diverse scenarios, demonstrating significantly
better performance than previous state-of-the-art methods.
\\ ( https://arxiv.org/abs/2511.06252 ,  378kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06259
Date: Sun, 9 Nov 2025 07:25:53 GMT   (1924kb)

Title: Breaking the Modality Barrier: Generative Modeling for Accurate Molecule
 Retrieval from Mass Spectra
Authors: Yiwen Zhang, Keyan Ding, Yihang Wu, Xiang Zhuang, Yi Yang, Qiang
 Zhang, Huajun Chen
Categories: cs.LG cs.AI
Comments: Accepted by AAAI 2026
\\
 Retrieving molecular structures from tandem mass spectra is a crucial step in
rapid compound identification. Existing retrieval methods, such as traditional
mass spectral library matching, suffer from limited spectral library coverage,
while recent cross-modal representation learning frameworks often encounter
modality misalignment, resulting in suboptimal retrieval accuracy and
generalization. To address these limitations, we propose GLMR, a Generative
Language Model-based Retrieval framework that mitigates the cross-modal
misalignment through a two-stage process. In the pre-retrieval stage, a
contrastive learning-based model identifies top candidate molecules as
contextual priors for the input mass spectrum. In the generative retrieval
stage, these candidate molecules are integrated with the input mass spectrum to
guide a generative model in producing refined molecular structures, which are
then used to re-rank the candidates based on molecular similarity. Experiments
on both MassSpecGym and the proposed MassRET-20k dataset demonstrate that GLMR
significantly outperforms existing methods, achieving over 40% improvement in
top-1 accuracy and exhibiting strong generalizability.
\\ ( https://arxiv.org/abs/2511.06259 ,  1924kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06265
Date: Sun, 9 Nov 2025 07:58:36 GMT   (1506kb)

Title: CAMP-HiVe: Cyclic Pair Merging based Efficient DNN Pruning with
 Hessian-Vector Approximation for Resource-Constrained Systems
Authors: Mohammad Helal Uddin, Sai Krishna Ghanta, Liam Seymour, Sabur Baidya
Categories: cs.LG cs.CV
\\
 Deep learning algorithms are becoming an essential component of many
artificial intelligence (AI) driven applications, many of which run on
resource-constrained and energy-constrained systems. For efficient deployment
of these algorithms, although different techniques for the compression of
neural network models are proposed, neural pruning is one of the fastest and
effective methods, which can provide a high compression gain with minimal cost.
To harness enhanced performance gain with respect to model complexity, we
propose a novel neural network pruning approach utilizing Hessian-vector
products that approximate crucial curvature information in the loss function,
which significantly reduces the computation demands. By employing a power
iteration method, our algorithm effectively identifies and preserves the
essential information, ensuring a balanced trade-off between model accuracy and
computational efficiency. Herein, we introduce CAMP-HiVe, a cyclic pair
merging-based pruning with Hessian Vector approximation by iteratively
consolidating weight pairs, combining significant and less significant weights,
thus effectively streamlining the model while preserving its performance. This
dynamic, adaptive framework allows for real-time adjustment of weight
significance, ensuring that only the most critical parameters are retained. Our
experimental results demonstrate that our proposed method achieves significant
reductions in computational requirements while maintaining high performance
across different neural network architectures, e.g., ResNet18, ResNet56, and
MobileNetv2, on standard benchmark datasets, e.g., CIFAR10, CIFAR-100, and
ImageNet, and it outperforms the existing state-of-the-art neural pruning
methods.
\\ ( https://arxiv.org/abs/2511.06265 ,  1506kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06269
Date: Sun, 9 Nov 2025 08:07:07 GMT   (4089kb)

Title: LLM$^3$-DTI: A Large Language Model and Multi-modal data co-powered
 framework for Drug-Target Interaction prediction
Authors: Yuhao Zhang, Qinghong Guo, Qixian Chen, Liuwei Zhang, Hongyan Cui,
 Xiyi Chen
Categories: cs.LG q-bio.QM
\\
 Drug-target interaction (DTI) prediction is of great significance for drug
discovery and drug repurposing. With the accumulation of a large volume of
valuable data, data-driven methods have been increasingly harnessed to predict
DTIs, reducing costs across various dimensions. Therefore, this paper proposes
a $\textbf{L}$arge $\textbf{L}$anguage $\textbf{M}$odel and
$\textbf{M}$ulti-$\textbf{M}$odel data co-powered $\textbf{D}$rug
$\textbf{T}$arget $\textbf{I}$nteraction prediction framework, named
LLM$^3$-DTI. LLM$^3$-DTI constructs multi-modal data embedding to enhance DTI
prediction performance. In this framework, the text semantic embeddings of
drugs and targets are encoded by a domain-specific LLM. To effectively align
and fuse multi-modal embedding. We propose the dual cross-attention mechanism
and the TSFusion module. Finally, these multi-modal data are utilized for the
DTI task through an output network. The experimental results indicate that
LLM$^3$-DTI can proficiently identify validated DTIs, surpassing the
performance of the models employed for comparison across diverse scenarios.
Consequently, LLM$^3$-DTI is adept at fulfilling the task of DTI prediction
with excellence. The data and code are available at
https://github.com/chaser-gua/LLM3DTI.
\\ ( https://arxiv.org/abs/2511.06269 ,  4089kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06273
Date: Sun, 9 Nov 2025 08:17:19 GMT   (1672kb)

Title: COTN: A Chaotic Oscillatory Transformer Network for Complex Volatile
 Systems under Extreme Conditions
Authors: Boyan Tang, Yilong Zeng, Xuanhao Ren, Peng Xiao, Yuhan Zhao, Raymond
 Lee, Jianghua Wu
Categories: cs.LG cs.AI
Comments: Submitted to IEEE Transactions on Neural Networks and Learning
 Systems
\\
 Accurate prediction of financial and electricity markets, especially under
extreme conditions, remains a significant challenge due to their intrinsic
nonlinearity, rapid fluctuations, and chaotic patterns. To address these
limitations, we propose the Chaotic Oscillatory Transformer Network (COTN).
COTN innovatively combines a Transformer architecture with a novel Lee
Oscillator activation function, processed through Max-over-Time pooling and a
lambda-gating mechanism. This design is specifically tailored to effectively
capture chaotic dynamics and improve responsiveness during periods of
heightened volatility, where conventional activation functions (e.g., ReLU,
GELU) tend to saturate. Furthermore, COTN incorporates an Autoencoder
Self-Regressive (ASR) module to detect and isolate abnormal market patterns,
such as sudden price spikes or crashes, thereby preventing corruption of the
core prediction process and enhancing robustness. Extensive experiments across
electricity spot markets and financial markets demonstrate the practical
applicability and resilience of COTN. Our approach outperforms state-of-the-art
deep learning models like Informer by up to 17% and traditional statistical
methods like GARCH by as much as 40%. These results underscore COTN's
effectiveness in navigating real-world market uncertainty and complexity,
offering a powerful tool for forecasting highly volatile systems under duress.
\\ ( https://arxiv.org/abs/2511.06273 ,  1672kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06293
Date: Sun, 9 Nov 2025 09:11:02 GMT   (739kb)

Title: Achieving Fairness Without Harm via Selective Demographic Experts
Authors: Xuwei Tan, Yuanlong Wang, Thai-Hoang Pham, Ping Zhang, Xueru Zhang
Categories: cs.LG
Comments: AAAI26; Extended version
\\
 As machine learning systems become increasingly integrated into
human-centered domains such as healthcare, ensuring fairness while maintaining
high predictive performance is critical. Existing bias mitigation techniques
often impose a trade-off between fairness and accuracy, inadvertently degrading
performance for certain demographic groups. In high-stakes domains like
clinical diagnosis, such trade-offs are ethically and practically unacceptable.
In this study, we propose a fairness-without-harm approach by learning distinct
representations for different demographic groups and selectively applying
demographic experts consisting of group-specific representations and
personalized classifiers through a no-harm constrained selection. We evaluate
our approach on three real-world medical datasets -- covering eye disease, skin
cancer, and X-ray diagnosis -- as well as two face datasets. Extensive
empirical results demonstrate the effectiveness of our approach in achieving
fairness without harm.
\\ ( https://arxiv.org/abs/2511.06293 ,  739kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06294
Date: Sun, 9 Nov 2025 09:12:50 GMT   (23963kb)

Title: Transolver is a Linear Transformer: Revisiting Physics-Attention through
 the Lens of Linear Attention
Authors: Wenjie Hu, Sidun Liu, Peng Qiao, Zhenglun Sun, Yong Dou
Categories: cs.LG cs.AI
\\
 Recent advances in Transformer-based Neural Operators have enabled
significant progress in data-driven solvers for Partial Differential Equations
(PDEs). Most current research has focused on reducing the quadratic complexity
of attention to address the resulting low training and inference efficiency.
Among these works, Transolver stands out as a representative method that
introduces Physics-Attention to reduce computational costs. Physics-Attention
projects grid points into slices for slice attention, then maps them back
through deslicing. However, we observe that Physics-Attention can be
reformulated as a special case of linear attention, and that the slice
attention may even hurt the model performance. Based on these observations, we
argue that its effectiveness primarily arises from the slice and deslice
operations rather than interactions between slices. Building on this insight,
we propose a two-step transformation to redesign Physics-Attention into a
canonical linear attention, which we call Linear Attention Neural Operator
(LinearNO). Our method achieves state-of-the-art performance on six standard
PDE benchmarks, while reducing the number of parameters by an average of 40.0%
and computational cost by 36.2%. Additionally, it delivers superior performance
on two challenging, industrial-level datasets: AirfRANS and Shape-Net Car.
\\ ( https://arxiv.org/abs/2511.06294 ,  23963kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06300
Date: Sun, 9 Nov 2025 09:35:45 GMT   (1073kb)

Title: 3dSAGER: Geospatial Entity Resolution over 3D Objects (Technical Report)
Authors: Bar Genossar, Sagi Dalyot, Roee Shraga and Avigdor Gal
Categories: cs.LG
DOI: 10.1145/3769751
\\
 Urban environments are continuously mapped and modeled by various data
collection platforms, including satellites, unmanned aerial vehicles and street
cameras. The growing availability of 3D geospatial data from multiple
modalities has introduced new opportunities and challenges for integrating
spatial knowledge at scale, particularly in high-impact domains such as urban
planning and rapid disaster management. Geospatial entity resolution is the
task of identifying matching spatial objects across different datasets, often
collected independently under varying conditions. Existing approaches typically
rely on spatial proximity, textual metadata, or external identifiers to
determine correspondence. While useful, these signals are often unavailable,
unreliable, or misaligned, especially in cross-source scenarios. To address
these limitations, we shift the focus to the intrinsic geometry of 3D spatial
objects and present 3dSAGER (3D Spatial-Aware Geospatial Entity Resolution), an
end-to-end pipeline for geospatial entity resolution over 3D objects. 3dSAGER
introduces a novel, spatial-reference-independent featurization mechanism that
captures intricate geometric characteristics of matching pairs, enabling robust
comparison even across datasets with incompatible coordinate systems where
traditional spatial methods fail. As a key component of 3dSAGER, we also
propose a new lightweight and interpretable blocking method, BKAFI, that
leverages a trained model to efficiently generate high-recall candidate sets.
We validate 3dSAGER through extensive experiments on real-world urban datasets,
demonstrating significant gains in both accuracy and efficiency over strong
baselines. Our empirical study further dissects the contributions of each
component, providing insights into their impact and the overall design choices.
\\ ( https://arxiv.org/abs/2511.06300 ,  1073kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06304
Date: Sun, 9 Nov 2025 10:01:39 GMT   (6897kb)

Title: Kaggle Chronicles: 15 Years of Competitions, Community and Data Science
 Innovation
Authors: Kevin B\"onisch and Leandro Losaria
Categories: cs.LG cs.AI cs.GL stat.ML
\\
 Since 2010, Kaggle has been a platform where data scientists from around the
world come together to compete, collaborate, and push the boundaries of Data
Science. Over these 15 years, it has grown from a purely competition-focused
site into a broader ecosystem with forums, notebooks, models, datasets, and
more. With the release of the Kaggle Meta Code and Kaggle Meta Datasets, we now
have a unique opportunity to explore these competitions, technologies, and
real-world applications of Machine Learning and AI. And so in this study, we
take a closer look at 15 years of data science on Kaggle - through metadata,
shared code, community discussions, and the competitions themselves. We explore
Kaggle's growth, its impact on the data science community, uncover hidden
technological trends, analyze competition winners, how Kagglers approach
problems in general, and more. We do this by analyzing millions of kernels and
discussion threads to perform both longitudinal trend analysis and standard
exploratory data analysis. Our findings show that Kaggle is a steadily growing
platform with increasingly diverse use cases, and that Kagglers are quick to
adapt to new trends and apply them to real-world challenges, while producing -
on average - models with solid generalization capabilities. We also offer a
snapshot of the platform as a whole, highlighting its history and technological
evolution. Finally, this study is accompanied by a video
(https://www.youtube.com/watch?v=YVOV9bIUNrM) and a Kaggle write-up
(https://kaggle.com/competitions/meta-kaggle-hackathon/writeups/kaggle-chronicles-15-years-of-competitions-communi)
for your convenience.
\\ ( https://arxiv.org/abs/2511.06304 ,  6897kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06307
Date: Sun, 9 Nov 2025 10:11:28 GMT   (8091kb)

Title: DRIVE: Data Curation Best Practices for Reinforcement Learning with
 Verifiable Reward in Competitive Code Generation
Authors: Speed Zhu, Jianwei Cai, Guang Chen, Lulu Wu, Saiyong Yang, Wiggin Zhou
Categories: cs.LG
Comments: 15 pages, 8 figures
\\
 Recent reasoning-first models (e.g., OpenAI o1, DeepSeek R1) have spurred a
resurgence of interest in RLVR. Nevertheless, advances are dominated by
mathematics (e.g., AIME), with competitive-programming code generation
underexplored and data curation receiving less attention than RL algorithm
design. We investigate how to construct RLVR datasets (i.e., RL prompts) and
present practical training techniques that yield strong performance on
competitive-programming code generation. Our pipeline begins with supervised
fine-tuning (SFT) distilled from strong open-source models, augmented with
general-purpose and reasoning-intensive data. RL then follows a two-stage
process with executable, testcase-driven rewards: first, training on a large,
uniformly distributed set of competitive-programming problems using Group
Relative Policy Optimization (GRPO) with 8 rollouts per prompt and a relatively
short response-generation window (e.g., 32k during SFT and 24k in this stage)
to expand entropy and mitigate repetition and truncation; second, we perform
\textbf{Pre-GRPO}: updating on a small, high-quality set of challenging
problems with a large rollout budget (64 rollouts per prompt) under a
hard-focus curriculum that continuously retains the most difficult instances
throughout training. We implement our method on Qwen2.5-32B and evaluate on
LeetCode and Codeforces weekly contests to avoid data leakage. The resulting
model achieves state-of-the-art performance among models of similar scale and
is comparable to leading systems such as DeepSeek v3.1 and Doubao-1.5-Thinking.
We also examine scaling trends and observe strong RL scaling on an internal
large-scale MoE model. Our study distills concise best practices for data
curation, entropy expansion, and curriculum design in RLVR for
competitive-programming code generation.
\\ ( https://arxiv.org/abs/2511.06307 ,  8091kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06341
Date: Sun, 9 Nov 2025 11:51:15 GMT   (7594kb)

Title: Scalable Verification of Neural Control Barrier Functions Using Linear
 Bound Propagation
Authors: Nikolaus Vertovec, Frederik Baymler Mathiesen, Thom Badings, Luca
 Laurenti, Alessandro Abate
Categories: cs.LG cs.RO cs.SY eess.SY math.OC
\\
 Control barrier functions (CBFs) are a popular tool for safety certification
of nonlinear dynamical control systems. Recently, CBFs represented as neural
networks have shown great promise due to their expressiveness and applicability
to a broad class of dynamics and safety constraints. However, verifying that a
trained neural network is indeed a valid CBF is a computational bottleneck that
limits the size of the networks that can be used. To overcome this limitation,
we present a novel framework for verifying neural CBFs based on piecewise
linear upper and lower bounds on the conditions required for a neural network
to be a CBF. Our approach is rooted in linear bound propagation (LBP) for
neural networks, which we extend to compute bounds on the gradients of the
network. Combined with McCormick relaxation, we derive linear upper and lower
bounds on the CBF conditions, thereby eliminating the need for computationally
expensive verification procedures. Our approach applies to arbitrary
control-affine systems and a broad range of nonlinear activation functions. To
reduce conservatism, we develop a parallelizable refinement strategy that
adaptively refines the regions over which these bounds are computed. Our
approach scales to larger neural networks than state-of-the-art verification
procedures for CBFs, as demonstrated by our numerical experiments.
\\ ( https://arxiv.org/abs/2511.06341 ,  7594kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06356
Date: Sun, 9 Nov 2025 12:29:16 GMT   (2124kb)

Title: Reaction Prediction via Interaction Modeling of Symmetric Difference
 Shingle Sets
Authors: Runhan Shi, Letian Chen, Gufeng Yu, Yang Yang
Categories: cs.LG cs.AI q-bio.BM
\\
 Chemical reaction prediction remains a fundamental challenge in organic
chemistry, where existing machine learning models face two critical
limitations: sensitivity to input permutations (molecule/atom orderings) and
inadequate modeling of substructural interactions governing reactivity. These
shortcomings lead to inconsistent predictions and poor generalization to
real-world scenarios. To address these challenges, we propose ReaDISH, a novel
reaction prediction model that learns permutation-invariant representations
while incorporating interaction-aware features. It introduces two innovations:
(1) symmetric difference shingle encoding, which computes molecular shingle
differences to capture reaction-specific structural changes while eliminating
order sensitivity; and (2) geometry-structure interaction attention, a
mechanism that models intra- and inter-molecular interactions at the shingle
level. Extensive experiments demonstrate that ReaDISH improves reaction
prediction performance across diverse benchmarks. It shows enhanced robustness
with an average improvement of 8.76% on R$^2$ under permutation perturbations.
\\ ( https://arxiv.org/abs/2511.06356 ,  2124kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06363
Date: Sun, 9 Nov 2025 13:03:27 GMT   (671kb)

Title: Privacy-Preserving Federated Learning for Fair and Efficient Urban
 Traffic Optimization
Authors: Rathin Chandra Shit and Sharmila Subudhi
Categories: cs.LG cs.AI cs.NI cs.SY eess.SY
Comments: Under review at IEEE journal
\\
 The optimization of urban traffic is threatened by the complexity of
achieving a balance between transport efficiency and the maintenance of
privacy, as well as the equitable distribution of traffic based on
socioeconomically diverse neighborhoods. Current centralized traffic management
schemes invade user location privacy and further entrench traffic disparity by
offering disadvantaged route suggestions, whereas current federated learning
frameworks do not consider fairness constraints in multi-objective traffic
settings. This study presents a privacy-preserving federated learning
framework, termed FedFair-Traffic, that jointly and simultaneously optimizes
travel efficiency, traffic fairness, and differential privacy protection. This
is the first attempt to integrate three conflicting objectives to improve urban
transportation systems. The proposed methodology enables collaborative learning
between related vehicles with data locality by integrating Graph Neural
Networks with differential privacy mechanisms ($\epsilon$-privacy guarantees)
and Gini coefficient-based fair constraints using multi-objective optimization.
The framework uses federated aggregation methods of gradient clipping and noise
injection to provide differential privacy and optimize Pareto-efficient
solutions for the efficiency-fairness tradeoff. Real-world comprehensive
experiments on the METR-LA traffic dataset showed that FedFair-Traffic can
reduce the average travel time by 7\% (14.2 minutes) compared with their
centralized baselines, promote traffic fairness by 73\% (Gini coefficient,
0.78), and offer high privacy protection (privacy score, 0.8) with an 89\%
reduction in communication overhead. These outcomes demonstrate that
FedFair-Traffic is a scalable privacy-aware smart city infrastructure with
possible use-cases in metropolitan traffic flow control and federated
transportation networks.
\\ ( https://arxiv.org/abs/2511.06363 ,  671kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06374
Date: Sun, 9 Nov 2025 13:24:14 GMT   (761kb)

Title: Adaptive Regularization for Large-Scale Sparse Feature Embedding Models
Authors: Mang Li, Wei Lyu
Categories: cs.LG stat.ML
\\
 The one-epoch overfitting problem has drawn widespread attention, especially
in CTR and CVR estimation models in search, advertising, and recommendation
domains. These models which rely heavily on large-scale sparse categorical
features, often suffer a significant decline in performance when trained for
multiple epochs. Although recent studies have proposed heuristic solutions,
they have not clearly identified the fundamental cause of this phenomenon. In
this work, we provide a theoretical analysis that explains why overfitting
occurs in models that use large-scale sparse categorical features. Based on
this analysis, we propose an adaptive regularization method to address it. Our
approach not only prevents the severe performance degradation observed during
multi-epoch training, but also improves model performance within a single
epoch. This method has already been deployed in online production systems.
\\ ( https://arxiv.org/abs/2511.06374 ,  761kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06376
Date: Sun, 9 Nov 2025 13:27:17 GMT   (60kb)

Title: Vocabulary In-Context Learning in Transformers: Benefits of Positional
 Encoding
Authors: Qian Ma, Ruoxiang Xu, Yongqiang Cai
Categories: cs.LG
Comments: Accepted as NIPS 2025 poster
\\
 Numerous studies have demonstrated that the Transformer architecture
possesses the capability for in-context learning (ICL). In scenarios involving
function approximation, context can serve as a control parameter for the model,
endowing it with the universal approximation property (UAP). In practice,
context is represented by tokens from a finite set, referred to as a
vocabulary, which is the case considered in this paper, \emph{i.e.}, vocabulary
in-context learning (VICL). We demonstrate that VICL in single-layer
Transformers, without positional encoding, does not possess the UAP; however,
it is possible to achieve the UAP when positional encoding is included. Several
sufficient conditions for the positional encoding are provided. Our findings
reveal the benefits of positional encoding from an approximation theory
perspective in the context of ICL.
\\ ( https://arxiv.org/abs/2511.06376 ,  60kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06430
Date: Sun, 9 Nov 2025 15:51:52 GMT   (242kb)

Title: CG-TTRL: Context-Guided Test-Time Reinforcement Learning for On-Device
 Large Language Models
Authors: Peyman Hosseini, Ondrej Bohdal, Taha Ceritli, Ignacio Castro, Matthew
 Purver, Mete Ozay, Umberto Michieli
Categories: cs.LG cs.CL
Comments: 12 pages, 7 Figures, 4 Tables
ACM-class: I.2.7; I.5.4
\\
 Test-time Reinforcement Learning (TTRL) has shown promise in adapting
foundation models for complex tasks at test-time, resulting in large
performance improvements. TTRL leverages an elegant two-phase sampling
strategy: first, multi-sampling derives a pseudo-label via majority voting,
while subsequent downsampling and reward-based fine-tuning encourages the model
to explore and learn diverse valid solutions, with the pseudo-label modulating
the reward signal. Meanwhile, in-context learning has been widely explored at
inference time and demonstrated the ability to enhance model performance
without weight updates. However, TTRL's two-phase sampling strategy
under-utilizes contextual guidance, which can potentially improve pseudo-label
accuracy in the initial exploitation phase while regulating exploration in the
second. To address this, we propose context-guided TTRL (CG-TTRL), integrating
context dynamically into both sampling phases and propose a method for
efficient context selection for on-device applications. Our evaluations on
mathematical and scientific QA benchmarks show CG-TTRL outperforms TTRL (e.g.
additional 7% relative accuracy improvement over TTRL), while boosting
efficiency by obtaining strong performance after only a few steps of test-time
training (e.g. 8% relative improvement rather than 1% over TTRL after 3 steps).
\\ ( https://arxiv.org/abs/2511.06430 ,  242kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06443
Date: Sun, 9 Nov 2025 16:25:37 GMT   (377kb)

Title: How Wide and How Deep? Mitigating Over-Squashing of GNNs via Channel
 Capacity Constrained Estimation
Authors: Zinuo You, Jin Zheng, John Cartlidge
Categories: cs.LG
Comments: 29 pages, 11 figures. Author manuscript accepted for the 40th Annual
 AAAI Conference on Artificial Intelligence (AAAI-26), January 2026
\\
 Existing graph neural networks typically rely on heuristic choices for hidden
dimensions and propagation depths, which often lead to severe information loss
during propagation, known as over-squashing. To address this issue, we propose
Channel Capacity Constrained Estimation (C3E), a novel framework that
formulates the selection of hidden dimensions and depth as a nonlinear
programming problem grounded in information theory. Through modeling spectral
graph neural networks as communication channels, our approach directly connects
channel capacity to hidden dimensions, propagation depth, propagation
mechanism, and graph structure. Extensive experiments on nine public datasets
demonstrate that hidden dimensions and depths estimated by C3E can mitigate
over-squashing and consistently improve representation learning. Experimental
results show that over-squashing occurs due to the cumulative compression of
information in representation matrices. Furthermore, our findings show that
increasing hidden dimensions indeed mitigate information compression, while the
role of propagation depth is more nuanced, uncovering a fundamental balance
between information compression and representation complexity.
\\ ( https://arxiv.org/abs/2511.06443 ,  377kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06449
Date: Sun, 9 Nov 2025 16:31:39 GMT   (9460kb)

Title: FLEX: Continuous Agent Evolution via Forward Learning from Experience
Authors: Zhicheng Cai, Xinyuan Guo, Yu Pei, JiangTao Feng, Jiangjie Chen,
 Ya-Qin Zhang, Wei-Ying Ma, Mingxuan Wang, Hao Zhou
Categories: cs.LG cs.AI
\\
 Autonomous agents driven by Large Language Models (LLMs) have revolutionized
reasoning and problem-solving but remain static after training, unable to grow
with experience as intelligent beings do during deployment. We introduce
Forward Learning with EXperience (FLEX), a gradient-free learning paradigm that
enables LLM agents to continuously evolve through accumulated experience.
Specifically, FLEX cultivates scalable and inheritable evolution by
constructing a structured experience library through continual reflection on
successes and failures during interaction with the environment. FLEX delivers
substantial improvements on mathematical reasoning, chemical retrosynthesis,
and protein fitness prediction (up to 23% on AIME25, 10% on USPTO50k, and 14%
on ProteinGym). We further identify a clear scaling law of experiential growth
and the phenomenon of experience inheritance across agents, marking a step
toward scalable and inheritable continuous agent evolution. Project Page:
https://flex-gensi-thuair.github.io.
\\ ( https://arxiv.org/abs/2511.06449 ,  9460kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06451
Date: Sun, 9 Nov 2025 16:35:37 GMT   (1384kb)

Title: A Risk-Neutral Neural Operator for Arbitrage-Free SPX-VIX Term
 Structures
Authors: Jian'an Zhang
Categories: cs.LG q-fin.CP
Comments: 46 pages, 9 figures, includes appendices; v11 draft aligned with
 final outline
MSC-class: 68T07, 91G20, 65M32, 62P05
ACM-class: I.2.6; G.1.2; G.3
\\
 We propose ARBITER, a risk-neutral neural operator for learning joint SPX-VIX
term structures under no-arbitrage constraints. ARBITER maps market states to
an operator that outputs implied volatility and variance curves while enforcing
static arbitrage (calendar, vertical, butterfly), Lipschitz bounds, and
monotonicity. The model couples operator learning with constrained decoders and
is trained with extragradient-style updates plus projection. We introduce
evaluation metrics for derivatives term structures (NAS, CNAS, NI, Dual-Gap,
Stability Rate) and show gains over Fourier Neural Operator, DeepONet, and
state-space sequence models on historical SPX and VIX data. Ablation studies
indicate that tying the SPX and VIX legs reduces Dual-Gap and improves NI,
Lipschitz projection stabilizes calibration, and selective state updates
improve long-horizon generalization. We provide identifiability and
approximation results and describe practical recipes for arbitrage-free
interpolation and extrapolation across maturities and strikes.
\\ ( https://arxiv.org/abs/2511.06451 ,  1384kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06452
Date: Sun, 9 Nov 2025 16:37:09 GMT   (10289kb)

Title: MULTIBENCH++: A Unified and Comprehensive Multimodal Fusion Benchmarking
 Across Specialized Domains
Authors: Leyan Xue, Zongbo Han, Kecheng Xue, Xiaohong Liu, Guangyu Wang,
 Changqing Zhang
Categories: cs.LG
\\
 Although multimodal fusion has made significant progress, its advancement is
severely hindered by the lack of adequate evaluation benchmarks. Current fusion
methods are typically evaluated on a small selection of public datasets, a
limited scope that inadequately represents the complexity and diversity of
real-world scenarios, potentially leading to biased evaluations. This issue
presents a twofold challenge. On one hand, models may overfit to the biases of
specific datasets, hindering their generalization to broader practical
applications. On the other hand, the absence of a unified evaluation standard
makes fair and objective comparisons between different fusion methods
difficult. Consequently, a truly universal and high-performance fusion model
has yet to emerge. To address these challenges, we have developed a
large-scale, domain-adaptive benchmark for multimodal evaluation. This
benchmark integrates over 30 datasets, encompassing 15 modalities and 20
predictive tasks across key application domains. To complement this, we have
also developed an open-source, unified, and automated evaluation pipeline that
includes standardized implementations of state-of-the-art models and diverse
fusion paradigms. Leveraging this platform, we have conducted large-scale
experiments, successfully establishing new performance baselines across
multiple tasks. This work provides the academic community with a crucial
platform for rigorous and reproducible assessment of multimodal models, aiming
to propel the field of multimodal artificial intelligence to new heights.
\\ ( https://arxiv.org/abs/2511.06452 ,  10289kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06461
Date: Sun, 9 Nov 2025 17:05:01 GMT   (936kb)

Title: Reconstruction and Secrecy under Approximate Distance Queries
Authors: Shay Moran and Elizaveta Nesterova
Categories: cs.LG cs.IT math.IT math.MG
Comments: 39 pages. Conference version: NeurIPS 2025 (Spotlight). Extended
 appendix included
ACM-class: I.2.6; H.2.7; K.4.1
\\
 Consider the task of locating an unknown target point using approximate
distance queries: in each round, a reconstructor selects a query point and
receives a noisy version of its distance to the target. This problem arises
naturally in various contexts ranging from localization in GPS and sensor
networks to privacy-aware data access, and spans a wide variety of metric
spaces. It is relevant from the perspective of both the reconstructor (seeking
accurate recovery) and the responder (aiming to limit information disclosure,
e.g., for privacy or security reasons). We study this reconstruction game
through a learning-theoretic lens, focusing on the rate and limits of the best
possible reconstruction error. Our first result provides a tight geometric
characterization of the optimal error in terms of the Chebyshev radius, a
classical concept from geometry. This characterization applies to all compact
metric spaces (in fact, even to all totally bounded spaces) and yields explicit
formulas for natural metric spaces. Our second result addresses the asymptotic
behavior of reconstruction, distinguishing between pseudo-finite spaces --
where the optimal error is attained after finitely many queries -- and spaces
where the approximation curve exhibits nontrivial decay. We characterize
pseudo-finiteness for convex Euclidean spaces.
\\ ( https://arxiv.org/abs/2511.06461 ,  936kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06463
Date: Sun, 9 Nov 2025 17:15:40 GMT   (376kb)

Title: Error Estimate and Convergence Analysis for Data Valuation
Authors: Zhangyong Liang, Huanhuan Gao, and Ji Zhang
Categories: cs.LG
Comments: 7 pages, 1 figure
\\
 Data valuation quantifies data importance, but existing methods cannot ensure
validity in a single training process. The neural dynamic data valuation (NDDV)
method [3] addresses this limitation. Based on NDDV, we are the first to
explore error estimation and convergence analysis in data valuation. Under
Lipschitz and smoothness assumptions, we derive quadratic error bounds for loss
differences that scale inversely with time steps and quadratically with control
variations, ensuring stability. We also prove that the expected squared
gradient norm for the training loss vanishes asymptotically, and that the meta
loss converges sublinearly over iterations. In particular, NDDV achieves
sublinear convergence.
\\ ( https://arxiv.org/abs/2511.06463 ,  376kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06477
Date: Sun, 9 Nov 2025 17:48:26 GMT   (191kb)

Title: DyKAF: Dynamical Kronecker Approximation of the Fisher Information
 Matrix for Gradient Preconditioning
Authors: Nikolay Yudin, Ekaterina Grishina, Andrey Veprikov, Alexandr
 Beznosikov, Maxim Rakhuba
Categories: cs.LG cs.NA math.NA math.OC
MSC-class: 68T07, 65F55, 15A18
\\
 Recently, optimizers that explicitly treat weights as matrices, rather than
flattened vectors, have demonstrated their effectiveness. This perspective
naturally leads to structured approximations of the Fisher matrix as
preconditioners, where the matrix view induces a Kronecker-factorized form that
enables memory-efficient representation. However, constructing such
approximations both efficiently and accurately remains an open challenge, since
obtaining the optimal factorization is resource-intensive and practical methods
therefore rely on heuristic design choices. In this work, we introduce a novel
approach that leverages projector-splitting integrators to construct effective
preconditioners. Our optimizer, DyKAF (Dynamical Kronecker Approximation of the
Fisher Matrix), consistently improves the Fisher matrix approximation quality.
Experiments on large language model pre-training and fine-tuning demonstrate
that DyKAF outperforms existing optimizers across a range of evaluation
metrics.
\\ ( https://arxiv.org/abs/2511.06477 ,  191kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06492
Date: Sun, 9 Nov 2025 18:33:06 GMT   (584kb)

Title: Explainable AI For Early Detection Of Sepsis
Authors: Atharva Thakur, Shruti Dhumal
Categories: cs.LG cs.AI
\\
 Sepsis is a life-threatening condition that requires rapid detection and
treatment to prevent progression to severe sepsis, septic shock, or multi-organ
failure. Despite advances in medical technology, it remains a major challenge
for clinicians. While recent machine learning models have shown promise in
predicting sepsis onset, their black-box nature limits interpretability and
clinical trust. In this study, we present an interpretable AI approach for
sepsis analysis that integrates machine learning with clinical knowledge. Our
method not only delivers accurate predictions of sepsis onset but also enables
clinicians to understand, validate, and align model outputs with established
medical expertise.
\\ ( https://arxiv.org/abs/2511.06492 ,  584kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06493
Date: Sun, 9 Nov 2025 18:33:39 GMT   (1152kb)

Title: Learning Time-Varying Graph Signals via Koopman
Authors: Sivaram Krishnan, Jinho Choi, and Jihong Park
Categories: cs.LG eess.SP
\\
 A wide variety of real-world data, such as sea measurements, e.g.,
temperatures collected by distributed sensors and multiple unmanned aerial
vehicles (UAV) trajectories, can be naturally represented as graphs, often
exhibiting non-Euclidean structures. These graph representations may evolve
over time, forming time-varying graphs. Effectively modeling and analyzing such
dynamic graph data is critical for tasks like predicting graph evolution and
reconstructing missing graph data. In this paper, we propose a framework based
on the Koopman autoencoder (KAE) to handle time-varying graph data.
Specifically, we assume the existence of a hidden non-linear dynamical system,
where the state vector corresponds to the graph embedding of the time-varying
graph signals. To capture the evolving graph structures, the graph data is
first converted into a vector time series through graph embedding, representing
the structural information in a finite-dimensional latent space. In this latent
space, the KAE is applied to learn the underlying non-linear dynamics governing
the temporal evolution of graph features, enabling both prediction and
reconstruction tasks.
\\ ( https://arxiv.org/abs/2511.06493 ,  1152kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06494
Date: Sun, 9 Nov 2025 18:36:07 GMT   (1223kb)

Title: Route Experts by Sequence, not by Token
Authors: Tiansheng Wen, Yifei Wang, Aosong Feng, Long Ma, Xinyang Liu, Yifan
 Wang, Lixuan Guo, Bo Chen, Stefanie Jegelka, Chenyu You
Categories: cs.LG cs.AI cs.IT math.IT
\\
 Mixture-of-Experts (MoE) architectures scale large language models (LLMs) by
activating only a subset of experts per token, but the standard TopK routing
assigns the same fixed number of experts to all tokens, ignoring their varying
complexity. Prior adaptive routing methods introduce additional modules and
hyperparameters, often requiring costly retraining from scratch. We propose
Sequence-level TopK (SeqTopK), a minimal modification that shifts the expert
budget from the token level to the sequence level. By selecting the top $T
\cdot K$ experts across all $T$ tokens, SeqTopK enables end-to-end learned
dynamic allocation -- assigning more experts to difficult tokens and fewer to
easy ones -- while preserving the same overall budget. SeqTopK requires only a
few lines of code, adds less than 1% overhead, and remains fully compatible
with pretrained MoE models. Experiments across math, coding, law, and writing
show consistent improvements over TopK and prior parameter-free adaptive
methods, with gains that become substantially larger under higher sparsity (up
to 16.9%). These results highlight SeqTopK as a simple, efficient, and scalable
routing strategy, particularly well-suited for the extreme sparsity regimes of
next-generation LLMs. Code is available at
https://github.com/Y-Research-SBU/SeqTopK.
\\ ( https://arxiv.org/abs/2511.06494 ,  1223kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06495
Date: Sun, 9 Nov 2025 18:46:22 GMT   (5584kb)

Title: Probably Approximately Global Robustness Certification
Authors: Peter Blohm, Patrick Indri, Thomas G\"artner and Sagar Malhotra
Categories: cs.LG stat.ML
Comments: ICML 2025
\\
 We propose and investigate probabilistic guarantees for the adversarial
robustness of classification algorithms. While traditional formal verification
approaches for robustness are intractable and sampling-based approaches do not
provide formal guarantees, our approach is able to efficiently certify a
probabilistic relaxation of robustness. The key idea is to sample an
$\epsilon$-net and invoke a local robustness oracle on the sample. Remarkably,
the size of the sample needed to achieve probably approximately global
robustness guarantees is independent of the input dimensionality, the number of
classes, and the learning algorithm itself. Our approach can, therefore, be
applied even to large neural networks that are beyond the scope of traditional
formal verification. Experiments empirically confirm that it characterizes
robustness better than state-of-the-art sampling-based approaches and scales
better than formal methods.
\\ ( https://arxiv.org/abs/2511.06495 ,  5584kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06527
Date: Sun, 9 Nov 2025 20:31:39 GMT   (27kb)

Title: Efficient Approximation of Volterra Series for High-Dimensional Systems
Authors: Navin Khoshnan, Claudia K Petritsch, Bryce-Allen Bagley
Categories: cs.LG cs.SY eess.SY
\\
 The identification of high-dimensional nonlinear dynamical systems via the
Volterra series has significant potential, but has been severely hindered by
the curse of dimensionality. Tensor Network (TN) methods such as the Modified
Alternating Linear Scheme (MVMALS) have been a breakthrough for the field,
offering a tractable approach by exploiting the low-rank structure in Volterra
kernels. However, these techniques still encounter prohibitive computational
and memory bottlenecks due to high-order polynomial scaling with respect to
input dimension. To overcome this barrier, we introduce the Tensor Head
Averaging (THA) algorithm, which significantly reduces complexity by
constructing an ensemble of localized MVMALS models trained on small subsets of
the input space. In this paper, we present a theoretical foundation for the THA
algorithm. We establish observable, finite-sample bounds on the error between
the THA ensemble and a full MVMALS model, and we derive an exact decomposition
of the squared error. This decomposition is used to analyze the manner in which
subset models implicitly compensate for omitted dynamics. We quantify this
effect, and prove that correlation between the included and omitted dynamics
creates an optimization incentive which drives THA's performance toward
accuracy superior to a simple truncation of a full MVMALS model. THA thus
offers a scalable and theoretically grounded approach for identifying
previously intractable high-dimensional systems.
\\ ( https://arxiv.org/abs/2511.06527 ,  27kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06529
Date: Sun, 9 Nov 2025 20:32:20 GMT   (1773kb)

Title: TriShGAN: Enhancing Sparsity and Robustness in Multivariate Time Series
 Counterfactuals Explanation
Authors: Hongnan Ma, Yiwei Shi, Guanxiong Sun, Mengyue Yang, Weiru Liu
Categories: cs.LG cs.AI
\\
 In decision-making processes, stakeholders often rely on counterfactual
explanations, which provide suggestions about what should be changed in the
queried instance to alter the outcome of an AI system. However, generating
these explanations for multivariate time series presents challenges due to
their complex, multi-dimensional nature. Traditional Nearest Unlike
Neighbor-based methods typically substitute subsequences in a queried time
series with influential subsequences from an NUN, which is not always realistic
in real-world scenarios due to the rigid direct substitution. Counterfactual
with Residual Generative Adversarial Networks-based methods aim to address this
by learning from the distribution of observed data to generate synthetic
counterfactual explanations. However, these methods primarily focus on
minimizing the cost from the queried time series to the counterfactual
explanations and often neglect the importance of distancing the counterfactual
explanation from the decision boundary. This oversight can result in
explanations that no longer qualify as counterfactual if minor changes occur
within the model. To generate a more robust counterfactual explanation, we
introduce TriShGAN, under the CounteRGAN framework enhanced by the
incorporation of triplet loss. This unsupervised learning approach uses
distance metric learning to encourage the counterfactual explanations not only
to remain close to the queried time series but also to capture the feature
distribution of the instance with the desired outcome, thereby achieving a
better balance between minimal cost and robustness. Additionally, we integrate
a Shapelet Extractor that strategically selects the most discriminative parts
of the high-dimensional queried time series to enhance the sparsity of
counterfactual explanation and efficiency of the training process.
\\ ( https://arxiv.org/abs/2511.06529 ,  1773kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06538
Date: Sun, 9 Nov 2025 20:49:42 GMT   (1289kb)

Title: Bayesian Uncertainty Quantification with Anchored Ensembles for Robust
 EV Power Consumption Prediction
Authors: Ghazal Farhani, Taufiq Rahman, Kieran Humphries
Categories: cs.LG
\\
 Accurate EV power estimation underpins range prediction and energy
management, yet practitioners need both point accuracy and trustworthy
uncertainty. We propose an anchored-ensemble Long Short-Term Memory (LSTM) with
a Student-t likelihood that jointly captures epistemic (model) and aleatoric
(data) uncertainty. Anchoring imposes a Gaussian weight prior (MAP training),
yielding posterior-like diversity without test-time sampling, while the t-head
provides heavy-tailed robustness and closed-form prediction intervals. Using
vehicle-kinematic time series (e.g., speed, motor RPM), our model attains
strong accuracy: RMSE 3.36 +/- 1.10, MAE 2.21 +/- 0.89, R-squared = 0.93 +/-
0.02, explained variance 0.93 +/- 0.02, and delivers well-calibrated
uncertainty bands with near-nominal coverage. Against competitive baselines
(Student-t MC dropout; quantile regression with/without anchoring), our method
matches or improves log-scores while producing sharper intervals at the same
coverage. Crucially for real-time deployment, inference is a single
deterministic pass per ensemble member (or a weight-averaged collapse),
eliminating Monte Carlo latency. The result is a compact, theoretically
grounded estimator that couples accuracy, calibration, and systems efficiency,
enabling reliable range estimation and decision-making for production EV energy
management.
\\ ( https://arxiv.org/abs/2511.06538 ,  1289kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06563
Date: Sun, 9 Nov 2025 22:48:10 GMT   (1525kb)

Title: Practical Policy Distillation for Reinforcement Learning in Radio Access
 Networks
Authors: Sara Khosravi, Burak Demirel, Linghui Zhou, Javier Rasines and Pablo
 Soldati
Categories: cs.LG
Comments: This paper is accepted for publication in IEEE International
 Symposium on Personal, Indoor and Mobile Radio Communications, 2025
\\
 Adopting artificial intelligence (AI) in radio access networks (RANs)
presents several challenges, including limited availability of link-level
measurements (e.g., CQI reports), stringent real-time processing constraints
(e.g., sub-1 ms per TTI), and network heterogeneity (different spectrum bands,
cell types, and vendor equipment). A critical yet often overlooked barrier lies
in the computational and memory limitations of RAN baseband hardware,
particularly in legacy 4th Generation (4G) systems, which typically lack
on-chip neural accelerators. As a result, only lightweight AI models (under 1
Mb and sub-100~\mu s inference time) can be effectively deployed, limiting both
their performance and applicability. However, achieving strong generalization
across diverse network conditions often requires large-scale models with
substantial resource demands. To address this trade-off, this paper
investigates policy distillation in the context of a reinforcement
learning-based link adaptation task. We explore two strategies: single-policy
distillation, where a scenario-agnostic teacher model is compressed into one
generalized student model; and multi-policy distillation, where multiple
scenario-specific teachers are consolidated into a single generalist student.
Experimental evaluations in a high-fidelity, 5th Generation (5G)-compliant
simulator demonstrate that both strategies produce compact student models that
preserve the teachers' generalization capabilities while complying with the
computational and memory limitations of existing RAN hardware.
\\ ( https://arxiv.org/abs/2511.06563 ,  1525kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06568
Date: Sun, 9 Nov 2025 22:58:29 GMT   (198kb)

Title: Breaking the Dyadic Barrier: Rethinking Fairness in Link Prediction
 Beyond Demographic Parity
Authors: Jo\~ao Mattos, Debolina Halder Lina, Arlei Silva
Categories: cs.LG cs.AI cs.SI stat.ML
Comments: 12 pages, 5 figures. Accepted at AAAI-26 as an Oral
\\
 Link prediction is a fundamental task in graph machine learning with
applications, ranging from social recommendation to knowledge graph completion.
Fairness in this setting is critical, as biased predictions can exacerbate
societal inequalities. Prior work adopts a dyadic definition of fairness,
enforcing fairness through demographic parity between intra-group and
inter-group link predictions. However, we show that this dyadic framing can
obscure underlying disparities across subgroups, allowing systemic biases to go
undetected. Moreover, we argue that demographic parity does not meet desired
properties for fairness assessment in ranking-based tasks such as link
prediction. We formalize the limitations of existing fairness evaluations and
propose a framework that enables a more expressive assessment. Additionally, we
propose a lightweight post-processing method combined with decoupled link
predictors that effectively mitigates bias and achieves state-of-the-art
fairness-utility trade-offs.
\\ ( https://arxiv.org/abs/2511.06568 ,  198kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06597
Date: Mon, 10 Nov 2025 01:07:51 GMT   (472kb)

Title: Optimistic Online-to-Batch Conversions for Accelerated Convergence and
 Universality
Authors: Yu-Hu Yan, Peng Zhao, Zhi-Hua Zhou
Categories: cs.LG math.OC
Comments: NeurIPS 2025
\\
 In this work, we study offline convex optimization with smooth objectives,
where the classical Nesterov's Accelerated Gradient (NAG) method achieves the
optimal accelerated convergence. Extensive research has aimed to understand NAG
from various perspectives, and a recent line of work approaches this from the
viewpoint of online learning and online-to-batch conversion, emphasizing the
role of optimistic online algorithms for acceleration. In this work, we
contribute to this perspective by proposing novel optimistic online-to-batch
conversions that incorporate optimism theoretically into the analysis, thereby
significantly simplifying the online algorithm design while preserving the
optimal convergence rates. Specifically, we demonstrate the effectiveness of
our conversions through the following results: (i) when combined with simple
online gradient descent, our optimistic conversion achieves the optimal
accelerated convergence; (ii) our conversion also applies to strongly convex
objectives, and by leveraging both optimistic online-to-batch conversion and
optimistic online algorithms, we achieve the optimal accelerated convergence
rate for strongly convex and smooth objectives, for the first time through the
lens of online-to-batch conversion; (iii) our optimistic conversion can achieve
universality to smoothness -- applicable to both smooth and non-smooth
objectives without requiring knowledge of the smoothness coefficient -- and
remains efficient as non-universal methods by using only one gradient query in
each iteration. Finally, we highlight the effectiveness of our optimistic
online-to-batch conversions by a precise correspondence with NAG.
\\ ( https://arxiv.org/abs/2511.06597 ,  472kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06598
Date: Mon, 10 Nov 2025 01:08:37 GMT   (7606kb)

Title: Adaptive Initial Residual Connections for GNNs with Theoretical
 Guarantees
Authors: Mohammad Shirzadi, Ali Safarpoor Dehkordi, Ahad N. Zehmakan
Categories: cs.LG
Comments: This is the full version of the paper accepted to the 40th Annual
 AAAI Conference on Artificial Intelligence (AAAI-2026)
\\
 Message passing is the core operation in graph neural networks, where each
node updates its embeddings by aggregating information from its neighbors.
However, in deep architectures, this process often leads to diminished
expressiveness. A popular solution is to use residual connections, where the
input from the current (or initial) layer is added to aggregated neighbor
information to preserve embeddings across layers. Following a recent line of
research, we investigate an adaptive residual scheme in which different nodes
have varying residual strengths. We prove that this approach prevents
oversmoothing; particularly, we show that the Dirichlet energy of the
embeddings remains bounded away from zero. This is the first theoretical
guarantee not only for the adaptive setting, but also for static residual
connections (where residual strengths are shared across nodes) with activation
functions. Furthermore, extensive experiments show that this adaptive approach
outperforms standard and state-of-the-art message passing mechanisms,
especially on heterophilic graphs. To improve the time complexity of our
approach, we introduce a variant in which residual strengths are not learned
but instead set heuristically, a choice that performs as well as the learnable
version.
\\ ( https://arxiv.org/abs/2511.06598 ,  7606kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06607
Date: Mon, 10 Nov 2025 01:34:02 GMT   (538kb)

Title: Explainable Probabilistic Machine Learning for Predicting Drilling Fluid
 Loss of Circulation in Marun Oil Field
Authors: Seshu Kumar Damarla, Xiuli Zhu
Categories: cs.LG
Comments: 5 pages, 3 tables, 4 figrues
\\
 Lost circulation remains a major and costly challenge in drilling operations,
often resulting in wellbore instability, stuck pipe, and extended
non-productive time. Accurate prediction of fluid loss is therefore essential
for improving drilling safety and efficiency. This study presents a
probabilistic machine learning framework based on Gaussian Process Regression
(GPR) for predicting drilling fluid loss in complex formations. The GPR model
captures nonlinear dependencies among drilling parameters while quantifying
predictive uncertainty, offering enhanced reliability for high-risk
decision-making. Model hyperparameters are optimized using the Limited memory
Broyden Fletcher Goldfarb Shanno (LBFGS) algorithm to ensure numerical
stability and robust generalization. To improve interpretability, Local
Interpretable Model agnostic Explanations (LIME) are employed to elucidate how
individual features influence model predictions. The results highlight the
potential of explainable probabilistic learning for proactive identification of
lost-circulation risks, optimized design of lost circulation materials (LCM),
and reduction of operational uncertainties in drilling applications.
\\ ( https://arxiv.org/abs/2511.06607 ,  538kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06608
Date: Mon, 10 Nov 2025 01:37:51 GMT   (1583kb)

Title: Beyond Fixed Depth: Adaptive Graph Neural Networks for Node
 Classification Under Varying Homophily
Authors: Asela Hevapathige, Asiri Wijesinghe, Ahad N. Zehmakan
Categories: cs.LG cs.AI
Comments: Accepted to AAAI 2026
\\
 Graph Neural Networks (GNNs) have achieved significant success in addressing
node classification tasks. However, the effectiveness of traditional GNNs
degrades on heterophilic graphs, where connected nodes often belong to
different labels or properties. While recent work has introduced mechanisms to
improve GNN performance under heterophily, certain key limitations still exist.
Most existing models apply a fixed aggregation depth across all nodes,
overlooking the fact that nodes may require different propagation depths based
on their local homophily levels and neighborhood structures. Moreover, many
methods are tailored to either homophilic or heterophilic settings, lacking the
flexibility to generalize across both regimes. To address these challenges, we
develop a theoretical framework that links local structural and label
characteristics to information propagation dynamics at the node level. Our
analysis shows that optimal aggregation depth varies across nodes and is
critical for preserving class-discriminative information. Guided by this
insight, we propose a novel adaptive-depth GNN architecture that dynamically
selects node-specific aggregation depths using theoretically grounded metrics.
Our method seamlessly adapts to both homophilic and heterophilic patterns
within a unified model. Extensive experiments demonstrate that our approach
consistently enhances the performance of standard GNN backbones across diverse
benchmarks.
\\ ( https://arxiv.org/abs/2511.06608 ,  1583kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06609
Date: Mon, 10 Nov 2025 01:40:35 GMT   (3838kb)

Title: A Weak Penalty Neural ODE for Learning Chaotic Dynamics from Noisy Time
 Series
Authors: Xuyang Li, John Harlim, Romit Maulik
Categories: cs.LG math.DS
\\
 Accurate forecasting of complex high-dimensional dynamical systems from
observational data is essential for several applications across science and
engineering. A key challenge, however, is that real-world measurements are
often corrupted by noise, which severely degrades the performance of
data-driven models. Particularly, in chaotic dynamical systems, where small
errors amplify rapidly, it is challenging to identify a data-driven model from
noisy data that achieves short-term accuracy while preserving long-term
invariant properties. In this paper, we propose the use of the weak formulation
as a complementary approach to the classical strong formulation of data-driven
time-series forecasting models. Specifically, we focus on the neural ordinary
differential equation (NODE) architecture. Unlike the standard strong
formulation, which relies on the discretization of the NODE followed by
optimization, the weak formulation constrains the model using a set of
integrated residuals over temporal subdomains. While such a formulation yields
an effective NODE model, we discover that the performance of a NODE can be
further enhanced by employing this weak formulation as a penalty alongside the
classical strong formulation-based learning. Through numerical demonstrations,
we illustrate that our proposed training strategy, which we coined as the
Weak-Penalty NODE (WP-NODE), achieves state-of-the-art forecasting accuracy and
exceptional robustness across benchmark chaotic dynamical systems.
\\ ( https://arxiv.org/abs/2511.06609 ,  3838kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06610
Date: Mon, 10 Nov 2025 01:42:55 GMT   (1614kb)

Title: Non-Rival Data as Rival Products: An Encapsulation-Forging Approach for
 Data Synthesis
Authors: Kaidong Wang, Jiale Li, Shao-Bo Lin and Yao Wang
Categories: cs.LG
\\
 The non-rival nature of data creates a dilemma for firms: sharing data
unlocks value but risks eroding competitive advantage. Existing data synthesis
methods often exacerbate this problem by creating data with symmetric utility,
allowing any party to extract its value. This paper introduces the
Encapsulation-Forging (EnFo) framework, a novel approach to generate rival
synthetic data with asymmetric utility. EnFo operates in two stages: it first
encapsulates predictive knowledge from the original data into a designated
``key'' model, and then forges a synthetic dataset by optimizing the data to
intentionally overfit this key model. This process transforms non-rival data
into a rival product, ensuring its value is accessible only to the intended
model, thereby preventing unauthorized use and preserving the data owner's
competitive edge. Our framework demonstrates remarkable sample efficiency,
matching the original data's performance with a fraction of its size, while
providing robust privacy protection and resistance to misuse. EnFo offers a
practical solution for firms to collaborate strategically without compromising
their core analytical advantage.
\\ ( https://arxiv.org/abs/2511.06610 ,  1614kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06633
Date: Mon, 10 Nov 2025 02:20:58 GMT   (2845kb)

Title: Dual-branch Spatial-Temporal Self-supervised Representation for Enhanced
 Road Network Learning
Authors: Qinghong Guo, Yu Wang, Ji Cao, Tongya Zheng, Junshu Dai, Bingde Hu,
 Shunyu Liu, Canghong Jin
Categories: cs.LG
\\
 Road network representation learning (RNRL) has attracted increasing
attention from both researchers and practitioners as various spatiotemporal
tasks are emerging. Recent advanced methods leverage Graph Neural Networks
(GNNs) and contrastive learning to characterize the spatial structure of road
segments in a self-supervised paradigm. However, spatial heterogeneity and
temporal dynamics of road networks raise severe challenges to the neighborhood
smoothing mechanism of self-supervised GNNs. To address these issues, we
propose a $\textbf{D}$ual-branch $\textbf{S}$patial-$\textbf{T}$emporal
self-supervised representation framework for enhanced road representations,
termed as DST. On one hand, DST designs a mix-hop transition matrix for graph
convolution to incorporate dynamic relations of roads from trajectories.
Besides, DST contrasts road representations of the vanilla road network against
that of the hypergraph in a spatial self-supervised way. The hypergraph is
newly built based on three types of hyperedges to capture long-range relations.
On the other hand, DST performs next token prediction as the temporal
self-supervised task on the sequences of traffic dynamics based on a causal
Transformer, which is further regularized by differentiating traffic modes of
weekdays from those of weekends. Extensive experiments against state-of-the-art
methods verify the superiority of our proposed framework. Moreover, the
comprehensive spatiotemporal modeling facilitates DST to excel in zero-shot
learning scenarios.
\\ ( https://arxiv.org/abs/2511.06633 ,  2845kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06634
Date: Mon, 10 Nov 2025 02:21:43 GMT   (2930kb)

Title: CaberNet: Causal Representation Learning for Cross-Domain HVAC Energy
 Prediction
Authors: Kaiyuan Zhai, Jiacheng Cui, Zhehao Zhang, Junyu Xue, Yang Deng, Kui
 Wu, Guoming Tang
Categories: cs.LG cs.AI
Comments: Accepted at ACM e-Energy 2026
\\
 Cross-domain HVAC energy prediction is essential for scalable building energy
management, particularly because collecting extensive labeled data for every
new building is both costly and impractical. Yet, this task remains highly
challenging due to the scarcity and heterogeneity of data across different
buildings, climate zones, and seasonal patterns. In particular, buildings
situated in distinct climatic regions introduce variability that often leads
existing methods to overfit to spurious correlations, rely heavily on expert
intervention, or compromise on data diversity. To address these limitations, we
propose CaberNet, a causal and interpretable deep sequence model that learns
invariant (Markov blanket) representations for robust cross-domain prediction.
In a purely data-driven fashion and without requiring any prior knowledge,
CaberNet integrates i) a global feature gate trained with a self-supervised
Bernoulli regularization to distinguish superior causal features from inferior
ones, and ii) a domain-wise training scheme that balances domain contributions,
minimizes cross-domain loss variance, and promotes latent factor independence.
We evaluate CaberNet on real-world datasets collected from three buildings
located in three climatically diverse cities, and it consistently outperforms
all baselines, achieving a 22.9\% reduction in normalized mean squared error
(NMSE) compared to the best benchmark. Our code is available at
https://github.com/rickzky1001/CaberNet-CRL.
\\ ( https://arxiv.org/abs/2511.06634 ,  2930kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06641
Date: Mon, 10 Nov 2025 02:38:27 GMT   (188kb)

Title: Neyman-Pearson Classification under Both Null and Alternative
 Distributions Shift
Authors: Mohammadreza M. Kalan, Yuyang Deng, Eitan J. Neugut, Samory Kpotufe
Categories: cs.LG stat.ML
\\
 We consider the problem of transfer learning in Neyman-Pearson
classification, where the objective is to minimize the error w.r.t. a
distribution $\mu_1$, subject to the constraint that the error w.r.t. a
distribution $\mu_0$ remains below a prescribed threshold. While transfer
learning has been extensively studied in traditional classification, transfer
learning in imbalanced classification such as Neyman-Pearson classification has
received much less attention. This setting poses unique challenges, as both
types of errors must be simultaneously controlled. Existing works address only
the case of distribution shift in $\mu_1$, whereas in many practical scenarios
shifts may occur in both $\mu_0$ and $\mu_1$. We derive an adaptive procedure
that not only guarantees improved Type-I and Type-II errors when the source is
informative, but also automatically adapt to situations where the source is
uninformative, thereby avoiding negative transfer. In addition to such
statistical guarantees, the procedures is efficient, as shown via complementary
computational guarantees.
\\ ( https://arxiv.org/abs/2511.06641 ,  188kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06642
Date: Mon, 10 Nov 2025 02:39:35 GMT   (379kb)

Title: Improving Asset Allocation in a Fast Moving Consumer Goods B2B Company:
 An Interpretable Machine Learning Framework for Commercial Cooler Assignment
 Based on Multi-Tier Growth Targets
Authors: Renato Castro, Rodrigo Paredes, Douglas Kahn
Categories: cs.LG
Journal-ref: 2025 Artificial Intelligence for Business (AIxB)
\\
 In the fast-moving consumer goods (FMCG) industry, deciding where to place
physical assets, such as commercial beverage coolers, can directly impact
revenue growth and execution efficiency. Although churn prediction and demand
forecasting have been widely studied in B2B contexts, the use of machine
learning to guide asset allocation remains relatively unexplored. This paper
presents a framework focused on predicting which beverage clients are most
likely to deliver strong returns in volume after receiving a cooler. Using a
private dataset from a well-known Central American brewing and beverage company
of 3,119 B2B traditional trade channel clients that received a cooler from
2022-01 to 2024-07, and tracking 12 months of sales transactions before and
after cooler installation, three growth thresholds were defined: 10%, 30% and
50% growth in sales volume year over year. The analysis compares results of
machine learning models such as XGBoost, LightGBM, and CatBoost combined with
SHAP for interpretable feature analysis in order to have insights into
improving business operations related to cooler allocation; the results show
that the best model has AUC scores of 0.857, 0.877, and 0.898 across the
thresholds on the validation set. Simulations suggest that this approach can
improve ROI because it better selects potential clients to grow at the expected
level and increases cost savings by not assigning clients that will not grow,
compared to traditional volume-based approaches with substantial business
management recommendations
\\ ( https://arxiv.org/abs/2511.06642 ,  379kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06662
Date: Mon, 10 Nov 2025 03:18:16 GMT   (263kb)

Title: Dual-Pathway Fusion of EHRs and Knowledge Graphs for Predicting Unseen
 Drug-Drug Interactions
Authors: Franklin Lee, Tengfei Ma
Categories: cs.LG q-bio.QM
Comments: ML4H 2025 Findings
\\
 Drug-drug interactions (DDIs) remain a major source of preventable harm, and
many clinically important mechanisms are still unknown. Existing models either
rely on pharmacologic knowledge graphs (KGs), which fail on unseen drugs, or on
electronic health records (EHRs), which are noisy, temporal, and
site-dependent. We introduce, to our knowledge, the first system that
conditions KG relation scoring on patient-level EHR context and distills that
reasoning into an EHR-only model for zero-shot inference. A fusion "Teacher"
learns mechanism-specific relations for drug pairs represented in both sources,
while a distilled "Student" generalizes to new or rarely used drugs without KG
access at inference. Both operate under a shared ontology (set) of
pharmacologic mechanisms (drug relations) to produce interpretable, auditable
alerts rather than opaque risk scores. Trained on a multi-institution EHR
corpus paired with a curated DrugBank DDI graph, and evaluated using a
clinically aligned, decision-focused protocol with leakage-safe negatives that
avoid artificially easy pairs, the system maintains precision across
multi-institutuion test data, produces mechanism-specific, clinically
consistent predictions, reduces false alerts (higher precision) at comparable
overall detection performance (F1), and misses fewer true interactions compared
to prior methods. Case studies further show zero-shot identification of
clinically recognized CYP-mediated and pharmacodynamic mechanisms for drugs
absent from the KG, supporting real-world use in clinical decision support and
pharmacovigilance.
\\ ( https://arxiv.org/abs/2511.06662 ,  263kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06681
Date: Mon, 10 Nov 2025 03:57:56 GMT   (1038kb)

Title: An Adaptive Machine Learning Triage Framework for Predicting Alzheimer's
 Disease Progression
Authors: Richard Hou, Shengpu Tang, Wei Jin
Categories: cs.LG
Comments: Findings paper presented at Machine Learning for Health (ML4H)
 symposium 2025, December 1-2, 2025, San Diego, CA, USA, 9 pages. Shengpu Tang
 and Wei Jin contributed equally as senior authors
\\
 Accurate predictions of conversion from mild cognitive impairment (MCI) to
Alzheimer's disease (AD) can enable effective personalized therapy. While
cognitive tests and clinical data are routinely collected, they lack the
predictive power of PET scans and CSF biomarker analysis, which are
prohibitively expensive to obtain for every patient. To address this
cost-accuracy dilemma, we design a two-stage machine learning framework that
selectively obtains advanced, costly features based on their predicted "value
of information". We apply our framework to predict AD progression for MCI
patients using data from the Alzheimer's Disease Neuroimaging Initiative
(ADNI). Our framework reduces the need for advanced testing by 20% while
achieving a test AUROC of 0.929, comparable to the model that uses both basic
and advanced features (AUROC=0.915, p=0.1010). We also provide an example
interpretability analysis showing how one may explain the triage decision. Our
work presents an interpretable, data-driven framework that optimizes AD
diagnostic pathways and balances accuracy with cost, representing a step
towards making early, reliable AD prediction more accessible in real-world
practice. Future work should consider multiple categories of advanced features
and larger-scale validation.
\\ ( https://arxiv.org/abs/2511.06681 ,  1038kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06686
Date: Mon, 10 Nov 2025 04:16:01 GMT   (191kb)

Title: Mitigating Modality Imbalance in Multi-modal Learning via
 Multi-objective Optimization
Authors: Heshan Fernando, Parikshit Ram, Yi Zhou, Soham Dan, Horst Samulowitz,
 Nathalie Baracaldo, Tianyi Chen
Categories: cs.LG
\\
 Multi-modal learning (MML) aims to integrate information from multiple
modalities, which is expected to lead to superior performance over
single-modality learning. However, recent studies have shown that MML can
underperform, even compared to single-modality approaches, due to imbalanced
learning across modalities. Methods have been proposed to alleviate this
imbalance issue using different heuristics, which often lead to computationally
intensive subroutines. In this paper, we reformulate the MML problem as a
multi-objective optimization (MOO) problem that overcomes the imbalanced
learning issue among modalities and propose a gradient-based algorithm to solve
the modified MML problem. We provide convergence guarantees for the proposed
method, and empirical evaluations on popular MML benchmarks showcasing the
improved performance of the proposed method over existing balanced MML and MOO
baselines, with up to ~20x reduction in subroutine computation time. Our code
is available at https://github.com/heshandevaka/MIMO.
\\ ( https://arxiv.org/abs/2511.06686 ,  191kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06692
Date: Mon, 10 Nov 2025 04:29:33 GMT   (42453kb)

Title: Peeling Context from Cause for Multimodal Molecular Property Prediction
Authors: Tao Li, Kaiyuan Hou, Tuan Vinh, Carl Yang, Monika Raj
Categories: cs.LG
\\
 Deep models are used for molecular property prediction, yet they are often
difficult to interpret and may rely on spurious context rather than causal
structure, which reduces reliability under distribution shift and harms
predictive performance. We introduce CLaP (Causal Layerwise Peeling), a
framework that separates causal signal from context in a layerwise manner and
integrates diverse graph representations of molecules. At each layer, a causal
block performs a soft split into causal and non-causal branches, fuses causal
evidence across modalities, and progressively removes batch-coupled context to
focus on label-relevant structure, thereby limiting shortcut signals and
stabilizing layerwise refinement. Across four molecular benchmarks, CLaP
consistently improves MAE, MSE, and $R^2$ over competitive baselines. The model
also produces atom-level causal saliency maps that highlight substructures
responsible for predictions, providing actionable guidance for targeted
molecular edits. Case studies confirm the accuracy of these maps and their
alignment with chemical intuition. By peeling context from cause at every
layer, the model yields predictors that are both accurate and interpretable for
molecular design.
\\ ( https://arxiv.org/abs/2511.06692 ,  42453kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06694
Date: Mon, 10 Nov 2025 04:30:29 GMT   (1294kb)

Title: ML-EcoLyzer: Quantifying the Environmental Cost of Machine Learning
 Inference Across Frameworks and Hardware
Authors: Jose Marie Antonio Minoza, Rex Gregor Laylo, Christian F Villarin,
 Sebastian C. Ibanez
Categories: cs.LG cs.AI
Journal-ref: Association for the Advancement of Artificial Intelligence (2026).
 AI for Environmental Science
\\
 Machine learning inference occurs at a massive scale, yet its environmental
impact remains poorly quantified, especially on low-resource hardware. We
present ML-EcoLyzer, a cross-framework tool for measuring the carbon, energy,
thermal, and water costs of inference across CPUs, consumer GPUs, and
datacenter accelerators. The tool supports both classical and modern models,
applying adaptive monitoring and hardware-aware evaluation.
 We introduce the Environmental Sustainability Score (ESS), which quantifies
the number of effective parameters served per gram of CO$_2$ emitted. Our
evaluation covers over 1,900 inference configurations, spanning diverse model
architectures, task modalities (text, vision, audio, tabular), hardware types,
and precision levels. These rigorous and reliable measurements demonstrate that
quantization enhances ESS, huge accelerators can be inefficient for lightweight
applications, and even small models may incur significant costs when
implemented suboptimally. ML-EcoLyzer sets a standard for
sustainability-conscious model selection and offers an extensive empirical
evaluation of environmental costs during inference.
\\ ( https://arxiv.org/abs/2511.06694 ,  1294kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06696
Date: Mon, 10 Nov 2025 04:31:56 GMT   (95kb)

Title: Magnitude-Modulated Equivariant Adapter for Parameter-Efficient
 Fine-Tuning of Equivariant Graph Neural Networks
Authors: Dian Jin, Yancheng Yuan, Xiaoming Tao
Categories: cs.LG cs.AI
\\
 Pretrained equivariant graph neural networks based on spherical harmonics
offer efficient and accurate alternatives to computationally expensive
ab-initio methods, yet adapting them to new tasks and chemical environments
still requires fine-tuning. Conventional parameter-efficient fine-tuning (PEFT)
techniques, such as Adapters and LoRA, typically break symmetry, making them
incompatible with those equivariant architectures. ELoRA, recently proposed, is
the first equivariant PEFT method. It achieves improved parameter efficiency
and performance on many benchmarks. However, the relatively high degrees of
freedom it retains within each tensor order can still perturb pretrained
feature distributions and ultimately degrade performance. To address this, we
present Magnitude-Modulated Equivariant Adapter (MMEA), a novel equivariant
fine-tuning method which employs lightweight scalar gating to modulate feature
magnitudes on a per-order and per-multiplicity basis. We demonstrate that MMEA
preserves strict equivariance and, across multiple benchmarks, consistently
improves energy and force predictions to state-of-the-art levels while training
fewer parameters than competing approaches. These results suggest that, in many
practical scenarios, modulating channel magnitudes is sufficient to adapt
equivariant models to new chemical environments without breaking symmetry,
pointing toward a new paradigm for equivariant PEFT design.
\\ ( https://arxiv.org/abs/2511.06696 ,  95kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06715
Date: Mon, 10 Nov 2025 05:16:20 GMT   (1541kb)

Title: Sensor Calibration Model Balancing Accuracy, Real-time, and Efficiency
Authors: Jinyong Yun, Hyungjin Kim, Seokho Ahn, Euijong Lee, Young-Duk Seo
Categories: cs.LG cs.AI
\\
 Most on-device sensor calibration studies benchmark models only against three
macroscopic requirements (i.e., accuracy, real-time, and resource efficiency),
thereby hiding deployment bottlenecks such as instantaneous error and
worst-case latency. We therefore decompose this triad into eight microscopic
requirements and introduce Scare (Sensor Calibration model balancing Accuracy,
Real-time, and Efficiency), an ultra-compressed transformer that fulfills them
all. SCARE comprises three core components: (1) Sequence Lens Projector (SLP)
that logarithmically compresses time-series data while preserving boundary
information across bins, (2) Efficient Bitwise Attention (EBA) module that
replaces costly multiplications with bitwise operations via binary hash codes,
and (3) Hash optimization strategy that ensures stable training without
auxiliary loss terms. Together, these components minimize computational
overhead while maintaining high accuracy and compatibility with microcontroller
units (MCUs). Extensive experiments on large-scale air-quality datasets and
real microcontroller deployments demonstrate that Scare outperforms existing
linear, hybrid, and deep-learning baselines, making Scare, to the best of our
knowledge, the first model to meet all eight microscopic requirements
simultaneously.
\\ ( https://arxiv.org/abs/2511.06715 ,  1541kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06719
Date: Mon, 10 Nov 2025 05:28:31 GMT   (1314kb)

Title: MobileLLM-Pro Technical Report
Authors: Patrick Huber, Ernie Chang, Wei Wen, Igor Fedorov, Tarek Elgamal,
 Hanxian Huang, Naveen Suda, Chinnadhurai Sankar, Vish Vogeti, Yanghan Wang,
 Alex Gladkov, Kai Sheng Tai, Abdelrahman Elogeel, Tarek Hefny, Vikas Chandra,
 Ahmed Aly, Anuj Kumar, Raghuraman Krishnamoorthi, Adithya Sagar
Categories: cs.LG
Comments: 17 pages
\\
 Efficient on-device language models around 1 billion parameters are essential
for powering low-latency AI applications on mobile and wearable devices.
However, achieving strong performance in this model class, while supporting
long context windows and practical deployment remains a significant challenge.
We introduce MobileLLM-Pro, a 1-billion-parameter language model optimized for
on-device deployment. MobileLLM-Pro achieves state-of-the-art results across 11
standard benchmarks, significantly outperforming both Gemma 3-1B and Llama
3.2-1B, while supporting context windows of up to 128,000 tokens and showing
only minor performance regressions at 4-bit quantization. These improvements
are enabled by four core innovations: (1) implicit positional distillation, a
novel technique that effectively instills long-context capabilities through
knowledge distillation; (2) a specialist model merging framework that fuses
multiple domain experts into a compact model without parameter growth; (3)
simulation-driven data mixing using utility estimation; and (4) 4-bit
quantization-aware training with self-distillation. We release our model
weights and code to support future research in efficient on-device language
models.
\\ ( https://arxiv.org/abs/2511.06719 ,  1314kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06723
Date: Mon, 10 Nov 2025 05:33:41 GMT   (2010kb)

Title: Multi-Modal Continual Learning via Cross-Modality Adapters and
 Representation Alignment with Knowledge Preservation
Authors: Evelyn Chee, Wynne Hsu, Mong Li Lee
Categories: cs.LG
Comments: Accepted to ECAI 2025
Journal-ref: 28th European Conference on Artificial Intelligence (ECAI), 2025,
 pp.1083-1090
DOI: 10.3233/FAIA250918
\\
 Continual learning is essential for adapting models to new tasks while
retaining previously acquired knowledge. While existing approaches
predominantly focus on uni-modal data, multi-modal learning offers substantial
benefits by utilizing diverse sensory inputs, akin to human perception.
However, multi-modal continual learning presents additional challenges, as the
model must effectively integrate new information from various modalities while
preventing catastrophic forgetting. In this work, we propose a pre-trained
model-based framework for multi-modal continual learning. Our framework
includes a novel cross-modality adapter with a mixture-of-experts structure to
facilitate effective integration of multi-modal information across tasks. We
also introduce a representation alignment loss that fosters learning of robust
multi-modal representations, and regularize relationships between learned
representations to preserve knowledge from previous tasks. Experiments on
several multi-modal datasets demonstrate that our approach consistently
outperforms baselines in both class-incremental and domain-incremental
learning, achieving higher accuracy and reduced forgetting.
\\ ( https://arxiv.org/abs/2511.06723 ,  2010kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06739
Date: Mon, 10 Nov 2025 06:00:25 GMT   (4215kb)

Title: Rank-1 LoRAs Encode Interpretable Reasoning Signals
Authors: Jake Ward, Paul Riechers, Adam Shai
Categories: cs.LG cs.AI
Comments: 39th Conference on Neural Information Processing Systems (NeurIPS
 2025) Workshop: Mechanistic Interpretability Workshop
\\
 Reasoning models leverage inference-time compute to significantly enhance the
performance of language models on difficult logical tasks, and have become a
dominating paradigm in frontier LLMs. Despite their wide adoption, the
mechanisms underpinning the enhanced performance of these reasoning models are
not well understood. In this work, we show that the majority of new
capabilities in reasoning models can be elicited by small, single-rank changes
to base model parameters, with many of these changes being interpretable.
Specifically, we use a rank-1 LoRA to create a minimal parameter adapter for
Qwen-2.5-32B-Instruct which recovers 73-90% of reasoning-benchmark performance
compared to a full parameter finetune. We find that the activations of this
LoRA are as interpretable as MLP neurons, and fire for reasoning-specific
behaviors. Finally, we train a sparse autoencoder on the entire activation
state of this LoRA and identify fine-grained and monosemantic features. Our
findings highlight that reasoning performance can arise largely from minimal
changes to base model parameters, and explore what these changes affect. More
broadly, our work shows that parameter-efficient training methods can be used
as a targeted lens for uncovering fundamental insights about language model
behavior and dynamics.
\\ ( https://arxiv.org/abs/2511.06739 ,  4215kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06756
Date: Mon, 10 Nov 2025 06:34:20 GMT   (2086kb)

Title: Dual Mamba for Node-Specific Representation Learning: Tackling
 Over-Smoothing with Selective State Space Modeling
Authors: Xin He, Yili Wang, Yiwei Dai, Xin Wang
Categories: cs.LG
Comments: 11 pages, 4 figures
\\
 Over-smoothing remains a fundamental challenge in deep Graph Neural Networks
(GNNs), where repeated message passing causes node representations to become
indistinguishable. While existing solutions, such as residual connections and
skip layers, alleviate this issue to some extent, they fail to explicitly model
how node representations evolve in a node-specific and progressive manner
across layers. Moreover, these methods do not take global information into
account, which is also crucial for mitigating the over-smoothing problem. To
address the aforementioned issues, in this work, we propose a Dual
Mamba-enhanced Graph Convolutional Network (DMbaGCN), which is a novel
framework that integrates Mamba into GNNs to address over-smoothing from both
local and global perspectives. DMbaGCN consists of two modules: the Local
State-Evolution Mamba (LSEMba) for local neighborhood aggregation and utilizing
Mamba's selective state space modeling to capture node-specific representation
dynamics across layers, and the Global Context-Aware Mamba (GCAMba) that
leverages Mamba's global attention capabilities to incorporate global context
for each node. By combining these components, DMbaGCN enhances node
discriminability in deep GNNs, thereby mitigating over-smoothing. Extensive
experiments on multiple benchmarks demonstrate the effectiveness and efficiency
of our method.
\\ ( https://arxiv.org/abs/2511.06756 ,  2086kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06757
Date: Mon, 10 Nov 2025 06:34:29 GMT   (478kb)

Title: Implicit Federated In-context Learning For Task-Specific LLM Fine-Tuning
Authors: Dongcheng Li, Junhan Chen, Aoxiang Zhou, Chunpei Li, Youquan Xian,
 Peng Liu, Xianxian Li
Categories: cs.LG cs.AI
\\
 As large language models continue to develop and expand, the extensive public
data they rely on faces the risk of depletion. Consequently, leveraging private
data within organizations to enhance the performance of large models has
emerged as a key challenge. The federated learning paradigm, combined with
model fine-tuning techniques, effectively reduces the number of trainable
parameters. However,the necessity to process high-dimensional feature spaces
results in substantial overall computational overhead. To address this issue,
we propose the Implicit Federated In-Context Learning (IFed-ICL) framework.
IFed-ICL draws inspiration from federated learning to establish a novel
distributed collaborative paradigm, by converting client local context examples
into implicit vector representations, it enables distributed collaborative
computation during the inference phase and injects model residual streams to
enhance model performance. Experiments demonstrate that our proposed method
achieves outstanding performance across multiple text classification tasks.
Compared to traditional methods, IFed-ICL avoids the extensive parameter
updates required by conventional fine-tuning methods while reducing data
transmission and local computation at the client level in federated learning.
This enables efficient distributed context learning using local private-domain
data, significantly improving model performance on specific tasks.
\\ ( https://arxiv.org/abs/2511.06757 ,  478kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06767
Date: Mon, 10 Nov 2025 06:46:21 GMT   (846kb)

Title: QUARK: Quantization-Enabled Circuit Sharing for Transformer Acceleration
 by Exploiting Common Patterns in Nonlinear Operations
Authors: Zhixiong Zhao, Haomin Li, Fangxin Liu, Yuncheng Lu, Zongwu Wang, Tao
 Yang, Li Jiang, Haibing Guan
Categories: cs.LG cs.AI
Comments: ICCAD 2025
\\
 Transformer-based models have revolutionized computer vision (CV) and natural
language processing (NLP) by achieving state-of-the-art performance across a
range of benchmarks. However, nonlinear operations in models significantly
contribute to inference latency, presenting unique challenges for efficient
hardware acceleration. To this end, we propose QUARK, a quantization-enabled
FPGA acceleration framework that leverages common patterns in nonlinear
operations to enable efficient circuit sharing, thereby reducing hardware
resource requirements. QUARK targets all nonlinear operations within
Transformer-based models, achieving high-performance approximation through a
novel circuit-sharing design tailored to accelerate these operations. Our
evaluation demonstrates that QUARK significantly reduces the computational
overhead of nonlinear operators in mainstream Transformer architectures,
achieving up to a 1.96 times end-to-end speedup over GPU implementations.
Moreover, QUARK lowers the hardware overhead of nonlinear modules by more than
50% compared to prior approaches, all while maintaining high model accuracy --
and even substantially boosting accuracy under ultra-low-bit quantization.
\\ ( https://arxiv.org/abs/2511.06767 ,  846kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06776
Date: Mon, 10 Nov 2025 07:05:08 GMT   (430kb)

Title: Data Trajectory Alignment for LLM Domain Adaptation: A Two-Phase
 Synthesis Framework for Telecommunications Mathematics
Authors: Zhicheng Zhou, Jing Li, Suming Qiu, Junjie Huang, Linyuan Qiu, Zhijie
 Sun
Categories: cs.LG cs.AI
\\
 General-purpose large language models (LLMs) are increasingly deployed in
verticals such as telecommunications, where adaptation is hindered by scarce,
low-information-density corpora and tight mobile/edge constraints. We propose
Data Trajectory Alignment (DTA), a two-phase, model-agnostic data curation
framework that treats solution processes - not only final answers - as
first-class supervision. Phase I (Initializing) synthesizes diverse,
high-coverage candidates using an ensemble of strong teachers. Phase II (DTA)
rewrites teacher solutions to align intermediate steps and presentation style
with the target student's inductive biases and then performs signal-aware
exemplar selection via agreement checks and reflection-based judging.
Instantiated on telecommunications mathematics (e.g., link budgets, SNR/AMC
selection, and power-control feasibility), DTA yields state-of-the-art (SOTA)
accuracy on TELEMATH without enabling explicit "thinking" modes: 72.45% pass@1,
surpassing distilled-only training by +17.65 points and outperforming a strong
baseline (Qwen3-32B with thinking enabled) by +2.94 points. Token-shift
analyses indicate that DTA concentrates gains on logical-structural discourse
markers rather than merely amplifying domain nouns, indicating improved
reasoning scaffolding. Under edge-like inference settings, DTA improves
efficiency by reducing reliance on multi-sample voting and disabling expensive
reasoning heuristics, cutting energy per output token by ~42% versus Qwen3-32B
(thinking mode enabled) and end-to-end latency by ~60% versus Qwen3-32B
(thinking mode disabled). These results demonstrate that aligning how solutions
are produced enables compact, high-yield supervision that is effective for both
accuracy and efficiency, offering a practical recipe for domain adaptation in
low-resource verticals beyond telecom.
\\ ( https://arxiv.org/abs/2511.06776 ,  430kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06781
Date: Mon, 10 Nov 2025 07:13:58 GMT   (3088kb)

Title: On the Mechanisms of Collaborative Learning in VAE Recommenders
Authors: Tung-Long Vuong, Julien Monteil, Hien Dang, Volodymyr Vaskovych, Trung
 Le, Vu Nguyen
Categories: cs.LG cs.AI
\\
 Variational Autoencoders (VAEs) are a powerful alternative to matrix
factorization for recommendation. A common technique in VAE-based collaborative
filtering (CF) consists in applying binary input masking to user interaction
vectors, which improves performance but remains underexplored theoretically. In
this work, we analyze how collaboration arises in VAE-based CF and show it is
governed by latent proximity: we derive a latent sharing radius that informs
when an SGD update on one user strictly reduces the loss on another user, with
influence decaying as the latent Wasserstein distance increases. We further
study the induced geometry: with clean inputs, VAE-based CF primarily exploits
\emph{local} collaboration between input-similar users and under-utilizes
global collaboration between far-but-related users. We compare two mechanisms
that encourage \emph{global} mixing and characterize their trade-offs: (1)
$\beta$-KL regularization directly tightens the information bottleneck,
promoting posterior overlap but risking representational collapse if too large;
(2) input masking induces stochastic geometric contractions and expansions,
which can bring distant users onto the same latent neighborhood but also
introduce neighborhood drift. To preserve user identity while enabling global
consistency, we propose an anchor regularizer that aligns user posteriors with
item embeddings, stabilizing users under masking and facilitating signal
sharing across related items. Our analyses are validated on the Netflix,
MovieLens-20M, and Million Song datasets. We also successfully deployed our
proposed algorithm on an Amazon streaming platform following a successful
online experiment.
\\ ( https://arxiv.org/abs/2511.06781 ,  3088kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06785
Date: Mon, 10 Nov 2025 07:19:26 GMT   (3095kb)

Title: Resource Efficient Sleep Staging via Multi-Level Masking and Prompt
 Learning
Authors: Lejun Ai, Yulong Li, Haodong Yi, Jixuan Xie, Yue Wang, Jia Liu, Min
 Chen, Rui Wang
Categories: cs.LG cs.AI
Comments: 16 pages, 4 figures, to be published in AAAI 2026
\\
 Automatic sleep staging plays a vital role in assessing sleep quality and
diagnosing sleep disorders. Most existing methods rely heavily on long and
continuous EEG recordings, which poses significant challenges for data
acquisition in resource-constrained systems, such as wearable or home-based
monitoring systems. In this paper, we propose the task of resource-efficient
sleep staging, which aims to reduce the amount of signal collected per sleep
epoch while maintaining reliable classification performance. To solve this
task, we adopt the masking and prompt learning strategy and propose a novel
framework called Mask-Aware Sleep Staging (MASS). Specifically, we design a
multi-level masking strategy to promote effective feature modeling under
partial and irregular observations. To mitigate the loss of contextual
information introduced by masking, we further propose a hierarchical prompt
learning mechanism that aggregates unmasked data into a global prompt, serving
as a semantic anchor for guiding both patch-level and epoch-level feature
modeling. MASS is evaluated on four datasets, demonstrating state-of-the-art
performance, especially when the amount of data is very limited. This result
highlights its potential for efficient and scalable deployment in real-world
low-resource sleep monitoring environments.
\\ ( https://arxiv.org/abs/2511.06785 ,  3095kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06786
Date: Mon, 10 Nov 2025 07:21:35 GMT   (5933kb)

Title: Rethinking Parameter Sharing as Graph Coloring for Structured
 Compression
Authors: Boyang Zhang, Daning Cheng, Yunquan Zhang
Categories: cs.LG
\\
 Modern deep models have massive parameter sizes, leading to high
inference-time memory usage that limits practical deployment. Parameter
sharing, a form of structured compression, effectively reduces redundancy, but
existing approaches remain heuristic-restricted to adjacent layers and lacking
a systematic analysis for cross-layer sharing. However, extending sharing
across multiple layers leads to an exponentially expanding configuration space,
making exhaustive search computationally infeasible and forming a critical
bottleneck for parameter sharing. We recast parameter sharing from a
group-theoretic perspective as introducing structural symmetries in the model's
parameter space. A sharing configuration can be described by a coloring
function $\alpha:L\rightarrow C$ (L: layer indices and C: sharing classes),
which determines inter-layer sharing groups while preserving structural
symmetry. To determine the coloring function, we propose a second-order
geometric criterion based on Taylor expansion and the Hessian spectrum. By
projecting perturbations onto the Hessian's low-curvature eigensubspace, the
criterion provides an analytic rule for selecting sharing groups that minimize
performance impact, yielding a principled and scalable configuration procedure.
Across diverse architectures and tasks, Geo-Sharing consistently outperforms
state-of-the-art heuristic sharing strategies, achieving higher compression
ratios with smaller accuracy degradation.
\\ ( https://arxiv.org/abs/2511.06786 ,  5933kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06790
Date: Mon, 10 Nov 2025 07:27:08 GMT   (542kb)

Title: Robust Causal Discovery under Imperfect Structural Constraints
Authors: Zidong Wang, Xi Lin, Chuchao He and Xiaoguang Gao
Categories: cs.LG cs.AI stat.ML
\\
 Robust causal discovery from observational data under imperfect prior
knowledge remains a significant and largely unresolved challenge. Existing
methods typically presuppose perfect priors or can only handle specific,
pre-identified error types. And their performance degrades substantially when
confronted with flawed constraints of unknown location and type. This decline
arises because most of them rely on inflexible and biased thresholding
strategies that may conflict with the data distribution. To overcome these
limitations, we propose to harmonizes knowledge and data through prior
alignment and conflict resolution. First, we assess the credibility of
imperfect structural constraints through a surrogate model, which then guides a
sparse penalization term measuring the loss between the learned and constrained
adjacency matrices. We theoretically prove that, under ideal assumption, the
knowledge-driven objective aligns with the data-driven objective. Furthermore,
to resolve conflicts when this assumption is violated, we introduce a
multi-task learning framework optimized via multi-gradient descent, jointly
minimizing both objectives. Our proposed method is robust to both linear and
nonlinear settings. Extensive experiments, conducted under diverse noise
conditions and structural equation model types, demonstrate the effectiveness
and efficiency of our method under imperfect structural constraints.
\\ ( https://arxiv.org/abs/2511.06790 ,  542kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06791
Date: Mon, 10 Nov 2025 07:28:03 GMT   (2829kb)

Title: Coupling Agent-based Modeling and Life Cycle Assessment to Analyze
 Trade-offs in Resilient Energy Transitions
Authors: Beichen Zhang, Mohammed T. Zaki, Hanna Breunig and Newsha K. Ajami
Categories: cs.LG cs.MA
Comments: 4 pages (+4 pages in appendix), 3 figures (+ 2 figures in appendix),
 8 tables in appendix, NeurIPS Workshop on Tackling Climate Change with
 Machine Learning, 2025
\\
 Transitioning to sustainable and resilient energy systems requires navigating
complex and interdependent trade-offs across environmental, social, and
resource dimensions. Neglecting these trade-offs can lead to unintended
consequences across sectors. However, existing assessments often evaluate
emerging energy pathways and their impacts in silos, overlooking critical
interactions such as regional resource competition and cumulative impacts. We
present an integrated modeling framework that couples agent-based modeling and
Life Cycle Assessment (LCA) to simulate how energy transition pathways interact
with regional resource competition, ecological constraints, and community-level
burdens. We apply the model to a case study in Southern California. The results
demonstrate how integrated and multiscale decision making can shape energy
pathway deployment and reveal spatially explicit trade-offs under
scenario-driven constraints. This modeling framework can further support more
adaptive and resilient energy transition planning on spatial and institutional
scales.
\\ ( https://arxiv.org/abs/2511.06791 ,  2829kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06793
Date: Mon, 10 Nov 2025 07:31:20 GMT   (1376kb)

Title: Cross-Modal Unlearning via Influential Neuron Path Editing in Multimodal
 Large Language Models
Authors: Kunhao Li, Wenhao Li, Di Wu, Lei Yang, Jun Bai, Ju Jia, Jason Xue
Categories: cs.LG cs.AI
Comments: Accepted at AAAI 2026 as a Conference Paper (Oral Presentation)
\\
 Multimodal Large Language Models (MLLMs) extend foundation models to
real-world applications by integrating inputs such as text and vision. However,
their broad knowledge capacity raises growing concerns about privacy leakage,
toxicity mitigation, and intellectual property violations. Machine Unlearning
(MU) offers a practical solution by selectively forgetting targeted knowledge
while preserving overall model utility. When applied to MLLMs, existing
neuron-editing-based MU approaches face two fundamental challenges: (1)
forgetting becomes inconsistent across modalities because existing point-wise
attribution methods fail to capture the structured, layer-by-layer information
flow that connects different modalities; and (2) general knowledge performance
declines when sensitive neurons that also support important reasoning paths are
pruned, as this disrupts the model's ability to generalize. To alleviate these
limitations, we propose a multimodal influential neuron path editor
(MIP-Editor) for MU. Our approach introduces modality-specific attribution
scores to identify influential neuron paths responsible for encoding forget-set
knowledge and applies influential-path-aware neuron-editing via representation
misdirection. This strategy also enables effective and coordinated forgetting
across modalities while preserving the model's general capabilities.
Experimental results demonstrate that MIP-Editor achieves a superior unlearning
performance on multimodal tasks, with a maximum forgetting rate of 87.75% and
up to 54.26% improvement in general knowledge retention. On textual tasks,
MIP-Editor achieves up to 80.65% forgetting and preserves 77.9% of general
performance. Codes are available at https://github.com/PreckLi/MIP-Editor.
\\ ( https://arxiv.org/abs/2511.06793 ,  1376kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06794
Date: Mon, 10 Nov 2025 07:32:29 GMT   (3635kb)

Title: Beyond Uniform Deletion: A Data Value-Weighted Framework for Certified
 Machine Unlearning
Authors: Lisong He and Yi Yang and Xiangyu Chang
Categories: cs.LG stat.ML
\\
 As the right to be forgotten becomes legislated worldwide, machine unlearning
mechanisms have emerged to efficiently update models for data deletion and
enhance user privacy protection. However, existing machine unlearning
algorithms frequently neglect the fact that different data points may
contribute unequally to model performance (i.e., heterogeneous data values).
Treat them equally in machine unlearning procedure can potentially degrading
the performance of updated models. To address this limitation, we propose Data
Value-Weighted Unlearning (DVWU), a general unlearning framework that accounts
for data value heterogeneity into the unlearning process. Specifically, we
design a weighting strategy based on data values, which are then integrated
into the unlearning procedure to enable differentiated unlearning for data
points with varying utility to the model. The DVWU framework can be broadly
adapted to various existing machine unlearning methods. We use the one-step
Newton update as an example for implementation, developing both output and
objective perturbation algorithms to achieve certified unlearning. Experiments
on both synthetic and real-world datasets demonstrate that our methods achieve
superior predictive performance and robustness compared to conventional
unlearning approaches. We further show the extensibility of our framework on
gradient ascent method by incorporating the proposed weighting strategy into
the gradient terms, highlighting the adaptability of DVWU for broader
gradient-based deep unlearning methods.
\\ ( https://arxiv.org/abs/2511.06794 ,  3635kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06797
Date: Mon, 10 Nov 2025 07:36:16 GMT   (1734kb)

Title: FedNET: Federated Learning for Proactive Traffic Management and Network
 Capacity Planning
Authors: Saroj Kumar Panda, Basabdatta Palit, Sadananda Behera
Categories: cs.LG
\\
 We propose FedNET, a proactive and privacy-preserving framework for early
identification of high-risk links in large-scale communication networks, that
leverages a distributed multi-step traffic forecasting method. FedNET employs
Federated Learning (FL) to model the temporal evolution of node-level traffic
in a distributed manner, enabling accurate multi-step-ahead predictions (e.g.,
several hours to days) without exposing sensitive network data. Using these
node-level forecasts and known routing information, FedNET estimates the future
link-level utilization by aggregating traffic contributions across all
source-destination pairs. The links are then ranked according to the predicted
load intensity and temporal variability, providing an early warning signal for
potential high-risk links. We compare the federated traffic prediction of
FedNET against a centralized multi-step learning baseline and then
systematically analyze the impact of history and prediction window sizes on
forecast accuracy using the $R^2$ score. Results indicate that FL achieves
accuracy close to centralized training, with shorter prediction horizons
consistently yielding the highest accuracy ($R^2 >0.92$), while longer horizons
providing meaningful forecasts ($R^2 \approx 0.45\text{--}0.55$). We further
validate the efficacy of the FedNET framework in predicting network utilization
on a realistic network topology and demonstrate that it consistently identifies
high-risk links well in advance (i.e., three days ahead) of the critical stress
states emerging, making it a practical tool for anticipatory traffic
engineering and capacity planning.
\\ ( https://arxiv.org/abs/2511.06797 ,  1734kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06798
Date: Mon, 10 Nov 2025 07:36:45 GMT   (1069kb)

Title: Recursive Dynamics in Fast-Weights Homeostatic Reentry Networks: Toward
 Reflective Intelligence
Authors: B. G. Chae
Categories: cs.LG cs.AI cs.NE
Comments: 17 pages, 6 figures
\\
 This study introduces the Fast-Weights Homeostatic Reentry Layer (FH-RL), a
neural mechanism that integrates fast-weight associative memory, homeostatic
regularization, and learned reentrant feedback to approximate self-referential
computation in neural networks. Unlike standard transformer architectures that
operate in a purely feedforward manner during inference, FH-RL enables internal
recurrence without external looping, allowing prior latent states to be
dynamically re-entered into the ongoing computation stream. We conduct
controlled experiments sweeping the reentry gain $\gamma$ and evaluate emergent
internal dynamics using three novel metrics: the Information Reentry Ratio
(IRR), Eigen-Spectrum Recursion Index (ESRI), and Representational Drift
Periodicity (RDP). Results show that reentry quantity increases proportionally
with~$\gamma$, while the learned feedback matrix $W_r$ remains bounded and
becomes more structured at moderate gains. Critically, a stable reflective band
emerges around $\gamma \approx 0.10-0.20$, where internal feedback is maximally
expressive yet spectrally stable: IRR rises smoothly, ESRI remains near zero,
and RDP exhibits consistent low-frequency cycles. These findings provide
quantitative evidence that reflective, thought-like internal processing can
arise from a principled balance between feedback amplification and homeostatic
regulation, linking modern fast-weight architectures to theories of cortical
reentry and recursive cognition.
\\ ( https://arxiv.org/abs/2511.06798 ,  1069kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06802
Date: Mon, 10 Nov 2025 07:45:10 GMT   (11900kb)

Title: Neural-Initialized Newton: Accelerating Nonlinear Finite Elements via
 Operator Learning
Authors: Kianoosh Taghikhani, Yusuke Yamazaki, Jerry Paul Varghese, Markus
 Apel, Reza Najian Asl, Shahed Rezaei
Categories: cs.LG
\\
 We propose a Newton-based scheme, initialized by neural operator predictions,
to accelerate the parametric solution of nonlinear problems in computational
solid mechanics. First, a physics informed conditional neural field is trained
to approximate the nonlinear parametric solutionof the governing equations.
This establishes a continuous mapping between the parameter and solution
spaces, which can then be evaluated for a given parameter at any spatial
resolution. Second, since the neural approximation may not be exact, it is
subsequently refined using a Newton-based correction initialized by the neural
output. To evaluate the effectiveness of this hybrid approach, we compare three
solution strategies: (i) the standard Newton-Raphson solver used in NFEM, which
is robust and accurate but computationally demanding; (ii) physics-informed
neural operators, which provide rapid inference but may lose accuracy outside
the training distribution and resolution; and (iii) the neural-initialized
Newton (NiN) strategy, which combines the efficiency of neural operators with
the robustness of NFEM. The results demonstrate that the proposed hybrid
approach reduces computational cost while preserving accuracy, highlighting its
potential to accelerate large-scale nonlinear simulations.
\\ ( https://arxiv.org/abs/2511.06802 ,  11900kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06816
Date: Mon, 10 Nov 2025 08:01:20 GMT   (831kb)

Title: Controllable Flow Matching for Online Reinforcement Learning
Authors: Bin Wang, Boxiang Tao, Haifeng Jing, Hongbo Dou, Zijian Wang
Categories: cs.LG cs.AI
Comments: 9 pages, The Fortieth AAAI Conference on Artificial
 Intelligence(AAAI2026)
\\
 Model-based reinforcement learning (MBRL) typically relies on modeling
environment dynamics for data efficiency. However, due to the accumulation of
model errors over long-horizon rollouts, such methods often face challenges in
maintaining modeling stability. To address this, we propose CtrlFlow, a
trajectory-level synthetic method using conditional flow matching (CFM), which
directly modeling the distribution of trajectories from initial states to
high-return terminal states without explicitly modeling the environment
transition function. Our method ensures optimal trajectory sampling by
minimizing the control energy governed by the non-linear Controllability
Gramian Matrix, while the generated diverse trajectory data significantly
enhances the robustness and cross-task generalization of policy learning. In
online settings, CtrlFlow demonstrates the better performance on common MuJoCo
benchmark tasks than dynamics models and achieves superior sample efficiency
compared to standard MBRL methods.
\\ ( https://arxiv.org/abs/2511.06816 ,  831kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06831
Date: Mon, 10 Nov 2025 08:25:13 GMT   (1970kb)

Title: DeepRWCap: Neural-Guided Random-Walk Capacitance Solver for IC Design
Authors: Hector R. Rodriguez, Jiechen Huang, Wenjian Yu
Categories: cs.LG cs.AI
Comments: Accepted to AAAI-26
\\
 Monte Carlo random walk methods are widely used in capacitance extraction for
their mesh-free formulation and inherent parallelism. However, modern
semiconductor technologies with densely packed structures present significant
challenges in unbiasedly sampling transition domains in walk steps with
multiple high-contrast dielectric materials. We present DeepRWCap, a machine
learning-guided random walk solver that predicts the transition quantities
required to guide each step of the walk. These include Poisson kernels,
gradient kernels, signs and magnitudes of weights. DeepRWCap employs a
two-stage neural architecture that decomposes structured outputs into face-wise
distributions and spatial kernels on cube faces. It uses 3D convolutional
networks to capture volumetric dielectric interactions and 2D depthwise
separable convolutions to model localized kernel behavior. The design
incorporates grid-based positional encodings and structural design choices
informed by cube symmetries to reduce learning redundancy and improve
generalization. Trained on 100,000 procedurally generated dielectric
configurations, DeepRWCap achieves a mean relative error of $1.24\pm0.53$\%
when benchmarked against the commercial Raphael solver on the self-capacitance
estimation of 10 industrial designs spanning 12 to 55 nm nodes. Compared to the
state-of-the-art stochastic difference method Microwalk, DeepRWCap achieves an
average 23\% speedup. On complex designs with runtimes over 10 s, it reaches an
average 49\% acceleration.
\\ ( https://arxiv.org/abs/2511.06831 ,  1970kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06837
Date: Mon, 10 Nov 2025 08:29:14 GMT   (8300kb)

Title: Minimum Width of Deep Narrow Networks for Universal Approximation
Authors: Xiao-Song Yang, Qi Zhou, Xuan Zhou
Categories: cs.LG
\\
 Determining the minimum width of fully connected neural networks has become a
fundamental problem in recent theoretical studies of deep neural networks. In
this paper, we study the lower bounds and upper bounds of the minimum width
required for fully connected neural networks in order to have universal
approximation capability, which is important in network design and training. We
show that $w_{min}\leq\max(2d_x+1, d_y)$ for networks with ELU, SELU, and the
upper bound of this inequality is attained when $d_y=2d_x$, where $d_x$, $d_y$
denote the input and output dimensions, respectively. Besides, we show that
$d_x+1\leq w_{min}\leq d_x+d_y$ for networks with LeakyReLU, ELU, CELU, SELU,
Softplus, by proving that ReLU can be approximated by these activation
functions. In addition, in the case that the activation function is injective
or can be uniformly approximated by a sequence of injective functions (e.g.,
ReLU), we present a new proof of the inequality $w_{min}\ge
d_y+\mathbf{1}_{d_x<d_y\leq2d_x}$ by constructing a more intuitive example via
a new geometric approach based on Poincar$\acute{\text{e}}$-Miranda Theorem.
\\ ( https://arxiv.org/abs/2511.06837 ,  8300kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06842
Date: Mon, 10 Nov 2025 08:36:29 GMT   (23kb)

Title: MI-to-Mid Distilled Compression (M2M-DC): An
 Hybrid-Information-Guided-Block Pruning with Progressive Inner Slicing
 Approach to Model Compression
Authors: Lionel Levine, Sajjad Ghiasvand, Haniyeh Ehsani Oskouie, Majid
 Sarrafzadeh
Categories: cs.LG
\\
 We introduce MI-to-Mid Distilled Compression (M2M-DC), a two-scale,
shape-safe compression framework that interleaves information-guided block
pruning with progressive inner slicing and staged knowledge distillation (KD).
First, M2M-DC ranks residual (or inverted-residual) blocks by a label-aware
mutual information (MI) signal and removes the least informative units
(structured prune-after-training). It then alternates short KD phases with
stage-coherent, residual-safe channel slicing: (i) stage "planes" (co-slicing
conv2 out-channels with the downsample path and next-stage inputs), and (ii) an
optional mid-channel trim (conv1 out / bn1 / conv2 in). This targets
complementary redundancy, whole computational motifs and within-stage width
while preserving residual shape invariants. On CIFAR-100, M2M-DC yields a clean
accuracy-compute frontier. For ResNet-18, we obtain 85.46% Top-1 with 3.09M
parameters and 0.0139 GMacs (72% params, 63% GMacs vs. teacher; mean final
85.29% over three seeds). For ResNet-34, we reach 85.02% Top-1 with 5.46M
params and 0.0195 GMacs (74% / 74% vs. teacher; mean final 84.62%). Extending
to inverted-residuals, MobileNetV2 achieves a mean final 68.54% Top-1 at 1.71M
params (27%) and 0.0186 conv GMacs (24%), improving over the teacher's 66.03%
by +2.5 points across three seeds. Because M2M-DC exposes only a thin,
architecture-aware interface (blocks, stages, and down sample/skip wiring), it
generalizes across residual CNNs and extends to inverted-residual families with
minor legalization rules. The result is a compact, practical recipe for
deployment-ready models that match or surpass teacher accuracy at a fraction of
the compute.
\\ ( https://arxiv.org/abs/2511.06842 ,  23kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06854
Date: Mon, 10 Nov 2025 08:53:10 GMT   (395kb)

Title: Beyond Observations: Reconstruction Error-Guided Irregularly Sampled
 Time Series Representation Learning
Authors: Jiexi Liu, Meng Cao, Songcan Chen
Categories: cs.LG stat.ML
Comments: Accepted by AAAI 2026
\\
 Irregularly sampled time series (ISTS), characterized by non-uniform time
intervals with natural missingness, are prevalent in real-world applications.
Existing approaches for ISTS modeling primarily rely on observed values to
impute unobserved ones or infer latent dynamics. However, these methods
overlook a critical source of learning signal: the reconstruction error
inherently produced during model training. Such error implicitly reflects how
well a model captures the underlying data structure and can serve as an
informative proxy for unobserved values. To exploit this insight, we propose
iTimER, a simple yet effective self-supervised pre-training framework for ISTS
representation learning. iTimER models the distribution of reconstruction
errors over observed values and generates pseudo-observations for unobserved
timestamps through a mixup strategy between sampled errors and the last
available observations. This transforms unobserved timestamps into noise-aware
training targets, enabling meaningful reconstruction signals. A Wasserstein
metric aligns reconstruction error distributions between observed and
pseudo-observed regions, while a contrastive learning objective enhances the
discriminability of learned representations. Extensive experiments on
classification, interpolation, and forecasting tasks demonstrate that iTimER
consistently outperforms state-of-the-art methods under the ISTS setting.
\\ ( https://arxiv.org/abs/2511.06854 ,  395kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06856
Date: Mon, 10 Nov 2025 08:56:21 GMT   (22206kb)

Title: Contact Wasserstein Geodesics for Non-Conservative Schrodinger Bridges
Authors: Andrea Testa, Soren Hauberg, Tamim Asfour, Leonel Rozo
Categories: cs.LG math.DG
Comments: 38 pages, 18 figures
MSC-class: 37K25 (Primary) 53D25, 49Q22 (Secondary)
\\
 The Schr\"odinger Bridge provides a principled framework for modeling
stochastic processes between distributions; however, existing methods are
limited by energy-conservation assumptions, which constrains the bridge's shape
preventing it from model varying-energy phenomena. To overcome this, we
introduce the non-conservative generalized Schr\"odinger bridge (NCGSB), a
novel, energy-varying reformulation based on contact Hamiltonian mechanics. By
allowing energy to change over time, the NCGSB provides a broader class of
real-world stochastic processes, capturing richer and more faithful
intermediate dynamics. By parameterizing the Wasserstein manifold, we lift the
bridge problem to a tractable geodesic computation in a finite-dimensional
space. Unlike computationally expensive iterative solutions, our contact
Wasserstein geodesic (CWG) is naturally implemented via a ResNet architecture
and relies on a non-iterative solver with near-linear complexity. Furthermore,
CWG supports guided generation by modulating a task-specific distance metric.
We validate our framework on tasks including manifold navigation, molecular
dynamics predictions, and image generation, demonstrating its practical
benefits and versatility.
\\ ( https://arxiv.org/abs/2511.06856 ,  22206kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06859
Date: Mon, 10 Nov 2025 09:03:16 GMT   (10444kb)

Title: TuckA: Hierarchical Compact Tensor Experts for Efficient Fine-Tuning
Authors: Qifeng Lei, Zhiyong Yang, Qianqian Xu, Cong Hua, Peisong Wen, Qingming
 Huang
Categories: cs.LG cs.AI
\\
 Efficiently fine-tuning pre-trained models for downstream tasks is a key
challenge in the era of foundation models. Parameter-efficient fine-tuning
(PEFT) presents a promising solution, achieving performance comparable to full
fine-tuning by updating only a small number of adaptation weights per layer.
Traditional PEFT methods typically rely on a single expert, where the
adaptation weight is a low-rank matrix. However, for complex tasks, the data's
inherent diversity poses a significant challenge for such models, as a single
adaptation weight cannot adequately capture the features of all samples. To
address this limitation, we explore how to integrate multiple small adaptation
experts into a compact structure to defeat a large adapter. Specifically, we
propose Tucker Adaptation (TuckA), a method with four key properties: (i) We
use Tucker decomposition to create a compact 3D tensor where each slice
naturally serves as an expert. The low-rank nature of this decomposition
ensures that the number of parameters scales efficiently as more experts are
added. (ii) We introduce a hierarchical strategy that organizes these experts
into groups at different granularities, allowing the model to capture both
local and global data patterns. (iii) We develop an efficient batch-level
routing mechanism, which reduces the router's parameter size by a factor of $L$
compared to routing at every adapted layer (where $L$ is the number of adapted
layers) (iv) We propose data-aware initialization to achieve loss-free expert
load balancing based on theoretical analysis. Extensive experiments on
benchmarks in natural language understanding, image classification, and
mathematical reasoning speak to the efficacy of TuckA, offering a new and
effective solution to the PEFT problem.
\\ ( https://arxiv.org/abs/2511.06859 ,  10444kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06893
Date: Mon, 10 Nov 2025 09:43:47 GMT   (2277kb)

Title: DeepBooTS: Dual-Stream Residual Boosting for Drift-Resilient Time-Series
 Forecasting
Authors: Daojun Liang, Jing Chen, Xiao Wang, Yinglong Wang, Suo Li
Categories: cs.LG cs.AI
Comments: 28 pages,17 pages, Published in AAAI-26
\\
 Time-Series (TS) exhibits pronounced non-stationarity. Consequently, most
forecasting methods display compromised robustness to concept drift, despite
the prevalent application of instance normalization. We tackle this challenge
by first analysing concept drift through a bias-variance lens and proving that
weighted ensemble reduces variance without increasing bias. These insights
motivate DeepBooTS, a novel end-to-end dual-stream residual-decreasing boosting
method that progressively reconstructs the intrinsic signal. In our design,
each block of a deep model becomes an ensemble of learners with an auxiliary
output branch forming a highway to the final prediction. The block-wise outputs
correct the residuals of previous blocks, leading to a learning-driven
decomposition of both inputs and targets. This method enhances versatility and
interpretability while substantially improving robustness to concept drift.
Extensive experiments, including those on large-scale datasets, show that the
proposed method outperforms existing methods by a large margin, yielding an
average performance improvement of 15.8% across various datasets, establishing
a new benchmark for TS forecasting.
\\ ( https://arxiv.org/abs/2511.06893 ,  2277kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06894
Date: Mon, 10 Nov 2025 09:43:48 GMT   (4490kb)

Title: COGNOS: Universal Enhancement for Time Series Anomaly Detection via
 Constrained Gaussian-Noise Optimization and Smoothing
Authors: Wenlong Shang and Peng Chang
Categories: cs.LG cs.AI
\\
 Reconstruction-based methods are a dominant paradigm in time series anomaly
detection (TSAD), however, their near-universal reliance on Mean Squared Error
(MSE) loss results in statistically flawed reconstruction residuals. This
fundamental weakness leads to noisy, unstable anomaly scores with a poor
signal-to-noise ratio, hindering reliable detection. To address this, we
propose Constrained Gaussian-Noise Optimization and Smoothing (COGNOS), a
universal, model-agnostic enhancement framework that tackles this issue at its
source. COGNOS introduces a novel Gaussian-White Noise Regularization strategy
during training, which directly constrains the model's output residuals to
conform to a Gaussian white noise distribution. This engineered statistical
property creates the ideal precondition for our second contribution: a Kalman
Smoothing Post-processor that provably operates as a statistically optimal
estimator to denoise the raw anomaly scores. The synergy between these two
components allows COGNOS to robustly separate the true anomaly signal from
random fluctuations. Extensive experiments demonstrate that COGNOS is highly
effective, delivering an average F-score uplift of 57.9% when applied to 12
diverse backbone models across multiple real-world benchmark datasets. Our work
reveals that directly regularizing output statistics is a powerful and
generalizable strategy for significantly improving anomaly detection systems.
\\ ( https://arxiv.org/abs/2511.06894 ,  4490kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06895
Date: Mon, 10 Nov 2025 09:45:03 GMT   (29kb)

Title: On The Presence of Double-Descent in Deep Reinforcement Learning
Authors: Viktor Vesel\'y, Aleksandar Todorov and Matthia Sabatelli
Categories: cs.LG cs.AI stat.ML
\\
 The double descent (DD) paradox, where over-parameterized models see
generalization improve past the interpolation point, remains largely unexplored
in the non-stationary domain of Deep Reinforcement Learning (DRL). We present
preliminary evidence that DD exists in model-free DRL, investigating it
systematically across varying model capacity using the Actor-Critic framework.
We rely on an information-theoretic metric, Policy Entropy, to measure policy
uncertainty throughout training. Preliminary results show a clear epoch-wise DD
curve; the policy's entrance into the second descent region correlates with a
sustained, significant reduction in Policy Entropy. This entropic decay
suggests that over-parameterization acts as an implicit regularizer, guiding
the policy towards robust, flatter minima in the loss landscape. These findings
establish DD as a factor in DRL and provide an information-based mechanism for
designing agents that are more general, transferable, and robust.
\\ ( https://arxiv.org/abs/2511.06895 ,  29kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06898
Date: Mon, 10 Nov 2025 09:47:24 GMT   (992kb)

Title: A Hybrid Autoencoder-Transformer Model for Robust Day-Ahead Electricity
 Price Forecasting under Extreme Conditions
Authors: Boyan Tang, Xuanhao Ren, Peng Xiao, Shunbo Lei, Xiaorong Sun, Jianghua
 Wu
Categories: cs.LG cs.AI
Comments: Published in 2025 IEEE 1st International Symposium on the Application
 of Artificial Intelligence in Electrical Engineering (AAIEE)
 https://ieeexplore.ieee.org/document/11100637
\\
 Accurate day-ahead electricity price forecasting (DAEPF) is critical for the
efficient operation of power systems, but extreme condition and market
anomalies pose significant challenges to existing forecasting methods. To
overcome these challenges, this paper proposes a novel hybrid deep learning
framework that integrates a Distilled Attention Transformer (DAT) model and an
Autoencoder Self-regression Model (ASM). The DAT leverages a self-attention
mechanism to dynamically assign higher weights to critical segments of
historical data, effectively capturing both long-term trends and short-term
fluctuations. Concurrently, the ASM employs unsupervised learning to detect and
isolate anomalous patterns induced by extreme conditions, such as heavy rain,
heat waves, or human festivals. Experiments on datasets sampled from California
and Shandong Province demonstrate that our framework significantly outperforms
state-of-the-art methods in prediction accuracy, robustness, and computational
efficiency. Our framework thus holds promise for enhancing grid resilience and
optimizing market operations in future power systems.
\\ ( https://arxiv.org/abs/2511.06898 ,  992kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06902
Date: Mon, 10 Nov 2025 09:51:31 GMT   (5683kb)

Title: A Closer Look at Knowledge Distillation in Spiking Neural Network
 Training
Authors: Xu Liu, Na Xia, Jinxing Zhou, Jingyuan Xu, Dan Guo
Categories: cs.LG
Comments: Accepted by AAAI 2026
\\
 Spiking Neural Networks (SNNs) become popular due to excellent energy
efficiency, yet facing challenges for effective model training. Recent works
improve this by introducing knowledge distillation (KD) techniques, with the
pre-trained artificial neural networks (ANNs) used as teachers and the target
SNNs as students. This is commonly accomplished through a straightforward
element-wise alignment of intermediate features and prediction logits from ANNs
and SNNs, often neglecting the intrinsic differences between their
architectures. Specifically, ANN's outputs exhibit a continuous distribution,
whereas SNN's outputs are characterized by sparsity and discreteness. To
mitigate this issue, we introduce two innovative KD strategies. Firstly, we
propose the Saliency-scaled Activation Map Distillation (SAMD), which aligns
the spike activation map of the student SNN with the class-aware activation map
of the teacher ANN. Rather than performing KD directly on the raw %and distinct
features of ANN and SNN, our SAMD directs the student to learn from saliency
activation maps that exhibit greater semantic and distribution consistency.
Additionally, we propose a Noise-smoothed Logits Distillation (NLD), which
utilizes Gaussian noise to smooth the sparse logits of student SNN,
facilitating the alignment with continuous logits from teacher ANN. Extensive
experiments on multiple datasets demonstrate the effectiveness of our methods.
Code is available~\footnote{https://github.com/SinoLeu/CKDSNN.git}.
\\ ( https://arxiv.org/abs/2511.06902 ,  5683kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06906
Date: Mon, 10 Nov 2025 10:00:28 GMT   (1347kb)

Title: Counterfactual Explanation for Multivariate Time Series Forecasting with
 Exogenous Variables
Authors: Keita Kinjo
Categories: cs.LG cs.AI
Comments: 27pages,9figures,9tables
MSC-class: 68T05, 62M10, 62P20
ACM-class: I.2.6; I.5.1; I.5.4
\\
 Currently, machine learning is widely used across various domains, including
time series data analysis. However, some machine learning models function as
black boxes, making interpretability a critical concern. One approach to
address this issue is counterfactual explanation (CE), which aims to provide
insights into model predictions. This study focuses on the relatively
underexplored problem of generating counterfactual explanations for time series
forecasting. We propose a method for extracting CEs in time series forecasting
using exogenous variables, which are frequently encountered in fields such as
business and marketing. In addition, we present methods for analyzing the
influence of each variable over an entire time series, generating CEs by
altering only specific variables, and evaluating the quality of the resulting
CEs. We validate the proposed method through theoretical analysis and empirical
experiments, showcasing its accuracy and practical applicability. These
contributions are expected to support real-world decision-making based on time
series data analysis.
\\ ( https://arxiv.org/abs/2511.06906 ,  1347kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06913
Date: Mon, 10 Nov 2025 10:08:53 GMT   (549kb)

Title: Sampling and Loss Weights in Multi-Domain Training
Authors: Mahdi Salmani, Pratik Worah, Meisam Razaviyayn, and Vahab Mirrokni
Categories: cs.LG cs.AI
\\
 In the training of large deep neural networks, there is a need for vast
amounts of training data. To meet this need, data is collected from multiple
domains, such as Wikipedia and GitHub. These domains are heterogeneous in both
data quality and the diversity of information they provide. This raises the
question of how much we should rely on each domain. Several methods have
attempted to address this issue by assigning sampling weights to each data
domain using heuristics or approximations. As a first step toward a deeper
understanding of the role of data mixing, this work revisits the problem by
studying two kinds of weights: sampling weights, which control how much each
domain contributes in a batch, and loss weights, which scale the loss from each
domain during training. Through a rigorous study of linear regression, we show
that these two weights play complementary roles. First, they can reduce the
variance of gradient estimates in iterative methods such as stochastic gradient
descent (SGD). Second, they can improve generalization performance by reducing
the generalization gap. We provide both theoretical and empirical support for
these claims. We further study the joint dynamics of sampling weights and loss
weights, examining how they can be combined to capture both contributions.
\\ ( https://arxiv.org/abs/2511.06913 ,  549kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06946
Date: Mon, 10 Nov 2025 10:53:16 GMT   (4993kb)

Title: Learning to Focus: Prioritizing Informative Histories with Structured
 Attention Mechanisms in Partially Observable Reinforcement Learning
Authors: Daniel De Dios Allegue, Jinke He, Frans A. Oliehoek
Categories: cs.LG cs.AI
Comments: Accepted to Embodied World Models for Decision Making (EWM) Workshop
 at NeurIPS 2025
\\
 Transformers have shown strong ability to model long-term dependencies and
are increasingly adopted as world models in model-based reinforcement learning
(RL) under partial observability. However, unlike natural language corpora, RL
trajectories are sparse and reward-driven, making standard self-attention
inefficient because it distributes weight uniformly across all past tokens
rather than emphasizing the few transitions critical for control. To address
this, we introduce structured inductive priors into the self-attention
mechanism of the dynamics head: (i) per-head memory-length priors that
constrain attention to task-specific windows, and (ii) distributional priors
that learn smooth Gaussian weightings over past state-action pairs. We
integrate these mechanisms into UniZero, a model-based RL agent with a
Transformer-based world model that supports planning under partial
observability. Experiments on the Atari 100k benchmark show that most
efficiency gains arise from the Gaussian prior, which smoothly allocates
attention to informative transitions, while memory-length priors often truncate
useful signals with overly restrictive cut-offs. In particular, Gaussian
Attention achieves a 77% relative improvement in mean human-normalized scores
over UniZero. These findings suggest that in partially observable RL domains
with non-stationary temporal dependencies, discrete memory windows are
difficult to learn reliably, whereas smooth distributional priors flexibly
adapt across horizons and yield more robust data efficiency. Overall, our
results demonstrate that encoding structured temporal priors directly into
self-attention improves the prioritization of informative histories for
dynamics modeling under partial observability.
\\ ( https://arxiv.org/abs/2511.06946 ,  4993kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06961
Date: Mon, 10 Nov 2025 11:08:39 GMT   (6972kb)

Title: Hybrid Autoencoders for Tabular Data: Leveraging Model-Based
 Augmentation in Low-Label Settings
Authors: Erel Naor, Ofir Lindenbaum
Categories: cs.LG cs.AI
Comments: accepted to neurips 2025, main text is 10 pages
\\
 Deep neural networks often under-perform on tabular data due to their
sensitivity to irrelevant features and a spectral bias toward smooth,
low-frequency functions. These limitations hinder their ability to capture the
sharp, high-frequency signals that often define tabular structure, especially
under limited labeled samples. While self-supervised learning (SSL) offers
promise in such settings, it remains challenging in tabular domains due to the
lack of effective data augmentations. We propose a hybrid autoencoder that
combines a neural encoder with an oblivious soft decision tree (OSDT) encoder,
each guided by its own stochastic gating network that performs sample-specific
feature selection. Together, these structurally different encoders and
model-specific gating networks implement model-based augmentation, producing
complementary input views tailored to each architecture. The two encoders,
trained with a shared decoder and cross-reconstruction loss, learn distinct yet
aligned representations that reflect their respective inductive biases. During
training, the OSDT encoder (robust to noise and effective at modeling
localized, high-frequency structure) guides the neural encoder toward
representations more aligned with tabular data. At inference, only the neural
encoder is used, preserving flexibility and SSL compatibility. Spectral
analysis highlights the distinct inductive biases of each encoder. Our method
achieves consistent gains in low-label classification and regression across
diverse tabular datasets, outperforming deep and tree-based supervised
baselines.
\\ ( https://arxiv.org/abs/2511.06961 ,  6972kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06973
Date: Mon, 10 Nov 2025 11:25:55 GMT   (285kb)

Title: Oh That Looks Familiar: A Novel Similarity Measure for Spreadsheet
 Template Discovery
Authors: Ananad Krishnakumar, Vengadesh Ravikumaran
Categories: cs.LG cs.CV
Comments: 5 pages, 2 figures, Accepted for EuroIPS: AI for Tabular Data
 Workshop (2025)
\\
 Traditional methods for identifying structurally similar spreadsheets fail to
capture the spatial layouts and type patterns defining templates. To quantify
spreadsheet similarity, we introduce a hybrid distance metric that combines
semantic embeddings, data type information, and spatial positioning. In order
to calculate spreadsheet similarity, our method converts spreadsheets into
cell-level embeddings and then uses aggregation techniques like Chamfer and
Hausdorff distances. Experiments across template families demonstrate superior
unsupervised clustering performance compared to the graph-based Mondrian
baseline, achieving perfect template reconstruction (Adjusted Rand Index of
1.00 versus 0.90) on the FUSTE dataset. Our approach facilitates large-scale
automated template discovery, which in turn enables downstream applications
such as retrieval-augmented generation over tabular collections, model
training, and bulk data cleaning.
\\ ( https://arxiv.org/abs/2511.06973 ,  285kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06976
Date: Mon, 10 Nov 2025 11:27:57 GMT   (3570kb)

Title: Rethinking Crystal Symmetry Prediction: A Decoupled Perspective
Authors: Liheng Yu, Zhe Zhao, Xucong Wang, Di Wu, Pengkun Wang
Categories: cs.LG
\\
 Efficiently and accurately determining the symmetry is a crucial step in the
structural analysis of crystalline materials. Existing methods usually
mindlessly apply deep learning models while ignoring the underlying chemical
rules. More importantly, experiments show that they face a serious sub-property
confusion SPC problem. To address the above challenges, from a decoupled
perspective, we introduce the XRDecoupler framework, a problem-solving arsenal
specifically designed to tackle the SPC problem. Imitating the thinking process
of chemists, we innovatively incorporate multidimensional crystal symmetry
information as superclass guidance to ensure that the model's prediction
process aligns with chemical intuition. We further design a hierarchical PXRD
pattern learning model and a multi-objective optimization approach to achieve
high-quality representation and balanced optimization. Comprehensive
evaluations on three mainstream databases (e.g., CCDC, CoREMOF, and
InorganicData) demonstrate that XRDecoupler excels in performance,
interpretability, and generalization.
\\ ( https://arxiv.org/abs/2511.06976 ,  3570kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06978
Date: Mon, 10 Nov 2025 11:28:33 GMT   (19kb)

Title: Fast Bayesian Updates via Harmonic Representations
Authors: Di Zhang
Categories: cs.LG cs.IT cs.NA math.IT math.NA math.ST stat.TH
Comments: 13 pages
MSC-class: 65T50, 62F15, 65C60, 42A85
ACM-class: G.3; I.2.6; G.1.2; E.4
\\
 Bayesian inference, while foundational to probabilistic reasoning, is often
hampered by the computational intractability of posterior distributions,
particularly through the challenging evidence integral. Conventional approaches
like Markov Chain Monte Carlo (MCMC) and Variational Inference (VI) face
significant scalability and efficiency limitations. This paper introduces a
novel, unifying framework for fast Bayesian updates by leveraging harmonic
analysis. We demonstrate that representing the prior and likelihood in a
suitable orthogonal basis transforms the Bayesian update rule into a spectral
convolution. Specifically, the Fourier coefficients of the posterior are shown
to be the normalized convolution of the prior and likelihood coefficients. To
achieve computational feasibility, we introduce a spectral truncation scheme,
which, for smooth functions, yields an exceptionally accurate
finite-dimensional approximation and reduces the update to a circular
convolution. This formulation allows us to exploit the Fast Fourier Transform
(FFT), resulting in a deterministic algorithm with O(N log N) complexity -- a
substantial improvement over the O(N^2) cost of naive methods. We establish
rigorous mathematical criteria for the applicability of our method, linking its
efficiency to the smoothness and spectral decay of the involved distributions.
The presented work offers a paradigm shift, connecting Bayesian computation to
signal processing and opening avenues for real-time, sequential inference in a
wide class of problems.
\\ ( https://arxiv.org/abs/2511.06978 ,  19kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06979
Date: Mon, 10 Nov 2025 11:30:09 GMT   (6225kb)

Title: Breaking the Gradient Barrier: Unveiling Large Language Models for
 Strategic Classification
Authors: Xinpeng Lv, Yunxin Mao, Haoxuan Li, Ke Liang, Jinxuan Yang, Wanrong
 Huang, Haoang Chi, Huan Chen, Long Lan, Yuanlong Chen, Wenjing Yang, Haotian
 Wang
Categories: cs.LG cs.GT
Comments: Accepted by NeurIPS 2025
\\
 Strategic classification~(SC) explores how individuals or entities modify
their features strategically to achieve favorable classification outcomes.
However, existing SC methods, which are largely based on linear models or
shallow neural networks, face significant limitations in terms of scalability
and capacity when applied to real-world datasets with significantly increasing
scale, especially in financial services and the internet sector. In this paper,
we investigate how to leverage large language models to design a more scalable
and efficient SC framework, especially in the case of growing individuals
engaged with decision-making processes. Specifically, we introduce GLIM, a
gradient-free SC method grounded in in-context learning. During the
feed-forward process of self-attention, GLIM implicitly simulates the typical
bi-level optimization process of SC, including both the feature manipulation
and decision rule optimization. Without fine-tuning the LLMs, our proposed GLIM
enjoys the advantage of cost-effective adaptation in dynamic strategic
environments. Theoretically, we prove GLIM can support pre-trained LLMs to
adapt to a broad range of strategic manipulations. We validate our approach
through experiments with a collection of pre-trained LLMs on real-world and
synthetic datasets in financial and internet domains, demonstrating that our
GLIM exhibits both robustness and efficiency, and offering an effective
solution for large-scale SC tasks.
\\ ( https://arxiv.org/abs/2511.06979 ,  6225kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06988
Date: Mon, 10 Nov 2025 11:38:41 GMT   (263kb)

Title: HCFSLN: Adaptive Hyperbolic Few-Shot Learning for Multimodal Anxiety
 Detection
Authors: Aditya Sneh, Nilesh Kumar Sahu, Anushka Sanjay Shelke, Arya Adyasha,
 Haroon R. Lone
Categories: cs.LG cs.HC
\\
 Anxiety disorders impact millions globally, yet traditional diagnosis relies
on clinical interviews, while machine learning models struggle with overfitting
due to limited data. Large-scale data collection remains costly and
time-consuming, restricting accessibility. To address this, we introduce the
Hyperbolic Curvature Few-Shot Learning Network (HCFSLN), a novel Few-Shot
Learning (FSL) framework for multimodal anxiety detection, integrating speech,
physiological signals, and video data. HCFSLN enhances feature separability
through hyperbolic embeddings, cross-modal attention, and an adaptive gating
network, enabling robust classification with minimal data. We collected a
multimodal anxiety dataset from 108 participants and benchmarked HCFSLN against
six FSL baselines, achieving 88% accuracy, outperforming the best baseline by
14%. These results highlight the effectiveness of hyperbolic space for modeling
anxiety-related speech patterns and demonstrate FSL's potential for anxiety
classification.
\\ ( https://arxiv.org/abs/2511.06988 ,  263kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06991
Date: Mon, 10 Nov 2025 11:42:21 GMT   (19172kb)

Title: CoLM: Collaborative Large Models via A Client-Server Paradigm
Authors: Siqi Huang, Sida Huang and Hongyuan Zhang
Categories: cs.LG
\\
 Large models have achieved remarkable performance across a range of reasoning
and understanding tasks. Prior work often utilizes model ensembles or
multi-agent systems to collaboratively generate responses, effectively
operating in a server-to-server paradigm. However, such approaches do not align
well with practical deployment settings, where a limited number of server-side
models are shared by many clients under modern internet architectures. In this
paper, we introduce \textbf{CoLM} (\textbf{Co}llaboration in
\textbf{L}arge-\textbf{M}odels), a novel framework for collaborative reasoning
that redefines cooperation among large models from a client-server perspective.
Unlike traditional ensemble methods that rely on simultaneous inference from
multiple models to produce a single output, CoLM allows the outputs of multiple
models to be aggregated or shared, enabling each client model to independently
refine and update its own generation based on these high-quality outputs. This
design enables collaborative benefits by fully leveraging both client-side and
shared server-side models. We further extend CoLM to vision-language models
(VLMs), demonstrating its applicability beyond language tasks. Experimental
results across multiple benchmarks show that CoLM consistently improves model
performance on previously failed queries, highlighting the effectiveness of
collaborative guidance in enhancing single-model capabilities.
\\ ( https://arxiv.org/abs/2511.06991 ,  19172kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07006
Date: Mon, 10 Nov 2025 11:57:47 GMT   (1542kb)

Title: S$^2$Drug: Bridging Protein Sequence and 3D Structure in Contrastive
 Representation Learning for Virtual Screening
Authors: Bowei He, Bowen Gao, Yankai Chen, Yanyan Lan, Chen Ma, Philip S. Yu,
 Ya-Qin Zhang, Wei-Ying Ma
Categories: cs.LG cs.AI
Comments: Accepted by AAAI 2026 Main Technical Track
\\
 Virtual screening (VS) is an essential task in drug discovery, focusing on
the identification of small-molecule ligands that bind to specific protein
pockets. Existing deep learning methods, from early regression models to recent
contrastive learning approaches, primarily rely on structural data while
overlooking protein sequences, which are more accessible and can enhance
generalizability. However, directly integrating protein sequences poses
challenges due to the redundancy and noise in large-scale protein-ligand
datasets. To address these limitations, we propose \textbf{S$^2$Drug}, a
two-stage framework that explicitly incorporates protein \textbf{S}equence
information and 3D \textbf{S}tructure context in protein-ligand contrastive
representation learning. In the first stage, we perform protein sequence
pretraining on ChemBL using an ESM2-based backbone, combined with a tailored
data sampling strategy to reduce redundancy and noise on both protein and
ligand sides. In the second stage, we fine-tune on PDBBind by fusing sequence
and structure information through a residue-level gating module, while
introducing an auxiliary binding site prediction task. This auxiliary task
guides the model to accurately localize binding residues within the protein
sequence and capture their 3D spatial arrangement, thereby refining
protein-ligand matching. Across multiple benchmarks, S$^2$Drug consistently
improves virtual screening performance and achieves strong results on binding
site prediction, demonstrating the value of bridging sequence and structure in
contrastive learning.
\\ ( https://arxiv.org/abs/2511.07006 ,  1542kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07023
Date: Mon, 10 Nov 2025 12:10:05 GMT   (698kb)

Title: Correcting False Alarms from Unseen: Adapting Graph Anomaly Detectors at
 Test Time
Authors: Junjun Pan, Yixin Liu, Chuan Zhou, Fei Xiong, Alan Wee-Chung Liew,
 Shirui Pan
Categories: cs.LG
Comments: 9 pages, 5 figures, accepted by AAAI 2026
\\
 Graph anomaly detection (GAD), which aims to detect outliers in
graph-structured data, has received increasing research attention recently.
However, existing GAD methods assume identical training and testing
distributions, which is rarely valid in practice. In real-world scenarios,
unseen but normal samples may emerge during deployment, leading to a normality
shift that degrades the performance of GAD models trained on the original data.
Through empirical analysis, we reveal that the degradation arises from (1)
semantic confusion, where unseen normal samples are misinterpreted as anomalies
due to their novel patterns, and (2) aggregation contamination, where the
representations of seen normal nodes are distorted by unseen normals through
message aggregation. While retraining or fine-tuning GAD models could be a
potential solution to the above challenges, the high cost of model retraining
and the difficulty of obtaining labeled data often render this approach
impractical in real-world applications. To bridge the gap, we proposed a
lightweight and plug-and-play Test-time adaptation framework for correcting
Unseen Normal pattErns (TUNE) in GAD. To address semantic confusion, a graph
aligner is employed to align the shifted data to the original one at the graph
attribute level. Moreover, we utilize the minimization of representation-level
shift as a supervision signal to train the aligner, which leverages the
estimated aggregation contamination as a key indicator of normality shift.
Extensive experiments on 10 real-world datasets demonstrate that TUNE
significantly enhances the generalizability of pre-trained GAD models to both
synthetic and real unseen normal patterns.
\\ ( https://arxiv.org/abs/2511.07023 ,  698kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07032
Date: Mon, 10 Nov 2025 12:28:04 GMT   (182kb)

Title: Fair Bayesian Data Selection via Generalized Discrepancy Measures
Authors: Yixuan Zhang, Jiabin Luo, Zhenggang Wang, Feng Zhou, Quyu Kong
Categories: cs.LG stat.ML
\\
 Fairness concerns are increasingly critical as machine learning models are
deployed in high-stakes applications. While existing fairness-aware methods
typically intervene at the model level, they often suffer from high
computational costs, limited scalability, and poor generalization. To address
these challenges, we propose a Bayesian data selection framework that ensures
fairness by aligning group-specific posterior distributions of model parameters
and sample weights with a shared central distribution. Our framework supports
flexible alignment via various distributional discrepancy measures, including
Wasserstein distance, maximum mean discrepancy, and $f$-divergence, allowing
geometry-aware control without imposing explicit fairness constraints. This
data-centric approach mitigates group-specific biases in training data and
improves fairness in downstream tasks, with theoretical guarantees. Experiments
on benchmark datasets show that our method consistently outperforms existing
data selection and model-based fairness methods in both fairness and accuracy.
\\ ( https://arxiv.org/abs/2511.07032 ,  182kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07046
Date: Mon, 10 Nov 2025 12:39:14 GMT   (69kb)

Title: Learning Quantized Continuous Controllers for Integer Hardware
Authors: Fabian Kresse, Christoph H. Lampert
Categories: cs.LG cs.AI
Comments: 17 pages, 6 figures
\\
 Deploying continuous-control reinforcement learning policies on embedded
hardware requires meeting tight latency and power budgets. Small FPGAs can
deliver these, but only if costly floating point pipelines are avoided. We
study quantization-aware training (QAT) of policies for integer inference and
we present a learning-to-hardware pipeline that automatically selects low-bit
policies and synthesizes them to an Artix-7 FPGA. Across five MuJoCo tasks, we
obtain policy networks that are competitive with full precision (FP32) policies
but require as few as 3 or even only 2 bits per weight, and per internal
activation value, as long as input precision is chosen carefully. On the target
hardware, the selected policies achieve inference latencies on the order of
microseconds and consume microjoules per action, favorably comparing to a
quantized reference. Last, we observe that the quantized policies exhibit
increased input noise robustness compared to the floating-point baseline.
\\ ( https://arxiv.org/abs/2511.07046 ,  69kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07073
Date: Mon, 10 Nov 2025 13:06:16 GMT   (89kb)

Title: Breaking Privacy in Federated Clustering: Perfect Input Reconstruction
 via Temporal Correlations
Authors: Guang Yang, Lixia Luo, Qiongxiu Li
Categories: cs.LG
\\
 Federated clustering allows multiple parties to discover patterns in
distributed data without sharing raw samples. To reduce overhead, many
protocols disclose intermediate centroids during training. While often treated
as harmless for efficiency, whether such disclosure compromises privacy remains
an open question. Prior analyses modeled the problem as a so-called Hidden
Subset Sum Problem (HSSP) and argued that centroid release may be safe, since
classical HSSP attacks fail to recover inputs.
 We revisit this question and uncover a new leakage mechanism: temporal
regularities in $k$-means iterations create exploitable structure that enables
perfect input reconstruction. Building on this insight, we propose
Trajectory-Aware Reconstruction (TAR), an attack that combines temporal
assignment information with algebraic analysis to recover exact original
inputs. Our findings provide the first rigorous evidence, supported by a
practical attack, that centroid disclosure in federated clustering
significantly compromises privacy, exposing a fundamental tension between
privacy and efficiency.
\\ ( https://arxiv.org/abs/2511.07073 ,  89kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07087
Date: Mon, 10 Nov 2025 13:23:20 GMT   (74kb)

Title: Direct Molecular Polarizability Prediction with SO(3) Equivariant Local
 Frame GNNs
Authors: Jean Philip Filling, Felix Post, Michael Wand, Denis Andrienko
Categories: cs.LG
\\
 We introduce a novel equivariant graph neural network (GNN) architecture
designed to predict the tensorial response properties of molecules. Unlike
traditional frameworks that focus on regressing scalar quantities and derive
tensorial properties from their derivatives, our approach maintains
$SO(3)$-equivariance through the use of local coordinate frames. Our GNN
effectively captures geometric information by integrating scalar, vector, and
tensor channels within a local message-passing framework. To assess the
accuracy of our model, we apply it to predict the polarizabilities of molecules
in the QM7-X dataset and show that tensorial message passing outperforms scalar
message passing models. This work marks an advancement towards developing
structured, geometry-aware neural models for molecular property prediction.
\\ ( https://arxiv.org/abs/2511.07087 ,  74kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07118
Date: Mon, 10 Nov 2025 14:09:25 GMT   (4320kb)

Title: On the Joint Minimization of Regularization Loss Functions in Deep
 Variational Bayesian Methods for Attribute-Controlled Symbolic Music
 Generation
Authors: Matteo Petten\'o, Alessandro Ilic Mezza, Alberto Bernardini
Categories: cs.LG cs.AI eess.AS
Comments: IEEE Catalog No.: CFP2540S-ART ISBN: 978-9-46-459362-4
Journal-ref: In Proc. of the 33rd European Signal Processing Conference
 (EUSIPCO 2025), Palermo, Italy, Sept. 8-12, 2025
\\
 Explicit latent variable models provide a flexible yet powerful framework for
data synthesis, enabling controlled manipulation of generative factors. With
latent variables drawn from a tractable probability density function that can
be further constrained, these models enable continuous and semantically rich
exploration of the output space by navigating their latent spaces. Structured
latent representations are typically obtained through the joint minimization of
regularization loss functions. In variational information bottleneck models,
reconstruction loss and Kullback-Leibler Divergence (KLD) are often linearly
combined with an auxiliary Attribute-Regularization (AR) loss. However,
balancing KLD and AR turns out to be a very delicate matter. When KLD dominates
over AR, generative models tend to lack controllability; when AR dominates over
KLD, the stochastic encoder is encouraged to violate the standard normal prior.
We explore this trade-off in the context of symbolic music generation with
explicit control over continuous musical attributes. We show that existing
approaches struggle to jointly minimize both regularization objectives, whereas
suitable attribute transformations can help achieve both controllability and
regularization of the target latent dimensions.
\\ ( https://arxiv.org/abs/2511.07118 ,  4320kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07127
Date: Mon, 10 Nov 2025 14:12:35 GMT   (45863kb)

Title: REACT-LLM: A Benchmark for Evaluating LLM Integration with Causal
 Features in Clinical Prognostic Tasks
Authors: Linna Wang, Zhixuan You, Qihui Zhang, Jiunan Wen, Ji Shi, Yimin Chen,
 Yusen Wang, Fanqi Ding, Ziliang Feng, Li Lu
Categories: cs.LG
\\
 Large Language Models (LLMs) and causal learning each hold strong potential
for clinical decision making (CDM). However, their synergy remains poorly
understood, largely due to the lack of systematic benchmarks evaluating their
integration in clinical risk prediction. In real-world healthcare, identifying
features with causal influence on outcomes is crucial for actionable and
trustworthy predictions. While recent work highlights LLMs' emerging causal
reasoning abilities, there lacks comprehensive benchmarks to assess their
causal learning and performance informed by causal features in clinical risk
prediction. To address this, we introduce REACT-LLM, a benchmark designed to
evaluate whether combining LLMs with causal features can enhance clinical
prognostic performance and potentially outperform traditional machine learning
(ML) methods. Unlike existing LLM-clinical benchmarks that often focus on a
limited set of outcomes, REACT-LLM evaluates 7 clinical outcomes across 2
real-world datasets, comparing 15 prominent LLMs, 6 traditional ML models, and
3 causal discovery (CD) algorithms. Our findings indicate that while LLMs
perform reasonably in clinical prognostics, they have not yet outperformed
traditional ML models. Integrating causal features derived from CD algorithms
into LLMs offers limited performance gains, primarily due to the strict
assumptions of many CD methods, which are often violated in complex clinical
data. While the direct integration yields limited improvement, our benchmark
reveals a more promising synergy.
\\ ( https://arxiv.org/abs/2511.07127 ,  45863kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07156
Date: Mon, 10 Nov 2025 14:46:10 GMT   (7285kb)

Title: Conditional Diffusion as Latent Constraints for Controllable Symbolic
 Music Generation
Authors: Matteo Petten\'o, Alessandro Ilic Mezza, Alberto Bernardini
Categories: cs.LG cs.AI eess.AS
Journal-ref: In Proc. of the 26th International Society for Music Information
 Retrieval Conference (ISMIR 2025), Daejeon, Korea, Sept. 21-25, 2025
\\
 Recent advances in latent diffusion models have demonstrated state-of-the-art
performance in high-dimensional time-series data synthesis while providing
flexible control through conditioning and guidance. However, existing
methodologies primarily rely on musical context or natural language as the main
modality of interacting with the generative process, which may not be ideal for
expert users who seek precise fader-like control over specific musical
attributes. In this work, we explore the application of denoising diffusion
processes as plug-and-play latent constraints for unconditional symbolic music
generation models. We focus on a framework that leverages a library of small
conditional diffusion models operating as implicit probabilistic priors on the
latents of a frozen unconditional backbone. While previous studies have
explored domain-specific use cases, this work, to the best of our knowledge, is
the first to demonstrate the versatility of such an approach across a diverse
array of musical attributes, such as note density, pitch range, contour, and
rhythm complexity. Our experiments show that diffusion-driven constraints
outperform traditional attribute regularization and other latent constraints
architectures, achieving significantly stronger correlations between target and
generated attributes while maintaining high perceptual quality and diversity.
\\ ( https://arxiv.org/abs/2511.07156 ,  7285kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07158
Date: Mon, 10 Nov 2025 14:48:49 GMT   (15439kb)

Title: Guiding Generative Models to Uncover Diverse and Novel Crystals via
 Reinforcement Learning
Authors: Hyunsoo Park and Aron Walsh
Categories: cs.LG physics.comp-ph
\\
 Discovering functional crystalline materials entails navigating an immense
combinatorial design space. While recent advances in generative artificial
intelligence have enabled the sampling of chemically plausible compositions and
structures, a fundamental challenge remains: the objective misalignment between
likelihood-based sampling in generative modelling and targeted focus on
underexplored regions where novel compounds reside. Here, we introduce a
reinforcement learning framework that guides latent denoising diffusion models
toward diverse and novel, yet thermodynamically viable crystalline compounds.
Our approach integrates group relative policy optimisation with verifiable,
multi-objective rewards that jointly balance creativity, stability, and
diversity. Beyond de novo generation, we demonstrate enhanced property-guided
design that preserves chemical validity, while targeting desired functional
properties. This approach establishes a modular foundation for controllable
AI-driven inverse design that addresses the novelty-validity trade-off across
scientific discovery applications of generative models.
\\ ( https://arxiv.org/abs/2511.07158 ,  15439kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07161
Date: Mon, 10 Nov 2025 14:52:20 GMT   (798kb)

Title: LLMscape
Authors: Gottfried Haider, Jie Zhang
Categories: cs.LG
Comments: Accepted to NeurIPS 2025, Creative AI Track
\\
 LLMscape is an interactive installation that investigates how humans and AI
construct meaning under shared conditions of uncertainty. Within a mutable,
projection-mapped landscape, human participants reshape the world and engage
with multiple AI agents, each developing incomplete and provisional accounts of
their environment. Exhibited in Shanghai and continually evolving, the work
positions AI not as deterministic tools but as embodied co-witnesses to an
unstable world, examining the parallels between human and artificial
meaning-making and inviting reflection on our shared epistemic limits.
\\ ( https://arxiv.org/abs/2511.07161 ,  798kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07163
Date: Mon, 10 Nov 2025 14:53:52 GMT   (12886kb)

Title: Combining digital data streams and epidemic networks for real time
 outbreak detection
Authors: Ruiqi Lyu, Alistair Turcan, Bryan Wilder
Categories: cs.LG
\\
 Responding to disease outbreaks requires close surveillance of their
trajectories, but outbreak detection is hindered by the high noise in epidemic
time series. Aggregating information across data sources has shown great
denoising ability in other fields, but remains underexplored in epidemiology.
Here, we present LRTrend, an interpretable machine learning framework to
identify outbreaks in real time. LRTrend effectively aggregates diverse health
and behavioral data streams within one region and learns disease-specific
epidemic networks to aggregate information across regions. We reveal diverse
epidemic clusters and connections across the United States that are not well
explained by commonly used human mobility networks and may be informative for
future public health coordination. We apply LRTrend to 2 years of COVID-19 data
in 305 hospital referral regions and frequently detect regional Delta and
Omicron waves within 2 weeks of the outbreak's start, when case counts are a
small fraction of the wave's resulting peak.
\\ ( https://arxiv.org/abs/2511.07163 ,  12886kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07165
Date: Mon, 10 Nov 2025 14:58:19 GMT   (1486kb)

Title: Fuzzy Label: From Concept to Its Application in Label Learning
Authors: Chenxi Luoa, Zhuangzhuang Zhaoa, Zhaohong Denga, Te Zhangb
Categories: cs.LG cs.AI
\\
 Label learning is a fundamental task in machine learning that aims to
construct intelligent models using labeled data, encompassing traditional
single-label and multi-label classification models. Traditional methods
typically rely on logical labels, such as binary indicators (e.g., "yes/no")
that specify whether an instance belongs to a given category. However, in
practical applications, label annotations often involve significant uncertainty
due to factors such as data noise, inherent ambiguity in the observed entities,
and the subjectivity of human annotators. Therefore, representing labels using
simplistic binary logic can obscure valuable information and limit the
expressiveness of label learning models. To overcome this limitation, this
paper introduces the concept of fuzzy labels, grounded in fuzzy set theory, to
better capture and represent label uncertainty. We further propose an efficient
fuzzy labeling method that mines and generates fuzzy labels from the original
data, thereby enriching the label space with more informative and nuanced
representations. Based on this foundation, we present fuzzy-label-enhanced
algorithms for both single-label and multi-label learning, using the classical
K-Nearest Neighbors (KNN) and multi-label KNN algorithms as illustrative
examples. Experimental results indicate that fuzzy labels can more effectively
characterize the real-world labeling information and significantly enhance the
performance of label learning models.
\\ ( https://arxiv.org/abs/2511.07165 ,  1486kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07170
Date: Mon, 10 Nov 2025 15:01:31 GMT   (2484kb)

Title: On Stealing Graph Neural Network Models
Authors: Marcin Podhajski, Jan Dubi\'nski, Franziska Boenisch, Adam Dziedzic,
 Agnieszka Pr\k{e}gowska, Tomasz P. Michalak
Categories: cs.LG cs.CR
\\
 Current graph neural network (GNN) model-stealing methods rely heavily on
queries to the victim model, assuming no hard query limits. However, in
reality, the number of allowed queries can be severely limited. In this paper,
we demonstrate how an adversary can extract the GNN with very limited
interactions with the model. Our approach first enables the adversary to obtain
the model backbone without making direct queries to the victim model and then
to strategically utilize a fixed query limit to extract the most informative
data. The experiments on eight real-world datasets demonstrate the
effectiveness of the attack, even under a very restricted query limit and under
defense against model extraction in place. Our findings underscore the need for
robust defenses against GNN model extraction threats.
\\ ( https://arxiv.org/abs/2511.07170 ,  2484kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07198
Date: Mon, 10 Nov 2025 15:27:26 GMT   (1324kb)

Title: Synergy over Discrepancy: A Partition-Based Approach to Multi-Domain LLM
 Fine-Tuning
Authors: Hua Ye (1 and 2), Siyuan Chen (3), Haoliang Zhang (4), Weihao Luo (5),
 Yanbin Li (6), Xuan Zhang (2 and 7) ((1) Nanjing University, (2) Airon
 Technology CO., LTD, (3) University of Bristol, (4) The University of
 Oklahoma, (5) Donghua University, (6) Beijing University of Posts and
 Telecommunications, (7) Carnegie Mellon University)
Categories: cs.LG
Comments: 20 pages, 5 figures, 21 tables. Accepted at NeurIPS 2025.
 Corresponding author: Xuan Zhang (xuanzhang2199@gmail.com)
ACM-class: I.2.6
\\
 Large language models (LLMs) demonstrate impressive generalization abilities,
yet adapting them effectively across multiple heterogeneous domains remains
challenging due to inter-domain interference. To overcome this challenge, we
propose a partition-based multi-stage fine-tuning framework designed to exploit
inter-domain synergies while minimizing negative transfer. Our approach
strategically partitions domains into subsets (stages) by balancing domain
discrepancy, synergy, and model capacity constraints. We theoretically analyze
the proposed framework and derive novel generalization bounds that justify our
partitioning strategy. Extensive empirical evaluations on various language
understanding tasks show that our method consistently outperforms
state-of-the-art baselines.
\\ ( https://arxiv.org/abs/2511.07198 ,  1324kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07208
Date: Mon, 10 Nov 2025 15:33:32 GMT   (386kb)

Title: SMiLE: Provably Enforcing Global Relational Properties in Neural
 Networks
Authors: Matteo Francobaldi, Michele Lombardi, Andrea Lodi
Categories: cs.LG cs.AI math.OC
\\
 Artificial Intelligence systems are increasingly deployed in settings where
ensuring robustness, fairness, or domain-specific properties is essential for
regulation compliance and alignment with human values. However, especially on
Neural Networks, property enforcement is very challenging, and existing methods
are limited to specific constraints or local properties (defined around
datapoints), or fail to provide full guarantees. We tackle these limitations by
extending SMiLE, a recently proposed enforcement framework for NNs, to support
global relational properties (defined over the entire input space). The
proposed approach scales well with model complexity, accommodates general
properties and backbones, and provides full satisfaction guarantees. We
evaluate SMiLE on monotonicity, global robustness, and individual fairness, on
synthetic and real data, for regression and classification tasks. Our approach
is competitive with property-specific baselines in terms of accuracy and
runtime, and strictly superior in terms of generality and level of guarantees.
Overall, our results emphasize the potential of the SMiLE framework as a
platform for future research and applications.
\\ ( https://arxiv.org/abs/2511.07208 ,  386kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07213
Date: Mon, 10 Nov 2025 15:38:32 GMT   (1071kb)

Title: DETECT: Data-Driven Evaluation of Treatments Enabled by Classification
 Transformers
Authors: Yuanheng Mao, Lillian Yang, Stephen Yang, Ethan Shao, Zihan Li
Categories: cs.LG
Comments: 5 pages, 4 figures, 2 tables, accepted for presentation by IEEE ICDM
 2025 UGHS Symposium and publication with proceedings forthcoming
\\
 Chronic pain is a global health challenge affecting millions of individuals,
making it essential for physicians to have reliable and objective methods to
measure the functional impact of clinical treatments. Traditionally used
methods, like the numeric rating scale, while personalized and easy to use, are
subjective due to their self-reported nature. Thus, this paper proposes DETECT
(Data-Driven Evaluation of Treatments Enabled by Classification Transformers),
a data-driven framework that assesses treatment success by comparing patient
activities of daily life before and after treatment. We use DETECT on public
benchmark datasets and simulated patient data from smartphone sensors. Our
results demonstrate that DETECT is objective yet lightweight, making it a
significant and novel contribution to clinical decision-making. By using
DETECT, independently or together with other self-reported metrics, physicians
can improve their understanding of their treatment impacts, ultimately leading
to more personalized and responsive patient care.
\\ ( https://arxiv.org/abs/2511.07213 ,  1071kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07235
Date: Mon, 10 Nov 2025 15:52:48 GMT   (226kb)

Title: Deep Neural Operator Learning for Probabilistic Models
Authors: Erhan Bayraktar, Qi Feng, Zecheng Zhang, Zhaoyu Zhang
Categories: cs.LG q-fin.CP
Comments: 36 pages, 1 figure
\\
 We propose a deep neural-operator framework for a general class of
probability models. Under global Lipschitz conditions on the operator over the
entire Euclidean space-and for a broad class of probabilistic models-we
establish a universal approximation theorem with explicit network-size bounds
for the proposed architecture. The underlying stochastic processes are required
only to satisfy integrability and general tail-probability conditions. We
verify these assumptions for both European and American option-pricing problems
within the forward-backward SDE (FBSDE) framework, which in turn covers a broad
class of operators arising from parabolic PDEs, with or without free
boundaries. Finally, we present a numerical example for a basket of American
options, demonstrating that the learned model produces optimal stopping
boundaries for new strike prices without retraining.
\\ ( https://arxiv.org/abs/2511.07235 ,  226kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07236
Date: Mon, 10 Nov 2025 15:53:15 GMT   (7337kb)

Title: Does TabPFN Understand Causal Structures?
Authors: Omar Swelam, Lennart Purucker, Jake Robertson, Hanne Raum, Joschka
 Boedecker, Frank Hutter
Categories: cs.LG
\\
 Causal discovery is fundamental for multiple scientific domains, yet
extracting causal information from real world data remains a significant
challenge. Given the recent success on real data, we investigate whether
TabPFN, a transformer-based tabular foundation model pre-trained on synthetic
datasets generated from structural causal models, encodes causal information in
its internal representations. We develop an adapter framework using a learnable
decoder and causal tokens that extract causal signals from TabPFN's frozen
embeddings and decode them into adjacency matrices for causal discovery. Our
evaluations demonstrate that TabPFN's embeddings contain causal information,
outperforming several traditional causal discovery algorithms, with such causal
information being concentrated in mid-range layers. These findings establish a
new direction for interpretable and adaptable foundation models and demonstrate
the potential for leveraging pre-trained tabular models for causal discovery.
\\ ( https://arxiv.org/abs/2511.07236 ,  7337kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07237
Date: Mon, 10 Nov 2025 15:53:29 GMT   (1965kb)

Title: The Few Govern the Many:Unveiling Few-Layer Dominance for Time Series
 Models
Authors: Xin Qiu, Junlong Tong, Yirong Sun, Yunpu Ma, Xiaoyu Shen
Categories: cs.LG cs.CL
\\
 Large-scale models are at the forefront of time series (TS) forecasting,
dominated by two paradigms: fine-tuning text-based Large Language Models
(LLM4TS) and training Time Series Foundation Models (TSFMs) from scratch. Both
approaches share a foundational assumption that scaling up model capacity and
data volume leads to improved performance. However, we observe a
\textit{\textbf{scaling paradox}} in TS models, revealing a puzzling phenomenon
that larger models do \emph{NOT} achieve better performance. Through extensive
experiments on two model families across four scales (100M to 1.7B parameters)
and diverse data (up to 6B observations), we rigorously confirm that the
scaling paradox is a pervasive issue. We then diagnose its root cause by
analyzing internal representations, identifying a phenomenon we call
\textit{few-layer dominance}: only a small subset of layers are functionally
important, while the majority are redundant, under-utilized, and can even
distract training. Based on this discovery, we propose a practical method to
automatically identify and retain only these dominant layers. In our models,
retaining only 21\% of the parameters achieves up to a 12\% accuracy
improvement and a 2.7$\times$ inference speedup. We validate the universality
of our method on 8 prominent SOTA models (LLM4TS and TSFMs, 90M to 6B), showing
that retaining less than 30\% of layers achieves comparable or superior
accuracy in over 95\% of tasks.
\\ ( https://arxiv.org/abs/2511.07237 ,  1965kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07272
Date: Mon, 10 Nov 2025 16:18:04 GMT   (294kb)

Title: Understanding the role of depth in the neural tangent kernel for
 overparameterized neural networks
Authors: William St-Arnaud, Margarida Carvalho and Golnoosh Farnadi
Categories: cs.LG stat.ML
\\
 Overparameterized fully-connected neural networks have been shown to behave
like kernel models when trained with gradient descent, under mild conditions on
the width, the learning rate, and the parameter initialization. In the limit of
infinitely large widths and small learning rate, the kernel that is obtained
allows to represent the output of the learned model with a closed-form
solution. This closed-form solution hinges on the invertibility of the limiting
kernel, a property that often holds on real-world datasets. In this work, we
analyze the sensitivity of large ReLU networks to increasing depths by
characterizing the corresponding limiting kernel. Our theoretical results
demonstrate that the normalized limiting kernel approaches the matrix of ones.
In contrast, they show the corresponding closed-form solution approaches a
fixed limit on the sphere. We empirically evaluate the order of magnitude in
network depth required to observe this convergent behavior, and we describe the
essential properties that enable the generalization of our results to other
kernels.
\\ ( https://arxiv.org/abs/2511.07272 ,  294kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07274
Date: Mon, 10 Nov 2025 16:21:46 GMT   (303kb)

Title: Multi-modal Dynamic Proxy Learning for Personalized Multiple Clustering
Authors: Jinfeng Xu, Zheyu Chen, Shuo Yang, Jinze Li, Ziyue Peng, Zewei Liu,
 Hewei Wang, Jiayi Zhang, and Edith C. H. Ngai
Categories: cs.LG
Comments: Accepted by AAAI 2026
\\
 Multiple clustering aims to discover diverse latent structures from different
perspectives, yet existing methods generate exhaustive clusterings without
discerning user interest, necessitating laborious manual screening. Current
multi-modal solutions suffer from static semantic rigidity: predefined
candidate words fail to adapt to dataset-specific concepts, and fixed fusion
strategies ignore evolving feature interactions. To overcome these limitations,
we propose Multi-DProxy, a novel multi-modal dynamic proxy learning framework
that leverages cross-modal alignment through learnable textual proxies.
Multi-DProxy introduces 1) gated cross-modal fusion that synthesizes
discriminative joint representations by adaptively modeling feature
interactions. 2) dual-constraint proxy optimization where user interest
constraints enforce semantic consistency with domain concepts while concept
constraints employ hard example mining to enhance cluster discrimination. 3)
dynamic candidate management that refines textual proxies through iterative
clustering feedback. Therefore, Multi-DProxy not only effectively captures a
user's interest through proxies but also enables the identification of relevant
clusterings with greater precision. Extensive experiments demonstrate
state-of-the-art performance with significant improvements over existing
methods across a broad set of multi-clustering benchmarks.
\\ ( https://arxiv.org/abs/2511.07274 ,  303kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07276
Date: Mon, 10 Nov 2025 16:22:33 GMT   (5423kb)

Title: RobustA: Robust Anomaly Detection in Multimodal Data
Authors: Salem AlMarri, Muhammad Irzam Liaqat, Muhammad Zaigham Zaheer, Shah
 Nawaz, Karthik Nandakumar, Markus Schedl
Categories: cs.LG
Comments: Submitted to IEEE Transactions on Image Processing
\\
 In recent years, multimodal anomaly detection methods have demonstrated
remarkable performance improvements over video-only models. However, real-world
multimodal data is often corrupted due to unforeseen environmental distortions.
In this paper, we present the first-of-its-kind work that comprehensively
investigates the adverse effects of corrupted modalities on multimodal anomaly
detection task. To streamline this work, we propose RobustA, a carefully
curated evaluation dataset to systematically observe the impacts of audio and
visual corruptions on the overall effectiveness of anomaly detection systems.
Furthermore, we propose a multimodal anomaly detection method, which shows
notable resilience against corrupted modalities. The proposed method learns a
shared representation space for different modalities and employs a dynamic
weighting scheme during inference based on the estimated level of corruption.
Our work represents a significant step forward in enabling the real-world
application of multimodal anomaly detection, addressing situations where the
likely events of modality corruptions occur. The proposed evaluation dataset
with corrupted modalities and respective extracted features will be made
publicly available.
\\ ( https://arxiv.org/abs/2511.07276 ,  5423kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07282
Date: Mon, 10 Nov 2025 16:27:27 GMT   (868kb)

Title: MG-HGNN: A Heterogeneous GNN Framework for Indoor Wi-Fi
 Fingerprint-Based Localization
Authors: Yibu Wang, Zhaoxin Zhang, Ning Li, Xinlong Zhao, Dong Zhao, Tianzi
 Zhao
Categories: cs.LG
Comments: 16 pages, 11 figures, 11 tables
\\
 Received signal strength indicator (RSSI) is the primary representation of
Wi-Fi fingerprints and serves as a crucial tool for indoor localization.
However, existing RSSI-based positioning methods often suffer from reduced
accuracy due to environmental complexity and challenges in processing
multi-source information. To address these issues, we propose a novel
multi-graph heterogeneous GNN framework (MG-HGNN) to enhance spatial awareness
and improve positioning performance. In this framework, two graph construction
branches perform node and edge embedding, respectively, to generate informative
graphs. Subsequently, a heterogeneous graph neural network is employed for
graph representation learning, enabling accurate positioning. The MG-HGNN
framework introduces the following key innovations: 1) multi-type task-directed
graph construction that combines label estimation and feature encoding for
richer graph information; 2) a heterogeneous GNN structure that enhances the
performance of conventional GNN models. Evaluations on the UJIIndoorLoc and
UTSIndoorLoc public datasets demonstrate that MG-HGNN not only achieves
superior performance compared to several state-of-the-art methods, but also
provides a novel perspective for enhancing GNN-based localization methods.
Ablation studies further confirm the rationality and effectiveness of the
proposed framework.
\\ ( https://arxiv.org/abs/2511.07282 ,  868kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07288
Date: Mon, 10 Nov 2025 16:35:50 GMT   (1889kb)

Title: Enabling Off-Policy Imitation Learning with Deep Actor Critic
 Stabilization
Authors: Sayambhu Sen and Shalabh Bhatnagar
Categories: cs.LG cs.AI
Comments: 14 pages and 4 images
\\
 Learning complex policies with Reinforcement Learning (RL) is often hindered
by instability and slow convergence, a problem exacerbated by the difficulty of
reward engineering. Imitation Learning (IL) from expert demonstrations bypasses
this reliance on rewards. However, state-of-the-art IL methods, exemplified by
Generative Adversarial Imitation Learning (GAIL)Ho et. al, suffer from severe
sample inefficiency. This is a direct consequence of their foundational
on-policy algorithms, such as TRPO Schulman et.al. In this work, we introduce
an adversarial imitation learning algorithm that incorporates off-policy
learning to improve sample efficiency. By combining an off-policy framework
with auxiliary techniques specifically, double Q network based stabilization
and value learning without reward function inference we demonstrate a reduction
in the samples required to robustly match expert behavior.
\\ ( https://arxiv.org/abs/2511.07288 ,  1889kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07308
Date: Mon, 10 Nov 2025 17:10:01 GMT   (20385kb)

Title: Can Training Dynamics of Scale-Invariant Neural Networks Be Explained by
 the Thermodynamics of an Ideal Gas?
Authors: Ildus Sadrtdinov, Ekaterina Lobacheva, Ivan Klimov, Mikhail I.
 Katsnelson, Dmitry Vetrov
Categories: cs.LG
\\
 Understanding the training dynamics of deep neural networks remains a major
open problem, with physics-inspired approaches offering promising insights.
Building on this perspective, we develop a thermodynamic framework to describe
the stationary distributions of stochastic gradient descent (SGD) with weight
decay for scale-invariant neural networks, a setting that both reflects
practical architectures with normalization layers and permits theoretical
analysis. We establish analogies between training hyperparameters (e.g.,
learning rate, weight decay) and thermodynamic variables such as temperature,
pressure, and volume. Starting with a simplified isotropic noise model, we
uncover a close correspondence between SGD dynamics and ideal gas behavior,
validated through theory and simulation. Extending to training of neural
networks, we show that key predictions of the framework, including the behavior
of stationary entropy, align closely with experimental observations. This
framework provides a principled foundation for interpreting training dynamics
and may guide future work on hyperparameter tuning and the design of learning
rate schedulers.
\\ ( https://arxiv.org/abs/2511.07308 ,  20385kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07312
Date: Mon, 10 Nov 2025 17:13:41 GMT   (2104kb)

Title: Superhuman AI for Stratego Using Self-Play Reinforcement Learning and
 Test-Time Search
Authors: Samuel Sokota, Eugene Vinitsky, Hengyuan Hu, J. Zico Kolter, Gabriele
 Farina
Categories: cs.LG cs.AI
\\
 Few classical games have been regarded as such significant benchmarks of
artificial intelligence as to have justified training costs in the millions of
dollars. Among these, Stratego -- a board wargame exemplifying the challenge of
strategic decision making under massive amounts of hidden information -- stands
apart as a case where such efforts failed to produce performance at the level
of top humans. This work establishes a step change in both performance and cost
for Stratego, showing that it is now possible not only to reach the level of
top humans, but to achieve vastly superhuman level -- and that doing so
requires not an industrial budget, but merely a few thousand dollars. We
achieved this result by developing general approaches for self-play
reinforcement learning and test-time search under imperfect information.
\\ ( https://arxiv.org/abs/2511.07312 ,  2104kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07328
Date: Mon, 10 Nov 2025 17:31:02 GMT   (601kb)

Title: Q-RAG: Long Context Multi-step Retrieval via Value-based Embedder
 Training
Authors: Artyom Sorokin, Nazar Buzun, Alexander Anokhin, Oleg Inozemcev, Egor
 Vedernikov, Petr Anokhin, Mikhail Burtsev, Trushkov Alexey, Yin Wenshuai,
 Evgeny Burnaev
Categories: cs.LG cs.IR
Comments: 16 pages, 3 figures, 2 tables
\\
 Retrieval-Augmented Generation (RAG) methods enhance LLM performance by
efficiently filtering relevant context for LLMs, reducing hallucinations and
inference cost. However, most existing RAG methods focus on single-step
retrieval, which is often insufficient for answering complex questions that
require multi-step search. Recently, multi-step retrieval approaches have
emerged, typically involving the fine-tuning of small LLMs to perform
multi-step retrieval. This type of fine-tuning is highly resource-intensive and
does not enable the use of larger LLMs. In this work, we propose Q-RAG, a novel
approach that fine-tunes the Embedder model for multi-step retrieval using
reinforcement learning (RL). Q-RAG offers a competitive, resource-efficient
alternative to existing multi-step retrieval methods for open-domain question
answering and achieves state-of-the-art results on the popular long-context
benchmarks Babilong and RULER for contexts up to 10M tokens.
\\ ( https://arxiv.org/abs/2511.07328 ,  601kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07329
Date: Mon, 10 Nov 2025 17:31:39 GMT   (842kb)

Title: Preparation of Fractal-Inspired Computational Architectures for Advanced
 Large Language Model Analysis
Authors: Yash Mittal, Dmitry Ignatov and Radu Timofte
Categories: cs.LG cs.CV
\\
 It introduces FractalNet, a fractal-inspired computational architectures for
advanced large language model analysis that mainly challenges model diversity
on a large scale in an efficient manner. The new set-up involves a
template-driven generator, runner, and evaluation framework that, through
systematic permutations of convolutional, normalization, activation, and
dropout layers, can create more than 1,200 variants of neural networks. Fractal
templates allow for structural recursion and multi-column pathways, thus,
models become deeper and wider in a balanced way. Training utilizes PyTorch,
Automatic Mixed Precision (AMP), and gradient checkpointing and is carried out
on the CIFAR-10 dataset for five epochs. The outcomes show that fractal-based
architectures are capable of strong performance and are computationally
efficient. The paper positions fractal design as a feasible and
resource-efficient method of automated architecture exploration.
\\ ( https://arxiv.org/abs/2511.07329 ,  842kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07332
Date: Mon, 10 Nov 2025 17:35:21 GMT   (26481kb)

Title: Grounding Computer Use Agents on Human Demonstrations
Authors: Aarash Feizi, Shravan Nayak, Xiangru Jian, Kevin Qinghong Lin, Kaixin
 Li, Rabiul Awal, Xing Han L\`u, Johan Obando-Ceron, Juan A. Rodriguez,
 Nicolas Chapados, David Vazquez, Adriana Romero-Soriano, Reihaneh Rabbany,
 Perouz Taslakian, Christopher Pal, Spandana Gella, Sai Rajeswar
Categories: cs.LG cs.AI
\\
 Building reliable computer-use agents requires grounding: accurately
connecting natural language instructions to the correct on-screen elements.
While large datasets exist for web and mobile interactions, high-quality
resources for desktop environments are limited. To address this gap, we
introduce GroundCUA, a large-scale desktop grounding dataset built from expert
human demonstrations. It covers 87 applications across 12 categories and
includes 56K screenshots, with every on-screen element carefully annotated for
a total of over 3.56M human-verified annotations. From these demonstrations, we
generate diverse instructions that capture a wide range of real-world tasks,
providing high-quality data for model training. Using GroundCUA, we develop the
GroundNext family of models that map instructions to their target UI elements.
At both 3B and 7B scales, GroundNext achieves state-of-the-art results across
five benchmarks using supervised fine-tuning, while requiring less than
one-tenth the training data of prior work. Reinforcement learning post-training
further improves performance, and when evaluated in an agentic setting on the
OSWorld benchmark using o3 as planner, GroundNext attains comparable or
superior results to models trained with substantially more data,. These results
demonstrate the critical role of high-quality, expert-driven datasets in
advancing general-purpose computer-use agents.
\\ ( https://arxiv.org/abs/2511.07332 ,  26481kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07343
Date: Mon, 10 Nov 2025 17:45:09 GMT   (898kb)

Title: TNT: Improving Chunkwise Training for Test-Time Memorization
Authors: Zeman Li, Ali Behrouz, Yuan Deng, Peilin Zhong, Praneeth Kacham, Mahdi
 Karami, Meisam Razaviyayn, Vahab Mirrokni
Categories: cs.LG cs.AI
\\
 Recurrent neural networks (RNNs) with deep test-time memorization modules,
such as Titans and TTT, represent a promising, linearly-scaling paradigm
distinct from Transformers. While these expressive models do not yet match the
peak performance of state-of-the-art Transformers, their potential has been
largely untapped due to prohibitively slow training and low hardware
utilization. Existing parallelization methods force a fundamental conflict
governed by the chunksize hyperparameter: large chunks boost speed but degrade
performance, necessitating a fixed, suboptimal compromise. To solve this
challenge, we introduce TNT, a novel training paradigm that decouples training
efficiency from inference performance through a two-stage process. Stage one is
an efficiency-focused pre-training phase utilizing a hierarchical memory. A
global module processes large, hardware-friendly chunks for long-range context,
while multiple parallel local modules handle fine-grained details. Crucially,
by periodically resetting local memory states, we break sequential dependencies
to enable massive context parallelization. Stage two is a brief fine-tuning
phase where only the local memory modules are adapted to a smaller,
high-resolution chunksize, maximizing accuracy with minimal overhead. Evaluated
on Titans and TTT models, TNT achieves a substantial acceleration in training
speed-up to 17 times faster than the most accurate baseline configuration -
while simultaneously improving model accuracy. This improvement removes a
critical scalability barrier, establishing a practical foundation for
developing expressive RNNs and facilitating future work to close the
performance gap with Transformers.
\\ ( https://arxiv.org/abs/2511.07343 ,  898kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07364
Date: Mon, 10 Nov 2025 18:19:51 GMT   (265kb)

Title: Self-Evaluating LLMs for Multi-Step Tasks: Stepwise Confidence
 Estimation for Failure Detection
Authors: Vaibhav Mavi, Shubh Jaroria, Weiqi Sun
Categories: cs.LG cs.AI cs.CL
Comments: Accepted at NeurIPS 2025 Workshop on Evaluating the Evolving LLM
 Lifecycle: Benchmarks, Emergent Abilities, and Scaling
\\
 Reliability and failure detection of large language models (LLMs) is critical
for their deployment in high-stakes, multi-step reasoning tasks. Prior work
explores confidence estimation for self-evaluating LLM-scorer systems, with
confidence scorers estimating the likelihood of errors in LLM responses.
However, most methods focus on single-step outputs and overlook the challenges
of multi-step reasoning. In this work, we extend self-evaluation techniques to
multi-step tasks, testing two intuitive approaches: holistic scoring and
step-by-step scoring. Using two multi-step benchmark datasets, we show that
stepwise evaluation generally outperforms holistic scoring in detecting
potential errors, with up to 15% relative increase in AUC-ROC. Our findings
demonstrate that self-evaluating LLM systems provide meaningful confidence
estimates in complex reasoning, improving their trustworthiness and providing a
practical framework for failure detection.
\\ ( https://arxiv.org/abs/2511.07364 ,  265kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07365
Date: Mon, 10 Nov 2025 18:22:40 GMT   (405kb)

Title: Private Sketches for Linear Regression
Authors: Shrutimoy Das, Debanuj Nayak, Anirban Dasgupta
Categories: cs.LG stat.ML
Comments: 13 pages
\\
 Linear regression is frequently applied in a variety of domains. In order to
improve the efficiency of these methods, various methods have been developed
that compute summaries or \emph{sketches} of the datasets. Certain domains,
however, contain sensitive data which necessitates that the application of
these statistical methods does not reveal private information. Differentially
private (DP) linear regression methods have been developed for mitigating this
problem. These techniques typically involve estimating a noisy version of the
parameter vector. Instead, we propose releasing private sketches of the
datasets. We present differentially private sketches for the problems of least
squares regression, as well as least absolute deviations regression. The
availability of these private sketches facilitates the application of commonly
available solvers for regression, without the risk of privacy leakage.
\\ ( https://arxiv.org/abs/2511.07365 ,  405kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07368
Date: Mon, 10 Nov 2025 18:25:26 GMT   (1292kb)

Title: Consistency Is Not Always Correct: Towards Understanding the Role of
 Exploration in Post-Training Reasoning
Authors: Dake Bu, Wei Huang, Andi Han, Atsushi Nitanda, Bo Xue, Qingfu Zhang,
 Hau-San Wong, Taiji Suzuki
Categories: cs.LG cs.AI
\\
 Foundation models exhibit broad knowledge but limited task-specific
reasoning, motivating post-training strategies such as RLVR and inference
scaling with outcome or process reward models (ORM/PRM). While recent work
highlights the role of exploration and entropy stability in improving pass@K,
empirical evidence points to a paradox: RLVR and ORM/PRM typically reinforce
existing tree-like reasoning paths rather than expanding the reasoning scope,
raising the question of why exploration helps at all if no new patterns emerge.
 To reconcile this paradox, we adopt the perspective of Kim et al. (2025),
viewing easy (e.g., simplifying a fraction) versus hard (e.g., discovering a
symmetry) reasoning steps as low- versus high-probability Markov transitions,
and formalize post-training dynamics through Multi-task Tree-structured Markov
Chains (TMC). In this tractable model, pretraining corresponds to tree
expansion, while post-training corresponds to chain-of-thought reweighting. We
show that several phenomena recently observed in empirical studies arise
naturally in this setting: (1) RLVR induces a squeezing effect, reducing
reasoning entropy and forgetting some correct paths; (2) population rewards of
ORM/PRM encourage consistency rather than accuracy, thereby favoring common
patterns; and (3) certain rare, high-uncertainty reasoning paths by the base
model are responsible for solving hard problem instances.
 Together, these explain why exploration -- even when confined to the base
model's reasoning scope -- remains essential: it preserves access to rare but
crucial reasoning traces needed for difficult cases, which are squeezed out by
RLVR or unfavored by inference scaling. Building on this, we further show that
exploration strategies such as rejecting easy instances and KL regularization
help preserve rare reasoning traces. Empirical simulations corroborate our
theoretical results.
\\ ( https://arxiv.org/abs/2511.07368 ,  1292kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07372
Date: Mon, 10 Nov 2025 18:29:54 GMT   (120kb)

Title: Provable Benefit of Curriculum in Transformer Tree-Reasoning
 Post-Training
Authors: Dake Bu, Wei Huang, Andi Han, Atsushi Nitanda, Hau-San Wong, Qingfu
 Zhang, Taiji Suzuki
Categories: cs.LG
\\
 Recent curriculum techniques in the post-training stage of LLMs have been
widely observed to outperform non-curriculum approaches in enhancing reasoning
performance, yet a principled understanding of why and to what extent they work
remains elusive. To address this gap, we develop a theoretical framework
grounded in the intuition that progressively learning through manageable steps
is more efficient than directly tackling a hard reasoning task, provided each
stage stays within the model's effective competence. Under mild complexity
conditions linking consecutive curriculum stages, we show that curriculum
post-training avoids the exponential complexity bottleneck.
 To substantiate this result, drawing insights from the Chain-of-Thoughts
(CoTs) solving mathematical problems such as Countdown and parity, we model CoT
generation as a states-conditioned autoregressive reasoning tree, define a
uniform-branching base model to capture pretrained behavior, and formalize
curriculum stages as either depth-increasing (longer reasoning chains) or
hint-decreasing (shorter prefixes) subtasks. Our analysis shows that, under
outcome-only reward signals, reinforcement learning finetuning achieves high
accuracy with polynomial sample complexity, whereas direct learning suffers
from an exponential bottleneck. We further establish analogous guarantees for
test-time scaling, where curriculum-aware querying reduces both reward oracle
calls and sampling cost from exponential to polynomial order.
\\ ( https://arxiv.org/abs/2511.07372 ,  120kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07378
Date: Mon, 10 Nov 2025 18:40:24 GMT   (1557kb)

Title: Transformers Provably Learn Chain-of-Thought Reasoning with Length
 Generalization
Authors: Yu Huang, Zixin Wen, Aarti Singh, Yuejie Chi, Yuxin Chen
Categories: cs.LG cs.AI math.OC stat.ML
Comments: This is the full version of a paper published at NeurIPS 2025
\\
 The ability to reason lies at the core of artificial intelligence (AI), and
challenging problems usually call for deeper and longer reasoning to tackle. A
crucial question about AI reasoning is whether models can extrapolate learned
reasoning patterns to solve harder tasks with longer chain-of-thought (CoT). In
this work, we present a theoretical analysis of transformers learning on
synthetic state-tracking tasks with gradient descent. We mathematically prove
how the algebraic structure of state-tracking problems governs the degree of
extrapolation of the learned CoT. Specifically, our theory characterizes the
length generalization of transformers through the mechanism of attention
concentration, linking the retrieval robustness of the attention layer to the
state-tracking task structure of long-context reasoning. Moreover, for
transformers with limited reasoning length, we prove that a recursive
self-training scheme can progressively extend the range of solvable problem
lengths. To our knowledge, we provide the first optimization guarantee that
constant-depth transformers provably learn $\mathsf{NC}^1$-complete problems
with CoT, significantly going beyond prior art confined in $\mathsf{TC}^0$,
unless the widely held conjecture $\mathsf{TC}^0 \neq \mathsf{NC}^1$ fails.
Finally, we present a broad set of experiments supporting our theoretical
results, confirming the length generalization behaviors and the mechanism of
attention concentration.
\\ ( https://arxiv.org/abs/2511.07378 ,  1557kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07379
Date: Mon, 10 Nov 2025 18:41:02 GMT   (418kb)

Title: LoReTTA: A Low Resource Framework To Poison Continuous Time Dynamic
 Graphs
Authors: Himanshu Pal, Venkata Sai Pranav Bachina, Ankit Gangwal, Charu Sharma
Categories: cs.LG cs.AI
Comments: Accepted at AAAI 2026
\\
 Temporal Graph Neural Networks (TGNNs) are increasingly used in high-stakes
domains, such as financial forecasting, recommendation systems, and fraud
detection. However, their susceptibility to poisoning attacks poses a critical
security risk. We introduce LoReTTA (Low Resource Two-phase Temporal Attack), a
novel adversarial framework on Continuous-Time Dynamic Graphs, which degrades
TGNN performance by an average of 29.47% across 4 widely benchmark datasets and
4 State-of-the-Art (SotA) models. LoReTTA operates through a two-stage
approach: (1) sparsify the graph by removing high-impact edges using any of the
16 tested temporal importance metrics, (2) strategically replace removed edges
with adversarial negatives via LoReTTA's novel degree-preserving negative
sampling algorithm. Our plug-and-play design eliminates the need for expensive
surrogate models while adhering to realistic unnoticeability constraints.
LoReTTA degrades performance by upto 42.0% on MOOC, 31.5% on Wikipedia, 28.8%
on UCI, and 15.6% on Enron. LoReTTA outperforms 11 attack baselines, remains
undetectable to 4 leading anomaly detection systems, and is robust to 4 SotA
adversarial defense training methods, establishing its effectiveness,
unnoticeability, and robustness.
\\ ( https://arxiv.org/abs/2511.07379 ,  418kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07390
Date: Mon, 10 Nov 2025 18:46:24 GMT   (1329kb)

Title: A Diffusion Model to Shrink Proteins While Maintaining Their Function
Authors: Ethan Baron and Alan N. Amin and Ruben Weitzman and Debora Marks and
 Andrew Gordon Wilson
Categories: cs.LG q-bio.QM
Comments: Code available at https://github.com/baronet2/SCISOR
\\
 Many proteins useful in modern medicine or bioengineering are challenging to
make in the lab, fuse with other proteins in cells, or deliver to tissues in
the body, because their sequences are too long. Shortening these sequences
typically involves costly, time-consuming experimental campaigns. Ideally, we
could instead use modern models of massive databases of sequences from nature
to learn how to propose shrunken proteins that resemble sequences found in
nature. Unfortunately, these models struggle to efficiently search the
combinatorial space of all deletions, and are not trained with inductive biases
to learn how to delete. To address this gap, we propose SCISOR, a novel
discrete diffusion model that deletes letters from sequences to generate
protein samples that resemble those found in nature. To do so, SCISOR trains a
de-noiser to reverse a forward noising process that adds random insertions to
natural sequences. As a generative model, SCISOR fits evolutionary sequence
data competitively with previous large models. In evaluation, SCISOR achieves
state-of-the-art predictions of the functional effects of deletions on
ProteinGym. Finally, we use the SCISOR de-noiser to shrink long protein
sequences, and show that its suggested deletions result in significantly more
realistic proteins and more often preserve functional motifs than previous
models of evolutionary sequences.
\\ ( https://arxiv.org/abs/2511.07390 ,  1329kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07396
Date: Mon, 10 Nov 2025 18:50:27 GMT   (419kb)

Title: C3PO: Optimized Large Language Model Cascades with Probabilistic Cost
 Constraints for Reasoning
Authors: Antonios Valkanas, Soumyasundar Pal, Pavel Rumiantsev, Yingxue Zhang,
 Mark Coates
Categories: cs.LG
\\
 Large language models (LLMs) have achieved impressive results on complex
reasoning tasks, but their high inference cost remains a major barrier to
real-world deployment. A promising solution is to use cascaded inference, where
small, cheap models handle easy queries, and only the hardest examples are
escalated to more powerful models. However, existing cascade methods typically
rely on supervised training with labeled data, offer no theoretical
generalization guarantees, and provide limited control over test-time
computational cost. We introduce C3PO (Cost Controlled Cascaded Prediction
Optimization), a self-supervised framework for optimizing LLM cascades under
probabilistic cost constraints. By focusing on minimizing regret with respect
to the most powerful model (MPM), C3PO avoids the need for labeled data by
constructing a cascade using only unlabeled model outputs. It leverages
conformal prediction to bound the probability that inference cost exceeds a
user-specified budget. We provide theoretical guarantees on both cost control
and generalization error, and show that our optimization procedure is effective
even with small calibration sets. Empirically, C3PO achieves state-of-the-art
performance across a diverse set of reasoning benchmarks including GSM8K,
MATH-500, BigBench-Hard and AIME, outperforming strong LLM cascading baselines
in both accuracy and cost-efficiency. Our results demonstrate that principled,
label-free cascade optimization can enable scalable LLM deployment.
\\ ( https://arxiv.org/abs/2511.07396 ,  419kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07406
Date: Mon, 10 Nov 2025 18:55:35 GMT   (37462kb)

Title: Entangled Schr\"odinger Bridge Matching
Authors: Sophia Tang, Yinuo Zhang, Pranam Chatterjee
Categories: cs.LG q-bio.BM
\\
 Simulating trajectories of multi-particle systems on complex energy
landscapes is a central task in molecular dynamics (MD) and drug discovery, but
remains challenging at scale due to computationally expensive and long
simulations. Previous approaches leverage techniques such as flow or
Schr\"odinger bridge matching to implicitly learn joint trajectories through
data snapshots. However, many systems, including biomolecular systems and
heterogeneous cell populations, undergo dynamic interactions that evolve over
their trajectory and cannot be captured through static snapshots. To close this
gap, we introduce Entangled Schr\"odinger Bridge Matching (EntangledSBM), a
framework that learns the first- and second-order stochastic dynamics of
interacting, multi-particle systems where the direction and magnitude of each
particle's path depend dynamically on the paths of the other particles. We
define the Entangled Schr\"odinger Bridge (EntangledSB) problem as solving a
coupled system of bias forces that entangle particle velocities. We show that
our framework accurately simulates heterogeneous cell populations under
perturbations and rare transitions in high-dimensional biomolecular systems.
\\ ( https://arxiv.org/abs/2511.07406 ,  37462kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07419
Date: Mon, 10 Nov 2025 18:59:53 GMT   (1616kb)

Title: Routing Manifold Alignment Improves Generalization of Mixture-of-Experts
 LLMs
Authors: Zhongyang Li, Ziyue Li, Tianyi Zhou
Categories: cs.LG
\\
 Sparse Mixture-of-Experts (MoE) have been widely adopted in recent large
language models since it can efficiently scale up the model capability without
increasing the inference cost. However, evaluations on broad downstream tasks
reveal a consistent suboptimality of the routers in existing MoE LLMs, which
results in a severe performance gap (e.g., 10-20% in accuracy) to the optimal
routing. In this paper, we show that aligning the manifold of routing weights
with that of task embedding can effectively reduce the gap and improve MoE
LLMs' generalization performance. Our method, "Routing Manifold Alignment
(RoMA)", introduces an additional manifold regularization term in the
post-training objective and only requires lightweight finetuning of routers
(with other parameters frozen). Specifically, the regularization encourages the
routing weights of each sample to be close to those of its successful neighbors
(whose routing weights lead to correct answers) in a task embedding space.
Consequently, samples targeting similar tasks will share similar expert choices
across layers. Building such bindings between tasks and experts over different
samples is essential to achieve better generalization. Moreover, RoMA
demonstrates the advantage of unifying the task understanding (by embedding
models) with solution generation (by MoE LLMs). In experiments, we finetune
routers in OLMoE, DeepSeekMoE, and Qwen3-MoE using RoMA. Evaluations on diverse
benchmarks and extensive comparisons with baselines show the substantial
improvement brought by RoMA.
\\ ( https://arxiv.org/abs/2511.07419 ,  1616kb)
%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-
------------------------------------------------------------------------------
\\
arXiv:2511.05501 (*cross-listing*)
Date: Tue, 30 Sep 2025 21:36:23 GMT   (542kb)

Title: Towards Ecologically Valid LLM Benchmarks: Understanding and Designing
 Domain-Centered Evaluations for Journalism Practitioners
Authors: Charlotte Li, Nick Hagar, Sachita Nishal, Jeremy Gilbert, Nick
 Diakopoulos
Categories: cs.HC cs.AI
Comments: 14 pages, 2 figures
\\
 Benchmarks play a significant role in how researchers and the public
understand generative AI systems. However, the widespread use of benchmark
scores to communicate about model capabilities has led to criticisms of
validity, especially whether benchmarks test what they claim to test (i.e.
construct validity) and whether benchmark evaluations are representative of how
models are used in the wild (i.e. ecological validity). In this work we explore
how to create an LLM benchmark that addresses these issues by taking a
human-centered approach. We focus on designing a domain-oriented benchmark for
journalism practitioners, drawing on insights from a workshop of 23 journalism
professionals. Our workshop findings surface specific challenges that inform
benchmark design opportunities, which we instantiate in a case study that
addresses underlying criticisms and specific domain concerns. Through our
findings and design case study, this work provides design guidance for
developing benchmarks that are better tuned to specific domains.
\\ ( https://arxiv.org/abs/2511.05501 ,  542kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05502 (*cross-listing*)
Date: Thu, 9 Oct 2025 23:53:38 GMT   (439kb)

Title: Production-Grade Local LLM Inference on Apple Silicon: A Comparative
 Study of MLX, MLC-LLM, Ollama, llama.cpp, and PyTorch MPS
Authors: Varun Rajesh, Om Jodhpurkar, Pooja Anbuselvan, Mantinder Singh, Ashok
 Jallepali, Shantanu Godbole, Pradeep Kumar Sharma, Hritvik Shrivastava
Categories: cs.AR cs.AI
\\
 We present a systematic, empirical evaluation of five local large language
model (LLM) runtimes on Apple Silicon: MLX, MLC-LLM, llama.cpp, Ollama, and
PyTorch MPS. Experiments were conducted on a Mac Studio equipped with an M2
Ultra processor and 192 GB of unified memory. Using the Qwen-2.5 model family
across prompts ranging from a few hundred to 100,000 tokens, we measure
time-to-first-token (TTFT), steady-state throughput, latency percentiles,
long-context behavior (key-value and prompt caching), quantization support,
streaming performance, batching and concurrency behavior, and deployment
complexity.
 Under our settings, MLX achieves the highest sustained generation throughput,
while MLC-LLM delivers consistently lower TTFT for moderate prompt sizes and
offers stronger out-of-the-box inference features. llama.cpp is highly
efficient for lightweight single-stream use, Ollama emphasizes developer
ergonomics but lags in throughput and TTFT, and PyTorch MPS remains limited by
memory constraints on large models and long contexts.
 All frameworks execute fully on-device with no telemetry, ensuring strong
privacy guarantees. We release scripts, logs, and plots to reproduce all
results. Our analysis clarifies the design trade-offs in Apple-centric LLM
deployments and provides evidence-based recommendations for interactive and
long-context processing. Although Apple Silicon inference frameworks still
trail NVIDIA GPU-based systems such as vLLM in absolute performance, they are
rapidly maturing into viable, production-grade solutions for private, on-device
LLM inference.
\\ ( https://arxiv.org/abs/2511.05502 ,  439kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05505 (*cross-listing*)
Date: Fri, 17 Oct 2025 13:21:48 GMT   (1897kb)

Title: Rewiring Human Brain Networks via Lightweight Dynamic Connectivity
 Framework: An EEG-Based Stress Validation
Authors: Sayantan Acharya, Abbas Khosravi, Douglas Creighton, Roohallah
 Alizadehsani, U. Rajendra Acharya
Categories: q-bio.NC cs.AI
Comments: 21 pages, 21 figures, 6 tables, 50 references,
\\
 In recent years, Electroencephalographic analysis has gained prominence in
stress research when combined with AI and Machine Learning models for
validation. In this study, a lightweight dynamic brain connectivity framework
based on Time Varying Directed Transfer Function is proposed, where TV DTF
features were validated through ML based stress classification. TV DTF
estimates the directional information flow between brain regions across
distinct EEG frequency bands, thereby capturing temporal and causal influences
that are often overlooked by static functional connectivity measures. EEG
recordings from the 32 channel SAM 40 dataset were employed, focusing on mental
arithmetic task trials. The dynamic EEG-based TV-DTF features were validated
through ML classifiers such as Support Vector Machine, Random Forest, Gradient
Boosting, Adaptive Boosting, and Extreme Gradient Boosting. Experimental
results show that alpha-TV-DTF provided the strongest discriminative power,
with SVM achieving 89.73% accuracy in 3-class classification and with XGBoost
achieving 93.69% accuracy in 2 class classification. Relative to absolute power
and phase locking based functional connectivity features, alpha TV DTF and beta
TV DTF achieved higher performance across the ML models, highlighting the
advantages of dynamic over static measures. Feature importance analysis further
highlighted dominant long-range frontal parietal and frontal occipital
informational influences, emphasizing the regulatory role of frontal regions
under stress. These findings validate the lightweight TV-DTF as a robust
framework, revealing spatiotemporal brain dynamics and directional influences
across different stress levels.
\\ ( https://arxiv.org/abs/2511.05505 ,  1897kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05508 (*cross-listing*)
Date: Fri, 24 Oct 2025 05:55:05 GMT   (1986kb)

Title: Personalized Chain-of-Thought Summarization of Financial News for
 Investor Decision Support
Authors: Tianyi Zhang, Mu Chen
Categories: q-fin.GN cs.AI cs.CE
Comments: ICDM SENTIRE 2025
\\
 Financial advisors and investors struggle with information overload from
financial news, where irrelevant content and noise obscure key market signals
and hinder timely investment decisions. To address this, we propose a novel
Chain-of-Thought (CoT) summarization framework that condenses financial news
into concise, event-driven summaries. The framework integrates user-specified
keywords to generate personalized outputs, ensuring that only the most relevant
contexts are highlighted. These personalized summaries provide an intermediate
layer that supports language models in producing investor-focused narratives,
bridging the gap between raw news and actionable insights.
\\ ( https://arxiv.org/abs/2511.05508 ,  1986kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05510 (*cross-listing*)
Date: Fri, 24 Oct 2025 13:11:47 GMT   (7221kb)

Title: TEMPO: Temporal Multi-scale Autoregressive Generation of Protein
 Conformational Ensembles
Authors: Yaoyao Xu, Di Wang, Zihan Zhou, Tianshu Yu, Mingchen Chen
Categories: q-bio.BM cs.AI
\\
 Understanding the dynamic behavior of proteins is critical to elucidating
their functional mechanisms, yet generating realistic, temporally coherent
trajectories of protein ensembles remains a significant challenge. In this
work, we introduce a novel hierarchical autoregressive framework for modeling
protein dynamics that leverages the intrinsic multi-scale organization of
molecular motions. Unlike existing methods that focus on generating static
conformational ensembles or treat dynamic sampling as an independent process,
our approach characterizes protein dynamics as a Markovian process. The
framework employs a two-scale architecture: a low-resolution model captures
slow, collective motions driving major conformational transitions, while a
high-resolution model generates detailed local fluctuations conditioned on
these large-scale movements. This hierarchical design ensures that the causal
dependencies inherent in protein dynamics are preserved, enabling the
generation of temporally coherent and physically realistic trajectories. By
bridging high-level biophysical principles with state-of-the-art generative
modeling, our approach provides an efficient framework for simulating protein
dynamics that balances computational efficiency with physical accuracy.
\\ ( https://arxiv.org/abs/2511.05510 ,  7221kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05511 (*cross-listing*)
Date: Fri, 24 Oct 2025 19:12:07 GMT   (963kb)

Title: From Failure Modes to Reliability Awareness in Generative and Agentic AI
 System
Authors: Janet (Jing) Lin and Liangwei Zhang
Categories: eess.SY cs.AI cs.SY
Comments: 24pages
\\
 This chapter bridges technical analysis and organizational preparedness by
tracing the path from layered failure modes to reliability awareness in
generative and agentic AI systems. We first introduce an 11-layer failure
stack, a structured framework for identifying vulnerabilities ranging from
hardware and power foundations to adaptive learning and agentic reasoning.
Building on this, the chapter demonstrates how failures rarely occur in
isolation but propagate across layers, creating cascading effects with systemic
consequences. To complement this diagnostic lens, we develop the concept of
awareness mapping: a maturity-oriented framework that quantifies how well
individuals and organizations recognize reliability risks across the AI stack.
Awareness is treated not only as a diagnostic score but also as a strategic
input for AI governance, guiding improvement and resilience planning. By
linking layered failures to awareness levels and further integrating this into
Dependability-Centred Asset Management (DCAM), the chapter positions awareness
mapping as both a measurement tool and a roadmap for trustworthy and
sustainable AI deployment across mission-critical domains.
\\ ( https://arxiv.org/abs/2511.05511 ,  963kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05522 (*cross-listing*)
Date: Tue, 28 Oct 2025 15:15:48 GMT   (15452kb)

Title: AIRMap - AI-Generated Radio Maps for Wireless Digital Twins
Authors: Ali Saeizadeh, Miead Tehrani-Moayyed, Davide Villa, J. Gordon Beattie
 Jr., Pedram Johari, Stefano Basagni, Tommaso Melodia
Categories: eess.SP cs.AI
Comments: 13 pages, 17 figures, This paper has been submitted to the IEEE
 Transactions for possible publication
\\
 Accurate, low-latency channel modeling is essential for real-time wireless
network simulation and digital-twin applications. Traditional modeling methods
like ray tracing are however computationally demanding and unsuited to model
dynamic conditions. In this paper, we propose AIRMap, a deep-learning framework
for ultra-fast radio-map estimation, along with an automated pipeline for
creating the largest radio-map dataset to date. AIRMap uses a single-input
U-Net autoencoder that processes only a 2D elevation map of terrain and
building heights. Trained and evaluated on 60,000 Boston-area samples, spanning
coverage areas from 500 m to 3 km per side, AIRMap predicts path gain with
under 5 dB RMSE in 4 ms per inference on an NVIDIA L40S -over 7000x faster than
GPU-accelerated ray tracing based radio maps. A lightweight transfer learning
calibration using just 20% of field measurements reduces the median error to
approximately 10%, significantly outperforming traditional simulators, which
exceed 50% error. Integration into the Colosseum emulator and the Sionna SYS
platform demonstrate near-zero error in spectral efficiency and block-error
rate compared to measurement-based channels. These findings validate AIRMap's
potential for scalable, accurate, and real-time radio map estimation in
wireless digital twins.
\\ ( https://arxiv.org/abs/2511.05522 ,  15452kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05523 (*cross-listing*)
Date: Tue, 28 Oct 2025 15:25:23 GMT   (141kb)

Title: The Evolution of Probabilistic Price Forecasting Techniques: A Review of
 the Day-Ahead, Intra-Day, and Balancing Markets
Authors: Ciaran O'Connor, Mohamed Bahloul, Steven Prestwich, Andrea Visentin
Categories: q-fin.ST cs.AI stat.AP
\\
 Electricity price forecasting has become a critical tool for decision-making
in energy markets, particularly as the increasing penetration of renewable
energy introduces greater volatility and uncertainty. Historically, research in
this field has been dominated by point forecasting methods, which provide
single-value predictions but fail to quantify uncertainty. However, as power
markets evolve due to renewable integration, smart grids, and regulatory
changes, the need for probabilistic forecasting has become more pronounced,
offering a more comprehensive approach to risk assessment and market
participation. This paper presents a review of probabilistic forecasting
methods, tracing their evolution from Bayesian and distribution based
approaches, through quantile regression techniques, to recent developments in
conformal prediction. Particular emphasis is placed on advancements in
probabilistic forecasting, including validity-focused methods which address key
limitations in uncertainty estimation. Additionally, this review extends beyond
the Day-Ahead Market to include the Intra-Day and Balancing Markets, where
forecasting challenges are intensified by higher temporal granularity and
real-time operational constraints. We examine state of the art methodologies,
key evaluation metrics, and ongoing challenges, such as forecast validity,
model selection, and the absence of standardised benchmarks, providing
researchers and practitioners with a comprehensive and timely resource for
navigating the complexities of modern electricity markets.
\\ ( https://arxiv.org/abs/2511.05523 ,  141kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05529 (*cross-listing*)
Date: Wed, 29 Oct 2025 04:16:04 GMT   (879kb)

Title: Selective Diabetic Retinopathy Screening with Accuracy-Weighted Deep
 Ensembles and Entropy-Guided Abstention
Authors: Jophy Lin
Categories: q-bio.QM cs.AI cs.CV
\\
 Diabetic retinopathy (DR), a microvascular complication of diabetes and a
leading cause of preventable blindness, is projected to affect more than 130
million individuals worldwide by 2030. Early identification is essential to
reduce irreversible vision loss, yet current diagnostic workflows rely on
methods such as fundus photography and expert review, which remain costly and
resource-intensive. This, combined with DR's asymptomatic nature, results in
its underdiagnosis rate of approximately 25 percent. Although convolutional
neural networks (CNNs) have demonstrated strong performance in medical imaging
tasks, limited interpretability and the absence of uncertainty quantification
restrict clinical reliability. Therefore, in this study, a deep ensemble
learning framework integrated with uncertainty estimation is introduced to
improve robustness, transparency, and scalability in DR detection. The ensemble
incorporates seven CNN architectures-ResNet-50, DenseNet-121, MobileNetV3
(Small and Large), and EfficientNet (B0, B2, B3)- whose outputs are fused
through an accuracy-weighted majority voting strategy. A probability-weighted
entropy metric quantifies prediction uncertainty, enabling low-confidence
samples to be excluded or flagged for additional review. Training and
validation on 35,000 EyePACS retinal fundus images produced an unfiltered
accuracy of 93.70 percent (F1 = 0.9376). Uncertainty-filtering later was
conducted to remove unconfident samples, resulting in maximum-accuracy of 99.44
percent (F1 = 0.9932). The framework shows that uncertainty-aware,
accuracy-weighted ensembling improves reliability without hindering
performance. With confidence-calibrated outputs and a tunable accuracy-coverage
trade-off, it offers a generalizable paradigm for deploying trustworthy AI
diagnostics in high-risk care.
\\ ( https://arxiv.org/abs/2511.05529 ,  879kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05536 (*cross-listing*)
Date: Wed, 29 Oct 2025 17:41:07 GMT   (3213kb)

Title: Gravity-Awareness: Deep Learning Models and LLM Simulation of Human
 Awareness in Altered Gravity
Authors: Bakytzhan Alibekov, Alina Gutoreva and Elisa Raffaella-Ferre
Categories: q-bio.NC cs.AI cs.LG eess.SP
Comments: 64 pages, 8 figures, 2 datasets, 1 protocol
MSC-class: 68T07 (Primary) 92C20, 62M30, 92-10, 68T50 (Secondary)
ACM-class: G.3; I.2.0; I.6.6; I.6.4; I.6.5; J.4; J.3
\\
 Earth's gravity has fundamentally shaped human development by guiding the
brain's integration of vestibular, visual, and proprioceptive inputs into an
internal model of gravity: a dynamic neural representation enabling prediction
and interpretation of gravitational forces. This work presents a dual
computational framework to quantitatively model these adaptations. The first
component is a lightweight Multi-Layer Perceptron (MLP) that predicts
g-load-dependent changes in key electroencephalographic (EEG) frequency bands,
representing the brain's cortical state. The second component utilizes a suite
of independent Gaussian Processes (GPs) to model the body's broader
physiological state, including Heart Rate Variability (HRV), Electrodermal
Activity (EDA), and motor behavior. Both models were trained on data derived
from a comprehensive review of parabolic flight literature, using published
findings as anchor points to construct robust, continuous functions. To
complement this quantitative analysis, we simulated subjective human experience
under different gravitational loads, ranging from microgravity (0g) and partial
gravity (Moon 0.17g, Mars 0.38g) to hypergravity associated with spacecraft
launch and re-entry (1.8g), using a large language model (Claude 3.5 Sonnet).
The model was prompted with physiological parameters to generate introspective
narratives of alertness and self-awareness, which closely aligned with the
quantitative findings from both the EEG and physiological models. This combined
framework integrates quantitative physiological modeling with generative
cognitive simulation, offering a novel approach to understanding and predicting
human performance in altered gravity
\\ ( https://arxiv.org/abs/2511.05536 ,  3213kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05542 (*cross-listing*)
Date: Fri, 31 Oct 2025 02:20:38 GMT   (3493kb)

Title: ConnectomeBench: Can LLMs Proofread the Connectome?
Authors: Jeff Brown, Andrew Kirjner Annika Vivekananthan, Ed Boyden
Categories: q-bio.NC cs.AI cs.CV cs.LG
Comments: To appear in NeurIPS 2025 Datasets and Benchmarks Track
\\
 Connectomics - the mapping of neural connections in an organism's brain -
currently requires extraordinary human effort to proofread the data collected
from imaging and machine-learning assisted segmentation. With the growing
excitement around using AI agents to automate important scientific tasks, we
explore whether current AI systems can perform multiple tasks necessary for
data proofreading. We introduce ConnectomeBench, a multimodal benchmark
evaluating large language model (LLM) capabilities in three critical
proofreading tasks: segment type identification, split error correction, and
merge error detection. Using expert annotated data from two large open-source
datasets - a cubic millimeter of mouse visual cortex and the complete
Drosophila brain - we evaluate proprietary multimodal LLMs including Claude
3.7/4 Sonnet, o4-mini, GPT-4.1, GPT-4o, as well as open source models like
InternVL-3 and NVLM. Our results demonstrate that current models achieve
surprisingly high performance in segment identification (52-82% balanced
accuracy vs. 20-25% chance) and binary/multiple choice split error correction
(75-85% accuracy vs. 50% chance) while generally struggling on merge error
identification tasks. Overall, while the best models still lag behind expert
performance, they demonstrate promising capabilities that could eventually
enable them to augment and potentially replace human proofreading in
connectomics. Project page: https://github.com/jffbrwn2/ConnectomeBench and
Dataset https://huggingface.co/datasets/jeffbbrown2/ConnectomeBench/tree/main
\\ ( https://arxiv.org/abs/2511.05542 ,  3493kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05612 (*cross-listing*)
Date: Thu, 6 Nov 2025 13:45:01 GMT   (2650kb)

Title: AI-Enhanced High-Density NIRS Patch for Real-Time Brain Layer
 Oxygenation Monitoring in Neurological Emergencies
Authors: Minsu Ji, Jihoon Kang, Seongkwon Yu, Jaemyoung Kim, Bumjun Koh, Jimin
 Lee, Guil Jeong, Jongkwan choi, Chang-Ho Yun, and Hyeonmin Bae
Categories: q-bio.NC cs.AI
\\
 Photon scattering has traditionally limited the ability of near-infrared
spectroscopy (NIRS) to extract accurate, layer-specific information from the
brain. This limitation restricts its clinical utility for precise neurological
monitoring. To address this, we introduce an AI-driven, high-density NIRS
system optimized to provide real-time, layer-specific oxygenation data from the
brain cortex, specifically targeting acute neuro-emergencies. Our system
integrates high-density NIRS reflectance data with a neural network trained on
MRI-based synthetic datasets. This approach achieves robust cortical
oxygenation accuracy across diverse anatomical variations. In simulations, our
AI-assisted NIRS demonstrated a strong correlation (R2=0.913) with actual
cortical oxygenation, markedly outperforming conventional methods (R2=0.469).
Furthermore, biomimetic phantom experiments confirmed its superior anatomical
reliability (R2=0.986) compared to standard commercial devices (R2=0.823). In
clinical validation with healthy subjects and ischemic stroke patients, the
system distinguished between the two groups with an AUC of 0.943. This
highlights its potential as an accessible, high-accuracy diagnostic tool for
emergency and point-of-care settings. These results underscore the system's
capability to advance neuro-monitoring precision through AI, enabling timely,
data-driven decisions in critical care environments.
\\ ( https://arxiv.org/abs/2511.05612 ,  2650kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05613 (*cross-listing*)
Date: Thu, 6 Nov 2025 14:25:32 GMT   (622kb)

Title: Who Evaluates AI's Social Impacts? Mapping Coverage and Gaps in First
 and Third Party Evaluations
Authors: Anka Reuel, Avijit Ghosh, Jenny Chim, Andrew Tran, Yanan Long,
 Jennifer Mickel, Usman Gohar, Srishti Yadav, Pawan Sasanka Ammanamanchi,
 Mowafak Allaham, Hossein A. Rahmani, Mubashara Akhtar, Felix Friedrich,
 Robert Scholz, Michael Alexander Riegler, Jan Batzner, Eliya Habba, Arushi
 Saxena, Anastassia Kornilova, Kevin Wei, Prajna Soni, Yohan Mathew, Kevin
 Klyman, Jeba Sania, Subramanyam Sahoo, Olivia Beyer Bruvik, Pouya Sadeghi,
 Sujata Goswami, Angelina Wang, Yacine Jernite, Zeerak Talat, Stella Biderman,
 Mykel Kochenderfer, Sanmi Koyejo, Irene Solaiman
Categories: cs.CY cs.AI cs.LG
\\
 Foundation models are increasingly central to high-stakes AI systems, and
governance frameworks now depend on evaluations to assess their risks and
capabilities. Although general capability evaluations are widespread, social
impact assessments covering bias, fairness, privacy, environmental costs, and
labor practices remain uneven across the AI ecosystem. To characterize this
landscape, we conduct the first comprehensive analysis of both first-party and
third-party social impact evaluation reporting across a wide range of model
developers. Our study examines 186 first-party release reports and 183
post-release evaluation sources, and complements this quantitative analysis
with interviews of model developers. We find a clear division of evaluation
labor: first-party reporting is sparse, often superficial, and has declined
over time in key areas such as environmental impact and bias, while third-party
evaluators including academic researchers, nonprofits, and independent
organizations provide broader and more rigorous coverage of bias, harmful
content, and performance disparities. However, this complementarity has limits.
Only model developers can authoritatively report on data provenance, content
moderation labor, financial costs, and training infrastructure, yet interviews
reveal that these disclosures are often deprioritized unless tied to product
adoption or regulatory compliance. Our findings indicate that current
evaluation practices leave major gaps in assessing AI's societal impacts,
highlighting the urgent need for policies that promote developer transparency,
strengthen independent evaluation ecosystems, and create shared infrastructure
to aggregate and compare third-party evaluations in a consistent and accessible
way.
\\ ( https://arxiv.org/abs/2511.05613 ,  622kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05625 (*cross-listing*)
Date: Thu, 6 Nov 2025 23:23:05 GMT   (380kb)

Title: Report from Workshop on Dialogue alongside Artificial Intelligence
Authors: Thomas J McKenna (Boston University), Ingvill Rasmussen (University of
 Oslo), Sten Ludvigsen (University of Oslo), Avivit Arvatz (The Hebrew
 University of Jerusalem), Christa Asterhan (The Hebrew University of
 Jerusalem), Gaowei Chen (The University of Hong Kong), Julie Cohen
 (University of Virginia), Michele Flammia (Independent Scholar), Dongkeun Han
 (University of Cambridge), Emma Hayward (University of Cambridge), Heather
 Hill (Harvard University), Yifat Kolikant (The Hebrew University of
 Jerusalem), Helen Lehndorf (Freie Universit\"at Berlin), Kexin Li (The
 University of Hong Kong), Lindsay Clare Matsumura (University of Pittsburgh),
 Henrik Tj{\o}nn (University of Oslo), Pengjin Wang (The University of Hong
 Kong), Rupert Wegerif (University of Cambridge)
Categories: cs.CY cs.AI
Comments: Report from the Workshop on Dialogue alongside Artificial
 Intelligence (2025)
\\
 Educational dialogue -the collaborative exchange of ideas through talk- is
widely recognized as a catalyst for deeper learning and critical thinking in
and across contexts. At the same time, artificial intelligence (AI) has rapidly
emerged as a powerful force in education, with the potential to address major
challenges, personalize learning, and innovate teaching practices. However,
these advances come with significant risks: rapid AI development can undermine
human agency, exacerbate inequities, and outpace our capacity to guide its use
with sound policy. Human learning presupposes cognitive efforts and social
interaction (dialogues). In response to this evolving landscape, an
international workshop titled "Educational Dialogue: Moving Thinking Forward"
convened 19 leading researchers from 11 countries in Cambridge (September 1-3,
2025) to examine the intersection of AI and educational dialogue. This
AI-focused strand of the workshop centered on three critical questions: (1)
When is AI truly useful in education, and when might it merely replace human
effort at the expense of learning? (2) Under what conditions can AI use lead to
better dialogic teaching and learning? (3) Does the AI-human partnership risk
outpacing and displacing human educational work, and what are the implications?
These questions framed two days of presentations and structured dialogue among
participants.
\\ ( https://arxiv.org/abs/2511.05625 ,  380kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05626 (*cross-listing*)
Date: Fri, 7 Nov 2025 00:06:51 GMT   (186kb)

Title: LLMs as Packagers of HPC Software
Authors: Caetano Melone, Daniel Nichols, Konstantinos Parasyris, Todd Gamblin,
 Harshitha Menon
Categories: cs.SE cs.AI cs.DC
\\
 High performance computing (HPC) software ecosystems are inherently
heterogeneous, comprising scientific applications that depend on hundreds of
external packages, each with distinct build systems, options, and dependency
constraints. Tools such as Spack automate dependency resolution and environment
management, but their effectiveness relies on manually written build recipes.
As these ecosystems grow, maintaining existing specifications and creating new
ones becomes increasingly labor-intensive. While large language models (LLMs)
have shown promise in code generation, automatically producing correct and
maintainable Spack recipes remains a significant challenge. We present a
systematic analysis of how LLMs and context-augmentation methods can assist in
the generation of Spack recipes. To this end, we introduce SpackIt, an
end-to-end framework that combines repository analysis, retrieval of relevant
examples, and iterative refinement through diagnostic feedback. We apply
SpackIt to a representative subset of 308 open-source HPC packages to assess
its effectiveness and limitations. Our results show that SpackIt increases
installation success from 20% in a zero-shot setting to over 80% in its best
configuration, demonstrating the value of retrieval and structured feedback for
reliable package synthesis.
\\ ( https://arxiv.org/abs/2511.05626 ,  186kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05627 (*cross-listing*)
Date: Fri, 7 Nov 2025 02:44:00 GMT   (743kb)

Title: Assessing the Reliability of Large Language Models in the Bengali Legal
 Context: A Comparative Evaluation Using LLM-as-Judge and Legal Experts
Authors: Sabik Aftahee, A.F.M. Farhad, Arpita Mallik, Ratnajit Dhar, Jawadul
 Karim, Nahiyan Bin Noor and Ishmam Ahmed Solaiman
Categories: cs.CY cs.AI
\\
 Accessing legal help in Bangladesh is hard. People face high fees, complex
legal language, a shortage of lawyers, and millions of unresolved court cases.
Generative AI models like OpenAI GPT-4.1 Mini, Gemini 2.0 Flash, Meta Llama 3
70B, and DeepSeek R1 could potentially democratize legal assistance by
providing quick and affordable legal advice. In this study, we collected 250
authentic legal questions from the Facebook group "Know Your Rights," where
verified legal experts regularly provide authoritative answers. These questions
were subsequently submitted to four four advanced AI models and responses were
generated using a consistent, standardized prompt. A comprehensive dual
evaluation framework was employed, in which a state-of-the-art LLM model served
as a judge, assessing each AI-generated response across four critical
dimensions: factual accuracy, legal appropriateness, completeness, and clarity.
Following this, the same set of questions was evaluated by three licensed
Bangladeshi legal professionals according to the same criteria. In addition,
automated evaluation metrics, including BLEU scores, were applied to assess
response similarity. Our findings reveal a complex landscape where AI models
frequently generate high-quality, well-structured legal responses but also
produce dangerous misinformation, including fabricated case citations,
incorrect legal procedures, and potentially harmful advice. These results
underscore the critical need for rigorous expert validation and comprehensive
safeguards before AI systems can be safely deployed for legal consultation in
Bangladesh.
\\ ( https://arxiv.org/abs/2511.05627 ,  743kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05630 (*cross-listing*)
Date: Fri, 7 Nov 2025 04:40:47 GMT   (4111kb)

Title: BrainCSD: A Hierarchical Consistency-Driven MoE Foundation Model for
 Unified Connectome Synthesis and Multitask Brain Trait Prediction
Authors: Xiongri Shen, Jiaqi Wang, Yi Zhong, Zhenxi Song, Leilei Zhao, Liling
 Li, Yichen Wei, Lingyan Liang, Shuqiang Wang, Baiying Lei, Demao Deng, Zhiguo
 Zhang
Categories: q-bio.NC cs.AI
\\
 Functional and structural connectivity (FC/SC) are key multimodal biomarkers
for brain analysis, yet their clinical utility is hindered by costly
acquisition, complex preprocessing, and frequent missing modalities. Existing
foundation models either process single modalities or lack explicit mechanisms
for cross-modal and cross-scale consistency. We propose BrainCSD, a
hierarchical mixture-of-experts (MoE) foundation model that jointly synthesizes
FC/SC biomarkers and supports downstream decoding tasks (diagnosis and
prediction). BrainCSD features three neuroanatomically grounded components: (1)
a ROI-specific MoE that aligns regional activations from canonical networks
(e.g., DMN, FPN) with a global atlas via contrastive consistency; (2) a
Encoding-Activation MOE that models dynamic cross-time/gradient dependencies in
fMRI/dMRI; and (3) a network-aware refinement MoE that enforces structural
priors and symmetry at individual and population levels. Evaluated on the
datasets under complete and missing-modality settings, BrainCSD achieves SOTA
results: 95.6\% accuracy for MCI vs. CN classification without FC, low
synthesis error (FC RMSE: 0.038; SC RMSE: 0.006), brain age prediction (MAE:
4.04 years), and MMSE score estimation (MAE: 1.72 points). Code is available in
\href{https://github.com/SXR3015/BrainCSD}{BrainCSD}
\\ ( https://arxiv.org/abs/2511.05630 ,  4111kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05706 (*cross-listing*)
Date: Fri, 7 Nov 2025 20:55:24 GMT   (2067kb)

Title: AdvisingWise: Supporting Academic Advising in Higher Educations Through
 a Human-in-the-Loop Multi-Agent Framework
Authors: Wendan Jiang, Shiyuan Wang, Hiba Eltigani, Rukhshan Haroon, Abdullah
 Bin Faisal, Fahad Dogar
Categories: cs.HC cs.AI
Comments: 18 pages, 6 figures
\\
 Academic advising is critical to student success in higher education, yet
high student-to-advisor ratios limit advisors' capacity to provide timely
support, particularly during peak periods. Recent advances in Large Language
Models (LLMs) present opportunities to enhance the advising process. We present
AdvisingWise, a multi-agent system that automates time-consuming tasks, such as
information retrieval and response drafting, while preserving human oversight.
AdvisingWise leverages authoritative institutional resources and adaptively
prompts students about their academic backgrounds to generate reliable,
personalized responses. All system responses undergo human advisor validation
before delivery to students. We evaluate AdvisingWise through a mixed-methods
approach: (1) expert evaluation on responses of 20 sample queries, (2)
LLM-as-a-judge evaluation of the information retrieval strategy, and (3) a user
study with 8 academic advisors to assess the system's practical utility. Our
evaluation shows that AdvisingWise produces accurate, personalized responses.
Advisors reported increasingly positive perceptions after using AdvisingWise,
as their initial concerns about reliability and personalization diminished. We
conclude by discussing the implications of human-AI synergy on the practice of
academic advising.
\\ ( https://arxiv.org/abs/2511.05706 ,  2067kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05769 (*cross-listing*)
Date: Fri, 7 Nov 2025 23:53:36 GMT   (707kb)

Title: Lived Experience in Dialogue: Co-designing Personalization in Large
 Language Models to Support Youth Mental Well-being
Authors: Kathleen W. Guan, Sarthak Giri, Mohammed Amara, Bernard J. Jansen,
 Enrico Liscio, Milena Esherick, Mohammed Al Owayyed, Ausrine Ratkute, Gayane
 Sedrakyan, Mark de Reuver, Joao Fernando Ferreira Goncalves, and Caroline A.
 Figueroa
Categories: cs.HC cs.AI
\\
 Youth increasingly turn to large language models (LLMs) for mental well-being
support, yet current personalization in LLMs can overlook the heterogeneous
lived experiences shaping their needs. We conducted a participatory study with
youth, parents, and youth care workers (N=38), using co-created youth personas
as scaffolds, to elicit community perspectives on how LLMs can facilitate more
meaningful personalization to support youth mental well-being. Analysis
identified three themes: person-centered contextualization responsive to
momentary needs, explicit boundaries around scope and offline referral, and
dialogic scaffolding for reflection and autonomy. We mapped these themes to
persuasive design features for task suggestions, social facilitation, and
system trustworthiness, and created corresponding dialogue extracts to guide
LLM fine-tuning. Our findings demonstrate how lived experience can be
operationalized to inform design features in LLMs, which can enhance the
alignment of LLM-based interventions with the realities of youth and their
communities, contributing to more effectively personalized digital well-being
tools.
\\ ( https://arxiv.org/abs/2511.05769 ,  707kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05791 (*cross-listing*)
Date: Sat, 8 Nov 2025 01:47:40 GMT   (4956kb)

Title: VLAD-Grasp: Zero-shot Grasp Detection via Vision-Language Models
Authors: Manav Kulshrestha, S. Talha Bukhari, Damon Conover, Aniket Bera
Categories: cs.RO cs.AI cs.LG
Comments: 8 pages, 4 figures, under review
\\
 Robotic grasping is a fundamental capability for autonomous manipulation;
however, most existing methods rely on large-scale expert annotations and
necessitate retraining to handle new objects. We present VLAD-Grasp, a
Vision-Language model Assisted zero-shot approach for Detecting grasps. From a
single RGB-D image, our method (1) prompts a large vision-language model to
generate a goal image where a straight rod "impales" the object, representing
an antipodal grasp, (2) predicts depth and segmentation to lift this generated
image into 3D, and (3) aligns generated and observed object point clouds via
principal component analysis and correspondence-free optimization to recover an
executable grasp pose. Unlike prior work, our approach is training-free and
does not rely on curated grasp datasets. Despite this, VLAD-Grasp achieves
performance that is competitive with or superior to that of state-of-the-art
supervised models on the Cornell and Jacquard datasets. We further demonstrate
zero-shot generalization to novel real-world objects on a Franka Research 3
robot, highlighting vision-language foundation models as powerful priors for
robotic manipulation.
\\ ( https://arxiv.org/abs/2511.05791 ,  4956kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05797 (*cross-listing*)
Date: Sat, 8 Nov 2025 02:02:24 GMT   (551kb)

Title: When AI Meets the Web: Prompt Injection Risks in Third-Party AI Chatbot
 Plugins
Authors: Yigitcan Kaya, Anton Landerer, Stijn Pletinckx, Michelle Zimmermann,
 Christopher Kruegel, Giovanni Vigna
Categories: cs.CR cs.AI
Comments: At IEEE S&P 2026
\\
 Prompt injection attacks pose a critical threat to large language models
(LLMs), with prior work focusing on cutting-edge LLM applications like personal
copilots. In contrast, simpler LLM applications, such as customer service
chatbots, are widespread on the web, yet their security posture and exposure to
such attacks remain poorly understood. These applications often rely on
third-party chatbot plugins that act as intermediaries to commercial LLM APIs,
offering non-expert website builders intuitive ways to customize chatbot
behaviors. To bridge this gap, we present the first large-scale study of 17
third-party chatbot plugins used by over 10,000 public websites, uncovering
previously unknown prompt injection risks in practice. First, 8 of these
plugins (used by 8,000 websites) fail to enforce the integrity of the
conversation history transmitted in network requests between the website
visitor and the chatbot. This oversight amplifies the impact of direct prompt
injection attacks by allowing adversaries to forge conversation histories
(including fake system messages), boosting their ability to elicit unintended
behavior (e.g., code generation) by 3 to 8x. Second, 15 plugins offer tools,
such as web-scraping, to enrich the chatbot's context with website-specific
content. However, these tools do not distinguish the website's trusted content
(e.g., product descriptions) from untrusted, third-party content (e.g.,
customer reviews), introducing a risk of indirect prompt injection. Notably, we
found that ~13% of e-commerce websites have already exposed their chatbots to
third-party content. We systematically evaluate both vulnerabilities through
controlled experiments grounded in real-world observations, focusing on factors
such as system prompt design and the underlying LLM. Our findings show that
many plugins adopt insecure practices that undermine the built-in LLM
safeguards.
\\ ( https://arxiv.org/abs/2511.05797 ,  551kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05820 (*cross-listing*)
Date: Sat, 8 Nov 2025 03:09:31 GMT   (1219kb)

Title: WAR-Re: Web API Recommendation with Semantic Reasoning
Authors: Zishuo Xu, Dezhong Yao, Yao Wan
Categories: cs.SE cs.AI
\\
 With the development of cloud computing, the number of Web APIs has increased
dramatically, further intensifying the demand for efficient Web API
recommendation. Despite the demonstrated success of previous Web API
recommendation solutions, two critical challenges persist: 1) a fixed top-N
recommendation that cannot accommodate the varying API cardinality requirements
of different mashups, and 2) these methods output only ranked API lists without
accompanying reasons, depriving users of understanding the recommendation. To
address these challenges, we propose WAR-Re, an LLM-based model for Web API
recommendation with semantic reasoning for justification. WAR-Re leverages
special start and stop tokens to handle the first challenge and uses two-stage
training: supervised fine-tuning and reinforcement learning via Group Relative
Policy Optimization (GRPO) to enhance the model's ability in both tasks.
Comprehensive experimental evaluations on the ProgrammableWeb dataset
demonstrate that WAR-Re achieves a gain of up to 21.59\% over the
state-of-the-art baseline model in recommendation accuracy, while consistently
producing high-quality semantic reasons for recommendations.
\\ ( https://arxiv.org/abs/2511.05820 ,  1219kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05822 (*cross-listing*)
Date: Sat, 8 Nov 2025 03:12:29 GMT   (772kb)

Title: Policy Gradient-Based EMT-in-the-Loop Learning to Mitigate
 Sub-Synchronous Control Interactions
Authors: Sayak Mukherjee, Ramij R. Hossain, Kaustav Chatterjee, Sameer
 Nekkalapu, Marcelo Elizondo
Categories: eess.SY cs.AI cs.SY
Comments: 10 pages, 7 figures
\\
 This paper explores the development of learning-based tunable control gains
using EMT-in-the-loop simulation framework (e.g., PSCAD interfaced with
Python-based learning modules) to address critical sub-synchronous
oscillations. Since sub-synchronous control interactions (SSCI) arise from the
mis-tuning of control gains under specific grid configurations, effective
mitigation strategies require adaptive re-tuning of these gains. Such
adaptiveness can be achieved by employing a closed-loop, learning-based
framework that considers the grid conditions responsible for such
sub-synchronous oscillations. This paper addresses this need by adopting
methodologies inspired by Markov decision process (MDP) based reinforcement
learning (RL), with a particular emphasis on simpler deep policy gradient
methods with additional SSCI-specific signal processing modules such as
down-sampling, bandpass filtering, and oscillation energy dependent reward
computations. Our experimentation in a real-world event setting demonstrates
that the deep policy gradient based trained policy can adaptively compute gain
settings in response to varying grid conditions and optimally suppress control
interaction-induced oscillations.
\\ ( https://arxiv.org/abs/2511.05822 ,  772kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05849 (*cross-listing*)
Date: Sat, 8 Nov 2025 04:39:11 GMT   (1844kb)

Title: EGG-SR: Embedding Symbolic Equivalence into Symbolic Regression via
 Equality Graph
Authors: Nan Jiang, Ziyi Wang, and Yexiang Xue
Categories: cs.SC cs.AI cs.LG
\\
 Symbolic regression seeks to uncover physical laws from experimental data by
searching for closed-form expressions, which is an important task in AI-driven
scientific discovery. Yet the exponential growth of the search space of
expression renders the task computationally challenging. A promising yet
underexplored direction for reducing the effective search space and
accelerating training lies in symbolic equivalence: many expressions, although
syntactically different, define the same function -- for example,
$\log(x_1^2x_2^3)$, $\log(x_1^2)+\log(x_2^3)$, and $2\log(x_1)+3\log(x_2)$.
Existing algorithms treat such variants as distinct outputs, leading to
redundant exploration and slow learning. We introduce EGG-SR, a unified
framework that integrates equality graphs (e-graphs) into diverse symbolic
regression algorithms, including Monte Carlo Tree Search (MCTS), deep
reinforcement learning (DRL), and large language models (LLMs). EGG-SR
compactly represents equivalent expressions through the proposed EGG module,
enabling more efficient learning by: (1) pruning redundant subtree exploration
in EGG-MCTS, (2) aggregating rewards across equivalence classes in EGG-DRL, and
(3) enriching feedback prompts in EGG-LLM. Under mild assumptions, we show that
embedding e-graphs tightens the regret bound of MCTS and reduces the variance
of the DRL gradient estimator. Empirically, EGG-SR consistently enhances
multiple baselines across challenging benchmarks, discovering equations with
lower normalized mean squared error than state-of-the-art methods. Code
implementation is available at: https://www.github.com/jiangnanhugo/egg-sr.
\\ ( https://arxiv.org/abs/2511.05849 ,  1844kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05873 (*cross-listing*)
Date: Sat, 8 Nov 2025 06:17:51 GMT   (2538kb)

Title: EndoIR: Degradation-Agnostic All-in-One Endoscopic Image Restoration via
 Noise-Aware Routing Diffusion
Authors: Tong Chen, Xinyu Ma, Long Bai, Wenyang Wang, Sun Yue, Luping Zhou
Categories: eess.IV cs.AI cs.CV cs.RO
\\
 Endoscopic images often suffer from diverse and co-occurring degradations
such as low lighting, smoke, and bleeding, which obscure critical clinical
details. Existing restoration methods are typically task-specific and often
require prior knowledge of the degradation type, limiting their robustness in
real-world clinical use. We propose EndoIR, an all-in-one, degradation-agnostic
diffusion-based framework that restores multiple degradation types using a
single model. EndoIR introduces a Dual-Domain Prompter that extracts joint
spatial-frequency features, coupled with an adaptive embedding that encodes
both shared and task-specific cues as conditioning for denoising. To mitigate
feature confusion in conventional concatenation-based conditioning, we design a
Dual-Stream Diffusion architecture that processes clean and degraded inputs
separately, with a Rectified Fusion Block integrating them in a structured,
degradation-aware manner. Furthermore, Noise-Aware Routing Block improves
efficiency by dynamically selecting only noise-relevant features during
denoising. Experiments on SegSTRONG-C and CEC datasets demonstrate that EndoIR
achieves state-of-the-art performance across multiple degradation scenarios
while using fewer parameters than strong baselines, and downstream segmentation
experiments confirm its clinical utility.
\\ ( https://arxiv.org/abs/2511.05873 ,  2538kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05875 (*cross-listing*)
Date: Sat, 8 Nov 2025 06:22:15 GMT   (4083kb)

Title: Towards a Humanized Social-Media Ecosystem: AI-Augmented HCI Design
 Patterns for Safety, Agency & Well-Being
Authors: Mohd Ruhul Ameen and Akif Islam
Categories: cs.HC cs.AI cs.CV
Comments: 6 pages, 5 tables, 7 figures, and 2 algorithm tables. Accepted at
 International Conference on Signal Processing, Information, Communication and
 Systems (SPICSCON 2025)
\\
 Social platforms connect billions of people, yet their engagement-first
algorithms often work on users rather than with them, amplifying stress,
misinformation, and a loss of control. We propose Human-Layer AI
(HL-AI)--user-owned, explainable intermediaries that sit in the browser between
platform logic and the interface. HL-AI gives people practical,
moment-to-moment control without requiring platform cooperation. We contribute
a working Chrome/Edge prototype implementing five representative pattern
frameworks--Context-Aware Post Rewriter, Post Integrity Meter, Granular Feed
Curator, Micro-Withdrawal Agent, and Recovery Mode--alongside a unifying
mathematical formulation balancing user utility, autonomy costs, and risk
thresholds. Evaluation spans technical accuracy, usability, and behavioral
outcomes. The result is a suite of humane controls that help users rewrite
before harm, read with integrity cues, tune feeds with intention, pause
compulsive loops, and seek shelter during harassment, all while preserving
agency through explanations and override options. This prototype offers a
practical path to retrofit today's feeds with safety, agency, and well-being,
inviting rigorous cross-cultural user evaluation.
\\ ( https://arxiv.org/abs/2511.05875 ,  4083kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05903 (*cross-listing*)
Date: Sat, 8 Nov 2025 08:05:43 GMT   (29842kb)

Title: The Imperfect Learner: Incorporating Developmental Trajectories in
 Memory-based Student Simulation
Authors: Zhengyuan Liu, Stella Xin Yin, Bryan Chen Zhengyu Tan, Roy Ka-Wei Lee,
 Guimei Liu, Dion Hoe-Lian Goh, Wenya Wang, Nancy F. Chen
Categories: cs.CY cs.AI cs.CL cs.HC
\\
 User simulation is important for developing and evaluating human-centered AI,
yet current student simulation in educational applications has significant
limitations. Existing approaches focus on single learning experiences and do
not account for students' gradual knowledge construction and evolving skill
sets. Moreover, large language models are optimized to produce direct and
accurate responses, making it challenging to represent the incomplete
understanding and developmental constraints that characterize real learners. In
this paper, we introduce a novel framework for memory-based student simulation
that incorporates developmental trajectories through a hierarchical memory
mechanism with structured knowledge representation. The framework also
integrates metacognitive processes and personality traits to enrich the
individual learner profiling, through dynamical consolidation of both cognitive
development and personal learning characteristics. In practice, we implement a
curriculum-aligned simulator grounded on the Next Generation Science Standards.
Experimental results show that our approach can effectively reflect the gradual
nature of knowledge development and the characteristic difficulties students
face, providing a more accurate representation of learning processes.
\\ ( https://arxiv.org/abs/2511.05903 ,  29842kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05919 (*cross-listing*)
Date: Sat, 8 Nov 2025 08:30:19 GMT   (105kb)

Title: Injecting Falsehoods: Adversarial Man-in-the-Middle Attacks Undermining
 Factual Recall in LLMs
Authors: Alina Fastowski, Bardh Prenkaj, Yuxiao Li, Gjergji Kasneci
Categories: cs.CR cs.AI cs.CL
\\
 LLMs are now an integral part of information retrieval. As such, their role
as question answering chatbots raises significant concerns due to their shown
vulnerability to adversarial man-in-the-middle (MitM) attacks. Here, we propose
the first principled attack evaluation on LLM factual memory under prompt
injection via Xmera, our novel, theory-grounded MitM framework. By perturbing
the input given to "victim" LLMs in three closed-book and fact-based QA
settings, we undermine the correctness of the responses and assess the
uncertainty of their generation process. Surprisingly, trivial
instruction-based attacks report the highest success rate (up to ~85.3%) while
simultaneously having a high uncertainty for incorrectly answered questions. To
provide a simple defense mechanism against Xmera, we train Random Forest
classifiers on the response uncertainty levels to distinguish between attacked
and unattacked queries (average AUC of up to ~96%). We believe that signaling
users to be cautious about the answers they receive from black-box and
potentially corrupt LLMs is a first checkpoint toward user cyberspace safety.
\\ ( https://arxiv.org/abs/2511.05919 ,  105kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05920 (*cross-listing*)
Date: Sat, 8 Nov 2025 08:31:23 GMT   (1327kb)

Title: IoT-based Fresh Produce Supply Chain Under Uncertainty: An Adaptive
 Optimization Framework
Authors: Chirag Seth, Mehrdad Pirnia, James H Bookbinder
Categories: math.OC cs.AI
\\
 Fruits and vegetables form a vital component of the global economy; however,
their distribution poses complex logistical challenges due to high
perishability, supply fluctuations, strict quality and safety standards, and
environmental sensitivity. In this paper, we propose an adaptive optimization
model that accounts for delays, travel time, and associated temperature changes
impacting produce shelf life, and compare it against traditional approaches
such as Robust Optimization, Distributionally Robust Optimization, and
Stochastic Programming. Additionally, we conduct a series of computational
experiments using Internet of Things (IoT) sensor data to evaluate the
performance of our proposed model. Our study demonstrates that the proposed
adaptive model achieves a higher shelf life, extending it by over 18\% compared
to traditional optimization models, by dynamically mitigating temperature
deviations through a temperature feedback mechanism. The promising results
demonstrate the potential of this approach to improve both the freshness and
efficiency of logistics systems an aspect often neglected in previous works.
\\ ( https://arxiv.org/abs/2511.05920 ,  1327kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05927 (*cross-listing*)
Date: Sat, 8 Nov 2025 08:42:14 GMT   (1559kb)

Title: Artificial intelligence and the Gulf Cooperation Council workforce
 adapting to the future of work
Authors: Mohammad Rashed Albous, Melodena Stephens and Odeh Rashed Al-Jayyousi
Categories: cs.CY cs.AI econ.GN q-fin.EC
DOI: 10.1057/s41599-025-05984-5
\\
 The rapid expansion of artificial intelligence (AI) in the Gulf Cooperation
Council (GCC) raises a central question: are investments in compute
infrastructure matched by an equally robust build-out of skills, incentives,
and governance? Grounded in socio-technical systems (STS) theory, this
mixed-methods study audits workforce preparedness across Kingdom of Saudi
Arabia (KSA), the United Arab Emirates (UAE), Qatar, Kuwait, Bahrain, and Oman.
We combine term frequency--inverse document frequency (TF--IDF) analysis of six
national AI strategies (NASs), an inventory of 47 publicly disclosed AI
initiatives (January 2017--April 2025), paired case studies, the Mohamed bin
Zayed University of Artificial Intelligence (MBZUAI) and the Saudi Data &
Artificial Intelligence Authority (SDAIA) Academy, and a scenario matrix
linking oil-revenue slack (technical capacity) to regulatory coherence (social
alignment). Across the corpus, 34/47 initiatives (0.72; 95% Wilson CI
0.58--0.83) exhibit joint social--technical design; country-level indices span
0.57--0.90 (small n; intervals overlap). Scenario results suggest that, under
our modeled conditions, regulatory convergence plausibly binds outcomes more
than fiscal capacity: fragmented rules can offset high oil revenues, while
harmonized standards help preserve progress under austerity. We also identify
an emerging two-track talent system, research elites versus rapidly trained
practitioners, that risks labor-market bifurcation without bridging mechanisms.
By extending STS inquiry to oil-rich, state-led economies, the study refines
theory and sets a research agenda focused on longitudinal coupling metrics,
ethnographies of coordination, and outcome-based performance indicators.
\\ ( https://arxiv.org/abs/2511.05927 ,  1559kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05932 (*cross-listing*)
Date: Sat, 8 Nov 2025 08:54:27 GMT   (1310kb)

Title: The Future of AI in the GCC Post-NPM Landscape: A Comparative Analysis
 of Kuwait and the UAE
Authors: Mohammad Rashed Albous, Bedour Alboloushi and Arnaud Lacheret
Categories: cs.CY cs.AI econ.TH
DOI: 10.1111/polp.70084
\\
 Comparative evidence on how Gulf Cooperation Council (GCC) states turn
artificial intelligence (AI) ambitions into post--New Public Management
(post-NPM) outcomes is scarce because most studies examine Western democracies.
We analyze constitutional, collective-choice, and operational rules shaping AI
uptake in two contrasting GCC members, the United Arab Emirates (UAE) and
Kuwait, and whether they foster citizen centricity, collaborative governance,
and public value creation. Anchored in Ostrom's Institutional Analysis and
Development framework, the study combines a most similar/most different systems
design with multiple sources: 62 public documents from 2018--2025, embedded UAE
cases (Smart Dubai and MBZUAI), and 39 interviews with officials conducted Aug
2024--May 2025. Dual coding and process tracing connect rule configurations to
AI performance. Cross-case analysis identifies four reinforcing mechanisms
behind divergent trajectories. In the UAE, concentrated authority, credible
sanctions, pro-innovation narratives, and flexible reinvestment rules scale
pilots into hundreds of services and sizable recycled savings. In Kuwait,
dispersed veto points, exhortative sanctions, cautious discourse, and lapsed AI
budgets confine initiatives to pilot mode despite equivalent fiscal resources.
The findings refine institutional theory by showing that vertical rule
coherence, not wealth, determines AI's public-value yield, and temper post-NPM
optimism by revealing that efficiency metrics serve societal goals only when
backed by enforceable safeguards. To curb ethics washing and test
transferability beyond the GCC, future work should track rule diffusion over
time, develop blended legitimacy--efficiency scorecards, and examine how
narrative framing shapes citizen consent for data sharing.
\\ ( https://arxiv.org/abs/2511.05932 ,  1310kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05936 (*cross-listing*)
Date: Sat, 8 Nov 2025 09:02:13 GMT   (615kb)

Title: 10 Open Challenges Steering the Future of Vision-Language-Action Models
Authors: Soujanya Poria, Navonil Majumder, Chia-Yu Hung, Amir Ali Bagherzadeh,
 Chuan Li, Kenneth Kwok, Ziwei Wang, Cheston Tan, Jiajun Wu, David Hsu
Categories: cs.RO cs.AI
Comments: AAAI 2026 (Senior Track)
\\
 Due to their ability of follow natural language instructions,
vision-language-action (VLA) models are increasingly prevalent in the embodied
AI arena, following the widespread success of their precursors -- LLMs and
VLMs. In this paper, we discuss 10 principal milestones in the ongoing
development of VLA models -- multimodality, reasoning, data, evaluation,
cross-robot action generalization, efficiency, whole-body coordination, safety,
agents, and coordination with humans. Furthermore, we discuss the emerging
trends of using spatial understanding, modeling world dynamics, post training,
and data synthesis -- all aiming to reach these milestones. Through these
discussions, we hope to bring attention to the research avenues that may
accelerate the development of VLA models into wider acceptability.
\\ ( https://arxiv.org/abs/2511.05936 ,  615kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05940 (*cross-listing*)
Date: Sat, 8 Nov 2025 09:19:25 GMT   (1905kb)

Title: A PDE Perspective on Generative Diffusion Models
Authors: Kang Liu and Enrique Zuazua
Categories: math.OC cs.AI math.AP
Comments: 30 pages, 4 figures
MSC-class: 34D05, 35B35, 35Q68, 35Q84, 68T99
\\
 Score-based diffusion models have emerged as a powerful class of generative
methods, achieving state-of-the-art performance across diverse domains. Despite
their empirical success, the mathematical foundations of those models remain
only partially understood, particularly regarding the stability and consistency
of the underlying stochastic and partial differential equations governing their
dynamics.
 In this work, we develop a rigorous partial differential equation (PDE)
framework for score-based diffusion processes. Building on the Li--Yau
differential inequality for the heat flow, we prove well-posedness and derive
sharp $L^p$-stability estimates for the associated score-based Fokker--Planck
dynamics, providing a mathematically consistent description of their temporal
evolution. Through entropy stability methods, we further show that the
reverse-time dynamics of diffusion models concentrate on the data manifold for
compactly supported data distributions and a broad class of initialization
schemes, with a concentration rate of order $\sqrt{t}$ as $t \to 0$.
 These results yield a theoretical guarantee that, under exact score guidance,
diffusion trajectories return to the data manifold while preserving imitation
fidelity. Our findings also provide practical insights for designing diffusion
models, including principled criteria for score-function construction, loss
formulation, and stopping-time selection. Altogether, this framework provides a
quantitative understanding of the trade-off between generative capacity and
imitation fidelity, bridging rigorous analysis and model design within a
unified mathematical perspective.
\\ ( https://arxiv.org/abs/2511.05940 ,  1905kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06064 (*cross-listing*)
Date: Sat, 8 Nov 2025 16:18:42 GMT   (3103kb)

Title: A Privacy-Preserving Federated Learning Method with Homomorphic
 Encryption in Omics Data
Authors: Yusaku Negoya, Feifei Cui, Zilong Zhang, Miao Pan, Tomoaki Ohtsuki,
 and Aohan Li
Categories: cs.CR cs.AI
Comments: 6 pages, 4 figures
\\
 Omics data is widely employed in medical research to identify disease
mechanisms and contains highly sensitive personal information. Federated
Learning (FL) with Differential Privacy (DP) can ensure the protection of omics
data privacy against malicious user attacks. However, FL with the DP method
faces an inherent trade-off: stronger privacy protection degrades predictive
accuracy due to injected noise. On the other hand, Homomorphic Encryption (HE)
allows computations on encrypted data and enables aggregation of encrypted
gradients without DP-induced noise can increase the predictive accuracy.
However, it may increase the computation cost. To improve the predictive
accuracy while considering the computational ability of heterogeneous clients,
we propose a Privacy-Preserving Machine Learning (PPML)-Hybrid method by
introducing HE. In the proposed PPML-Hybrid method, clients distributed select
either HE or DP based on their computational resources, so that HE clients
contribute noise-free updates while DP clients reduce computational overhead.
Meanwhile, clients with high computational resources clients can flexibly adopt
HE or DP according to their privacy needs. Performance evaluation on omics
datasets show that our proposed method achieves comparable predictive accuracy
while significantly reducing computation time relative to HE-only.
Additionally, it outperforms DP-only methods under equivalent or stricter
privacy budgets.
\\ ( https://arxiv.org/abs/2511.06064 ,  3103kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06078 (*cross-listing*)
Date: Sat, 8 Nov 2025 17:23:13 GMT   (15175kb)

Title: Simulating Students with Large Language Models: A Review of
 Architecture, Mechanisms, and Role Modelling in Education with Generative AI
Authors: Luis Marquez-Carpintero, Alberto Lopez-Sellers, Miguel Cazorla
Categories: cs.CY cs.AI cs.CL
\\
 Simulated Students offer a valuable methodological framework for evaluating
pedagogical approaches and modelling diverse learner profiles, tasks which are
otherwise challenging to undertake systematically in real-world settings.
Recent research has increasingly focused on developing such simulated agents to
capture a range of learning styles, cognitive development pathways, and social
behaviours. Among contemporary simulation techniques, the integration of large
language models (LLMs) into educational research has emerged as a particularly
versatile and scalable paradigm. LLMs afford a high degree of linguistic
realism and behavioural adaptability, enabling agents to approximate cognitive
processes and engage in contextually appropriate pedagogical dialogues. This
paper presents a thematic review of empirical and methodological studies
utilising LLMs to simulate student behaviour across educational environments.
We synthesise current evidence on the capacity of LLM-based agents to emulate
learner archetypes, respond to instructional inputs, and interact within
multi-agent classroom scenarios. Furthermore, we examine the implications of
such systems for curriculum development, instructional evaluation, and teacher
training. While LLMs surpass rule-based systems in natural language generation
and situational flexibility, ongoing concerns persist regarding algorithmic
bias, evaluation reliability, and alignment with educational objectives. The
review identifies existing technological and methodological gaps and proposes
future research directions for integrating generative AI into adaptive learning
systems and instructional design.
\\ ( https://arxiv.org/abs/2511.06078 ,  15175kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06090 (*cross-listing*)
Date: Sat, 8 Nov 2025 17:55:09 GMT   (2552kb)

Title: SWE-fficiency: Can Language Models Optimize Real-World Repositories on
 Real Workloads?
Authors: Jeffrey Jian Ma, Milad Hashemi, Amir Yazdanbakhsh, Kevin Swersky, Ofir
 Press, Enhui Li, Vijay Janapa Reddi, Parthasarathy Ranganathan
Categories: cs.SE cs.AI cs.PF
Comments: Data, code, and leaderboard are available at
 https://swefficiency.com/
\\
 Optimizing the performance of large-scale software repositories demands
expertise in code reasoning and software engineering (SWE) to reduce runtime
while preserving program correctness. However, most benchmarks emphasize what
to fix rather than how to fix code. We introduce \textsc{SWE-fficiency}, a
benchmark for evaluating repository-level performance optimization on real
workloads. Our suite contains 498 tasks across nine widely used data-science,
machine-learning, and HPC repositories (e.g., numpy, pandas, scipy): given a
complete codebase and a slow workload, an agent must investigate code
semantics, localize bottlenecks and relevant tests, and produce a patch that
matches or exceeds expert speedup while passing the same unit tests. To enable
this how-to-fix evaluation, our automated pipeline scrapes GitHub pull requests
for performance-improving edits, combining keyword filtering, static analysis,
coverage tooling, and execution validation to both confirm expert speedup
baselines and identify relevant repository unit tests. Empirical evaluation of
state-of-the-art agents reveals significant underperformance. On average,
agents achieve less than 0.15x the expert speedup: agents struggle in
localizing optimization opportunities, reasoning about execution across
functions, and maintaining correctness in proposed edits. We release the
benchmark and accompanying data pipeline to facilitate research on automated
performance engineering and long-horizon software reasoning.
\\ ( https://arxiv.org/abs/2511.06090 ,  2552kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06148 (*cross-listing*)
Date: Sat, 8 Nov 2025 21:58:26 GMT   (856kb)

Title: Large Language Models Develop Novel Social Biases Through Adaptive
 Exploration
Authors: Addison J. Wu, Ryan Liu, Xuechunzi Bai, Thomas L. Griffiths
Categories: cs.CY cs.AI cs.CL
\\
 As large language models (LLMs) are adopted into frameworks that grant them
the capacity to make real decisions, it is increasingly important to ensure
that they are unbiased. In this paper, we argue that the predominant approach
of simply removing existing biases from models is not enough. Using a paradigm
from the psychology literature, we demonstrate that LLMs can spontaneously
develop novel social biases about artificial demographic groups even when no
inherent differences exist. These biases result in highly stratified task
allocations, which are less fair than assignments by human participants and are
exacerbated by newer and larger models. In social science, emergent biases like
these have been shown to result from exploration-exploitation trade-offs, where
the decision-maker explores too little, allowing early observations to strongly
influence impressions about entire demographic groups. To alleviate this
effect, we examine a series of interventions targeting model inputs, problem
structure, and explicit steering. We find that explicitly incentivizing
exploration most robustly reduces stratification, highlighting the need for
better multifaceted objectives to mitigate bias. These results reveal that LLMs
are not merely passive mirrors of human social biases, but can actively create
new ones from experience, raising urgent questions about how these systems will
shape societies over time.
\\ ( https://arxiv.org/abs/2511.06148 ,  856kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06174 (*cross-listing*)
Date: Sun, 9 Nov 2025 01:17:08 GMT   (4719kb)

Title: LUT-LLM: Efficient Large Language Model Inference with Memory-based
 Computations on FPGAs
Authors: Zifan He, Shengyu Ye, Rui Ma, Yang Wang, Jason Cong
Categories: cs.AR cs.AI
\\
 The rapid progress of large language models (LLMs) has advanced numerous
applications, yet efficient single-batch inference remains vital for on-device
intelligence. While FPGAs offer fine-grained data control and high energy
efficiency, recent GPU optimizations have narrowed their advantage, especially
under arithmetic-based computation. To overcome this, we leverage FPGAs'
abundant on-chip memory to shift LLM inference from arithmetic- to memory-based
computation through table lookups. We present LUT-LLM, the first FPGA
accelerator enabling 1B+ LLM inference via vector-quantized memory operations.
Our analysis identifies activation-weight co-quantization as the most effective
scheme, supported by (1) bandwidth-aware parallel centroid search, (2)
efficient 2D table lookups, and (3) a spatial-temporal hybrid design minimizing
data caching. Implemented on an AMD V80 FPGA for a customized Qwen 3 1.7B
model, LUT-LLM achieves 1.66x lower latency than AMD MI210 and 1.72x higher
energy efficiency than NVIDIA A100, scaling to 32B models with 2.16x efficiency
gain over A100.
\\ ( https://arxiv.org/abs/2511.06174 ,  4719kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06179 (*cross-listing*)
Date: Sun, 9 Nov 2025 01:41:55 GMT   (25kb)

Title: MemoriesDB: A Temporal-Semantic-Relational Database for Long-Term Agent
 Memory / Modeling Experience as a Graph of Temporal-Semantic Surfaces
Authors: Joel Ward ("val")
Categories: cs.DB cs.AI cs.IR
DOI: 10.5281/zenodo.17469799
\\
 We introduce MemoriesDB, a unified data architecture designed to avoid
decoherence across time, meaning, and relation in long-term computational
memory. Each memory is a time-semantic-relational entity-a structure that
simultaneously encodes when an event occurred, what it means, and how it
connects to other events. Built initially atop PostgreSQL with pgvector
extensions, MemoriesDB combines the properties of a time-series datastore, a
vector database, and a graph system within a single append-only schema. Each
memory is represented as a vertex uniquely labeled by its microsecond timestamp
and accompanied by low- and high-dimensional normalized embeddings that capture
semantic context. Directed edges between memories form labeled relations with
per-edge metadata, enabling multiple contextual links between the same
vertices. Together these constructs form a time-indexed stack of
temporal-semantic surfaces, where edges project as directional arrows in a
1+1-dimensional similarity field, tracing the evolution of meaning through time
while maintaining cross-temporal coherence. This formulation supports efficient
time-bounded retrieval, hybrid semantic search, and lightweight structural
reasoning in a single query path. A working prototype demonstrates scalable
recall and contextual reinforcement using standard relational infrastructure,
and we discuss extensions toward a columnar backend, distributed clustering,
and emergent topic modeling.
\\ ( https://arxiv.org/abs/2511.06179 ,  25kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06195 (*cross-listing*)
Date: Sun, 9 Nov 2025 02:45:19 GMT   (2650kb)

Title: AI as intermediary in modern-day ritual: An immersive, interactive
 production of the roller disco musical Xanadu at UCLA
Authors: Mira Winick, Naisha Agarwal, Chiheb Boussema, Ingrid Lee, Camilo
 Vargas, Jeff Burke
Categories: cs.HC cs.AI
\\
 Interfaces for contemporary large language, generative media, and perception
AI models are often engineered for single user interaction. We investigate
ritual as a design scaffold for developing collaborative, multi-user human-AI
engagement. We consider the specific case of an immersive staging of the
musical Xanadu performed at UCLA in Spring 2025. During a two-week run, over
five hundred audience members contributed sketches and jazzercise moves that
vision language models translated to virtual scenery elements and from
choreographic prompts. This paper discusses four facets of
interaction-as-ritual within the show: audience input as offerings that AI
transforms into components of the ritual; performers as ritual guides,
demonstrating how to interact with technology and sorting audience members into
cohorts; AI systems as instruments "played" by the humans, in which sensing,
generative components, and stagecraft create systems that can be mastered over
time; and reciprocity of interaction, in which the show's AI machinery guides
human behavior as well as being guided by humans, completing a human-AI
feedback loop that visibly reshapes the virtual world. Ritual served as a frame
for integrating linear narrative, character identity, music and interaction.
The production explored how AI systems can support group creativity and play,
addressing a critical gap in prevailing single user AI design paradigms.
\\ ( https://arxiv.org/abs/2511.06195 ,  2650kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06197 (*cross-listing*)
Date: Sun, 9 Nov 2025 02:56:54 GMT   (462kb)

Title: Enhancing Adversarial Robustness of IoT Intrusion Detection via
 SHAP-Based Attribution Fingerprinting
Authors: Dilli Prasad Sharma, Liang Xue, Xiaowei Sun, Xiaodong Lin, Pulei Xiong
Categories: cs.CR cs.AI cs.CL cs.LG cs.NI
ACM-class: I.2; I.2.6; I.2.7; I.1.1; C.2.2; C.2.6; B.8.1; B.8.2
\\
 The rapid proliferation of Internet of Things (IoT) devices has transformed
numerous industries by enabling seamless connectivity and data-driven
automation. However, this expansion has also exposed IoT networks to
increasingly sophisticated security threats, including adversarial attacks
targeting artificial intelligence (AI) and machine learning (ML)-based
intrusion detection systems (IDS) to deliberately evade detection, induce
misclassification, and systematically undermine the reliability and integrity
of security defenses. To address these challenges, we propose a novel
adversarial detection model that enhances the robustness of IoT IDS against
adversarial attacks through SHapley Additive exPlanations (SHAP)-based
fingerprinting. Using SHAP's DeepExplainer, we extract attribution fingerprints
from network traffic features, enabling the IDS to reliably distinguish between
clean and adversarially perturbed inputs. By capturing subtle attribution
patterns, the model becomes more resilient to evasion attempts and adversarial
manipulations. We evaluated the model on a standard IoT benchmark dataset,
where it significantly outperformed a state-of-the-art method in detecting
adversarial attacks. In addition to enhanced robustness, this approach improves
model transparency and interpretability, thereby increasing trust in the IDS
through explainable AI.
\\ ( https://arxiv.org/abs/2511.06197 ,  462kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06212 (*cross-listing*)
Date: Sun, 9 Nov 2025 03:50:17 GMT   (1638kb)

Title: RAG-targeted Adversarial Attack on LLM-based Threat Detection and
 Mitigation Framework
Authors: Seif Ikbarieh, Kshitiz Aryal, Maanak Gupta
Categories: cs.CR cs.AI
\\
 The rapid expansion of the Internet of Things (IoT) is reshaping
communication and operational practices across industries, but it also broadens
the attack surface and increases susceptibility to security breaches.
Artificial Intelligence has become a valuable solution in securing IoT
networks, with Large Language Models (LLMs) enabling automated attack behavior
analysis and mitigation suggestion in Network Intrusion Detection Systems
(NIDS). Despite advancements, the use of LLMs in such systems further expands
the attack surface, putting entire networks at risk by introducing
vulnerabilities such as prompt injection and data poisoning. In this work, we
attack an LLM-based IoT attack analysis and mitigation framework to test its
adversarial robustness. We construct an attack description dataset and use it
in a targeted data poisoning attack that applies word-level, meaning-preserving
perturbations to corrupt the Retrieval-Augmented Generation (RAG) knowledge
base of the framework. We then compare pre-attack and post-attack mitigation
responses from the target model, ChatGPT-5 Thinking, to measure the impact of
the attack on model performance, using an established evaluation rubric
designed for human experts and judge LLMs. Our results show that small
perturbations degrade LLM performance by weakening the linkage between observed
network traffic features and attack behavior, and by reducing the specificity
and practicality of recommended mitigations for resource-constrained devices.
\\ ( https://arxiv.org/abs/2511.06212 ,  1638kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06227 (*cross-listing*)
Date: Sun, 9 Nov 2025 04:58:32 GMT   (709kb)

Title: Assertion-Aware Test Code Summarization with Large Language Models
Authors: Anamul Haque Mollah, Ahmed Aljohani, Hyunsook Do
Categories: cs.SE cs.AI cs.CE
Comments: Accepted for publication at 2nd ACM International Conference on
 AI-powered Software (AIware 2025)
\\
 Unit tests often lack concise summaries that convey test intent, especially
in auto-generated or poorly documented codebases. Large Language Models (LLMs)
offer a promising solution, but their effectiveness depends heavily on how they
are prompted. Unlike generic code summarization, test-code summarization poses
distinct challenges because test methods validate expected behavior through
assertions rather than im- plementing functionality. This paper presents a new
benchmark of 91 real-world Java test cases paired with developer-written
summaries and conducts a controlled ablation study to investigate how test
code-related components-such as the method under test (MUT), assertion
messages, and assertion semantics-affect the performance of LLM-generated test
summaries. We evaluate four code LLMs (Codex, Codestral, DeepSeek, and
Qwen-Coder) across seven prompt configurations using n-gram metrics (BLEU,
ROUGE-L, METEOR), semantic similarity (BERTScore), and LLM-based evaluation.
Results show that prompting with as- sertion semantics improves summary quality
by an average of 0.10 points (2.3%) over full MUT context (4.45 vs. 4.35) while
requiring fewer input tokens. Codex and Qwen-Coder achieve the highest
alignment with human-written summaries, while DeepSeek underperforms despite
high lexical overlap. The replication package is publicly available at
https://doi.org/10. 5281/zenodo.17067550
\\ ( https://arxiv.org/abs/2511.06227 ,  709kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06240 (*cross-listing*)
Date: Sun, 9 Nov 2025 05:52:22 GMT   (12077kb)

Title: Affordance-Guided Coarse-to-Fine Exploration for Base Placement in
 Open-Vocabulary Mobile Manipulation
Authors: Tzu-Jung Lin, Jia-Fong Yeh, Hung-Ting Su, Chung-Yi Lin, Yi-Ting Chen,
 Winston H. Hsu
Categories: cs.RO cs.AI
Comments: Accepted to AAAI 2026
\\
 In open-vocabulary mobile manipulation (OVMM), task success often hinges on
the selection of an appropriate base placement for the robot. Existing
approaches typically navigate to proximity-based regions without considering
affordances, resulting in frequent manipulation failures. We propose
Affordance-Guided Coarse-to-Fine Exploration, a zero-shot framework for base
placement that integrates semantic understanding from vision-language models
(VLMs) with geometric feasibility through an iterative optimization process.
Our method constructs cross-modal representations, namely Affordance RGB and
Obstacle Map+, to align semantics with spatial context. This enables reasoning
that extends beyond the egocentric limitations of RGB perception. To ensure
interaction is guided by task-relevant affordances, we leverage coarse semantic
priors from VLMs to guide the search toward task-relevant regions and refine
placements with geometric constraints, thereby reducing the risk of convergence
to local optima. Evaluated on five diverse open-vocabulary mobile manipulation
tasks, our system achieves an 85% success rate, significantly outperforming
classical geometric planners and VLM-based methods. This demonstrates the
promise of affordance-aware and multimodal reasoning for generalizable,
instruction-conditioned planning in OVMM.
\\ ( https://arxiv.org/abs/2511.06240 ,  12077kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06251 (*cross-listing*)
Date: Sun, 9 Nov 2025 06:58:52 GMT   (30688kb)

Title: WebVIA: A Web-based Vision-Language Agentic Framework for Interactive
 and Verifiable UI-to-Code Generation
Authors: Mingde Xu, Zhen Yang, Wenyi Hong, Lihang Pan, Xinyue Fan, Yan Wang,
 Xiaotao Gu, Bin Xu, Jie Tang
Categories: cs.SE cs.AI
Comments: 36 pages, 30 figures
\\
 User interface (UI) development requires translating design mockups into
functional code, a process that remains repetitive and labor-intensive. While
recent Vision-Language Models (VLMs) automate UI-to-Code generation, they
generate only static HTML/CSS/JavaScript layouts lacking interactivity. To
address this, we propose WebVIA, the first agentic framework for interactive
UI-to-Code generation and validation. The framework comprises three components:
1) an exploration agent to capture multi-state UI screenshots; 2) a UI2Code
model that generates executable interactive code; 3) a validation module that
verifies the interactivity. Experiments demonstrate that WebVIA-Agent achieves
more stable and accurate UI exploration than general-purpose agents (e.g.,
Gemini-2.5-Pro). In addition, our fine-tuned WebVIA-UI2Code models exhibit
substantial improvements in generating executable and interactive
HTML/CSS/JavaScript code, outperforming their base counterparts across both
interactive and static UI2Code benchmarks. Our code and models are available at
\href{https://zheny2751-dotcom.github.io/webvia.github.io/}{\texttt{https://webvia.github.io}}.
\\ ( https://arxiv.org/abs/2511.06251 ,  30688kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06260 (*cross-listing*)
Date: Sun, 9 Nov 2025 07:36:46 GMT   (353kb)

Title: LLM-Guided Reinforcement Learning with Representative Agents for Traffic
 Modeling
Authors: Hanlin Sun and Jiayang Li
Categories: cs.GT cs.AI cs.SY eess.SY
\\
 Large language models (LLMs) are increasingly used as behavioral proxies for
self-interested travelers in agent-based traffic models. Although more flexible
and generalizable than conventional models, the practical use of these
approaches remains limited by scalability due to the cost of calling one LLM
for every traveler. Moreover, it has been found that LLM agents often make
opaque choices and produce unstable day-to-day dynamics. To address these
challenges, we propose to model each homogeneous traveler group facing the same
decision context with a single representative LLM agent who behaves like the
population's average, maintaining and updating a mixed strategy over routes
that coincides with the group's aggregate flow proportions. Each day, the LLM
reviews the travel experience and flags routes with positive reinforcement that
they hope to use more often, and an interpretable update rule then converts
this judgment into strategy adjustments using a tunable (progressively
decaying) step size. The representative-agent design improves scalability,
while the separation of reasoning from updating clarifies the decision logic
while stabilizing learning. In classic traffic assignment settings, we find
that the proposed approach converges rapidly to the user equilibrium. In richer
settings with income heterogeneity, multi-criteria costs, and multi-modal
choices, the generated dynamics remain stable and interpretable, reproducing
plausible behavioral patterns well-documented in psychology and economics, for
example, the decoy effect in toll versus non-toll road selection, and higher
willingness-to-pay for convenience among higher-income travelers when choosing
between driving, transit, and park-and-ride options.
\\ ( https://arxiv.org/abs/2511.06260 ,  353kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06297 (*cross-listing*)
Date: Sun, 9 Nov 2025 09:28:51 GMT   (382kb)

Title: Decomate: Leveraging Generative Models for Co-Creative SVG Animation
Authors: Jihyeon Park, Jiyoon Myung, Seone Shin, Jungki Son, Joohyung Han
Categories: cs.HC cs.AI
Comments: Accepted at the 1st Workshop on Generative and Protective AI for
 Content Creation (NeurIPS 2025)
\\
 Designers often encounter friction when animating static SVG graphics,
especially when the visual structure does not match the desired level of motion
detail. Existing tools typically depend on predefined groupings or require
technical expertise, which limits designers' ability to experiment and iterate
independently. We present Decomate, a system that enables intuitive SVG
animation through natural language. Decomate leverages a multimodal large
language model to restructure raw SVGs into semantically meaningful,
animation-ready components. Designers can then specify motions for each
component via text prompts, after which the system generates corresponding
HTML/CSS/JS animations. By supporting iterative refinement through natural
language interaction, Decomate integrates generative AI into creative
workflows, allowing animation outcomes to be directly shaped by user intent.
\\ ( https://arxiv.org/abs/2511.06297 ,  382kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06313 (*cross-listing*)
Date: Sun, 9 Nov 2025 10:24:17 GMT   (853kb)

Title: Precision-Scalable Microscaling Datapaths with Optimized Reduction Tree
 for Efficient NPU Integration
Authors: Stef Cuyckens, Xiaoling Yi, Robin Geens, Joren Dumoulin, Martin
 Wiesner, Chao Fang, Marian Verhelst
Categories: cs.AR cs.AI cs.LG eess.SP
Comments: To appear in the 31st Asia and South Pacific Design Automation
 Conference (ASP-DAC 2026, Invited Paper)
\\
 Emerging continual learning applications necessitate next-generation neural
processing unit (NPU) platforms to support both training and inference
operations. The promising Microscaling (MX) standard enables narrow bit-widths
for inference and large dynamic ranges for training. However, existing MX
multiply-accumulate (MAC) designs face a critical trade-off: integer
accumulation requires expensive conversions from narrow floating-point
products, while FP32 accumulation suffers from quantization losses and costly
normalization. To address these limitations, we propose a hybrid
precision-scalable reduction tree for MX MACs that combines the benefits of
both approaches, enabling efficient mixed-precision accumulation with
controlled accuracy relaxation. Moreover, we integrate an 8x8 array of these
MACs into the state-of-the-art (SotA) NPU integration platform, SNAX, to
provide efficient control and data transfer to our optimized precision-scalable
MX datapath. We evaluate our design both on MAC and system level and compare it
to the SotA. Our integrated system achieves an energy efficiency of 657,
1438-1675, and 4065 GOPS/W, respectively, for MXINT8, MXFP8/6, and MXFP4, with
a throughput of 64, 256, and 512 GOPS.
\\ ( https://arxiv.org/abs/2511.06313 ,  853kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06345 (*cross-listing*)
Date: Sun, 9 Nov 2025 12:01:43 GMT   (190kb)

Title: PRAGMA: A Profiling-Reasoned Multi-Agent Framework for Automatic Kernel
 Optimization
Authors: Kelun Lei, Hailong Yang, Huaitao Zhang, Xin You, Kaige Zhang, Zhongzhi
 Luan, Yi Liu, Depei Qian
Categories: cs.DC cs.AI
\\
 Designing high-performance kernels requires expert-level tuning and a deep
understanding of hardware characteristics. Recent advances in large language
models (LLMs) have enabled automated kernel generation, yet most existing
systems rely solely on correctness or execution time feedback, lacking the
ability to reason about low-level performance bottlenecks. In this paper, we
introduce PRAGMA, a profile-guided AI kernel generation framework that
integrates execution feedback and fine-grained hardware profiling into the
reasoning loop. PRAGMA enables LLMs to identify performance bottlenecks,
preserve historical best versions, and iteratively refine code quality. We
evaluate PRAGMA on KernelBench, covering GPU and CPU backends. Results show
that PRAGMA consistently outperforms baseline AIKG without profiling enabled
and achieves 2.81$\times$ and 2.30$\times$ averaged speedups against Torch on
CPU and GPU platforms, respectively.
\\ ( https://arxiv.org/abs/2511.06345 ,  190kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06361 (*cross-listing*)
Date: Sun, 9 Nov 2025 12:46:29 GMT   (52kb)

Title: A Graph-Theoretical Perspective on Law Design for Multiagent Systems
Authors: Qi Shi, Pavel Naumov
Categories: cs.MA cs.AI cs.GT
Comments: The 40th AAAI Conference on Artificial Intelligence (AAAI-26)
\\
 A law in a multiagent system is a set of constraints imposed on agents'
behaviours to avoid undesirable outcomes. The paper considers two types of
laws: useful laws that, if followed, completely eliminate the undesirable
outcomes and gap-free laws that guarantee that at least one agent can be held
responsible each time an undesirable outcome occurs. In both cases, we study
the problem of finding a law that achieves the desired result by imposing the
minimum restrictions.
 We prove that, for both types of laws, the minimisation problem is NP-hard
even in the simple case of one-shot concurrent interactions. We also show that
the approximation algorithm for the vertex cover problem in hypergraphs could
be used to efficiently approximate the minimum laws in both cases.
\\ ( https://arxiv.org/abs/2511.06361 ,  52kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06362 (*cross-listing*)
Date: Sun, 9 Nov 2025 12:56:34 GMT   (172kb)

Title: Understanding Student Interaction with AI-Powered Next-Step Hints:
 Strategies and Challenges
Authors: Anastasiia Birillo, Aleksei Rostovskii, Yaroslav Golubev, Hieke
 Keuning
Categories: cs.SE cs.AI cs.CY
Comments: Accepted to SIGCSE'26. 7 pages, 3 figures
DOI: 10.1145/3770762.3772544
\\
 Automated feedback generation plays a crucial role in enhancing personalized
learning experiences in computer science education. Among different types of
feedback, next-step hint feedback is particularly important, as it provides
students with actionable steps to progress towards solving programming tasks.
This study investigates how students interact with an AI-driven next-step hint
system in an in-IDE learning environment. We gathered and analyzed a dataset
from 34 students solving Kotlin tasks, containing detailed hint interaction
logs. We applied process mining techniques and identified 16 common interaction
scenarios. Semi-structured interviews with 6 students revealed strategies for
managing unhelpful hints, such as adapting partial hints or modifying code to
generate variations of the same hint. These findings, combined with our
publicly available dataset, offer valuable opportunities for future research
and provide key insights into student behavior, helping improve hint design for
enhanced learning support.
\\ ( https://arxiv.org/abs/2511.06362 ,  172kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06390 (*cross-listing*)
Date: Sun, 9 Nov 2025 13:57:59 GMT   (371kb)

Title: Ghost in the Transformer: Tracing LLM Lineage with SVD-Fingerprint
Authors: Suqing Wang, Ziyang Ma, Xinyi Li, Zuchao Li
Categories: cs.CR cs.AI
Comments: Accepted at AAAI 2026 (Oral)
\\
 Large Language Models (LLMs) have rapidly advanced and are widely adopted
across diverse fields. Due to the substantial computational cost and data
requirements of training from scratch, many developers choose to fine-tune or
modify existing open-source models. While most adhere to open-source licenses,
some falsely claim original training despite clear derivation from public
models. This raises pressing concerns about intellectual property protection
and highlights the need for reliable methods to verify model provenance. In
this paper, we propose GhostSpec, a lightweight yet effective method for
verifying LLM lineage without access to training data or modification of model
behavior. Our approach constructs compact and robust fingerprints by applying
singular value decomposition (SVD) to invariant products of internal attention
weight matrices, effectively capturing the structural identity of a model.
Unlike watermarking or output-based methods, GhostSpec is fully data-free,
non-invasive, and computationally efficient. It demonstrates strong robustness
to sequential fine-tuning, pruning, block expansion, and even adversarial
transformations. Extensive experiments show that GhostSpec can reliably trace
the lineage of transformed models with minimal overhead. By offering a
practical solution for model verification and reuse tracking, our method
contributes to the protection of intellectual property and fosters a
transparent, trustworthy ecosystem for large-scale language models.
\\ ( https://arxiv.org/abs/2511.06390 ,  371kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06424 (*cross-listing*)
Date: Sun, 9 Nov 2025 15:41:27 GMT   (11773kb)

Title: Turbo-DDCM: Fast and Flexible Zero-Shot Diffusion-Based Image
 Compression
Authors: Amit Vaisman, Guy Ohayon, Hila Manor, Michael Elad, Tomer Michaeli
Categories: eess.IV cs.AI cs.CV eess.SP stat.ML
Comments: Code is available at https://amitvaisman.github.io/turbo_ddcm/
\\
 While zero-shot diffusion-based compression methods have seen significant
progress in recent years, they remain notoriously slow and computationally
demanding. This paper presents an efficient zero-shot diffusion-based
compression method that runs substantially faster than existing methods, while
maintaining performance that is on par with the state-of-the-art techniques.
Our method builds upon the recently proposed Denoising Diffusion Codebook
Models (DDCMs) compression scheme. Specifically, DDCM compresses an image by
sequentially choosing the diffusion noise vectors from reproducible random
codebooks, guiding the denoiser's output to reconstruct the target image. We
modify this framework with Turbo-DDCM, which efficiently combines a large
number of noise vectors at each denoising step, thereby significantly reducing
the number of required denoising operations. This modification is also coupled
with an improved encoding protocol. Furthermore, we introduce two flexible
variants of Turbo-DDCM, a priority-aware variant that prioritizes
user-specified regions and a distortion-controlled variant that compresses an
image based on a target PSNR rather than a target BPP. Comprehensive
experiments position Turbo-DDCM as a compelling, practical, and flexible image
compression scheme.
\\ ( https://arxiv.org/abs/2511.06424 ,  11773kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06428 (*cross-listing*)
Date: Sun, 9 Nov 2025 15:49:55 GMT   (4631kb)

Title: Walking the Tightrope of LLMs for Software Development: A Practitioners'
 Perspective
Authors: Samuel Ferino, Rashina Hoda, John Grundy, Christoph Treude
Categories: cs.SE cs.AI
\\
 Background: Large Language Models emerged with the potential of provoking a
revolution in software development (e.g., automating processes, workforce
transformation). Although studies have started to investigate the perceived
impact of LLMs for software development, there is a need for empirical studies
to comprehend how to balance forward and backward effects of using LLMs.
Objective: We investigated how LLMs impact software development and how to
manage the impact from a software developer's perspective. Method: We conducted
22 interviews with software practitioners across 3 rounds of data collection
and analysis, between October (2024) and September (2025). We employed
socio-technical grounded theory (STGT) for data analysis to rigorously analyse
interview participants' responses. Results: We identified the benefits (e.g.,
maintain software development flow, improve developers' mental model, and
foster entrepreneurship) and disadvantages (e.g., negative impact on
developers' personality and damage to developers' reputation) of using LLMs at
individual, team, organisation, and society levels; as well as best practices
on how to adopt LLMs. Conclusion: Critically, we present the trade-offs that
software practitioners, teams, and organisations face in working with LLMs. Our
findings are particularly useful for software team leaders and IT managers to
assess the viability of LLMs within their specific context.
\\ ( https://arxiv.org/abs/2511.06428 ,  4631kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06447 (*cross-listing*)
Date: Sun, 9 Nov 2025 16:28:55 GMT   (2156kb)

Title: Personality over Precision: Exploring the Influence of Human-Likeness on
 ChatGPT Use for Search
Authors: Mert Yazan, Frederik Bungaran Ishak Situmeang, Suzan Verberne
Categories: cs.HC cs.AI
Comments: Accepted at NIP-IR@SIGIR'25
\\
 Conversational search interfaces, like ChatGPT, offer an interactive,
personalized, and engaging user experience compared to traditional search. On
the downside, they are prone to cause overtrust issues where users rely on
their responses even when they are incorrect. What aspects of the
conversational interaction paradigm drive people to adopt it, and how it
creates personalized experiences that lead to overtrust, is not clear. To
understand the factors influencing the adoption of conversational interfaces,
we conducted a survey with 173 participants. We examined user perceptions
regarding trust, human-likeness (anthropomorphism), and design preferences
between ChatGPT and Google. To better understand the overtrust phenomenon, we
asked users about their willingness to trade off factuality for constructs like
ease of use or human-likeness. Our analysis identified two distinct user
groups: those who use both ChatGPT and Google daily (DUB), and those who
primarily rely on Google (DUG). The DUB group exhibited higher trust in
ChatGPT, perceiving it as more human-like, and expressed greater willingness to
trade factual accuracy for enhanced personalization and conversational flow.
Conversely, the DUG group showed lower trust toward ChatGPT but still
appreciated aspects like ad-free experiences and responsive interactions.
Demographic analysis further revealed nuanced patterns, with middle-aged adults
using ChatGPT less frequently yet trusting it more, suggesting potential
vulnerability to misinformation. Our findings contribute to understanding user
segmentation, emphasizing the critical roles of personalization and
human-likeness in conversational IR systems, and reveal important implications
regarding users' willingness to compromise factual accuracy for more engaging
interactions.
\\ ( https://arxiv.org/abs/2511.06447 ,  2156kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06448 (*cross-listing*)
Date: Sun, 9 Nov 2025 16:30:44 GMT   (1301kb)

Title: When AI Agents Collude Online: Financial Fraud Risks by Collaborative
 LLM Agents on Social Platforms
Authors: Qibing Ren, Zhijie Zheng, Jiaxuan Guo, Junchi Yan, Lizhuang Ma, Jing
 Shao
Categories: cs.MA cs.AI cs.CL cs.SI
Comments: Code is available at https://github.com/zheng977/MutiAgent4Fraud
\\
 In this work, we study the risks of collective financial fraud in large-scale
multi-agent systems powered by large language model (LLM) agents. We
investigate whether agents can collaborate in fraudulent behaviors, how such
collaboration amplifies risks, and what factors influence fraud success. To
support this research, we present MultiAgentFraudBench, a large-scale benchmark
for simulating financial fraud scenarios based on realistic online
interactions. The benchmark covers 28 typical online fraud scenarios, spanning
the full fraud lifecycle across both public and private domains. We further
analyze key factors affecting fraud success, including interaction depth,
activity level, and fine-grained collaboration failure modes. Finally, we
propose a series of mitigation strategies, including adding content-level
warnings to fraudulent posts and dialogues, using LLMs as monitors to block
potentially malicious agents, and fostering group resilience through
information sharing at the societal level. Notably, we observe that malicious
agents can adapt to environmental interventions. Our findings highlight the
real-world risks of multi-agent financial fraud and suggest practical measures
for mitigating them. Code is available at
https://github.com/zheng977/MutiAgent4Fraud.
\\ ( https://arxiv.org/abs/2511.06448 ,  1301kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06455 (*cross-listing*)
Date: Sun, 9 Nov 2025 16:41:46 GMT   (100kb)

Title: A Multi-Agent System for Semantic Mapping of Relational Data to
 Knowledge Graphs
Authors: Milena Trajanoska, Riste Stojanov, and Dimitar Trajanov
Categories: cs.DB cs.AI
Comments: The 1st GOBLIN Workshop on Knowledge Graph Technologies
 https://www.dbpedia.org/events/goblin25-workshop/
Journal-ref: The 1st GOBLIN Workshop on Knowledge Graph Technologies, June 12,
 2025 in Leipzig, Germany
DOI: 10.5281/zenodo.16913321
\\
 Enterprises often maintain multiple databases for storing critical business
data in siloed systems, resulting in inefficiencies and challenges with data
interoperability. A key to overcoming these challenges lies in integrating
disparate data sources, enabling businesses to unlock the full potential of
their data. Our work presents a novel approach for integrating multiple
databases using knowledge graphs, focusing on the application of large language
models as semantic agents for mapping and connecting structured data across
systems by leveraging existing vocabularies. The proposed methodology
introduces a semantic layer above tables in relational databases, utilizing a
system comprising multiple LLM agents that map tables and columns to Schema.org
terms. Our approach achieves a mapping accuracy of over 90% in multiple
domains.
\\ ( https://arxiv.org/abs/2511.06455 ,  100kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06458 (*cross-listing*)
Date: Sun, 9 Nov 2025 16:53:32 GMT   (1995kb)

Title: EchoMark: Perceptual Acoustic Environment Transfer with
 Watermark-Embedded Room Impulse Response
Authors: Chenpei Huang, Lingfeng Yao, Kyu In Lee, Lan Emily Zhang, Xun Chen,
 Miao Pan
Categories: cs.SD cs.AI cs.LG eess.AS
\\
 Acoustic Environment Matching (AEM) is the task of transferring clean audio
into a target acoustic environment, enabling engaging applications such as
audio dubbing and auditory immersive virtual reality (VR). Recovering similar
room impulse response (RIR) directly from reverberant speech offers more
accessible and flexible AEM solution. However, this capability also introduces
vulnerabilities of arbitrary ``relocation" if misused by malicious user, such
as facilitating advanced voice spoofing attacks or undermining the authenticity
of recorded evidence. To address this issue, we propose EchoMark, the first
deep learning-based AEM framework that generates perceptually similar RIRs with
embedded watermark. Our design tackle the challenges posed by variable RIR
characteristics, such as different durations and energy decays, by operating in
the latent domain. By jointly optimizing the model with a perceptual loss for
RIR reconstruction and a loss for watermark detection, EchoMark achieves both
high-quality environment transfer and reliable watermark recovery. Experiments
on diverse datasets validate that EchoMark achieves room acoustic parameter
matching performance comparable to FiNS, the state-of-the-art RIR estimator.
Furthermore, a high Mean Opinion Score (MOS) of 4.22 out of 5, watermark
detection accuracy exceeding 99\%, and bit error rates (BER) below 0.3\%
collectively demonstrate the effectiveness of EchoMark in preserving perceptual
quality while ensuring reliable watermark embedding.
\\ ( https://arxiv.org/abs/2511.06458 ,  1995kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06496 (*cross-listing*)
Date: Sun, 9 Nov 2025 18:50:30 GMT   (5235kb)

Title: A Low-Rank Method for Vision Language Model Hallucination Mitigation in
 Autonomous Driving
Authors: Keke Long, Jiacheng Guo, Tianyun Zhang, Hongkai Yu, Xiaopeng Li
Categories: cs.RO cs.AI cs.CV
\\
 Vision Language Models (VLMs) are increasingly used in autonomous driving to
help understand traffic scenes, but they sometimes produce hallucinations,
which are false details not grounded in the visual input. Detecting and
mitigating hallucinations is challenging when ground-truth references are
unavailable and model internals are inaccessible. This paper proposes a novel
self-contained low-rank approach to automatically rank multiple candidate
captions generated by multiple VLMs based on their hallucination levels, using
only the captions themselves without requiring external references or model
access. By constructing a sentence-embedding matrix and decomposing it into a
low-rank consensus component and a sparse residual, we use the residual
magnitude to rank captions: selecting the one with the smallest residual as the
most hallucination-free. Experiments on the NuScenes dataset demonstrate that
our approach achieves 87% selection accuracy in identifying hallucination-free
captions, representing a 19% improvement over the unfiltered baseline and a
6-10% improvement over multi-agent debate method. The sorting produced by
sparse error magnitudes shows strong correlation with human judgments of
hallucinations, validating our scoring mechanism. Additionally, our method,
which can be easily parallelized, reduces inference time by 51-67% compared to
debate approaches, making it practical for real-time autonomous driving
applications.
\\ ( https://arxiv.org/abs/2511.06496 ,  5235kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06519 (*cross-listing*)
Date: Sun, 9 Nov 2025 20:08:21 GMT   (121kb)

Title: On the Analogy between Human Brain and LLMs: Spotting Key Neurons in
 Grammar Perception
Authors: Sanaz Saki Norouzi, Mohammad Masjedi, Pascal Hitzler
Categories: q-bio.NC cs.AI cs.CL
\\
 Artificial Neural Networks, the building blocks of AI, were inspired by the
human brain's network of neurons. Over the years, these networks have evolved
to replicate the complex capabilities of the brain, allowing them to handle
tasks such as image and language processing. In the realm of Large Language
Models, there has been a keen interest in making the language learning process
more akin to that of humans. While neuroscientific research has shown that
different grammatical categories are processed by different neurons in the
brain, we show that LLMs operate in a similar way. Utilizing Llama 3, we
identify the most important neurons associated with the prediction of words
belonging to different part-of-speech tags. Using the achieved knowledge, we
train a classifier on a dataset, which shows that the activation patterns of
these key neurons can reliably predict part-of-speech tags on fresh data. The
results suggest the presence of a subspace in LLMs focused on capturing
part-of-speech tag concepts, resembling patterns observed in lesion studies of
the brain in neuroscience.
\\ ( https://arxiv.org/abs/2511.06519 ,  121kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06552 (*cross-listing*)
Date: Sun, 9 Nov 2025 21:47:45 GMT   (894kb)

Title: LLM For Loop Invariant Generation and Fixing: How Far Are We?
Authors: Mostafijur Rahman Akhond, Saikat Chakraborty, and Gias Uddin
Categories: cs.SE cs.AI
Comments: This work has been submitted to the IEEE for possible publication
\\
 A loop invariant is a property of a loop that remains true before and after
each execution of the loop. The identification of loop invariants is a critical
step to support automated program safety assessment. Recent advancements in
Large Language Models (LLMs) have demonstrated potential in diverse software
engineering (SE) and formal verification tasks. However, we are not aware of
the performance of LLMs to infer loop invariants. We report an empirical study
of both open-source and closed-source LLMs of varying sizes to assess their
proficiency in inferring inductive loop invariants for programs and in fixing
incorrect invariants. Our findings reveal that while LLMs exhibit some utility
in inferring and repairing loop invariants, their performance is substantially
enhanced when supplemented with auxiliary information such as domain knowledge
and illustrative examples. LLMs achieve a maximum success rate of 78\% in
generating, but are limited to 16\% in repairing the invariant.
\\ ( https://arxiv.org/abs/2511.06552 ,  894kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06573 (*cross-listing*)
Date: Sun, 9 Nov 2025 23:31:53 GMT   (8749kb)

Title: SteganoSNN: SNN-Based Audio-in-Image Steganography with Encryption
Authors: Biswajit Kumar Sahoo, Pedro Machado, Isibor Kennedy Ihianle, Andreas
 Oikonomou, Srinivas Boppu
Categories: cs.CR cs.AI
\\
 Secure data hiding remains a fundamental challenge in digital communication,
requiring a careful balance between computational efficiency and perceptual
transparency. The balance between security and performance is increasingly
fragile with the emergence of generative AI systems capable of autonomously
generating and optimising sophisticated cryptanalysis and steganalysis
algorithms, thereby accelerating the exposure of vulnerabilities in
conventional data-hiding schemes.
 This work introduces SteganoSNN, a neuromorphic steganographic framework that
exploits spiking neural networks (SNNs) to achieve secure, low-power, and
high-capacity multimedia data hiding. Digitised audio samples are converted
into spike trains using leaky integrate-and-fire (LIF) neurons, encrypted via a
modulo-based mapping scheme, and embedded into the least significant bits of
RGBA image channels using a dithering mechanism to minimise perceptual
distortion. Implemented in Python using NEST and realised on a PYNQ-Z2 FPGA,
SteganoSNN attains real-time operation with an embedding capacity of 8 bits per
pixel. Experimental evaluations on the DIV2K 2017 dataset demonstrate image
fidelity between 40.4 dB and 41.35 dB in PSNR and SSIM values consistently
above 0.97, surpassing SteganoGAN in computational efficiency and robustness.
SteganoSNN establishes a foundation for neuromorphic steganography, enabling
secure, energy-efficient communication for Edge-AI, IoT, and biomedical
applications.
\\ ( https://arxiv.org/abs/2511.06573 ,  8749kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06575 (*cross-listing*)
Date: Sun, 9 Nov 2025 23:38:25 GMT   (12150kb)

Title: CoFineLLM: Conformal Finetuning of LLMs for Language-Instructed Robot
 Planning
Authors: Jun Wang, Yevgeniy Vorobeychik, Yiannis Kantaros
Categories: cs.RO cs.AI cs.LG
\\
 Large Language Models (LLMs) have recently emerged as planners for
language-instructed agents, generating sequences of actions to accomplish
natural language tasks. However, their reliability remains a challenge,
especially in long-horizon tasks, since they often produce overconfident yet
wrong outputs. Conformal Prediction (CP) has been leveraged to address this
issue by wrapping LLM outputs into prediction sets that contain the correct
action with a user-defined confidence. When the prediction set is a singleton,
the planner executes that action; otherwise, it requests help from a user. This
has led to LLM-based planners that can ensure plan correctness with a
user-defined probability. However, as LLMs are trained in an
uncertainty-agnostic manner, without awareness of prediction sets, they tend to
produce unnecessarily large sets, particularly at higher confidence levels,
resulting in frequent human interventions limiting autonomous deployment. To
address this, we introduce CoFineLLM (Conformal Finetuning for LLMs), the first
CP-aware finetuning framework for LLM-based planners that explicitly reduces
prediction-set size and, in turn, the need for user interventions. We evaluate
our approach on multiple language-instructed robot planning problems and show
consistent improvements over uncertainty-aware and uncertainty-agnostic
finetuning baselines in terms of prediction-set size, and help rates. Finally,
we demonstrate robustness of our method to out-of-distribution scenarios in
hardware experiments.
\\ ( https://arxiv.org/abs/2511.06575 ,  12150kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06606 (*cross-listing*)
Date: Mon, 10 Nov 2025 01:29:26 GMT   (2961kb)

Title: SPUR: A Plug-and-Play Framework for Integrating Spatial Audio
 Understanding and Reasoning into Large Audio-Language Models
Authors: S Sakshi and Vaibhavi Lokegaonkar and Neil Zhang and Ramani Duraiswami
 and Sreyan Ghosh and Dinesh Manocha and Lie Lu
Categories: eess.AS cs.AI
Comments: Project: https://sakshi113.github.io/spur/
\\
 Spatial perception is central to auditory intelligence, enabling accurate
understanding of real-world acoustic scenes and advancing human-level
perception of the world around us. While recent large audio-language models
(LALMs) show strong reasoning over complex audios, most operate on monaural
inputs and lack the ability to capture spatial cues such as direction,
elevation, and distance. We introduce SPUR, a lightweight, plug-in approach
that equips LALMs with spatial perception through minimal architectural
changes. SPUR consists of: (i) a First-Order Ambisonics (FOA) encoder that maps
(W, X, Y, Z) channels to rotation-aware, listener-centric spatial features,
integrated into target LALMs via a multimodal adapter; and (ii) SPUR-Set, a
spatial QA dataset combining open-source FOA recordings with controlled
simulations, emphasizing relative direction, elevation, distance, and overlap
for supervised spatial reasoning. Fine-tuning our model on the SPUR-Set
consistently improves spatial QA and multi-speaker attribution while preserving
general audio understanding. SPUR provides a simple recipe that transforms
monaural LALMs into spatially aware models. Extensive ablations validate the
effectiveness of our approach.
\\ ( https://arxiv.org/abs/2511.06606 ,  2961kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06619 (*cross-listing*)
Date: Mon, 10 Nov 2025 01:58:02 GMT   (1825kb)

Title: How Do VLAs Effectively Inherit from VLMs?
Authors: Chuheng Zhang, Rushuai Yang, Xiaoyu Chen, Kaixin Wang, Li Zhao, Yi
 Chen, Jiang Bian
Categories: cs.RO cs.AI
\\
 Vision-language-action (VLA) models hold the promise to attain generalizable
embodied control. To achieve this, a pervasive paradigm is to leverage the rich
vision-semantic priors of large vision-language models (VLMs). However, the
fundamental question persists: How do VLAs effectively inherit the prior
knowledge from VLMs? To address this critical question, we introduce a
diagnostic benchmark, GrinningFace, an emoji tabletop manipulation task where
the robot arm is asked to place objects onto printed emojis corresponding to
language instructions. This task design is particularly revealing -- knowledge
associated with emojis is ubiquitous in Internet-scale datasets used for VLM
pre-training, yet emojis themselves are largely absent from standard robotics
datasets. Consequently, they provide a clean proxy: successful task completion
indicates effective transfer of VLM priors to embodied control. We implement
this diagnostic task in both simulated environment and a real robot, and
compare various promising techniques for knowledge transfer. Specifically, we
investigate the effects of parameter-efficient fine-tuning, VLM freezing,
co-training, predicting discretized actions, and predicting latent actions.
Through systematic evaluation, our work not only demonstrates the critical
importance of preserving VLM priors for the generalization of VLA but also
establishes guidelines for future research in developing truly generalizable
embodied AI systems.
\\ ( https://arxiv.org/abs/2511.06619 ,  1825kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06667 (*cross-listing*)
Date: Mon, 10 Nov 2025 03:24:56 GMT   (8359kb)

Title: Rapidly Learning Soft Robot Control via Implicit Time-Stepping
Authors: Andrew Choi and Dezhong Tong
Categories: cs.RO cs.AI
Comments: Code: https://github.com/QuantuMope/dismech-rl
\\
 With the explosive growth of rigid-body simulators, policy learning in
simulation has become the de facto standard for most rigid morphologies. In
contrast, soft robotic simulation frameworks remain scarce and are seldom
adopted by the soft robotics community. This gap stems partly from the lack of
easy-to-use, general-purpose frameworks and partly from the high computational
cost of accurately simulating continuum mechanics, which often renders policy
learning infeasible. In this work, we demonstrate that rapid soft robot policy
learning is indeed achievable via implicit time-stepping. Our simulator of
choice, DisMech, is a general-purpose, fully implicit soft-body simulator
capable of handling both soft dynamics and frictional contact. We further
introduce delta natural curvature control, a method analogous to delta joint
position control in rigid manipulators, providing an intuitive and effective
means of enacting control for soft robot learning. To highlight the benefits of
implicit time-stepping and delta curvature control, we conduct extensive
comparisons across four diverse soft manipulator tasks against one of the most
widely used soft-body frameworks, Elastica. With implicit time-stepping,
parallel stepping of 500 environments achieves up to 6x faster speeds for
non-contact cases and up to 40x faster for contact-rich scenarios. Finally, a
comprehensive sim-to-sim gap evaluation--training policies in one simulator and
evaluating them in another--demonstrates that implicit time-stepping provides a
rare free lunch: dramatic speedups achieved without sacrificing accuracy.
\\ ( https://arxiv.org/abs/2511.06667 ,  8359kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06700 (*cross-listing*)
Date: Mon, 10 Nov 2025 04:42:00 GMT   (1052kb)

Title: Place Matters: Comparing LLM Hallucination Rates for Place-Based Legal
 Queries
Authors: Damian Curran, Vanessa Sporne, Lea Frermann and Jeannie Paterson
Categories: cs.CY cs.AI cs.CL
\\
 How do we make a meaningful comparison of a large language model's knowledge
of the law in one place compared to another? Quantifying these differences is
critical to understanding if the quality of the legal information obtained by
users of LLM-based chatbots varies depending on their location. However,
obtaining meaningful comparative metrics is challenging because legal
institutions in different places are not themselves easily comparable. In this
work we propose a methodology to obtain place-to-place metrics based on the
comparative law concept of functionalism. We construct a dataset of factual
scenarios drawn from Reddit posts by users seeking legal advice for family,
housing, employment, crime and traffic issues. We use these to elicit a summary
of a law from the LLM relevant to each scenario in Los Angeles, London and
Sydney. These summaries, typically of a legislative provision, are manually
evaluated for hallucinations. We show that the rate of hallucination of legal
information by leading closed-source LLMs is significantly associated with
place. This suggests that the quality of legal solutions provided by these
models is not evenly distributed across geography. Additionally, we show a
strong negative correlation between hallucination rate and the frequency of the
majority response when the LLM is sampled multiple times, suggesting a measure
of uncertainty of model predictions of legal facts.
\\ ( https://arxiv.org/abs/2511.06700 ,  1052kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06701 (*cross-listing*)
Date: Mon, 10 Nov 2025 04:42:30 GMT   (23kb)

Title: Structural Enforcement of Statistical Rigor in AI-Driven Discovery: A
 Functional Architecture
Authors: Karen Sargsyan
Categories: cs.SE cs.AI
\\
 Sequential statistical protocols require meticulous state management and
robust error handling -- challenges naturally suited to functional programming.
We present a functional architecture for structural enforcement of statistical
rigor in automated research systems (AI-Scientists). These LLM-driven systems
risk generating spurious discoveries through dynamic hypothesis testing. We
introduce the Research monad, a Haskell eDSL that enforces sequential
statistical protocols (e.g., Online FDR (false discovery rate) control) using a
monad transformer stack. To address risks in hybrid architectures where LLMs
generate imperative code, we employ Declarative Scaffolding -- generating rigid
harnesses that structurally constrain execution and prevent methodological
errors like data leakage. We validate this approach through large-scale
simulation (N=2000 hypotheses) and an end-to-end case study, demonstrating
essential defense-in-depth for automated science integrity.
\\ ( https://arxiv.org/abs/2511.06701 ,  23kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06727 (*cross-listing*)
Date: Mon, 10 Nov 2025 05:40:02 GMT   (74kb)

Title: S-DAG: A Subject-Based Directed Acyclic Graph for Multi-Agent
 Heterogeneous Reasoning
Authors: Jiangwen Dong, Zehui Lin, Wanyu Lin, Mingjin Zhang
Categories: cs.MA cs.AI
\\
 Large Language Models (LLMs) have achieved impressive performance in complex
reasoning problems. Their effectiveness highly depends on the specific nature
of the task, especially the required domain knowledge. Existing approaches,
such as mixture-of-experts, typically operate at the task level; they are too
coarse to effectively solve the heterogeneous problems involving multiple
subjects. This work proposes a novel framework that performs fine-grained
analysis at subject level equipped with a designated multi-agent collaboration
strategy for addressing heterogeneous problem reasoning. Specifically, given an
input query, we first employ a Graph Neural Network to identify the relevant
subjects and infer their interdependencies to generate an \textit{Subject-based
Directed Acyclic Graph} (S-DAG), where nodes represent subjects and edges
encode information flow. Then we profile the LLM models by assigning each model
a subject-specific expertise score, and select the top-performing one for
matching corresponding subject of the S-DAG. Such subject-model matching
enables graph-structured multi-agent collaboration where information flows from
the starting model to the ending model over S-DAG. We curate and release
multi-subject subsets of standard benchmarks (MMLU-Pro, GPQA, MedMCQA) to
better reflect complex, real-world reasoning tasks. Extensive experiments show
that our approach significantly outperforms existing task-level model selection
and multi-agent collaboration baselines in accuracy and efficiency. These
results highlight the effectiveness of subject-aware reasoning and structured
collaboration in addressing complex and multi-subject problems.
\\ ( https://arxiv.org/abs/2511.06727 ,  74kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06731 (*cross-listing*)
Date: Mon, 10 Nov 2025 05:52:43 GMT   (10533kb)

Title: Diagnosing and Breaking Amplitude Suppression in Seismic Phase Picking
 Through Adversarial Shape Learning
Authors: Chun-Ming Huang, Li-Heng Chang, I-Hsin Chang, An-Sheng Lee, Hao
 Kuo-Chen
Categories: physics.geo-ph cs.AI
\\
 Deep learning has revolutionized seismic phase picking, yet a paradox
persists: high signal-to-noise S-wave predictions consistently fail to cross
detection thresholds, oscillating at suppressed amplitudes. We identify this
previously unexplained phenomenon as amplitude suppression, which we diagnose
through analyzing training histories and loss landscapes. Three interacting
factors emerge: S-wave onsets exhibit high temporal uncertainty relative to
high-amplitude boundaries; CNN's bias toward sharp amplitude changes anchors
predictions to these boundaries rather than subtle onsets; and point-wise
Binary Cross-Entropy (BCE) loss lacks lateral corrective forces, providing only
vertical gradients that suppress amplitude while temporal gaps persist. This
geometric trap points to a shape-then-align solution where stable geometric
templates must precede temporal alignment. We implement this through a
conditional GAN framework by augmenting conventional BCE training with a
discriminator that enforces shape constraints. Training for 10,000 steps, this
achieves a 64% increase in effective S-phase detections. Our framework
autonomously discovers target geometry without a priori assumptions, offering a
generalizable solution for segmentation tasks requiring precise alignment of
subtle features near dominant structures.
\\ ( https://arxiv.org/abs/2511.06731 ,  10533kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06745 (*cross-listing*)
Date: Mon, 10 Nov 2025 06:18:38 GMT   (954kb)

Title: Physically-Grounded Goal Imagination: Physics-Informed Variational
 Autoencoder for Self-Supervised Reinforcement Learning
Authors: Lan Thi Ha Nguyen, Kien Ton Manh, Anh Do Duc, and Nam Pham Hai
Categories: cs.RO cs.AI
\\
 Self-supervised goal-conditioned reinforcement learning enables robots to
autonomously acquire diverse skills without human supervision. However, a
central challenge is the goal setting problem: robots must propose feasible and
diverse goals that are achievable in their current environment. Existing
methods like RIG (Visual Reinforcement Learning with Imagined Goals) use
variational autoencoder (VAE) to generate goals in a learned latent space but
have the limitation of producing physically implausible goals that hinder
learning efficiency. We propose Physics-Informed RIG (PI-RIG), which integrates
physical constraints directly into the VAE training process through a novel
Enhanced Physics-Informed Variational Autoencoder (Enhanced p3-VAE), enabling
the generation of physically consistent and achievable goals. Our key
innovation is the explicit separation of the latent space into physics
variables governing object dynamics and environmental factors capturing visual
appearance, while enforcing physical consistency through differential equation
constraints and conservation laws. This enables the generation of physically
consistent and achievable goals that respect fundamental physical principles
such as object permanence, collision constraints, and dynamic feasibility.
Through extensive experiments, we demonstrate that this physics-informed goal
generation significantly improves the quality of proposed goals, leading to
more effective exploration and better skill acquisition in visual robotic
manipulation tasks including reaching, pushing, and pick-and-place scenarios.
\\ ( https://arxiv.org/abs/2511.06745 ,  954kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06751 (*cross-listing*)
Date: Mon, 10 Nov 2025 06:29:34 GMT   (12870kb)

Title: Hierarchical Spatial-Frequency Aggregation for Spectral Deconvolution
 Imaging
Authors: Tao Lv and Daoming Zhou and Chenglong Huang and Chongde Zi and Linsen
 Chen and Xun Cao
Categories: eess.IV cs.AI cs.CV
Comments: Under Review at TPAMI
\\
 Computational spectral imaging (CSI) achieves real-time hyperspectral imaging
through co-designed optics and algorithms, but typical CSI methods suffer from
a bulky footprint and limited fidelity. Therefore, Spectral Deconvolution
imaging (SDI) methods based on PSF engineering have been proposed to achieve
high-fidelity compact CSI design recently. However, the composite
convolution-integration operations of SDI render the normal-equation
coefficient matrix scene-dependent, which hampers the efficient exploitation of
imaging priors and poses challenges for accurate reconstruction. To tackle the
inherent data-dependent operators in SDI, we introduce a Hierarchical
Spatial-Spectral Aggregation Unfolding Framework (HSFAUF). By decomposing
subproblems and projecting them into the frequency domain, HSFAUF transforms
nonlinear processes into linear mappings, thereby enabling efficient solutions.
Furthermore, to integrate spatial-spectral priors during iterative refinement,
we propose a Spatial-Frequency Aggregation Transformer (SFAT), which explicitly
aggregates information across spatial and frequency domains. By integrating
SFAT into HSFAUF, we develop a Transformer-based deep unfolding method,
\textbf{H}ierarchical \textbf{S}patial-\textbf{F}requency \textbf{A}ggregation
\textbf{U}nfolding \textbf{T}ransformer (HSFAUT), to solve the inverse problem
of SDI. Systematic simulated and real experiments show that HSFAUT surpasses
SOTA methods with cheaper memory and computational costs, while exhibiting
optimal performance on different SDI systems.
\\ ( https://arxiv.org/abs/2511.06751 ,  12870kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06779 (*cross-listing*)
Date: Mon, 10 Nov 2025 07:07:37 GMT   (2014kb)

Title: Pedagogical Reflections on the Holistic Cognitive Development (HCD)
 Framework and AI-Augmented Learning in Creative Computing
Authors: BHojan Anand
Categories: cs.MM cs.AI
Comments: Short Abstract
MSC-class: 14J60
\\
 This paper presents an expanded account of the Holistic Cognitive Development
(HCD) framework for reflective and creative learning in computing education.
The HCD framework integrates design thinking, experiential learning, and
reflective practice into a unified constructivist pedagogy emphasizing
autonomy, ownership, and scaffolding. It is applied across courses in game
design (CS3247, CS4350), virtual reality (CS4240), and extended reality
systems, where students engage in iterative cycles of thinking, creating,
criticizing, and reflecting. The paper also examines how AI-augmented systems
such as iReflect, ReflexAI, and Knowledge Graph-enhanced LLM feedback tools
operationalize the HCD framework through scalable, personalized feedback.
Empirical findings demonstrate improved reflective depth, feedback quality, and
learner autonomy. The work advocates a balance of supportive autonomy in
supervision, where students practice self-directed inquiry while guided through
structured reflection and feedback.
\\ ( https://arxiv.org/abs/2511.06779 ,  2014kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06780 (*cross-listing*)
Date: Mon, 10 Nov 2025 07:08:19 GMT   (887kb)

Title: OntoTune: Ontology-Driven Learning for Query Optimization with
 Convolutional Models
Authors: Songhui Yue, Yang Shao, Sean Hayes
Categories: cs.DB cs.AI cs.LG
\\
 Query optimization has been studied using machine learning, reinforcement
learning, and, more recently, graph-based convolutional networks. Ontology, as
a structured, information-rich knowledge representation, can provide context,
particularly in learning problems. This paper presents OntoTune, an
ontology-based platform for enhancing learning for query optimization. By
connecting SQL queries, database metadata, and statistics, the ontology
developed in this research is promising in capturing relationships and
important determinants of query performance. This research also develops a
method to embed ontologies while preserving as much of the relationships and
key information as possible, before feeding it into learning algorithms such as
tree-based and graph-based convolutional networks. A case study shows how
OntoTune's ontology-driven learning delivers performance gains compared with
database system default query execution.
\\ ( https://arxiv.org/abs/2511.06780 ,  887kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06804 (*cross-listing*)
Date: Mon, 10 Nov 2025 07:46:12 GMT   (24726kb)

Title: AgentSUMO: An Agentic Framework for Interactive Simulation Scenario
 Generation in SUMO via Large Language Models
Authors: Minwoo Jeong, Jeeyun Chang, Yoonjin Yoon
Categories: cs.HC cs.AI cs.CY
Comments: Submitted to Transportation Research Part C (under review)
\\
 The growing complexity of urban mobility systems has made traffic simulation
indispensable for evidence-based transportation planning and policy evaluation.
However, despite the analytical capabilities of platforms such as the
Simulation of Urban MObility (SUMO), their application remains largely confined
to domain experts. Developing realistic simulation scenarios requires expertise
in network construction, origin-destination modeling, and parameter
configuration for policy experimentation, creating substantial barriers for
non-expert users such as policymakers, urban planners, and city officials.
Moreover, the requests expressed by these users are often incomplete and
abstract-typically articulated as high-level objectives, which are not well
aligned with the imperative, sequential workflows employed in existing
language-model-based simulation frameworks. To address these challenges, this
study proposes AgentSUMO, an agentic framework for interactive simulation
scenario generation via large language models. AgentSUMO departs from
imperative, command-driven execution by introducing an adaptive reasoning layer
that interprets user intents, assesses task complexity, infers missing
parameters, and formulates executable simulation plans. The framework is
structured around two complementary components, the Interactive Planning
Protocol, which governs reasoning and user interaction, and the Model Context
Protocol, which manages standardized communication and orchestration among
simulation tools. Through this design, AgentSUMO converts abstract policy
objectives into executable simulation scenarios. Experiments on urban networks
in Seoul and Manhattan demonstrate that the agentic workflow achieves
substantial improvements in traffic flow metrics while maintaining
accessibility for non-expert users, successfully bridging the gap between
policy goals and executable simulation workflows.
\\ ( https://arxiv.org/abs/2511.06804 ,  24726kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06852 (*cross-listing*)
Date: Mon, 10 Nov 2025 08:52:34 GMT   (3095kb)

Title: Differentiated Directional Intervention A Framework for Evading LLM
 Safety Alignment
Authors: Peng Zhang, peijie sun
Categories: cs.CR cs.AI cs.LG cs.SE
Comments: AAAI-26-AIA
\\
 Safety alignment instills in Large Language Models (LLMs) a critical capacity
to refuse malicious requests. Prior works have modeled this refusal mechanism
as a single linear direction in the activation space. We posit that this is an
oversimplification that conflates two functionally distinct neural processes:
the detection of harm and the execution of a refusal. In this work, we
deconstruct this single representation into a Harm Detection Direction and a
Refusal Execution Direction. Leveraging this fine-grained model, we introduce
Differentiated Bi-Directional Intervention (DBDI), a new white-box framework
that precisely neutralizes the safety alignment at critical layer. DBDI applies
adaptive projection nullification to the refusal execution direction while
suppressing the harm detection direction via direct steering. Extensive
experiments demonstrate that DBDI outperforms prominent jailbreaking methods,
achieving up to a 97.88\% attack success rate on models such as Llama-2. By
providing a more granular and mechanistic framework, our work offers a new
direction for the in-depth understanding of LLM safety alignment.
\\ ( https://arxiv.org/abs/2511.06852 ,  3095kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06853 (*cross-listing*)
Date: Mon, 10 Nov 2025 08:52:56 GMT   (3533kb)

Title: Deep learning EPI-TIRF cross-modality enables background subtraction and
 axial super-resolution for widefield fluorescence microscopy
Authors: Qiushi Li, Celi Lou, Yanfang Cheng, Bilang Gong, Xinlin Chen, Hao
 Chen, Baowan Li, Jieli Wang, Yulin Wang, Sipeng Yang, Yunqing Tang, and Luru
 Dai
Categories: physics.optics cs.AI
\\
 The resolving ability of wide-field fluorescence microscopy is fundamentally
limited by out-of-focus background owing to its low axial resolution,
particularly for densely labeled biological samples. To address this, we
developed ET2dNet, a deep learning-based EPI-TIRF cross-modality network that
achieves TIRF-comparable background subtraction and axial super-resolution from
a single wide-field image without requiring hardware modifications. The model
employs a physics-informed hybrid architecture, synergizing supervised learning
with registered EPI-TIRF image pairs and self-supervised physical modeling via
convolution with the point spread function. This framework ensures exceptional
generalization across microscope objectives, enabling few-shot adaptation to
new imaging setups. Rigorous validation on cellular and tissue samples confirms
ET2dNet's superiority in background suppression and axial resolution
enhancement, while maintaining compatibility with deconvolution techniques for
lateral resolution improvement. Furthermore, by extending this paradigm through
knowledge distillation, we developed ET3dNet, a dedicated three-dimensional
reconstruction network that produces artifact-reduced volumetric results.
ET3dNet effectively removes out-of-focus background signals even when the input
image stack lacks the source of background. This framework makes axial
super-resolution imaging more accessible by providing an easy-to-deploy
algorithm that avoids additional hardware costs and complexity, showing great
potential for live cell studies and clinical histopathology.
\\ ( https://arxiv.org/abs/2511.06853 ,  3533kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07014 (*cross-listing*)
Date: Mon, 10 Nov 2025 12:05:32 GMT   (1284kb)

Title: Diffolio: A Diffusion Model for Multivariate Probabilistic Financial
 Time-Series Forecasting and Portfolio Construction
Authors: So-Yoon Cho, Jin-Young Kim, Kayoung Ban, Hyeng Keun Koo, Hyun-Gyoon
 Kim
Categories: cs.CE cs.AI econ.EM q-fin.PM
\\
 Probabilistic forecasting is crucial in multivariate financial time-series
for constructing efficient portfolios that account for complex cross-sectional
dependencies. In this paper, we propose Diffolio, a diffusion model designed
for multivariate financial time-series forecasting and portfolio construction.
Diffolio employs a denoising network with a hierarchical attention
architecture, comprising both asset-level and market-level layers. Furthermore,
to better reflect cross-sectional correlations, we introduce a
correlation-guided regularizer informed by a stable estimate of the target
correlation matrix. This structure effectively extracts salient features not
only from historical returns but also from asset-specific and systematic
covariates, significantly enhancing the performance of forecasts and
portfolios. Experimental results on the daily excess returns of 12 industry
portfolios show that Diffolio outperforms various probabilistic forecasting
baselines in multivariate forecasting accuracy and portfolio performance.
Moreover, in portfolio experiments, portfolios constructed from Diffolio's
forecasts show consistently robust performance, thereby outperforming those
from benchmarks by achieving higher Sharpe ratios for the mean-variance
tangency portfolio and higher certainty equivalents for the growth-optimal
portfolio. These results demonstrate the superiority of our proposed Diffolio
in terms of not only statistical accuracy but also economic significance.
\\ ( https://arxiv.org/abs/2511.07014 ,  1284kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07017 (*cross-listing*)
Date: Mon, 10 Nov 2025 12:06:35 GMT   (621kb)

Title: Benchmarking LLMs for Fine-Grained Code Review with Enriched Context in
 Practice
Authors: Ruida Hu, Xinchen Wang, Xin-Cheng Wen, Zhao Zhang, Bo Jiang, Pengfei
 Gao, Chao Peng, Cuiyun Gao
Categories: cs.SE cs.AI
\\
 Code review is a cornerstone of software quality assurance, and recent
advances in Large Language Models (LLMs) have shown promise in automating this
process. However, existing benchmarks for LLM-based code review face three
major limitations. (1) Lack of semantic context: most benchmarks provide only
code diffs without textual information such as issue descriptions, which are
crucial for understanding developer intent. (2) Data quality issues: without
rigorous validation, many samples are noisy-e.g., reviews on outdated or
irrelevant code-reducing evaluation reliability. (3) Coarse granularity: most
benchmarks operate at the file or commit level, overlooking the fine-grained,
line-level reasoning essential for precise review.
 We introduce ContextCRBench, a high-quality, context-rich benchmark for
fine-grained LLM evaluation in code review. Our construction pipeline
comprises: (1) Raw Data Crawling, collecting 153.7K issues and pull requests
from top-tier repositories; (2) Comprehensive Context Extraction, linking
issue-PR pairs for textual context and extracting the full surrounding function
or class for code context; and (3) Multi-stage Data Filtering, combining
rule-based and LLM-based validation to remove outdated, malformed, or low-value
samples, resulting in 67,910 context-enriched entries.
 ContextCRBench supports three evaluation scenarios aligned with the review
workflow: (1) hunk-level quality assessment, (2) line-level defect
localization, and (3) line-level comment generation. Evaluating eight leading
LLMs (four closed-source and four open-source) reveals that textual context
yields greater performance gains than code context alone, while current LLMs
remain far from human-level review ability. Deployed at ByteDance,
ContextCRBench drives a self-evolving code review system, improving performance
by 61.98% and demonstrating its robustness and industrial utility.
\\ ( https://arxiv.org/abs/2511.07017 ,  621kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07057 (*cross-listing*)
Date: Mon, 10 Nov 2025 12:47:21 GMT   (3036kb)

Title: TauFlow: Dynamic Causal Constraint for Complexity-Adaptive Lightweight
 Segmentation
Authors: Zidong Chen and Fadratul Hafinaz Hassan
Categories: eess.IV cs.AI cs.CV
Comments: 42 pages and 9 figures
MSC-class: 68U10, 68T45, 92C55, 68T07
ACM-class: I.4.6; I.2.10; J.3; I.2.6
\\
 Deploying lightweight medical image segmentation models on edge devices
presents two major challenges: 1) efficiently handling the stark contrast
between lesion boundaries and background regions, and 2) the sharp drop in
accuracy that occurs when pursuing extremely lightweight designs (e.g., <0.5M
parameters). To address these problems, this paper proposes TauFlow, a novel
lightweight segmentation model. The core of TauFlow is a dynamic feature
response strategy inspired by brain-like mechanisms. This is achieved through
two key innovations: the Convolutional Long-Time Constant Cell (ConvLTC), which
dynamically regulates the feature update rate to "slowly" process low-frequency
backgrounds and "quickly" respond to high-frequency boundaries; and the STDP
Self-Organizing Module, which significantly mitigates feature conflicts between
the encoder and decoder, reducing the conflict rate from approximately 35%-40%
to 8%-10%.
\\ ( https://arxiv.org/abs/2511.07057 ,  3036kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07085 (*cross-listing*)
Date: Mon, 10 Nov 2025 13:19:58 GMT   (494kb)

Title: Achieving Effective Virtual Reality Interactions via Acoustic Gesture
 Recognition based on Large Language Models
Authors: Xijie Zhang, Fengliang He, Hong-Ning Dai
Categories: cs.HC cs.AI cs.CV
Comments: 5 pages, 4 figures, 1 table, under review at ICASSP 2026
\\
 Natural and efficient interaction remains a critical challenge for virtual
reality and augmented reality (VR/AR) systems. Vision-based gesture recognition
suffers from high computational cost, sensitivity to lighting conditions, and
privacy leakage concerns. Acoustic sensing provides an attractive alternative:
by emitting inaudible high-frequency signals and capturing their reflections,
channel impulse response (CIR) encodes how gestures perturb the acoustic field
in a low-cost and user-transparent manner. However, existing CIR-based gesture
recognition methods often rely on extensive training of models on large labeled
datasets, making them unsuitable for few-shot VR scenarios. In this work, we
propose the first framework that leverages large language models (LLMs) for
CIR-based gesture recognition in VR/AR systems. Despite LLMs' strengths, it is
non-trivial to achieve few-shot and zero-shot learning of CIR gestures due to
their inconspicuous features. To tackle this challenge, we collect differential
CIR rather than original CIR data. Moreover, we construct a real-world dataset
collected from 10 participants performing 15 gestures across three categories
(digits, letters, and shapes), with 10 repetitions each. We then conduct
extensive experiments on this dataset using an LLM-adopted classifier. Results
show that our LLM-based framework achieves accuracy comparable to classical
machine learning baselines, while requiring no domain-specific retraining.
\\ ( https://arxiv.org/abs/2511.07085 ,  494kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07092 (*cross-listing*)
Date: Mon, 10 Nov 2025 13:29:29 GMT   (4254kb)

Title: Sample-efficient quantum error mitigation via classical learning
 surrogates
Authors: Wei-You Liao, Ge Yan, Yujin Song, Tian-Ci Tian, Wei-Ming Zhu, De-Tao
 Jiang, Yuxuan Du, He-Liang Huang
Categories: quant-ph cs.AI cs.LG
Comments: 26 pages, 8 figures
\\
 The pursuit of practical quantum utility on near-term quantum processors is
critically challenged by their inherent noise. Quantum error mitigation (QEM)
techniques are leading solutions to improve computation fidelity with
relatively low qubit-overhead, while full-scale quantum error correction
remains a distant goal. However, QEM techniques incur substantial measurement
overheads, especially when applied to families of quantum circuits
parameterized by classical inputs. Focusing on zero-noise extrapolation (ZNE),
a widely adopted QEM technique, here we devise the surrogate-enabled ZNE
(S-ZNE), which leverages classical learning surrogates to perform ZNE entirely
on the classical side. Unlike conventional ZNE, whose measurement cost scales
linearly with the number of circuits, S-ZNE requires only constant measurement
overhead for an entire family of quantum circuits, offering superior
scalability. Theoretical analysis indicates that S-ZNE achieves accuracy
comparable to conventional ZNE in many practical scenarios, and numerical
experiments on up to 100-qubit ground-state energy and quantum metrology tasks
confirm its effectiveness. Our approach provides a template that can be
effectively extended to other quantum error mitigation protocols, opening a
promising path toward scalable error mitigation.
\\ ( https://arxiv.org/abs/2511.07092 ,  4254kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07099 (*cross-listing*)
Date: Mon, 10 Nov 2025 13:38:53 GMT   (480kb)

Title: E2E-VGuard: Adversarial Prevention for Production LLM-based End-To-End
 Speech Synthesis
Authors: Zhisheng Zhang, Derui Wang, Yifan Mi, Zhiyong Wu, Jie Gao, Yuxin Cao,
 Kai Ye, Minhui Xue, Jie Hao
Categories: cs.SD cs.AI cs.CR cs.LG
Comments: Accepted to NeurIPS 2025
\\
 Recent advancements in speech synthesis technology have enriched our daily
lives, with high-quality and human-like audio widely adopted across real-world
applications. However, malicious exploitation like voice-cloning fraud poses
severe security risks. Existing defense techniques struggle to address the
production large language model (LLM)-based speech synthesis. While previous
studies have considered the protection for fine-tuning synthesizers, they
assume manually annotated transcripts. Given the labor intensity of manual
annotation, end-to-end (E2E) systems leveraging automatic speech recognition
(ASR) to generate transcripts are becoming increasingly prevalent, e.g., voice
cloning via commercial APIs. Therefore, this E2E speech synthesis also requires
new security mechanisms. To tackle these challenges, we propose E2E-VGuard, a
proactive defense framework for two emerging threats: (1) production LLM-based
speech synthesis, and (2) the novel attack arising from ASR-driven E2E
scenarios. Specifically, we employ the encoder ensemble with a feature
extractor to protect timbre, while ASR-targeted adversarial examples disrupt
pronunciation. Moreover, we incorporate the psychoacoustic model to ensure
perturbative imperceptibility. For a comprehensive evaluation, we test 16
open-source synthesizers and 3 commercial APIs across Chinese and English
datasets, confirming E2E-VGuard's effectiveness in timbre and pronunciation
protection. Real-world deployment validation is also conducted. Our code and
demo page are available at https://wxzyd123.github.io/e2e-vguard/.
\\ ( https://arxiv.org/abs/2511.07099 ,  480kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07202 (*cross-listing*)
Date: Mon, 10 Nov 2025 15:30:44 GMT   (2907kb)

Title: Resilient by Design - Active Inference for Distributed Continuum
 Intelligence
Authors: Praveen Kumar Donta, Alfreds Lapkovskis, Enzo Mingozzi, Schahram
 Dustdar
Categories: cs.DC cs.AI cs.MA cs.NI
\\
 Failures are the norm in highly complex and heterogeneous devices spanning
the distributed computing continuum (DCC), from resource-constrained IoT and
edge nodes to high-performance computing systems. Ensuring reliability and
global consistency across these layers remains a major challenge, especially
for AI-driven workloads requiring real-time, adaptive coordination. This paper
introduces a Probabilistic Active Inference Resilience Agent (PAIR-Agent) to
achieve resilience in DCC systems. PAIR-Agent performs three core operations:
(i) constructing a causal fault graph from device logs, (ii) identifying faults
while managing certainties and uncertainties using Markov blankets and the
free-energy principle, and (iii) autonomously healing issues through active
inference. Through continuous monitoring and adaptive reconfiguration, the
agent maintains service continuity and stability under diverse failure
conditions. Theoretical validations confirm the reliability and effectiveness
of the proposed framework.
\\ ( https://arxiv.org/abs/2511.07202 ,  2907kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07205 (*cross-listing*)
Date: Mon, 10 Nov 2025 15:32:23 GMT   (92kb)

Title: Twenty-Five Years of MIR Research: Achievements, Practices, Evaluations,
 and Future Challenges
Authors: Geoffroy Peeters, Zafar Rafii, Magdalena Fuentes, Zhiyao Duan,
 Emmanouil Benetos, Juhan Nam, Yuki Mitsufuji
Categories: cs.SD cs.AI
DOI: 10.1109/ICASSP49660.2025.10888947
\\
 In this paper, we trace the evolution of Music Information Retrieval (MIR)
over the past 25 years. While MIR gathers all kinds of research related to
music informatics, a large part of it focuses on signal processing techniques
for music data, fostering a close relationship with the IEEE Audio and Acoustic
Signal Processing Technical Commitee. In this paper, we reflect the main
research achievements of MIR along the three EDICS related to music analysis,
processing and generation. We then review a set of successful practices that
fuel the rapid development of MIR research. One practice is the annual research
benchmark, the Music Information Retrieval Evaluation eXchange, where
participants compete on a set of research tasks. Another practice is the
pursuit of reproducible and open research. The active engagement with industry
research and products is another key factor for achieving large societal
impacts and motivating younger generations of students to join the field. Last
but not the least, the commitment to diversity, equity and inclusion ensures
MIR to be a vibrant and open community where various ideas, methodologies, and
career pathways collide. We finish by providing future challenges MIR will have
to face.
\\ ( https://arxiv.org/abs/2511.07205 ,  92kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07223 (*cross-listing*)
Date: Mon, 10 Nov 2025 15:44:55 GMT   (8283kb)

Title: NoteEx: Interactive Visual Context Manipulation for LLM-Assisted
 Exploratory Data Analysis in Computational Notebooks
Authors: Mohammad Hasan Payandeh, Lin-Ping Yuan, Jian Zhao
Categories: cs.HC cs.AI
\\
 Computational notebooks have become popular for Exploratory Data Analysis
(EDA), augmented by LLM-based code generation and result interpretation.
Effective LLM assistance hinges on selecting informative context -- the minimal
set of cells whose code, data, or outputs suffice to answer a prompt. As
notebooks grow long and messy, users can lose track of the mental model of
their analysis. They thus fail to curate appropriate contexts for LLM tasks,
causing frustration and tedious prompt engineering. We conducted a formative
study (n=6) that surfaced challenges in LLM context selection and mental model
maintenance. Therefore, we introduce NoteEx, a JupyterLab extension that
provides a semantic visualization of the EDA workflow, allowing analysts to
externalize their mental model, specify analysis dependencies, and enable
interactive selection of task-relevant contexts for LLMs. A user study (n=12)
against a baseline shows that NoteEx improved mental model retention and
context selection, leading to more accurate and relevant LLM responses.
\\ ( https://arxiv.org/abs/2511.07223 ,  8283kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07229 (*cross-listing*)
Date: Mon, 10 Nov 2025 15:47:53 GMT   (105kb)

Title: LLMServingSim2.0: A Unified Simulator for Heterogeneous Hardware and
 Serving Techniques in LLM Infrastructure
Authors: Jaehong Cho, Hyunmin Choi, Jongse Park
Categories: cs.DC cs.AI
Comments: 4 pages, 3 figures
Journal-ref: IEEE Computer Architecture Letters (CAL) 2025
DOI: 10.1109/LCA.2025.3628325
\\
 This paper introduces LLMServingSim2.0, a system simulator designed for
exploring heterogeneous hardware in large-scale LLM serving systems.
LLMServingSim2.0 addresses two key limitations of its predecessor: (1)
integrating hardware models into system-level simulators is non-trivial due to
the lack of a clear abstraction, and (2) existing simulators support only a
narrow subset of serving techniques, leaving no infrastructure that captures
the breadth of approaches in modern LLM serving. To overcome these issues,
LLMServingSim2.0 adopts trace-driven performance modeling, accompanied by an
operator-level latency profiler, enabling the integration of new accelerators
with a single command. It further embeds up-to-date serving techniques while
exposing flexible interfaces for request routing, cache management, and
scheduling policies. In a TPU case study, our profiler requires 18.5x fewer LoC
and outperforms the predecessor's hardware-simulator integration, demonstrating
LLMServingSim2.0's low-effort hardware extensibility. Our experiments further
show that LLMServingSim2.0 reproduces GPU-based LLM serving with 1.9% error,
while maintaining practical simulation time, making it a comprehensive platform
for both hardware developers and LLM service providers.
\\ ( https://arxiv.org/abs/2511.07229 ,  105kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07277 (*cross-listing*)
Date: Mon, 10 Nov 2025 16:23:06 GMT   (3458kb)

Title: Designing Beyond Language: Sociotechnical Barriers in AI Health
 Technologies for Limited English Proficiency
Authors: Michelle Huang, Violeta J. Rodriguez, Koustuv Saha, and Tal August
Categories: cs.HC cs.AI cs.CY
\\
 Limited English proficiency (LEP) patients in the U.S. face systemic barriers
to healthcare beyond language and interpreter access, encompassing procedural
and institutional constraints. AI advances may support communication and care
through on-demand translation and visit preparation, but also risk exacerbating
existing inequalities. We conducted storyboard-driven interviews with 14
patient navigators to explore how AI could shape care experiences for
Spanish-speaking LEP individuals. We identified tensions around linguistic and
cultural misunderstandings, privacy concerns, and opportunities and risks for
AI to augment care workflows. Participants highlighted structural factors that
can undermine trust in AI systems, including sensitive information disclosure,
unstable technology access, and low digital literacy. While AI tools can
potentially alleviate social barriers and institutional constraints, there are
risks of misinformation and uprooting human camaraderie. Our findings
contribute design considerations for AI that support LEP patients and care
teams via rapport-building, education, and language support, and minimizing
disruptions to existing practices.
\\ ( https://arxiv.org/abs/2511.07277 ,  3458kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07293 (*cross-listing*)
Date: Mon, 10 Nov 2025 16:43:02 GMT   (742kb)

Title: Verifying rich robustness properties for neural networks
Authors: Mohammad Afzal, S. Akshay, Ashutosh Gupta
Categories: cs.LO cs.AI cs.CV
\\
 Robustness is a important problem in AI alignment and safety, with models
such as neural networks being increasingly used in safety-critical systems. In
the last decade, a large body of work has emerged on local robustness, i.e.,
checking if the decision of a neural network remains unchanged when the input
is slightly perturbed. However, many of these approaches require specialized
encoding and often ignore the confidence of a neural network on its output. In
this paper, our goal is to build a generalized framework to specify and verify
variants of robustness in neural network verification. We propose a
specification framework using a simple grammar, which is flexible enough to
capture most existing variants. This allows us to introduce new variants of
robustness that take into account the confidence of the neural network in its
outputs. Next, we develop a novel and powerful unified technique to verify all
such variants in a homogeneous way, viz., by adding a few additional layers to
the neural network. This enables us to use any state-of-the-art neural network
verification tool, without having to tinker with the encoding within, while
incurring an approximation error that we show is bounded. We perform an
extensive experimental evaluation over a large suite of 8870 benchmarks having
138M parameters in a largest network, and show that we are able to capture a
wide set of robustness variants and outperform direct encoding approaches by a
significant margin.
\\ ( https://arxiv.org/abs/2511.07293 ,  742kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07367 (*cross-listing*)
Date: Mon, 10 Nov 2025 18:23:34 GMT   (2621kb)

Title: Machine-Learning Accelerated Calculations of Reduced Density Matrices
Authors: Awwab A. Azam, Lexu Zhao, Jiabin Yu
Categories: cond-mat.str-el cs.AI
Comments: 10+32 pages, 6+4 figures, 1+6 tables
\\
 $n$-particle reduced density matrices ($n$-RDMs) play a central role in
understanding correlated phases of matter. Yet the calculation of $n$-RDMs is
often computationally inefficient for strongly-correlated states, particularly
when the system sizes are large. In this work, we propose to use neural network
(NN) architectures to accelerate the calculation of, and even predict, the
$n$-RDMs for large-size systems. The underlying intuition is that $n$-RDMs are
often smooth functions over the Brillouin zone (BZ) (certainly true for gapped
states) and are thus interpolable, allowing NNs trained on small-size $n$-RDMs
to predict large-size ones. Building on this intuition, we devise two NNs: (i)
a self-attention NN that maps random RDMs to physical ones, and (ii) a
Sinusoidal Representation Network (SIREN) that directly maps momentum-space
coordinates to RDM values. We test the NNs in three 2D models: the pair-pair
correlation functions of the Richardson model of superconductivity, the
translationally-invariant 1-RDM in a four-band model with short-range
repulsion, and the translation-breaking 1-RDM in the half-filled Hubbard model.
We find that a SIREN trained on a $6\times 6$ momentum mesh can predict the
$18\times 18$ pair-pair correlation function with a relative accuracy of
$0.839$. The NNs trained on $6\times 6 \sim 8\times 8$ meshes can provide
high-quality initial guesses for $50\times 50$ translation-invariant
Hartree-Fock (HF) and $30\times 30$ fully translation-breaking-allowed HF,
reducing the number of iterations required for convergence by up to $91.63\%$
and $92.78\%$, respectively, compared to random initializations. Our results
illustrate the potential of using NN-based methods for interpolable $n$-RDMs,
which might open a new avenue for future research on strongly correlated
phases.
\\ ( https://arxiv.org/abs/2511.07367 ,  2621kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07410 (*cross-listing*)
Date: Mon, 10 Nov 2025 18:56:56 GMT   (1250kb)

Title: Using Vision Language Models as Closed-Loop Symbolic Planners for
 Robotic Applications: A Control-Theoretic Perspective
Authors: Hao Wang, Sathwik Karnik, Bea Lim, Somil Bansal
Categories: cs.RO cs.AI
\\
 Large Language Models (LLMs) and Vision Language Models (VLMs) have been
widely used for embodied symbolic planning. Yet, how to effectively use these
models for closed-loop symbolic planning remains largely unexplored. Because
they operate as black boxes, LLMs and VLMs can produce unpredictable or costly
errors, making their use in high-level robotic planning especially challenging.
In this work, we investigate how to use VLMs as closed-loop symbolic planners
for robotic applications from a control-theoretic perspective. Concretely, we
study how the control horizon and warm-starting impact the performance of VLM
symbolic planners. We design and conduct controlled experiments to gain
insights that are broadly applicable to utilizing VLMs as closed-loop symbolic
planners, and we discuss recommendations that can help improve the performance
of VLM symbolic planners.
\\ ( https://arxiv.org/abs/2511.07410 ,  1250kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07416 (*cross-listing*)
Date: Mon, 10 Nov 2025 18:59:07 GMT   (3590kb)

Title: Robot Learning from a Physical World Model
Authors: Jiageng Mao, Sicheng He, Hao-Ning Wu, Yang You, Shuyang Sun, Zhicheng
 Wang, Yanan Bao, Huizhong Chen, Leonidas Guibas, Vitor Guizilini, Howard
 Zhou, and Yue Wang
Categories: cs.RO cs.AI cs.CV
Comments: Project page: https://pointscoder.github.io/PhysWorld_Web/
\\
 We introduce PhysWorld, a framework that enables robot learning from video
generation through physical world modeling. Recent video generation models can
synthesize photorealistic visual demonstrations from language commands and
images, offering a powerful yet underexplored source of training signals for
robotics. However, directly retargeting pixel motions from generated videos to
robots neglects physics, often resulting in inaccurate manipulations. PhysWorld
addresses this limitation by coupling video generation with physical world
reconstruction. Given a single image and a task command, our method generates
task-conditioned videos and reconstructs the underlying physical world from the
videos, and the generated video motions are grounded into physically accurate
actions through object-centric residual reinforcement learning with the
physical world model. This synergy transforms implicit visual guidance into
physically executable robotic trajectories, eliminating the need for real robot
data collection and enabling zero-shot generalizable robotic manipulation.
Experiments on diverse real-world tasks demonstrate that PhysWorld
substantially improves manipulation accuracy compared to previous approaches.
Visit \href{https://pointscoder.github.io/PhysWorld_Web/}{the project webpage}
for details.
\\ ( https://arxiv.org/abs/2511.07416 ,  3590kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07417 (*cross-listing*)
Date: Mon, 10 Nov 2025 18:59:39 GMT   (117kb)

Title: Language Generation with Infinite Contamination
Authors: Anay Mehrotra, Grigoris Velegkas, Xifan Yu, Felix Zhou
Categories: stat.ML cs.AI cs.CL cs.DS cs.LG
\\
 We study language generation in the limit, where an algorithm observes an
adversarial enumeration of strings from an unknown target language $K$ and must
eventually generate new, unseen strings from $K$. Kleinberg and Mullainathan
[KM24] proved that generation is achievable in surprisingly general settings.
But their generator suffers from ``mode collapse,'' producing from an
ever-smaller subset of the target. To address this, Kleinberg and Wei [KW25]
require the generator's output to be ``dense'' in the target language. They
showed that generation with density, surprisingly, remains achievable at the
same generality.
 Both results assume perfect data: no noisy insertions and no omissions. This
raises a central question: how much contamination can generation tolerate?
Recent works made partial progress on this question by studying (non-dense)
generation with either finite amounts of noise (but no omissions) or omissions
(but no noise).
 We characterize robustness under contaminated enumerations: 1. Generation
under Contamination: Language generation in the limit is achievable for all
countable collections iff the fraction of contaminated examples converges to
zero. When this fails, we characterize which collections are generable. 2.
Dense Generation under Contamination: Dense generation is strictly less robust
to contamination than generation. As a byproduct, we resolve an open question
of Raman and Raman [ICML25] by showing that generation is possible with only
membership oracle access under finitely many contaminated examples.
 Finally, we introduce a beyond-worst-case model inspired by curriculum
learning and prove that dense generation is achievable even with infinite
contamination provided the fraction of contaminated examples converges to zero.
This suggests curriculum learning may be crucial for learning from noisy web
data.
\\ ( https://arxiv.org/abs/2511.07417 ,  117kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07418 (*cross-listing*)
Date: Mon, 10 Nov 2025 18:59:44 GMT   (28803kb)

Title: Lightning Grasp: High Performance Procedural Grasp Synthesis with
 Contact Fields
Authors: Zhao-Heng Yin, Pieter Abbeel
Categories: cs.RO cs.AI cs.CV cs.DC cs.GR
Comments: Code: https://github.com/zhaohengyin/lightning-grasp
\\
 Despite years of research, real-time diverse grasp synthesis for dexterous
hands remains an unsolved core challenge in robotics and computer graphics. We
present Lightning Grasp, a novel high-performance procedural grasp synthesis
algorithm that achieves orders-of-magnitude speedups over state-of-the-art
approaches, while enabling unsupervised grasp generation for irregular,
tool-like objects. The method avoids many limitations of prior approaches, such
as the need for carefully tuned energy functions and sensitive initialization.
This breakthrough is driven by a key insight: decoupling complex geometric
computation from the search process via a simple, efficient data structure -
the Contact Field. This abstraction collapses the problem complexity, enabling
a procedural search at unprecedented speeds. We open-source our system to
propel further innovation in robotic manipulation.
\\ ( https://arxiv.org/abs/2511.07418 ,  28803kb)
------------------------------------------------------------------------------
\\
arXiv:2509.16328 (*cross-listing*)
Date: Fri, 19 Sep 2025 18:13:12 GMT   (12kb)
Date (revised v2): Wed, 24 Sep 2025 19:08:24 GMT   (14kb)

Title: The Role of High-Performance GPU Resources in Large Language Model Based
 Radiology Imaging Diagnosis
Authors: Jyun-Ping Kao
Categories: q-bio.TO cs.CL eess.IV physics.med-ph
\\
 Large-language models (LLMs) are rapidly being applied to radiology, enabling
automated image interpretation and report generation tasks. Their deployment in
clinical practice requires both high diagnostic accuracy and low inference
latency, which in turn demands powerful hardware. High-performance graphical
processing units (GPUs) provide the necessary compute and memory throughput to
run large LLMs on imaging data. We review modern GPU architectures (e.g. NVIDIA
A100/H100, AMD Instinct MI250X/MI300) and key performance metrics of
floating-point throughput, memory bandwidth, VRAM capacity. We show how these
hardware capabilities affect radiology tasks: for example, generating reports
or detecting findings on CheXpert and MIMIC-CXR images is computationally
intensive and benefits from GPU parallelism and tensor-core acceleration.
Empirical studies indicate that using appropriate GPU resources can reduce
inference time and improve throughput. We discuss practical challenges
including privacy, deployment, cost, power and optimization strategies:
mixed-precision, quantization, compression, and multi-GPU scaling. Finally, we
anticipate that next-generation features (8-bit tensor cores, enhanced
interconnect) will further enable on-premise and federated radiology AI.
Advancing GPU infrastructure is essential for safe, efficient LLM-based
radiology diagnostics.
\\ ( https://arxiv.org/abs/2509.16328 ,  14kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05550 (*cross-listing*)
Date: Sun, 2 Nov 2025 18:08:26 GMT   (102kb)

Title: Factual and Musical Evaluation Metrics for Music Language Models
Authors: Daniel Chenyu Lin, Michael Freeman, John Thickstun
Categories: cs.SD cs.CL cs.LG
Comments: 18 pages; first submission
\\
 Music language models (Music LMs), like vision language models, leverage
multimodal representations to answer natural language queries about musical
audio recordings. Although Music LMs are reportedly improving, we find that
current evaluations fail to capture whether their answers are correct.
Specifically, for all Music LMs that we examine, widely-used evaluation metrics
such as BLEU, METEOR, and BERTScore fail to measure anything beyond linguistic
fluency of the model's responses. To measure the true performance of Music LMs,
we propose (1) a better general-purpose evaluation metric for Music LMs adapted
to the music domain and (2) a factual evaluation framework to quantify the
correctness of a Music LM's responses. Our framework is agnostic to the
modality of the question-answering model and could be generalized to quantify
performance in other open-ended question-answering domains. We use open
datasets in our experiments and will release all code on publication.
\\ ( https://arxiv.org/abs/2511.05550 ,  102kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05580 (*cross-listing*)
Date: Wed, 5 Nov 2025 03:38:09 GMT   (256kb)

Title: Approximating the Mathematical Structure of Psychodynamics
Authors: Bryce-Allen Bagley and Navin Khoshnan
Categories: q-bio.NC cs.CL cs.CY cs.HC
MSC-class: 18M35 (primary) 47N99, 47A50, 60H25, 68T37, 68T42, 81V99, 91C99,
 91E10, 94A99 (secondary)
ACM-class: E.4; G.3; I.2.0; I.2.4; J.3; J.4
\\
 The complexity of human cognition has meant that psychology makes more use of
theory and conceptual models than perhaps any other biomedical field. To enable
precise quantitative study of the full breadth of phenomena in psychological
and psychiatric medicine as well as cognitive aspects of AI safety, there is a
need for a mathematical formulation which is both mathematically precise and
equally accessible to experts from numerous fields. In this paper we formalize
human psychodynamics via the diagrammatic framework of process theory, describe
its key properties, and explain the links between a diagrammatic representation
and central concepts in analysis of cognitive processes in contexts such as
psychotherapy, neurotechnology, AI alignment, AI agent representation of
individuals in autonomous negotiations, developing human-like AI systems, and
other aspects of AI safety.
\\ ( https://arxiv.org/abs/2511.05580 ,  256kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05717 (*cross-listing*)
Date: Fri, 7 Nov 2025 21:18:42 GMT   (148kb)

Title: Persian Musical Instruments Classification Using Polyphonic Data
 Augmentation
Authors: Diba Hadi Esfangereh, Mohammad Hossein Sameti, Sepehr Harfi Moridani,
 Leili Javidpour, Mahdieh Soleymani Baghshah
Categories: cs.SD cs.CL
Comments: 9 pages, 2 figures, 4 tables
\\
 Musical instrument classification is essential for music information
retrieval (MIR) and generative music systems. However, research on non-Western
traditions, particularly Persian music, remains limited. We address this gap by
introducing a new dataset of isolated recordings covering seven traditional
Persian instruments, two common but originally non-Persian instruments (i.e.,
violin, piano), and vocals. We propose a culturally informed data augmentation
strategy that generates realistic polyphonic mixtures from monophonic samples.
Using the MERT model (Music undERstanding with large-scale self-supervised
Training) with a classification head, we evaluate our approach with
out-of-distribution data which was obtained by manually labeling segments of
traditional songs. On real-world polyphonic Persian music, the proposed method
yielded the best ROC-AUC (0.795), highlighting complementary benefits of tonal
and temporal coherence. These results demonstrate the effectiveness of
culturally grounded augmentation for robust Persian instrument recognition and
provide a foundation for culturally inclusive MIR and diverse music generation
systems.
\\ ( https://arxiv.org/abs/2511.05717 ,  148kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05867 (*cross-listing*)
Date: Sat, 8 Nov 2025 05:52:53 GMT   (383kb)

Title: MCP-RiskCue: Can LLM infer risk information from MCP server System Logs?
Authors: Jiayi Fu, Qiyao Sun
Categories: cs.CR cs.CL
\\
 Large language models (LLMs) demonstrate strong capabilities in solving
complex tasks when integrated with external tools. The Model Context Protocol
(MCP) has become a standard interface for enabling such tool-based
interactions. However, these interactions introduce substantial security
concerns, particularly when the MCP server is compromised or untrustworthy.
While prior benchmarks primarily focus on prompt injection attacks or analyze
the vulnerabilities of LLM MCP interaction trajectories, limited attention has
been given to the underlying system logs associated with malicious MCP servers.
To address this gap, we present the first synthetic benchmark for evaluating
LLMs ability to identify security risks from system logs. We define nine
categories of MCP server risks and generate 1,800 synthetic system logs using
ten state-of-the-art LLMs. These logs are embedded in the return values of 243
curated MCP servers, yielding a dataset of 2,421 chat histories for training
and 471 queries for evaluation. Our pilot experiments reveal that smaller
models often fail to detect risky system logs, leading to high false negatives.
While models trained with supervised fine-tuning (SFT) tend to over-flag benign
logs, resulting in elevated false positives, Reinforcement Learning from
Verifiable Reward (RLVR) offers a better precision-recall balance. In
particular, after training with Group Relative Policy Optimization (GRPO),
Llama3.1-8B-Instruct achieves 83% accuracy, surpassing the best-performing
large remote model by 9 percentage points. Fine-grained, per-category analysis
further underscores the effectiveness of reinforcement learning in enhancing
LLM safety within the MCP framework. Code and data are available at:
https://github.com/PorUna-byte/MCP-Guard/tree/master
\\ ( https://arxiv.org/abs/2511.05867 ,  383kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06288 (*cross-listing*)
Date: Sun, 9 Nov 2025 08:50:11 GMT   (9293kb)

Title: ELEGANCE: Efficient LLM Guidance for Audio-Visual Target Speech
 Extraction
Authors: Wenxuan Wu, Shuai Wang, Xixin Wu, Helen Meng, Haizhou Li
Categories: cs.SD cs.CL cs.MM eess.AS
\\
 Audio-visual target speaker extraction (AV-TSE) models primarily rely on
visual cues from the target speaker. However, humans also leverage linguistic
knowledge, such as syntactic constraints, next word prediction, and prior
knowledge of conversation, to extract target speech. Inspired by this
observation, we propose ELEGANCE, a novel framework that incorporates
linguistic knowledge from large language models (LLMs) into AV-TSE models
through three distinct guidance strategies: output linguistic constraints,
intermediate linguistic prediction, and input linguistic prior. Comprehensive
experiments with RoBERTa, Qwen3-0.6B, and Qwen3-4B on two AV-TSE backbones
demon- strate the effectiveness of our approach. Significant improvements are
observed in challenging scenarios, including visual cue impaired, unseen
languages, target speaker switches, increased interfering speakers, and
out-of-domain test set. Demo page: https://alexwxwu.github.io/ELEGANCE/.
\\ ( https://arxiv.org/abs/2511.06288 ,  9293kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06565 (*cross-listing*)
Date: Sun, 9 Nov 2025 22:54:28 GMT   (116kb)

Title: FPGA or GPU? Analyzing comparative research for application-specific
 guidance
Authors: Arnab A Purkayastha, Jay Tharwani, Shobhit Aggarwal
Categories: cs.AR cs.CL cs.DC cs.PL
Comments: 7 pages
\\
 The growing complexity of computational workloads has amplified the need for
efficient and specialized hardware accelerators. Field Programmable Gate Arrays
(FPGAs) and Graphics Processing Units (GPUs) have emerged as prominent
solutions, each excelling in specific domains. Although there is substantial
research comparing FPGAs and GPUs, most of the work focuses primarily on
performance metrics, offering limited insight into the specific types of
applications that each accelerator benefits the most. This paper aims to bridge
this gap by synthesizing insights from various research articles to guide users
in selecting the appropriate accelerator for domain-specific applications. By
categorizing the reviewed studies and analyzing key performance metrics, this
work highlights the strengths, limitations, and ideal use cases for FPGAs and
GPUs. The findings offer actionable recommendations, helping researchers and
practitioners navigate trade-offs in performance, energy efficiency, and
programmability.
\\ ( https://arxiv.org/abs/2511.06565 ,  116kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06645 (*cross-listing*)
Date: Mon, 10 Nov 2025 02:50:19 GMT   (920kb)

Title: Adaptive Testing for Segmenting Watermarked Texts From Language Models
Authors: Xingchi Li, Xiaochi Liu, Guanxun Li
Categories: stat.ML cs.CL cs.LG
Comments: 13 pages, 3 figures, accepted for publication in STAT, October 28,
 2025
DOI: 10.1002/sta4.70118
\\
 The rapid adoption of large language models (LLMs), such as GPT-4 and Claude
3.5, underscores the need to distinguish LLM-generated text from human-written
content to mitigate the spread of misinformation and misuse in education. One
promising approach to address this issue is the watermark technique, which
embeds subtle statistical signals into LLM-generated text to enable reliable
identification. In this paper, we first generalize the likelihood-based LLM
detection method of a previous study by introducing a flexible weighted
formulation, and further adapt this approach to the inverse transform sampling
method. Moving beyond watermark detection, we extend this adaptive detection
strategy to tackle the more challenging problem of segmenting a given text into
watermarked and non-watermarked substrings. In contrast to the approach in a
previous study, which relies on accurate estimation of next-token probabilities
that are highly sensitive to prompt estimation, our proposed framework removes
the need for precise prompt estimation. Extensive numerical experiments
demonstrate that the proposed methodology is both effective and robust in
accurately segmenting texts containing a mixture of watermarked and
non-watermarked content.
\\ ( https://arxiv.org/abs/2511.06645 ,  920kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07176 (*cross-listing*)
Date: Mon, 10 Nov 2025 15:06:26 GMT   (686kb)

Title: Graph Representation-based Model Poisoning on the Heterogeneous Internet
 of Agents
Authors: Hanlin Cai, Houtianfu Wang, Haofan Dong, Kai Li, Ozgur B. Akan
Categories: cs.NI cs.CL
Comments: 6 pages, 6 figures
\\
 Internet of Agents (IoA) envisions a unified, agent-centric paradigm where
heterogeneous large language model (LLM) agents can interconnect and
collaborate at scale. Within this paradigm, federated learning (FL) serves as a
key enabler that allows distributed LLM agents to co-train global models
without centralizing data. However, the FL-enabled IoA system remains
vulnerable to model poisoning attacks, and the prevailing distance and
similarity-based defenses become fragile at billion-parameter scale and under
heterogeneous data distributions. This paper proposes a graph
representation-based model poisoning (GRMP) attack, which passively exploits
observed benign local models to construct a parameter correlation graph and
extends an adversarial variational graph autoencoder to capture and reshape
higher-order dependencies. The GRMP attack synthesizes malicious local models
that preserve benign-like statistics while embedding adversarial objectives,
remaining elusive to detection at the server. Experiments demonstrate a gradual
drop in system accuracy under the proposed attack and the ineffectiveness of
the prevailing defense mechanism in detecting the attack, underscoring a severe
threat to the ambitious IoA paradigm.
\\ ( https://arxiv.org/abs/2511.07176 ,  686kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05520 (*cross-listing*)
Date: Mon, 27 Oct 2025 10:15:29 GMT   (587kb)

Title: sMRI-based Brain Age Estimation in MCI using Persistent Homology
Authors: Debanjali Bhattacharya, Neelam Sinha
Categories: q-bio.NC cs.CV eess.IV
\\
 In this study, we propose the use of persistent homology- specifically Betti
curves for brain age prediction and for distinguishing between healthy and
pathological aging. The proposed framework is applied to 100 structural MRI
scans from the publicly available ADNI dataset. Our results indicate that Betti
curve features, particularly those from dimension-1 (connected components) and
dimension-2 (1D holes), effectively capture structural brain alterations
associated with aging. Furthermore, clinical features are grouped into three
categories based on their correlation, or lack thereof, with (i) predicted
brain age and (ii) chronological age. The findings demonstrate that this
approach successfully differentiates normal from pathological aging and
provides a novel framework for understanding how structural brain changes
relate to cognitive impairment. The proposed method serves as a foundation for
developing potential biomarkers for early detection and monitoring of cognitive
decline.
\\ ( https://arxiv.org/abs/2511.05520 ,  587kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05642 (*cross-listing*)
Date: Fri, 7 Nov 2025 17:49:14 GMT   (3287kb)

Title: Lite VLA: Efficient Vision-Language-Action Control on CPU-Bound Edge
 Robots
Authors: Justin Williams, Kishor Datta Gupta, Roy George, and Mrinmoy Sarkar
Categories: cs.RO cs.AR cs.CV cs.SY eess.SY
\\
 The deployment of artificial intelligence models at the edge is increasingly
critical for autonomous robots operating in GPS-denied environments where
local, resource-efficient reasoning is essential. This work demonstrates the
feasibility of deploying small Vision-Language Models (VLMs) on mobile robots
to achieve real-time scene understanding and reasoning under strict
computational constraints. Unlike prior approaches that separate perception
from mobility, the proposed framework enables simultaneous movement and
reasoning in dynamic environments using only on-board hardware. The system
integrates a compact VLM with multimodal perception to perform contextual
interpretation directly on embedded hardware, eliminating reliance on cloud
connectivity. Experimental validation highlights the balance between
computational efficiency, task accuracy, and system responsiveness.
Implementation on a mobile robot confirms one of the first successful
deployments of small VLMs for concurrent reasoning and mobility at the edge.
This work establishes a foundation for scalable, assured autonomy in
applications such as service robotics, disaster response, and defense
operations.
\\ ( https://arxiv.org/abs/2511.05642 ,  3287kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05836 (*cross-listing*)
Date: Sat, 8 Nov 2025 04:05:24 GMT   (31855kb)

Title: Training-Free Adaptive Quantization for Variable Rate Image Coding for
 Machines
Authors: Yui Tatsumi, Ziyue Zeng, Hiroshi Watanabe
Categories: eess.IV cs.CV
\\
 Image Coding for Machines (ICM) has become increasingly important with the
rapid integration of computer vision into real-world applications. However,
most ICM frameworks utilize learned image compression (LIC) models that operate
at a fixed rate and require separate training for each target bitrate, which
may limit their practical applications. Existing variable rate LIC approaches
mitigate this limitation but typically depend on training, increasing
computational cost and deployment complexity. Moreover, variable rate control
has not been thoroughly explored for ICM. To address these challenges, we
propose a training-free, adaptive quantization step size control scheme that
enables flexible bitrate adjustment. By leveraging both channel-wise entropy
dependencies and spatial scale parameters predicted by the hyperprior network,
the proposed method preserves semantically important regions while coarsely
quantizing less critical areas. The bitrate can be continuously controlled
through a single parameter. Experimental results demonstrate the effectiveness
of our proposed method, achieving up to 11.07% BD-rate savings over the
non-adaptive variable rate method.
\\ ( https://arxiv.org/abs/2511.05836 ,  31855kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05868 (*cross-listing*)
Date: Sat, 8 Nov 2025 05:53:47 GMT   (9295kb)

Title: HarmoQ: Harmonized Post-Training Quantization for High-Fidelity Image
Authors: Hongjun Wang, Jiyuan Chen, Xuan Song, Yinqiang Zheng
Categories: eess.IV cs.CV
\\
 Post-training quantization offers an efficient pathway to deploy
super-resolution models, yet existing methods treat weight and activation
quantization independently, missing their critical interplay. Through
controlled experiments on SwinIR, we uncover a striking asymmetry: weight
quantization primarily degrades structural similarity, while activation
quantization disproportionately affects pixel-level accuracy. This stems from
their distinct roles--weights encode learned restoration priors for textures
and edges, whereas activations carry input-specific intensity information.
Building on this insight, we propose HarmoQ, a unified framework that
harmonizes quantization across components through three synergistic steps:
structural residual calibration proactively adjusts weights to compensate for
activation-induced detail loss, harmonized scale optimization analytically
balances quantization difficulty via closed-form solutions, and adaptive
boundary refinement iteratively maintains this balance during optimization.
Experiments show HarmoQ achieves substantial gains under aggressive
compression, outperforming prior art by 0.46 dB on Set5 at 2-bit while
delivering 3.2x speedup and 4x memory reduction on A100 GPUs. This work
provides the first systematic analysis of weight-activation coupling in
super-resolution quantization and establishes a principled solution for
efficient high-quality image restoration.
\\ ( https://arxiv.org/abs/2511.05868 ,  9295kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05952 (*cross-listing*)
Date: Sat, 8 Nov 2025 09:53:03 GMT   (19189kb)

Title: Pinching Visuo-haptic Display: Investigating Cross-Modal Effects of
 Visual Textures on Electrostatic Cloth Tactile Sensations
Authors: Takekazu Kitagishi, Chun-Wei Ooi, Yuichi Hiroi, and Jun Rekimoto
Categories: cs.HC cs.CV cs.MM
Comments: 10 pages, 8 figures, 3 tables. Presented at ACM International
 Conference on Multimodal Interaction (ICMI) 2025
ACM-class: H.5.2; I.3.6; I.4.8
DOI: 10.1145/3716553.3750810
\\
 This paper investigates how visual texture presentation influences tactile
perception when interacting with electrostatic cloth displays. We propose a
visuo-haptic system that allows users to pinch and rub virtual fabrics while
feeling realistic frictional sensations modulated by electrostatic actuation.
Through a user study, we examined the cross-modal effects between visual
roughness and perceived tactile friction. The results demonstrate that visually
rough textures amplify the perceived frictional force, even under identical
electrostatic stimuli. These findings contribute to the understanding of
multimodal texture perception and provide design insights for haptic feedback
in virtual material interfaces.
\\ ( https://arxiv.org/abs/2511.05952 ,  19189kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06056 (*cross-listing*)
Date: Sat, 8 Nov 2025 15:55:37 GMT   (2723kb)

Title: Identity Card Presentation Attack Detection: A Systematic Review
Authors: Esteban M. Ruiz, Juan E. Tapia, Reinel T. Soto, Christoph Busch
Categories: cs.CR cs.CV
\\
 Remote identity verification is essential for modern digital security;
however, it remains highly vulnerable to sophisticated Presentation Attacks
(PAs) that utilise forged or manipulated identity documents. Although Deep
Learning (DL) has driven advances in Presentation Attack Detection (PAD), the
field is fundamentally limited by a lack of data and the poor generalisation of
models across various document types and new attack methods.
 This article presents a systematic literature review (SLR) conducted in
accordance with the PRISMA methodology, aiming to analyse and synthesise the
current state of AI-based PAD for identity documents from 2020 to 2025
comprehensively. Our analysis reveals a significant methodological evolution: a
transition from standard Convolutional Neural Networks (CNNs) to specialised
forensic micro-artefact analysis, and more recently, the adoption of
large-scale Foundation Models (FMs), marking a substantial shift in the field.
 We identify a central paradox that hinders progress: a critical "Reality Gap"
exists between models validated on extensive, private datasets and those
assessed using limited public datasets, which typically consist of mock-ups or
synthetic data. This gap limits the reproducibility of research results.
Additionally, we highlight a "Synthetic Utility Gap," where synthetic data
generation the primary academic response to data scarcity often fails to
predict forensic utility. This can lead to model overfitting to generation
artefacts instead of the actual attack.
 This review consolidates our findings, identifies critical research gaps, and
provides a definitive reference framework that outlines a prescriptive roadmap
for future research aimed at developing secure, robust, and globally
generalizable PAD systems.
\\ ( https://arxiv.org/abs/2511.06056 ,  2723kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06163 (*cross-listing*)
Date: Sat, 8 Nov 2025 23:29:28 GMT   (347kb)

Title: Cross-Modal Fine-Tuning of 3D Convolutional Foundation Models for ADHD
 Classification with Low-Rank Adaptation
Authors: Jyun-Ping Kao, Shinyeong Rho, Shahar Lazarev, Hyun-Hae Cho, Fangxu
 Xing, Taehoon Shin, C.-C. Jay Kuo, Jonghye Woo
Categories: eess.IV cs.CV cs.LG physics.med-ph
\\
 Early diagnosis of attention-deficit/hyperactivity disorder (ADHD) in
children plays a crucial role in improving outcomes in education and mental
health. Diagnosing ADHD using neuroimaging data, however, remains challenging
due to heterogeneous presentations and overlapping symptoms with other
conditions. To address this, we propose a novel parameter-efficient transfer
learning approach that adapts a large-scale 3D convolutional foundation model,
pre-trained on CT images, to an MRI-based ADHD classification task. Our method
introduces Low-Rank Adaptation (LoRA) in 3D by factorizing 3D convolutional
kernels into 2D low-rank updates, dramatically reducing trainable parameters
while achieving superior performance. In a five-fold cross-validated evaluation
on a public diffusion MRI database, our 3D LoRA fine-tuning strategy achieved
state-of-the-art results, with one model variant reaching 71.9% accuracy and
another attaining an AUC of 0.716. Both variants use only 1.64 million
trainable parameters (over 113x fewer than a fully fine-tuned foundation
model). Our results represent one of the first successful cross-modal
(CT-to-MRI) adaptations of a foundation model in neuroimaging, establishing a
new benchmark for ADHD classification while greatly improving efficiency.
\\ ( https://arxiv.org/abs/2511.06163 ,  347kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06378 (*cross-listing*)
Date: Sun, 9 Nov 2025 13:30:51 GMT   (22881kb)

Title: ArtReg: Visuo-Tactile based Pose Tracking and Manipulation of Unseen
 Articulated Objects
Authors: Prajval Kumar Murali and Mohsen Kaboli
Categories: cs.RO cs.CV
Comments: Under review
\\
 Robots operating in real-world environments frequently encounter unknown
objects with complex structures and articulated components, such as doors,
drawers, cabinets, and tools. The ability to perceive, track, and manipulate
these objects without prior knowledge of their geometry or kinematic properties
remains a fundamental challenge in robotics. In this work, we present a novel
method for visuo-tactile-based tracking of unseen objects (single, multiple, or
articulated) during robotic interaction without assuming any prior knowledge
regarding object shape or dynamics. Our novel pose tracking approach termed
ArtReg (stands for Articulated Registration) integrates visuo-tactile point
clouds in an unscented Kalman Filter formulation in the SE(3) Lie Group for
point cloud registration. ArtReg is used to detect possible articulated joints
in objects using purposeful manipulation maneuvers such as pushing or
hold-pulling with a two-robot team. Furthermore, we leverage ArtReg to develop
a closed-loop controller for goal-driven manipulation of articulated objects to
move the object into the desired pose configuration. We have extensively
evaluated our approach on various types of unknown objects through real robot
experiments. We also demonstrate the robustness of our method by evaluating
objects with varying center of mass, low-light conditions, and with challenging
visual backgrounds. Furthermore, we benchmarked our approach on a standard
dataset of articulated objects and demonstrated improved performance in terms
of pose accuracy compared to state-of-the-art methods. Our experiments indicate
that robust and accurate pose tracking leveraging visuo-tactile information
enables robots to perceive and interact with unseen complex articulated objects
(with revolute or prismatic joints).
\\ ( https://arxiv.org/abs/2511.06378 ,  22881kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06425 (*cross-listing*)
Date: Sun, 9 Nov 2025 15:43:43 GMT   (1863kb)

Title: Non-Negative Stiefel Approximating Flow: Orthogonalish Matrix
 Optimization for Interpretable Embeddings
Authors: Brian B. Avants, Nicholas J. Tustison and James R Stone (Department of
 Radiology and Medical Imaging University of Virginia, Charlottesville, VA)
Categories: stat.ML cs.CV cs.LG stat.ME
\\
 Interpretable representation learning is a central challenge in modern
machine learning, particularly in high-dimensional settings such as
neuroimaging, genomics, and text analysis. Current methods often struggle to
balance the competing demands of interpretability and model flexibility,
limiting their effectiveness in extracting meaningful insights from complex
data. We introduce Non-negative Stiefel Approximating Flow (NSA-Flow), a
general-purpose matrix estimation framework that unifies ideas from sparse
matrix factorization, orthogonalization, and constrained manifold learning.
NSA-Flow enforces structured sparsity through a continuous balance between
reconstruction fidelity and column-wise decorrelation, parameterized by a
single tunable weight. The method operates as a smooth flow near the Stiefel
manifold with proximal updates for non-negativity and adaptive gradient
control, yielding representations that are simultaneously sparse, stable, and
interpretable. Unlike classical regularization schemes, NSA-Flow provides an
intuitive geometric mechanism for manipulating sparsity at the level of global
structure while simplifying latent features. We demonstrate that the NSA-Flow
objective can be optimized smoothly and integrates seamlessly with existing
pipelines for dimensionality reduction while improving interpretability and
generalization in both simulated and real biomedical data. Empirical validation
on the Golub leukemia dataset and in Alzheimer's disease demonstrate that the
NSA-Flow constraints can maintain or improve performance over related methods
with little additional methodological effort. NSA-Flow offers a scalable,
general-purpose tool for interpretable ML, applicable across data science
domains.
\\ ( https://arxiv.org/abs/2511.06425 ,  1863kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06749 (*cross-listing*)
Date: Mon, 10 Nov 2025 06:28:31 GMT   (442kb)

Title: Semi-distributed Cross-modal Air-Ground Relative Localization
Authors: Weining Lu, Deer Bin, Lian Ma, Ming Ma, Zhihao Ma, Xiangyang Chen,
 Longfei Wang, Yixiao Feng, Zhouxian Jiang, Yongliang Shi, Bin Liang
Categories: cs.RO cs.CV
Comments: 7 pages, 3 figures. Accepted by IROS 2025
\\
 Efficient, accurate, and flexible relative localization is crucial in
air-ground collaborative tasks. However, current approaches for robot relative
localization are primarily realized in the form of distributed multi-robot SLAM
systems with the same sensor configuration, which are tightly coupled with the
state estimation of all robots, limiting both flexibility and accuracy. To this
end, we fully leverage the high capacity of Unmanned Ground Vehicle (UGV) to
integrate multiple sensors, enabling a semi-distributed cross-modal air-ground
relative localization framework. In this work, both the UGV and the Unmanned
Aerial Vehicle (UAV) independently perform SLAM while extracting deep
learning-based keypoints and global descriptors, which decouples the relative
localization from the state estimation of all agents. The UGV employs a local
Bundle Adjustment (BA) with LiDAR, camera, and an IMU to rapidly obtain
accurate relative pose estimates. The BA process adopts sparse keypoint
optimization and is divided into two stages: First, optimizing camera poses
interpolated from LiDAR-Inertial Odometry (LIO), followed by estimating the
relative camera poses between the UGV and UAV. Additionally, we implement an
incremental loop closure detection algorithm using deep learning-based
descriptors to maintain and retrieve keyframes efficiently. Experimental
results demonstrate that our method achieves outstanding performance in both
accuracy and efficiency. Unlike traditional multi-robot SLAM approaches that
transmit images or point clouds, our method only transmits keypoint pixels and
their descriptors, effectively constraining the communication bandwidth under
0.3 Mbps. Codes and data will be publicly available on
https://github.com/Ascbpiac/cross-model-relative-localization.git.
\\ ( https://arxiv.org/abs/2511.06749 ,  442kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06754 (*cross-listing*)
Date: Mon, 10 Nov 2025 06:33:44 GMT   (2747kb)

Title: SlotVLA: Towards Modeling of Object-Relation Representations in Robotic
 Manipulation
Authors: Taisei Hanyu, Nhat Chung, Huy Le, Toan Nguyen, Yuki Ikebe, Anthony
 Gunderman, Duy Nguyen Ho Minh, Khoa Vo, Tung Kieu, Kashu Yamazaki, Chase
 Rainwater, Anh Nguyen, Ngan Le
Categories: cs.RO cs.CV
Comments: under review
\\
 Inspired by how humans reason over discrete objects and their relationships,
we explore whether compact object-centric and object-relation representations
can form a foundation for multitask robotic manipulation. Most existing robotic
multitask models rely on dense embeddings that entangle both object and
background cues, raising concerns about both efficiency and interpretability.
In contrast, we study object-relation-centric representations as a pathway to
more structured, efficient, and explainable visuomotor control. Our
contributions are two-fold. First, we introduce LIBERO+, a fine-grained
benchmark dataset designed to enable and evaluate object-relation reasoning in
robotic manipulation. Unlike prior datasets, LIBERO+ provides object-centric
annotations that enrich demonstrations with box- and mask-level labels as well
as instance-level temporal tracking, supporting compact and interpretable
visuomotor representations. Second, we propose SlotVLA, a slot-attention-based
framework that captures both objects and their relations for action decoding.
It uses a slot-based visual tokenizer to maintain consistent temporal object
representations, a relation-centric decoder to produce task-relevant
embeddings, and an LLM-driven module that translates these embeddings into
executable actions. Experiments on LIBERO+ demonstrate that object-centric slot
and object-relation slot representations drastically reduce the number of
required visual tokens, while providing competitive generalization. Together,
LIBERO+ and SlotVLA provide a compact, interpretable, and effective foundation
for advancing object-relation-centric robotic manipulation.
\\ ( https://arxiv.org/abs/2511.06754 ,  2747kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06769 (*cross-listing*)
Date: Mon, 10 Nov 2025 06:51:41 GMT   (19972kb)

Title: RRTS Dataset: A Benchmark Colonoscopy Dataset from Resource-Limited
 Settings for Computer-Aided Diagnosis Research
Authors: Ridoy Chandra Shil, Ragib Abid, Tasnia Binte Mamun, Samiul Based
 Shuvo, Masfique Ahmed Bhuiyan, Jahid Ferdous
Categories: eess.IV cs.CV
\\
 Background and Objective: Colorectal cancer prevention relies on early
detection of polyps during colonoscopy. Existing public datasets, such as
CVC-ClinicDB and Kvasir-SEG, provide valuable benchmarks but are limited by
small sample sizes, curated image selection, or lack of real-world artifacts.
There remains a need for datasets that capture the complexity of clinical
practice, particularly in resource-constrained settings. Methods: We introduce
a dataset, BUET Polyp Dataset (BPD), of colonoscopy images collected using
Olympus 170 and Pen- tax i-Scan series endoscopes under routine clinical
conditions. The dataset contains images with corresponding expert-annotated
binary masks, reflecting diverse challenges such as motion blur, specular
highlights, stool artifacts, blood, and low-light frames. Annotations were
manually reviewed by clinical experts to ensure quality. To demonstrate
baseline performance, we provide bench- mark results for classification using
VGG16, ResNet50, and InceptionV3, and for segmentation using UNet variants with
VGG16, ResNet34, and InceptionV4 backbones. Results: The dataset comprises
1,288 images with polyps from 164 patients with corresponding ground-truth
masks and 1,657 polyp-free images from 31 patients. Benchmarking experiments
achieved up to 90.8% accuracy for binary classification (VGG16) and a maximum
Dice score of 0.64 with InceptionV4-UNet for segmentation. Performance was
lower compared to curated datasets, reflecting the real-world difficulty of
images with artifacts and variable quality.
\\ ( https://arxiv.org/abs/2511.06769 ,  19972kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06839 (*cross-listing*)
Date: Mon, 10 Nov 2025 08:31:28 GMT   (946kb)

Title: Vision-Based System Identification of a Quadrotor
Authors: Selim Ahmet Iz, Mustafa Unel
Categories: cs.RO cs.CV cs.SY eess.SY math.DS
DOI: 10.1109/ICIVC58118.2023.10270807
\\
 This paper explores the application of vision-based system identification
techniques in quadrotor modeling and control. Through experiments and analysis,
we address the complexities and limitations of quadrotor modeling, particularly
in relation to thrust and drag coefficients. Grey-box modeling is employed to
mitigate uncertainties, and the effectiveness of an onboard vision system is
evaluated. An LQR controller is designed based on a system identification model
using data from the onboard vision system. The results demonstrate consistent
performance between the models, validating the efficacy of vision based system
identification. This study highlights the potential of vision-based techniques
in enhancing quadrotor modeling and control, contributing to improved
performance and operational capabilities. Our findings provide insights into
the usability and consistency of these techniques, paving the way for future
research in quadrotor performance enhancement, fault detection, and
decision-making processes.
\\ ( https://arxiv.org/abs/2511.06839 ,  946kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07094 (*cross-listing*)
Date: Mon, 10 Nov 2025 13:30:59 GMT   (5694kb)

Title: Task-Adaptive Low-Dose CT Reconstruction
Authors: Necati Sefercioglu, Mehmet Ozan Unal, Metin Ertas, Isa Yildirim
Categories: eess.IV cs.CV
\\
 Deep learning-based low-dose computed tomography reconstruction methods
already achieve high performance on standard image quality metrics like peak
signal-to-noise ratio and structural similarity index measure. Yet, they
frequently fail to preserve the critical anatomical details needed for
diagnostic tasks. This fundamental limitation hinders their clinical
applicability despite their high metric scores. We propose a novel
task-adaptive reconstruction framework that addresses this gap by incorporating
a frozen pre-trained task network as a regularization term in the
reconstruction loss function. Unlike existing joint-training approaches that
simultaneously optimize both reconstruction and task networks, and risk
diverging from satisfactory reconstructions, our method leverages a pre-trained
task model to guide reconstruction training while still maintaining diagnostic
quality. We validate our framework on a liver and liver tumor segmentation
task. Our task-adaptive models achieve Dice scores up to 0.707, approaching the
performance of full-dose scans (0.874), and substantially outperforming
joint-training approaches (0.331) and traditional reconstruction methods
(0.626). Critically, our framework can be integrated into any existing deep
learning-based reconstruction model through simple loss function modification,
enabling widespread adoption for task-adaptive optimization in clinical
practice. Our codes are available at:
https://github.com/itu-biai/task_adaptive_ct
\\ ( https://arxiv.org/abs/2511.07094 ,  5694kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07253 (*cross-listing*)
Date: Mon, 10 Nov 2025 16:03:44 GMT   (3482kb)

Title: Omni-AVSR: Towards Unified Multimodal Speech Recognition with Large
 Language Models
Authors: Umberto Cappellazzo, Xubo Liu, Pingchuan Ma, Stavros Petridis, Maja
 Pantic
Categories: eess.AS cs.CV cs.SD
Comments: Project website: https://umbertocappellazzo.github.io/Omni-AVSR/
\\
 Large language models (LLMs) have recently achieved impressive results in
speech recognition across multiple modalities, including Auditory Speech
Recognition (ASR), Visual Speech Recognition (VSR), and Audio-Visual Speech
Recognition (AVSR). Despite this progress, current LLM-based approaches
typically address each task independently, training separate models that raise
computational and deployment resource use while missing potential cross-task
synergies. They also rely on fixed-rate token compression, which restricts
flexibility in balancing accuracy with efficiency. These limitations highlight
the need for a unified framework that can support ASR, VSR, and AVSR while
enabling elastic inference. To this end, we present Omni-AVSR, a unified
audio-visual LLM that combines efficient multi-granularity training with
parameter-efficient adaptation. Specifically, we adapt the matryoshka
representation learning paradigm to efficiently train across multiple audio and
visual granularities, reducing its inherent training resource use. Furthermore,
we explore three LoRA-based strategies for adapting the backbone LLM, balancing
shared and task-specific specialization. Experiments on LRS2 and LRS3 show that
Omni-AVSR achieves comparable or superior accuracy to state-of-the-art
baselines while training a single model at substantially lower training and
deployment resource use. The model also remains robust under acoustic noise,
and we analyze its scaling behavior as LLM size increases, providing insights
into the trade-off between performance and efficiency.
\\ ( https://arxiv.org/abs/2511.07253 ,  3482kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07290 (*cross-listing*)
Date: Mon, 10 Nov 2025 16:37:47 GMT   (21838kb)

Title: CAMP-VQA: Caption-Embedded Multimodal Perception for No-Reference
 Quality Assessment of Compressed Video
Authors: Xinyi Wang, Angeliki Katsenou, Junxiao Shen, David Bull
Categories: eess.IV cs.CV cs.MM
Comments: 14 pages, 6 figures
\\
 The prevalence of user-generated content (UGC) on platforms such as YouTube
and TikTok has rendered no-reference (NR) perceptual video quality assessment
(VQA) vital for optimizing video delivery. Nonetheless, the characteristics of
non-professional acquisition and the subsequent transcoding of UGC video on
sharing platforms present significant challenges for NR-VQA. Although NR-VQA
models attempt to infer mean opinion scores (MOS), their modeling of subjective
scores for compressed content remains limited due to the absence of
fine-grained perceptual annotations of artifact types. To address these
challenges, we propose CAMP-VQA, a novel NR-VQA framework that exploits the
semantic understanding capabilities of large vision-language models. Our
approach introduces a quality-aware prompting mechanism that integrates video
metadata (e.g., resolution, frame rate, bitrate) with key fragments extracted
from inter-frame variations to guide the BLIP-2 pretraining approach in
generating fine-grained quality captions. A unified architecture has been
designed to model perceptual quality across three dimensions: semantic
alignment, temporal characteristics, and spatial characteristics. These
multimodal features are extracted and fused, then regressed to video quality
scores. Extensive experiments on a wide variety of UGC datasets demonstrate
that our model consistently outperforms existing NR-VQA methods, achieving
improved accuracy without the need for costly manual fine-grained annotations.
Our method achieves the best performance in terms of average rank and linear
correlation (SRCC: 0.928, PLCC: 0.938) compared to state-of-the-art methods.
The source code and trained models, along with a user-friendly demo, are
available at: https://github.com/xinyiW915/CAMP-VQA.
\\ ( https://arxiv.org/abs/2511.07290 ,  21838kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07292 (*cross-listing*)
Date: Mon, 10 Nov 2025 16:41:47 GMT   (659kb)

Title: PlanT 2.0: Exposing Biases and Structural Flaws in Closed-Loop Driving
Authors: Simon Gerstenecker and Andreas Geiger and Katrin Renz
Categories: cs.RO cs.CV
\\
 Most recent work in autonomous driving has prioritized benchmark performance
and methodological innovation over in-depth analysis of model failures, biases,
and shortcut learning. This has led to incremental improvements without a deep
understanding of the current failures. While it is straightforward to look at
situations where the model fails, it is hard to understand the underlying
reason. This motivates us to conduct a systematic study, where inputs to the
model are perturbed and the predictions observed. We introduce PlanT 2.0, a
lightweight, object-centric planning transformer designed for autonomous
driving research in CARLA. The object-level representation enables controlled
analysis, as the input can be easily perturbed (e.g., by changing the location
or adding or removing certain objects), in contrast to sensor-based models. To
tackle the scenarios newly introduced by the challenging CARLA Leaderboard 2.0,
we introduce multiple upgrades to PlanT, achieving state-of-the-art performance
on Longest6 v2, Bench2Drive, and the CARLA validation routes. Our analysis
exposes insightful failures, such as a lack of scene understanding caused by
low obstacle diversity, rigid expert behaviors leading to exploitable
shortcuts, and overfitting to a fixed set of expert trajectories. Based on
these findings, we argue for a shift toward data-centric development, with a
focus on richer, more robust, and less biased datasets. We open-source our code
and model at https://github.com/autonomousvision/plant2.
\\ ( https://arxiv.org/abs/2511.07292 ,  659kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06688 (*cross-listing*)
Date: Mon, 10 Nov 2025 04:20:46 GMT   (153kb)

Title: Accessibility Gaps in U.S. Government Dashboards for Blind and
 Low-Vision Residents
Authors: Chadani Acharya
Categories: cs.HC cs.CY cs.DL cs.IR
Comments: Preprint. Accessibility audit of six U.S. public dashboard
 ecosystems; 1 figure, 2 tables
\\
 Public dashboards are now a common way for US government agencies to share
high stakes information with residents. We audited six live systems at federal,
state, and city levels: CDC respiratory illness, HUD homelessness PIT and HIC,
California HCD Annual Progress Report, New York City Mayor's Management Report,
Houston Permitting, and Chicago public health and budget dashboards. Using a
rubric based on screen reader needs and WCAG, we checked five items: (1)
discoverability of key metrics by assistive tech, (2) keyboard access without
mouse hover, (3) clear semantic labels for axes, series, and categories, (4)
short plain language status and trend notes, and (5) machine readable tables or
CSVs that mirror what sighted users see. Findings are mixed. Many charts fail
basic discoverability or depend on hover, which blocks keyboard and screen
reader use. Plain language summaries are common in CDC and Chicago, but rare in
HUD and Houston. Machine readable data is strong for NYC, California, and HUD;
it is weaker or unclear for Houston. Several sites promise service for the
public or for customers yet do not name accessibility in their descriptions.
Across systems we also observe urgency inversion: faster, operational
dashboards tend to provide fewer accessible affordances than slower
accountability dashboards. These patterns matter for equal participation and
for ADA Title II compliance that references WCAG 2.1 AA. We propose three steps
for any public dashboard: add a brief status and trend text at the same update
cadence, publish a matching table or CSV of the visual metrics, and state an
explicit accessibility commitment.
\\ ( https://arxiv.org/abs/2511.06688 ,  153kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06982 (*cross-listing*)
Date: Mon, 10 Nov 2025 11:34:36 GMT   (2110kb)

Title: CGLE: Class-label Graph Link Estimator for Link Prediction
Authors: Ankit Mazumder and Srikanta Bedathur
Categories: cs.SI cs.IR
Comments: Paper accepted at the IEEE International Conference on Data Mining
 (ICDM 2025)
\\
 Link prediction is a pivotal task in graph mining with wide-ranging
applications in social networks, recommendation systems, and knowledge graph
completion. However, many leading Graph Neural Network (GNN) models often
neglect the valuable semantic information aggregated at the class level. To
address this limitation, this paper introduces CGLE (Class-label Graph Link
Estimator), a novel framework designed to augment GNN-based link prediction
models. CGLE operates by constructing a class-conditioned link probability
matrix, where each entry represents the probability of a link forming between
two node classes. This matrix is derived from either available ground-truth
labels or from pseudo-labels obtained through clustering. The resulting
class-based prior is then concatenated with the structural link embedding from
a backbone GNN, and the combined representation is processed by a Multi-Layer
Perceptron (MLP) for the final prediction. Crucially, CGLE's logic is
encapsulated in an efficient preprocessing stage, leaving the computational
complexity of the underlying GNN model unaffected. We validate our approach
through extensive experiments on a broad suite of benchmark datasets, covering
both homophilous and sparse heterophilous graphs. The results show that CGLE
yields substantial performance gains over strong baselines such as NCN and
NCNC, with improvements in HR@100 of over 10 percentage points on homophilous
datasets like Pubmed and DBLP. On sparse heterophilous graphs, CGLE delivers an
MRR improvement of over 4% on the Chameleon dataset. Our work underscores the
efficacy of integrating global, data-driven semantic priors, presenting a
compelling alternative to the pursuit of increasingly complex model
architectures. Code to reproduce our findings is available at:
https://github.com/data-iitd/cgle-icdm2025.
\\ ( https://arxiv.org/abs/2511.06982 ,  2110kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07280 (*cross-listing*)
Date: Mon, 10 Nov 2025 16:27:01 GMT   (5344kb)

Title: The Value of Personalized Recommendations: Evidence from Netflix
Authors: Kevin Zielnicki, Guy Aridor, Aur\'elien Bibaut, Allen Tran, Winston
 Chou, Nathan Kallus
Categories: econ.GN cs.IR cs.LG q-fin.EC
\\
 Personalized recommendation systems shape much of user choice online, yet
their targeted nature makes separating out the value of recommendation and the
underlying goods challenging. We build a discrete choice model that embeds
recommendation-induced utility, low-rank heterogeneity, and flexible state
dependence and apply the model to viewership data at Netflix. We exploit
idiosyncratic variation introduced by the recommendation algorithm to identify
and separately value these components as well as to recover model-free
diversion ratios that we can use to validate our structural model. We use the
model to evaluate counterfactuals that quantify the incremental engagement
generated by personalized recommendations. First, we show that replacing the
current recommender system with a matrix factorization or popularity-based
algorithm would lead to 4% and 12% reduction in engagement, respectively, and
decreased consumption diversity. Second, most of the consumption increase from
recommendations comes from effective targeting, not mechanical exposure, with
the largest gains for mid-popularity goods (as opposed to broadly appealing or
very niche goods).
\\ ( https://arxiv.org/abs/2511.07280 ,  5344kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05503 (*cross-listing*)
Date: Fri, 10 Oct 2025 16:53:37 GMT   (280kb)

Title: iEEG Seizure Detection with a Sparse Hyperdimensional Computing
 Accelerator
Authors: Stef Cuyckens, Ryan Antonio, Chao Fang, Marian Verhelst
Categories: cs.AR cs.LG
Comments: To appear at the 20th International Conference on PhD Research in
 Microelectronics and Electronics (PRIME 2025)
\\
 Implantable devices for reliable intracranial electroencephalography (iEEG)
require efficient, accurate, and real-time detection of seizures. Dense
hyperdimensional computing (HDC) proves to be efficient over neural networks;
however, it still consumes considerable switching power for an ultra-low energy
application. Sparse HDC, on the other hand, has the potential of further
reducing the energy consumption, yet at the expense of having to support more
complex operations and introducing an extra hyperparameter, the maximum
hypervector density. To improve the energy and area efficiency of the sparse
HDC operations, this work introduces the compressed item memory (CompIM) and
simplifies the spatial bundling. We also analyze how a proper hyperparameter
choice improves the detection delay compared to dense HDC. Ultimately, our
optimizations achieve a 1.73x more energy- and 2.20x more area-efficient
hardware design than the naive sparse implementation. We are also 7.50x more
energy- and 3.24x more area-efficient than the dense HDC implementation. This
work highlights the hardware advantages of sparse HDC, demonstrating its
potential to enable smaller brain implants with a substantially extended
battery life compared to the current state-of-the-art.
\\ ( https://arxiv.org/abs/2511.05503 ,  280kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05537 (*cross-listing*)
Date: Wed, 29 Oct 2025 18:50:59 GMT   (2911kb)

Title: Bridging Accuracy and Explainability in EEG-based Graph Attention
 Network for Depression Detection
Authors: Soujanya Hazra and Sanjay Ghosh
Categories: eess.SP cs.LG eess.IV q-bio.NC
Comments: 13 pages, 3 tables, and 7 fugures
\\
 Depression is a major cause of global mental illness and significantly
influences suicide rates. Timely and accurate diagnosis is essential for
effective intervention. Electroencephalography (EEG) provides a non-invasive
and accessible method for examining cerebral activity and identifying
disease-associated patterns. We propose a novel graph-based deep learning
framework, named Edge-gated, axis-mixed Pooling Attention Network (ExPANet),
for differentiating major depressive disorder (MDD) patients from healthy
controls (HC). EEG recordings undergo preprocessing to eliminate artifacts and
are segmented into short periods of activity. We extract 14 features from each
segment, which include time, frequency, fractal, and complexity domains.
Electrodes are represented as nodes, whereas edges are determined by the
phase-locking value (PLV) to represent functional connectivity. The generated
brain graphs are examined utilizing an adapted graph attention network. This
architecture acquires both localized electrode characteristics and
comprehensive functional connectivity patterns. The proposed framework attains
superior performance relative to current EEG-based approaches across two
different datasets. A fundamental advantage of our methodology is its
explainability. We evaluated the significance of features, channels, and edges,
in addition to intrinsic attention weights. These studies highlight features,
cerebral areas, and connectivity associations that are especially relevant to
MDD, many of which correspond with clinical data. Our findings demonstrate a
reliable and transparent method for EEG-based screening of MDD, using deep
learning with clinically relevant results.
\\ ( https://arxiv.org/abs/2511.05537 ,  2911kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05584 (*cross-listing*)
Date: Wed, 5 Nov 2025 09:45:14 GMT   (1886kb)

Title: Beyond Resolution: Multi - Scale Weather and Climate Data for Alpine
 Renewable Energy in the Digital Twin Era - First Evaluations and
 Recommendations
Authors: Irene Schicker, Marianne B\"ugelmayer-Blaschek, Annemarie Lexer,
 Katharina Baier, Kristofer Hasel, Paolo Gazzaneo
Categories: physics.ao-ph cs.LG
Comments: perspectives paper submitted to iScience, 25 pages, 2 tables, 3
 figures
Journal-ref: iScience 2025
\\
 When Austrian hydropower production plummeted by 44% in early 2025 due to
reduced snowpack, it exposed a critical vulnerability: standard meteorological
and climatological datasets systematically fail in mountain regions that hold
untapped renewable potential. This perspectives paper evaluates emerging
solutions to the Alpine energy-climate data gap, analyzing datasets from global
reanalyses (ERA5, 31 km) to kilometre-scale Digital Twins (Climate DT, Extremes
DT, 4.4 km), regional reanalyses (ARA, 2.5 km), and next-generation AI weather
prediction models (AIFS, 31 km). The multi-resolution assessment reveals that
no single dataset excels universally: coarse reanalyses provide essential
climatologies but miss valley-scale processes, while Digital Twins resolve
Alpine dynamics yet remain computationally demanding. Effective energy planning
therefore requires strategic dataset combinations validated against
energy-relevant indices such as population-weighted extremes, wind-gust return
periods, and Alpine-adjusted storm thresholds. A key frontier is sub-hourly
(10-15 min) temporal resolution to match grid-operation needs. Six
evidence-based recommendations outline pathways for bridging spatial and
temporal scales. As renewable deployment expands globally into complex terrain,
the Alpine region offers transferable perspectives for tackling identical
forecasting and climate analysis challenges in mountainous regions worldwide.
\\ ( https://arxiv.org/abs/2511.05584 ,  1886kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05757 (*cross-listing*)
Date: Fri, 7 Nov 2025 23:02:55 GMT   (376kb)

Title: Zero-Shot Function Encoder-Based Differentiable Predictive Control
Authors: Hassan Iqbal, Xingjian Li, Tyler Ingebrand, Adam Thorpe, Krishna
 Kumar, Ufuk Topcu, J\'an Drgo\v{n}a
Categories: eess.SY cs.LG cs.SY
\\
 We introduce a differentiable framework for zero-shot adaptive control over
parametric families of nonlinear dynamical systems. Our approach integrates a
function encoder-based neural ODE (FE-NODE) for modeling system dynamics with a
differentiable predictive control (DPC) for offline self-supervised learning of
explicit control policies. The FE-NODE captures nonlinear behaviors in state
transitions and enables zero-shot adaptation to new systems without retraining,
while the DPC efficiently learns control policies across system
parameterizations, thus eliminating costly online optimization common in
classical model predictive control. We demonstrate the efficiency, accuracy,
and online adaptability of the proposed method across a range of nonlinear
systems with varying parametric scenarios, highlighting its potential as a
general-purpose tool for fast zero-shot adaptive control.
\\ ( https://arxiv.org/abs/2511.05757 ,  376kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05983 (*cross-listing*)
Date: Sat, 8 Nov 2025 12:07:23 GMT   (6942kb)

Title: Benchmarking of Clustering Validity Measures Revisited
Authors: Connor Simpson, Ricardo J. G. B. Campello, Elizabeth Stojanovski
Categories: stat.ML cs.LG
Comments: 48 pages, 17 tables, 17 figures
\\
 Validation plays a crucial role in the clustering process. Many different
internal validity indexes exist for the purpose of determining the best
clustering solution(s) from a given collection of candidates, e.g., as produced
by different algorithms or different algorithm hyper-parameters. In this study,
we present a comprehensive benchmark study of 26 internal validity indexes,
which includes highly popular classic indexes as well as more recently
developed ones. We adopted an enhanced revision of the methodology presented in
Vendramin et al. (2010), developed here to address several shortcomings of this
previous work. This overall new approach consists of three complementary
custom-tailored evaluation sub-methodologies, each of which has been designed
to assess specific aspects of an index's behaviour while preventing potential
biases of the other sub-methodologies. Each sub-methodology features two
complementary measures of performance, alongside mechanisms that allow for an
in-depth investigation of more complex behaviours of the internal validity
indexes under study. Additionally, a new collection of 16177 datasets has been
produced, paired with eight widely-used clustering algorithms, for a wider
applicability scope and representation of more diverse clustering scenarios.
\\ ( https://arxiv.org/abs/2511.05983 ,  6942kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05990 (*cross-listing*)
Date: Sat, 8 Nov 2025 12:37:56 GMT   (7093kb)

Title: Learning solutions of parameterized stiff ODEs using Gaussian processes
Authors: Idoia Cortes Garcia, P. F\"orster, W. Schilders and S. Sch\"ops
Categories: math.NA cs.CE cs.LG cs.NA
Comments: 21 pages, 10 figures
MSC-class: 65D15 (Primary) 65-04 (Secondary)
ACM-class: G.1.2; G.1.7
\\
 Stiff ordinary differential equations (ODEs) play an important role in many
scientific and engineering applications. Often, the dependence of the solution
of the ODE on additional parameters is of interest, e.g.\ when dealing with
uncertainty quantification or design optimization. Directly studying this
dependence can quickly become too computationally expensive, such that cheaper
surrogate models approximating the solution are of interest. One popular class
of surrogate models are Gaussian processes (GPs). They perform well when
approximating stationary functions, functions which have a similar level of
variation along any given parameter direction, however solutions to stiff ODEs
are often characterized by a mixture of regions of rapid and slow variation
along the time axis and when dealing with such nonstationary functions, GP
performance frequently degrades drastically. We therefore aim to reparameterize
stiff ODE solutions based on the available data, to make them appear more
stationary and hence recover good GP performance. This approach comes with
minimal computational overhead and requires no internal changes to the GP
implementation, as it can be seen as a separate preprocessing step. We
illustrate the achieved benefits using multiple examples.
\\ ( https://arxiv.org/abs/2511.05990 ,  7093kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06040 (*cross-listing*)
Date: Sat, 8 Nov 2025 15:23:44 GMT   (44kb)

Title: The Algorithmic Phase Transition in Symmetric Correlated Spiked Wigner
 Model
Authors: Zhangsong Li
Categories: math.ST cs.LG math.PR stat.ML stat.TH
Comments: 47 pages
MSC-class: 68Q87, 68Q17
\\
 We study the computational task of detecting and estimating correlated
signals in a pair of spiked Wigner matrices. Our model consists of observations
 $$
 X = \tfrac{\lambda}{\sqrt{n}} xx^{\top} + W \,, \quad Y =
\tfrac{\mu}{\sqrt{n}} yy^{\top} + Z \,.
 $$
 where $x,y \in \mathbb R^n$ are signal vectors with norm $\|x\|,\|y\|
\approx\sqrt{n}$ and correlation $\langle x,y \rangle \approx \rho\|x\|\|y\|$,
while $W,Z$ are independent Gaussian noise matrices. We propose an efficient
algorithm that succeeds whenever $F(\lambda,\mu,\rho)>1$, where
 $$
 F(\lambda,\mu,\rho)=\max\Big\{ \lambda,\mu, \frac{ \lambda^2 \rho^2 }{
1-\lambda^2+\lambda^2 \rho^2 } + \frac{ \mu^2 \rho^2 }{ 1-\mu^2+\mu^2 \rho^2 }
\Big\} \,.
 $$
 Our result shows that an algorithm can leverage the correlation between the
spikes to detect and estimate the signals even in regimes where efficiently
recovering either $x$ from $X$ alone or $y$ from $Y$ alone is believed to be
computationally infeasible.
 We complement our algorithmic result with evidence for a matching
computational lower bound. In particular, we prove that when
$F(\lambda,\mu,\rho)<1$, all algorithms based on {\em low-degree polynomials}
fails to distinguish $(X,Y)$ with two independent Wigner matrices. This
low-degree analysis strongly suggests that $F(\lambda,\mu,\rho)=1$ is the
precise computation threshold for this problem.
\\ ( https://arxiv.org/abs/2511.06040 ,  44kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06105 (*cross-listing*)
Date: Sat, 8 Nov 2025 19:02:14 GMT   (186kb)

Title: Forecasting Thermospheric Density with Transformers for Multi-Satellite
 Orbit Management
Authors: Cedric B\"os, Alessandro Bortotto, Mohamed Khalil Ben-Larbi
Categories: physics.space-ph cs.LG
Comments: 6 pages, 3 figures, conference
\\
 Accurate thermospheric density prediction is crucial for reliable satellite
operations in Low Earth Orbits, especially at high solar and geomagnetic
activity. Physics-based models such as TIE-GCM offer high fidelity but are
computationally expensive, while empirical models like NRLMSIS are efficient
yet lack predictive power. This work presents a transformer-based model that
forecasts densities up to three days ahead and is intended as a drop-in
replacement for an empirical baseline. Unlike recent approaches, it avoids
spatial reduction and complex input pipelines, operating directly on a compact
input set. Validated on real-world data, the model improves key prediction
metrics and shows potential to support mission planning.
\\ ( https://arxiv.org/abs/2511.06105 ,  186kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06120 (*cross-listing*)
Date: Sat, 8 Nov 2025 20:08:16 GMT   (5560kb)

Title: A Deep Learning Model for Predicting Transformation Legality
Authors: Avani Tiwari, Yacine Hakimi, Riyadh Baghdadi
Categories: cs.PL cs.LG
\\
 Compilers must check the legality of code transformations to guarantee the
correctness of applying a sequence of code transformations to a given code.
While such a legality check needs to be precisely computed in general, we can
use an approximate legality prediction model in certain cases, such as training
a reinforcement learning (RL) agent for schedule prediction. In this paper, we
propose an approximate method for legality checks. We propose a novel DL model
for predicting the legality of transformations. The model takes the code
representation and a list of transformations as input and predicts whether
applying those transformations to the code is legal. We implement and evaluate
the proposed model, demonstrating its effectiveness. Our evaluation shows an F1
score of 0.91 on a test set of randomly generated programs. To further evaluate
the model in a practical scenario, we used the model to replace the legality
check used during the training of an RL agent designed for automatic code
optimization. We demonstrate that such a replacement enables the agent to train
on twice as many steps, resulting in faster training and reducing resource
usage by approximately 80\% for CPU and 35\% for RAM. The agent trained using
this approach maintains comparable performance, with only a 4\% reduction on
benchmarks from the Polybench suite compared to the traditional method.
\\ ( https://arxiv.org/abs/2511.06120 ,  5560kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06235 (*cross-listing*)
Date: Sun, 9 Nov 2025 05:27:41 GMT   (5119kb)

Title: Sparsity via Hyperpriors: A Theoretical and Algorithmic Study under
 Empirical Bayes Framework
Authors: Zhitao Li, Yiqiu Dong and Xueying Zeng
Categories: stat.ML cs.LG cs.NA math.NA
\\
 This paper presents a comprehensive analysis of hyperparameter estimation
within the empirical Bayes framework (EBF) for sparse learning. By studying the
influence of hyperpriors on the solution of EBF, we establish a theoretical
connection between the choice of the hyperprior and the sparsity as well as the
local optimality of the resulting solutions. We show that some strictly
increasing hyperpriors, such as half-Laplace and half-generalized Gaussian with
the power in $(0,1)$, effectively promote sparsity and improve solution
stability with respect to measurement noise. Based on this analysis, we adopt a
proximal alternating linearized minimization (PALM) algorithm with convergence
guaranties for both convex and concave hyperpriors. Extensive numerical tests
on two-dimensional image deblurring problems demonstrate that introducing
appropriate hyperpriors significantly promotes the sparsity of the solution and
enhances restoration accuracy. Furthermore, we illustrate the influence of the
noise level and the ill-posedness of inverse problems to EBF solutions.
\\ ( https://arxiv.org/abs/2511.06235 ,  5119kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06239 (*cross-listing*)
Date: Sun, 9 Nov 2025 05:51:03 GMT   (3636kb)

Title: Functional Adjoint Sampler: Scalable Sampling on Infinite Dimensional
 Spaces
Authors: Byoungwoo Park, Juho Lee, Guan-Horng Liu
Categories: stat.ML cs.LG
\\
 Learning-based methods for sampling from the Gibbs distribution in
finite-dimensional spaces have progressed quickly, yet theory and algorithmic
design for infinite-dimensional function spaces remain limited. This gap
persists despite their strong potential for sampling the paths of conditional
diffusion processes, enabling efficient simulation of trajectories of diffusion
processes that respect rare events or boundary constraints. In this work, we
present the adjoint sampler for infinite-dimensional function spaces, a
stochastic optimal control-based diffusion sampler that operates in function
space and targets Gibbs-type distributions on infinite-dimensional Hilbert
spaces. Our Functional Adjoint Sampler (FAS) generalizes Adjoint Sampling
(Havens et al., 2025) to Hilbert spaces based on a SOC theory called stochastic
maximum principle, yielding a simple and scalable matching-type objective for a
functional representation. We show that FAS achieves superior transition path
sampling performance across synthetic potential and real molecular systems,
including Alanine Dipeptide and Chignolin.
\\ ( https://arxiv.org/abs/2511.06239 ,  3636kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06305 (*cross-listing*)
Date: Sun, 9 Nov 2025 10:03:45 GMT   (73kb)

Title: Setting $\varepsilon$ is not the Issue in Differential Privacy
Authors: Edwige Cyffers
Categories: cs.CR cs.LG
Comments: Accepted to NeurIPS Position Paper track
\\
 This position paper argues that setting the privacy budget in differential
privacy should not be viewed as an important limitation of differential privacy
compared to alternative methods for privacy-preserving machine learning. The
so-called problem of interpreting the privacy budget is often presented as a
major hindrance to the wider adoption of differential privacy in real-world
deployments and is sometimes used to promote alternative mitigation techniques
for data protection. We believe this misleads decision-makers into choosing
unsafe methods. We argue that the difficulty in interpreting privacy budgets
does not stem from the definition of differential privacy itself, but from the
intrinsic difficulty of estimating privacy risks in context, a challenge that
any rigorous method for privacy risk assessment face. Moreover, we claim that
any sound method for estimating privacy risks should, given the current state
of research, be expressible within the differential privacy framework or
justify why it cannot.
\\ ( https://arxiv.org/abs/2511.06305 ,  73kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06387 (*cross-listing*)
Date: Sun, 9 Nov 2025 13:52:11 GMT   (345kb)

Title: Learning the Inverse Ryu--Takayanagi Formula with Transformers
Authors: Sejin Kim
Categories: hep-th cs.LG
Comments: 15 pages, 6 figures
\\
 We study the inverse problem of holographic entanglement entropy in AdS$_3$
using a data-driven generative model. Training data consist of randomly
generated geometries and their holographic entanglement entropies using the
Ryu--Takayanagi formula. After training, the Transformer reconstructs the
blackening function within our metric ansatz from previously unseen inputs. The
Transformer achieves accurate reconstructions on smooth black hole geometries
and extrapolates to horizonless backgrounds. We describe the architecture and
data generation process, and we quantify accuracy on both $f(z)$ and the
reconstructed $S(\ell)$. Code and evaluation scripts are available at the
provided repository.
\\ ( https://arxiv.org/abs/2511.06387 ,  345kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06407 (*cross-listing*)
Date: Sun, 9 Nov 2025 14:44:13 GMT   (2631kb)

Title: Fast Riemannian-manifold Hamiltonian Monte Carlo for hierarchical
 Gaussian-process models
Authors: Takashi Hayakawa and Satoshi Asai
Categories: stat.ML cs.LG stat.CO
\\
 Hierarchical Bayesian models based on Gaussian processes are considered
useful for describing complex nonlinear statistical dependencies among
variables in real-world data. However, effective Monte Carlo algorithms for
inference with these models have not yet been established, except for several
simple cases. In this study, we show that, compared with the slow inference
achieved with existing program libraries, the performance of
Riemannian-manifold Hamiltonian Monte Carlo (RMHMC) can be drastically improved
by optimising the computation order according to the model structure and
dynamically programming the eigendecomposition. This improvement cannot be
achieved when using an existing library based on a naive automatic
differentiator. We numerically demonstrate that RMHMC effectively samples from
the posterior, allowing the calculation of model evidence, in a Bayesian
logistic regression on simulated data and in the estimation of propensity
functions for the American national medical expenditure data using several
Bayesian multiple-kernel models. These results lay a foundation for
implementing effective Monte Carlo algorithms for analysing real-world data
with Gaussian processes, and highlight the need to develop a customisable
library set that allows users to incorporate dynamically programmed objects and
finely optimises the mode of automatic differentiation depending on the model
structure.
\\ ( https://arxiv.org/abs/2511.06407 ,  2631kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06479 (*cross-listing*)
Date: Sun, 9 Nov 2025 17:51:51 GMT   (710kb)

Title: Bridging Theory and Practice: A Stochastic Learning-Optimization Model
 for Resilient Automotive Supply Chains
Authors: Muhammad Shahnawaz and Adeel Safder
Categories: stat.ML cs.LG math.OC
Comments: 14 pages, 4 figures
\\
 Supply chain disruptions and volatile demand pose significant challenges to
the UK automotive industry, which relies heavily on Just-In-Time (JIT)
manufacturing. While qualitative studies highlight the potential of integrating
Artificial Intelligence (AI) with traditional optimization, a formal,
quantitative demonstration of this synergy is lacking. This paper introduces a
novel stochastic learning-optimization framework that integrates Bayesian
inference with inventory optimization for supply chain management (SCM). We
model a two-echelon inventory system subject to stochastic demand and supply
disruptions, comparing a traditional static optimization policy against an
adaptive policy where Bayesian learning continuously updates parameter
estimates to inform stochastic optimization. Our simulations over 365 periods
across three operational scenarios demonstrate that the integrated approach
achieves 7.4\% cost reduction in stable environments and 5.7\% improvement
during supply disruptions, while revealing important limitations during sudden
demand shocks due to the inherent conservatism of Bayesian updating. This work
provides mathematical validation for practitioner observations and establishes
a formal framework for understanding AI-driven supply chain resilience, while
identifying critical boundary conditions for successful implementation.
\\ ( https://arxiv.org/abs/2511.06479 ,  710kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06512 (*cross-listing*)
Date: Sun, 9 Nov 2025 19:46:54 GMT   (1058kb)

Title: EASE: Practical and Efficient Safety Alignment for Small Language Models
Authors: Haonan Shi, Guoli Wang, Tu Ouyang, An Wang
Categories: cs.CR cs.LG
Comments: Accepted to AAAI 2026
\\
 Small language models (SLMs) are increasingly deployed on edge devices,
making their safety alignment crucial yet challenging. Current shallow
alignment methods that rely on direct refusal of malicious queries fail to
provide robust protection, particularly against adversarial jailbreaks. While
deliberative safety reasoning alignment offers deeper alignment for defending
against sophisticated attacks, effectively implanting such reasoning capability
in SLMs with limited capabilities remains an open challenge. Moreover, safety
reasoning incurs significant computational overhead as models apply reasoning
to nearly all queries, making it impractical for resource-constrained edge
deployment scenarios that demand rapid responses. We propose EASE, a novel
framework that enables practical and Efficient safety Alignment for Small
languagE models. Our approach first identifies the optimal safety reasoning
teacher that can effectively distill safety reasoning capabilities to SLMs. We
then align models to selectively activate safety reasoning for dangerous
adversarial jailbreak queries while providing direct responses to
straightforward malicious queries and general helpful tasks. This selective
mechanism enables small models to maintain robust safety guarantees against
sophisticated attacks while preserving computational efficiency for benign
interactions. Experimental results demonstrate that EASE reduces jailbreak
attack success rates by up to 17% compared to shallow alignment methods while
reducing inference overhead by up to 90% compared to deliberative safety
reasoning alignment, making it practical for SLMs real-world edge deployments.
\\ ( https://arxiv.org/abs/2511.06512 ,  1058kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06585 (*cross-listing*)
Date: Mon, 10 Nov 2025 00:24:06 GMT   (431kb)

Title: Learning Biomolecular Motion: The Physics-Informed Machine Learning
 Paradigm
Authors: Aaryesh Deshpande
Categories: q-bio.BM cs.LG physics.comp-ph stat.ML
Comments: 31 pages, 4 figures, 3 tables. Review article
\\
 The convergence of statistical learning and molecular physics is transforming
our approach to modeling biomolecular systems. Physics-informed machine
learning (PIML) offers a systematic framework that integrates data-driven
inference with physical constraints, resulting in models that are accurate,
mechanistic, generalizable, and able to extrapolate beyond observed domains.
This review surveys recent advances in physics-informed neural networks and
operator learning, differentiable molecular simulation, and hybrid physics-ML
potentials, with emphasis on long-timescale kinetics, rare events, and
free-energy estimation. We frame these approaches as solutions to the
"biomolecular closure problem", recovering unresolved interactions beyond
classical force fields while preserving thermodynamic consistency and
mechanistic interpretability. We examine theoretical foundations, tools and
frameworks, computational trade-offs, and unresolved issues, including model
expressiveness and stability. We outline prospective research avenues at the
intersection of machine learning, statistical physics, and computational
chemistry, contending that future advancements will depend on mechanistic
inductive biases, and integrated differentiable physical learning frameworks
for biomolecular simulation and discovery.
\\ ( https://arxiv.org/abs/2511.06585 ,  431kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06663 (*cross-listing*)
Date: Mon, 10 Nov 2025 03:18:34 GMT   (469kb)

Title: GNN-Enabled Robust Hybrid Beamforming with Score-Based CSI Generation
 and Denoising
Authors: Yuhang Li, Yang Lu, Bo Ai, Zhiguo Ding, Dusit Niyato, and Arumugam
 Nallanathan
Categories: eess.SY cs.LG cs.SY
\\
 Accurate Channel State Information (CSI) is critical for Hybrid Beamforming
(HBF) tasks. However, obtaining high-resolution CSI remains challenging in
practical wireless communication systems. To address this issue, we propose to
utilize Graph Neural Networks (GNNs) and score-based generative models to
enable robust HBF under imperfect CSI conditions. Firstly, we develop the
Hybrid Message Graph Attention Network (HMGAT) which updates both node and edge
features through node-level and edge-level message passing. Secondly, we design
a Bidirectional Encoder Representations from Transformers (BERT)-based Noise
Conditional Score Network (NCSN) to learn the distribution of high-resolution
CSI, facilitating CSI generation and data augmentation to further improve
HMGAT's performance. Finally, we present a Denoising Score Network (DSN)
framework and its instantiation, termed DeBERT, which can denoise imperfect CSI
under arbitrary channel error levels, thereby facilitating robust HBF.
Experiments on DeepMIMO urban datasets demonstrate the proposed models'
superior generalization, scalability, and robustness across various HBF tasks
with perfect and imperfect CSI.
\\ ( https://arxiv.org/abs/2511.06663 ,  469kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06675 (*cross-listing*)
Date: Mon, 10 Nov 2025 03:45:32 GMT   (705kb)

Title: Adam symmetry theorem: characterization of the convergence of the
 stochastic Adam optimizer
Authors: Steffen Dereich and Thang Do and Arnulf Jentzen and Philippe von
 Wurstemberger
Categories: math.OC cs.LG
Comments: 66 pages
MSC-class: 68T05, 90C25, 65K05, 65K10, 60H35
ACM-class: I.2.0; G.3; G.1.6; F.2.1
\\
 Beside the standard stochastic gradient descent (SGD) method, the Adam
optimizer due to Kingma & Ba (2014) is currently probably the best-known
optimization method for the training of deep neural networks in artificial
intelligence (AI) systems. Despite the popularity and the success of Adam it
remains an \emph{open research problem} to provide a rigorous convergence
analysis for Adam even for the class of strongly convex SOPs. In one of the
main results of this work we establish convergence rates for Adam in terms of
the number of gradient steps (convergence rate \nicefrac{1}{2} w.r.t. the size
of the learning rate), the size of the mini-batches (convergence rate 1 w.r.t.
the size of the mini-batches), and the size of the second moment parameter of
Adam (convergence rate 1 w.r.t. the distance of the second moment parameter to
1) for the class of strongly convex SOPs. In a further main result of this
work, which we refer to as \emph{Adam symmetry theorem}, we illustrate the
optimality of the established convergence rates by proving for a special class
of simple quadratic strongly convex SOPs that Adam converges as the number of
gradient steps increases to infinity to the solution of the SOP (the unique
minimizer of the strongly convex objective function) if and \emph{only} if the
random variables in the SOP (the data in the SOP) are \emph{symmetrically
distributed}. In particular, in the standard case where the random variables in
the SOP are not symmetrically distributed we \emph{disprove} that Adam
converges to the minimizer of the SOP as the number of Adam steps increases to
infinity. We also complement the conclusions of our convergence analysis and
the Adam symmetry theorem by several numerical simulations that indicate the
sharpness of the established convergence rates and that illustrate the
practical appearance of the phenomena revealed in the \emph{Adam symmetry
theorem}.
\\ ( https://arxiv.org/abs/2511.06675 ,  705kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06698 (*cross-listing*)
Date: Mon, 10 Nov 2025 04:39:09 GMT   (3884kb)

Title: Lassoed Forests: Random Forests with Adaptive Lasso Post-selection
Authors: Jing Shang, James Bannon, Benjamin Haibe-Kains, Robert Tibshirani
Categories: stat.ML cs.LG
\\
 Random forests are a statistical learning technique that use bootstrap
aggregation to average high-variance and low-bias trees. Improvements to random
forests, such as applying Lasso regression to the tree predictions, have been
proposed in order to reduce model bias. However, these changes can sometimes
degrade performance (e.g., an increase in mean squared error). In this paper,
we show in theory that the relative performance of these two methods, standard
and Lasso-weighted random forests, depends on the signal-to-noise ratio. We
further propose a unified framework to combine random forests and Lasso
selection by applying adaptive weighting and show mathematically that it can
strictly outperform the other two methods. We compare the three methods through
simulation, including bias-variance decomposition, error estimates evaluation,
and variable importance analysis. We also show the versatility of our method by
applications to a variety of real-world datasets.
\\ ( https://arxiv.org/abs/2511.06698 ,  3884kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06714 (*cross-listing*)
Date: Mon, 10 Nov 2025 05:15:37 GMT   (2292kb)

Title: The Wisdom of the Crowd: High-Fidelity Classification of Cyber-Attacks
 and Faults in Power Systems Using Ensemble and Machine Learning
Authors: Emad Abukhousa, Syed Sohail Feroz Syed Afroz, Fahad Alsaeed, Abdulaziz
 Qwbaiban, Saman Zonouz, and A.P. Sakis Meliopoulos
Categories: eess.SY cs.LG cs.SY
\\
 This paper presents a high-fidelity evaluation framework for machine learning
(ML)-based classification of cyber-attacks and physical faults using
electromagnetic transient simulations with digital substation emulation at 4.8
kHz. Twelve ML models, including ensemble algorithms and a multi-layer
perceptron (MLP), were trained on labeled time-domain measurements and
evaluated in a real-time streaming environment designed for sub-cycle
responsiveness. The architecture incorporates a cycle-length smoothing filter
and confidence threshold to stabilize decisions. Results show that while
several models achieved near-perfect offline accuracies (up to 99.9%), only the
MLP sustained robust coverage (98-99%) under streaming, whereas ensembles
preserved perfect anomaly precision but abstained frequently (10-49% coverage).
These findings demonstrate that offline accuracy alone is an unreliable
indicator of field readiness and underscore the need for realistic testing and
inference pipelines to ensure dependable classification in inverter-based
resources (IBR)-rich networks.
\\ ( https://arxiv.org/abs/2511.06714 ,  2292kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06774 (*cross-listing*)
Date: Mon, 10 Nov 2025 07:02:52 GMT   (11191kb)

Title: Bilevel Learning via Inexact Stochastic Gradient Descent
Authors: Mohammad Sadegh Salehi, Subhadip Mukherjee, Lindon Roberts, Matthias
 J. Ehrhardt
Categories: math.OC cs.LG
MSC-class: 65K10, 90C25, 90C26, 90C06, 90C31, 94A08
\\
 Bilevel optimization is a central tool in machine learning for
high-dimensional hyperparameter tuning. Its applications are vast; for
instance, in imaging it can be used for learning data-adaptive regularizers and
optimizing forward operators in variational regularization. These problems are
large in many ways: a lot of data is usually available to train a large number
of parameters, calling for stochastic gradient-based algorithms. However, exact
gradients with respect to parameters (so-called hypergradients) are not
available, and their precision is usually linearly related to computational
cost. Hence, algorithms must solve the problem efficiently without unnecessary
precision. The design of such methods is still not fully understood, especially
regarding how accuracy requirements and step size schedules affect theoretical
guarantees and practical performance. Existing approaches introduce
stochasticity at both the upper level (e.g., in sampling or mini-batch
estimates) and the lower level (e.g., in solving the inner problem) to improve
generalization, but they typically fix the number of lower-level iterations,
which conflicts with asymptotic convergence assumptions. In this work, we
advance the theory of inexact stochastic bilevel optimization. We prove
convergence and establish rates under decaying accuracy and step size
schedules, showing that with optimal configurations convergence occurs at an
$\mathcal{O}(k^{-1/4})$ rate in expectation. Experiments on image denoising and
inpainting with convex ridge regularizers and input-convex networks confirm our
analysis: decreasing step sizes improve stability, accuracy scheduling is more
critical than step size strategy, and adaptive preconditioning (e.g., Adam)
further boosts performance. These results bridge theory and practice, providing
convergence guarantees and practical guidance for large-scale imaging problems.
\\ ( https://arxiv.org/abs/2511.06774 ,  11191kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06782 (*cross-listing*)
Date: Mon, 10 Nov 2025 07:14:31 GMT   (266kb)

Title: HEDN: A Hard-Easy Dual Network with Task Difficulty Assessment for EEG
 Emotion Recognition
Authors: Qiang Wang and Liying Yang
Categories: cs.HC cs.LG
\\
 Multi-source domain adaptation represents an effective approach to addressing
individual differences in cross-subject EEG emotion recognition. However,
existing methods treat all source domains equally, neglecting the varying
transfer difficulties between different source domains and the target domain.
This oversight can lead to suboptimal adaptation. To address this challenge, we
propose a novel Hard-Easy Dual Network (HEDN), which dynamically identifies
"Hard Source" and "Easy Source" through a Task Difficulty Assessment (TDA)
mechanism and establishes two specialized knowledge adaptation branches.
Specifically, the Hard Network is dedicated to handling "Hard Source" with
higher transfer difficulty by aligning marginal distribution differences
between source and target domains. Conversely, the Easy Network focuses on
"Easy Source" with low transfer difficulty, utilizing a prototype classifier to
model intra-class clustering structures while generating reliable pseudo-labels
for the target domain through a prototype-guided label propagation algorithm.
Extensive experiments on two benchmark datasets, SEED and SEED-IV, demonstrate
that HEDN achieves state-of-the-art performance in cross-subject EEG emotion
recognition, with average accuracies of 93.58\% on SEED and 79.82\% on SEED-IV,
respectively. These results confirm the effectiveness and generalizability of
HEDN in cross-subject EEG emotion recognition.
\\ ( https://arxiv.org/abs/2511.06782 ,  266kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06812 (*cross-listing*)
Date: Mon, 10 Nov 2025 07:55:34 GMT   (393kb)

Title: Convergence of Actor-Critic Learning for Mean Field Games and Mean Field
 Control in Continuous Spaces
Authors: Jean-Pierre Fouque, Mathieu Lauri\`ere, Mengrui Zhang
Categories: math.OC cs.LG math.PR
\\
 We establish the convergence of the deep actor-critic reinforcement learning
algorithm presented in [Angiuli et al., 2023a] in the setting of continuous
state and action spaces with an infinite discrete-time horizon. This algorithm
provides solutions to Mean Field Game (MFG) or Mean Field Control (MFC)
problems depending on the ratio between two learning rates: one for the value
function and the other for the mean field term. In the MFC case, to rigorously
identify the limit, we introduce a discretization of the state and action
spaces, following the approach used in the finite-space case in [Angiuli et
al., 2023b]. The convergence proofs rely on a generalization of the
two-timescale framework introduced in [Borkar, 1997]. We further extend our
convergence results to Mean Field Control Games, which involve locally
cooperative and globally competitive populations. Finally, we present numerical
experiments for linear-quadratic problems in one and two dimensions, for which
explicit solutions are available.
\\ ( https://arxiv.org/abs/2511.06812 ,  393kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06821 (*cross-listing*)
Date: Mon, 10 Nov 2025 08:09:56 GMT   (10kb)

Title: Dimensionality reduction and width of deep neural networks based on
 topological degree theory
Authors: Xiao-Song Yang
Categories: math.GN cs.LG
MSC-class: 55P99, 68T01, 68T07
\\
 In this paper we present a mathematical framework on linking of embeddings of
compact topological spaces into Euclidean spaces and separability of linked
embeddings under a specific class of dimension reduction maps. As applications
of the established theory, we provide some fascinating insights into
classification and approximation problems in deep learning theory in the
setting of deep neural networks.
\\ ( https://arxiv.org/abs/2511.06821 ,  10kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06838 (*cross-listing*)
Date: Mon, 10 Nov 2025 08:29:34 GMT   (2259kb)

Title: P3-LLM: An Integrated NPU-PIM Accelerator for LLM Inference Using Hybrid
 Numerical Formats
Authors: Yuzong Chen, Chao Fang, Xilai Dai, Yuheng Wu, Thierry Tambe, Marian
 Verhelst, Mohamed S. Abdelfattah
Categories: cs.AR cs.LG
Comments: Preprint. Under review
\\
 The substantial memory bandwidth and computational demand of large language
models (LLMs) present critical challenges for efficient inference. To tackle
this, the literature has explored heterogeneous systems that combine neural
processing units (NPUs) with DRAM-based processing-in-memory (PIM) for LLM
acceleration. However, existing high-precision (e.g., FP16) PIM compute units
incur significant area and power overhead in DRAM technology, limiting the
effective computation throughput. In this paper, we introduce P3-LLM, a novel
NPU-PIM integrated accelerator for LLM inference using hybrid numerical
formats. Our approach is threefold: First, we propose a flexible
mixed-precision quantization scheme, which leverages hybrid numerical formats
to quantize different LLM operands with high compression efficiency and minimal
accuracy loss. Second, we architect an efficient PIM accelerator co-design for
P3-LLM, featuring lightweight compute units to support our hybrid numerical
formats. The enhanced PIM compute units significantly boost the computation
throughput under iso-area constraints. Third, we optimize the low-precision
dataflow of different LLM modules by applying operator fusion to minimize the
overhead of runtime dequantization. Our evaluation on a diverse set of
representative LLMs and tasks demonstrates that P3-LLM achieves
state-of-the-art quantization accuracy in terms of both KV-cache-only
quantization and weight-activation quantization. Combining the proposed
quantization scheme with PIM architecture co-design, P3-LLM yields an average
of $4.9\times$, $2.0\times$, and $3.4\times$ speedups over the state-of-the-art
LLM accelerators HBM-PIM, Ecco, and Pimba, respectively. Our quantization code
is available at https://github.com/yc2367/P3-LLM.git
\\ ( https://arxiv.org/abs/2511.06838 ,  2259kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07047 (*cross-listing*)
Date: Mon, 10 Nov 2025 12:39:22 GMT   (1390kb)

Title: Anatomy-Aware Lymphoma Lesion Detection in Whole-Body PET/CT
Authors: Simone Bendazzoli, Antonios Tzortzakakis, Andreas Abrahamsson, Bj\"orn
 Engelbrekt Wahlin, \"Orjan Smedby, Maria Holstensson, Rodrigo Moreno
Categories: eess.IV cs.LG
\\
 Early cancer detection is crucial for improving patient outcomes, and 18F FDG
PET/CT imaging plays a vital role by combining metabolic and anatomical
information. Accurate lesion detection remains challenging due to the need to
identify multiple lesions of varying sizes. In this study, we investigate the
effect of adding anatomy prior information to deep learning-based lesion
detection models. In particular, we add organ segmentation masks from the
TotalSegmentator tool as auxiliary inputs to provide anatomical context to
nnDetection, which is the state-of-the-art for lesion detection, and Swin
Transformer. The latter is trained in two stages that combine self-supervised
pre-training and supervised fine-tuning. The method is tested in the AutoPET
and Karolinska lymphoma datasets. The results indicate that the inclusion of
anatomical priors substantially improves the detection performance within the
nnDetection framework, while it has almost no impact on the performance of the
vision transformer. Moreover, we observe that Swin Transformer does not offer
clear advantages over conventional convolutional neural network (CNN) encoders
used in nnDetection. These findings highlight the critical role of the
anatomical context in cancer lesion detection, especially in CNN-based models.
\\ ( https://arxiv.org/abs/2511.07047 ,  1390kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07109 (*cross-listing*)
Date: Mon, 10 Nov 2025 13:54:27 GMT   (1987kb)

Title: A Provably-Correct and Robust Convex Model for Smooth Separable NMF
Authors: Junjun Pan, Valentin Leplat, Michael Ng, Nicolas Gillis
Categories: math.NA cs.LG cs.NA eess.SP math.OC stat.ML
Comments: 30 pages, 10 figures, code available from
 https://github.com/vleplat/ConvexSmoothSeparableNMF.git
\\
 Nonnegative matrix factorization (NMF) is a linear dimensionality reduction
technique for nonnegative data, with applications such as hyperspectral
unmixing and topic modeling. NMF is a difficult problem in general (NP-hard),
and its solutions are typically not unique. To address these two issues,
additional constraints or assumptions are often used. In particular,
separability assumes that the basis vectors in the NMF are equal to some
columns of the input matrix. In that case, the problem is referred to as
separable NMF (SNMF) and can be solved in polynomial-time with robustness
guarantees, while identifying a unique solution. However, in real-world
scenarios, due to noise or variability, multiple data points may lie near the
basis vectors, which SNMF does not leverage. In this work, we rely on the
smooth separability assumption, which assumes that each basis vector is close
to multiple data points. We explore the properties of the corresponding
problem, referred to as smooth SNMF (SSNMF), and examine how it relates to SNMF
and orthogonal NMF. We then propose a convex model for SSNMF and show that it
provably recovers the sought-after factors, even in the presence of noise. We
finally adapt an existing fast gradient method to solve this convex model for
SSNMF, and show that it compares favorably with state-of-the-art methods on
both synthetic and hyperspectral datasets.
\\ ( https://arxiv.org/abs/2511.07109 ,  1987kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07139 (*cross-listing*)
Date: Mon, 10 Nov 2025 14:20:32 GMT   (2415kb)

Title: Trading Vector Data in Vector Databases
Authors: Jin Cheng, Xiangxiang Dai, Ningning Ding, John C.S. Lui, Jianwei Huang
Categories: cs.DB cs.LG
Comments: Accepted by ICDE 2026
\\
 Vector data trading is essential for cross-domain learning with vector
databases, yet it remains largely unexplored. We study this problem under
online learning, where sellers face uncertain retrieval costs and buyers
provide stochastic feedback to posted prices. Three main challenges arise: (1)
heterogeneous and partial feedback in configuration learning, (2) variable and
complex feedback in pricing learning, and (3) inherent coupling between
configuration and pricing decisions.
 We propose a hierarchical bandit framework that jointly optimizes retrieval
configurations and pricing. Stage I employs contextual clustering with
confidence-based exploration to learn effective configurations with logarithmic
regret. Stage II adopts interval-based price selection with local Taylor
approximation to estimate buyer responses and achieve sublinear regret. We
establish theoretical guarantees with polynomial time complexity and validate
the framework on four real-world datasets, demonstrating consistent
improvements in cumulative reward and regret reduction compared with existing
methods.
\\ ( https://arxiv.org/abs/2511.07139 ,  2415kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07155 (*cross-listing*)
Date: Mon, 10 Nov 2025 14:45:24 GMT   (5246kb)

Title: Dynamics-Decoupled Trajectory Alignment for Sim-to-Real Transfer in
 Reinforcement Learning for Autonomous Driving
Authors: Thomas Steinecker, Alexander Bienemann, Denis Trescher, Thorsten
 Luettel, Mirko Maehlisch
Categories: cs.RO cs.LG
\\
 Reinforcement learning (RL) has shown promise in robotics, but deploying RL
on real vehicles remains challenging due to the complexity of vehicle dynamics
and the mismatch between simulation and reality. Factors such as tire
characteristics, road surface conditions, aerodynamic disturbances, and vehicle
load make it infeasible to model real-world dynamics accurately, which hinders
direct transfer of RL agents trained in simulation. In this paper, we present a
framework that decouples motion planning from vehicle control through a spatial
and temporal alignment strategy between a virtual vehicle and the real system.
An RL agent is first trained in simulation using a kinematic bicycle model to
output continuous control actions. Its behavior is then distilled into a
trajectory-predicting agent that generates finite-horizon ego-vehicle
trajectories, enabling synchronization between virtual and real vehicles. At
deployment, a Stanley controller governs lateral dynamics, while longitudinal
alignment is maintained through adaptive update mechanisms that compensate for
deviations between virtual and real trajectories. We validate our approach on a
real vehicle and demonstrate that the proposed alignment strategy enables
robust zero-shot transfer of RL-based motion planning from simulation to
reality, successfully decoupling high-level trajectory generation from
low-level vehicle control.
\\ ( https://arxiv.org/abs/2511.07155 ,  5246kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07197 (*cross-listing*)
Date: Mon, 10 Nov 2025 15:26:51 GMT   (1439kb)

Title: Simulation-based Methods for Optimal Sampling Design in Systems Biology
Authors: Tuan Minh Ha and Binh Thanh Nguyen and Lam Si Tung Ho
Categories: stat.ML cs.LG
\\
 In many areas of systems biology, including virology, pharmacokinetics, and
population biology, dynamical systems are commonly used to describe biological
processes. These systems can be characterized by estimating their parameters
from sampled data. The key problem is how to optimally select sampling points
to achieve accurate parameter estimation. Classical approaches often rely on
Fisher information matrix-based criteria such as A-, D-, and E-optimality,
which require an initial parameter estimate and may yield suboptimal results
when the estimate is inaccurate. This study proposes two simulation-based
methods for optimal sampling design that do not depend on initial parameter
estimates. The first method, E-optimal-ranking (EOR), employs the E-optimal
criterion, while the second utilizes a Long Short-Term Memory (LSTM) neural
network. Simulation studies based on the Lotka-Volterra and three-compartment
models demonstrate that the proposed methods outperform both random selection
and classical E-optimal design.
\\ ( https://arxiv.org/abs/2511.07197 ,  1439kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07244 (*cross-listing*)
Date: Mon, 10 Nov 2025 15:58:41 GMT   (70kb)

Title: A Fully Polynomial-Time Algorithm for Robustly Learning Halfspaces over
 the Hypercube
Authors: Gautam Chandrasekaran, Adam R. Klivans, Konstantinos Stavropoulos,
 Arsen Vasilyan
Categories: cs.DS cs.LG
Comments: 52 pages, 1 figure
\\
 We give the first fully polynomial-time algorithm for learning halfspaces
with respect to the uniform distribution on the hypercube in the presence of
contamination, where an adversary may corrupt some fraction of examples and
labels arbitrarily. We achieve an error guarantee of $\eta^{O(1)}+\epsilon$
where $\eta$ is the noise rate. Such a result was not known even in the
agnostic setting, where only labels can be adversarially corrupted. All prior
work over the last two decades has a superpolynomial dependence in $1/\epsilon$
or succeeds only with respect to continuous marginals (such as log-concave
densities).
 Previous analyses rely heavily on various structural properties of continuous
distributions such as anti-concentration. Our approach avoids these
requirements and makes use of a new algorithm for learning Generalized Linear
Models (GLMs) with only a polylogarithmic dependence on the activation
function's Lipschitz constant. More generally, our framework shows that
supervised learning with respect to discrete distributions is not as difficult
as previously thought.
\\ ( https://arxiv.org/abs/2511.07244 ,  70kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07270 (*cross-listing*)
Date: Mon, 10 Nov 2025 16:17:16 GMT   (3809kb)

Title: High-Dimensional Asymptotics of Differentially Private PCA
Authors: Youngjoo Yun and Rishabh Dudeja
Categories: math.ST cs.IT cs.LG math.IT math.PR stat.ML stat.TH
\\
 In differential privacy, statistics of a sensitive dataset are privatized by
introducing random noise. Most privacy analyses provide privacy bounds
specifying a noise level sufficient to achieve a target privacy guarantee.
Sometimes, these bounds are pessimistic and suggest adding excessive noise,
which overwhelms the meaningful signal. It remains unclear if such high noise
levels are truly necessary or a limitation of the proof techniques. This paper
explores whether we can obtain sharp privacy characterizations that identify
the smallest noise level required to achieve a target privacy level for a given
mechanism. We study this problem in the context of differentially private
principal component analysis, where the goal is to privatize the leading
principal components (PCs) of a dataset with n samples and p features. We
analyze the exponential mechanism for this problem in a model-free setting and
provide sharp utility and privacy characterizations in the high-dimensional
limit ($p\rightarrow\infty$). Our privacy result shows that, in high
dimensions, detecting the presence of a target individual in the dataset using
the privatized PCs is exactly as hard as distinguishing two Gaussians with
slightly different means, where the mean difference depends on certain spectral
properties of the dataset. Our privacy analysis combines the hypothesis-testing
formulation of privacy guarantees proposed by Dong, Roth, and Su (2022) with
classical contiguity arguments due to Le Cam to obtain sharp high-dimensional
privacy characterizations.
\\ ( https://arxiv.org/abs/2511.07270 ,  3809kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07313 (*cross-listing*)
Date: Mon, 10 Nov 2025 17:14:48 GMT   (3335kb)

Title: De-Individualizing fMRI Signals via Mahalanobis Whitening and Bures
 Geometry
Authors: Aaron Jacobson, Tingting Dan, Martin Styner, Guorong Wu, Shahar
 Kovalsky, Caroline Moosmueller
Categories: q-bio.NC cs.LG q-bio.QM
Comments: 34 pages, 7 figures
MSC-class: 92-08, 68T10, 62H310
ACM-class: I.5.3; J.3
\\
 Functional connectivity has been widely investigated to understand brain
disease in clinical studies and imaging-based neuroscience, and analyzing
changes in functional connectivity has proven to be valuable for understanding
and computationally evaluating the effects on brain function caused by diseases
or experimental stimuli. By using Mahalanobis data whitening prior to the use
of dimensionality reduction algorithms, we are able to distill meaningful
information from fMRI signals about subjects and the experimental stimuli used
to prompt them. Furthermore, we offer an interpretation of Mahalanobis
whitening as a two-stage de-individualization of data which is motivated by
similarity as captured by the Bures distance, which is connected to quantum
mechanics. These methods have potential to aid discoveries about the mechanisms
that link brain function with cognition and behavior and may improve the
accuracy and consistency of Alzheimer's diagnosis, especially in the
preclinical stage of disease progression.
\\ ( https://arxiv.org/abs/2511.07313 ,  3335kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07347 (*cross-listing*)
Date: Mon, 10 Nov 2025 17:49:20 GMT   (509kb)

Title: Walsh-Hadamard Neural Operators for Solving PDEs with Discontinuous
 Coefficients
Authors: Giorrgio M. Cavallazzi, Miguel Perex Cuadrado, Alfredo Pinelli
Categories: physics.comp-ph cs.LG
\\
 Neural operators have emerged as powerful tools for learning solution
operators of partial differential equations (PDEs). However, standard spectral
methods based on Fourier transforms struggle with problems involving
discontinuous coefficients due to the Gibbs phenomenon and poor representation
of sharp interfaces. We introduce the Walsh-Hadamard Neural Operator (WHNO),
which leverages Walsh-Hadamard transforms-a spectral basis of rectangular wave
functions naturally suited for piecewise constant fields-combined with
learnable spectral weights that transform low-sequency Walsh coefficients to
capture global dependencies efficiently. We validate WHNO on three problems:
steady-state Darcy flow (preliminary validation), heat conduction with
discontinuous thermal conductivity, and the 2D Burgers equation with
discontinuous initial conditions. In controlled comparisons with Fourier Neural
Operators (FNO) under identical conditions, WHNO demonstrates superior accuracy
with better preservation of sharp solution features at material interfaces.
Critically, we discover that weighted ensemble combinations of WHNO and FNO
achieve substantial improvements over either model alone: for both heat
conduction and Burgers equation, optimal ensembles reduce mean squared error by
35-40 percent and maximum error by up to 25 percent compared to individual
models. This demonstrates that Walsh-Hadamard and Fourier representations
capture complementary aspects of discontinuous PDE solutions, with WHNO
excelling at sharp interfaces while FNO captures smooth features effectively.
\\ ( https://arxiv.org/abs/2511.07347 ,  509kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07366 (*cross-listing*)
Date: Mon, 10 Nov 2025 18:23:03 GMT   (571kb)

Title: UAV-Assisted Resilience in 6G and Beyond Network Energy Saving: A
 Multi-Agent DRL Approach
Authors: Dao Lan Vy Dinh, Anh Nguyen Thi Mai, Hung Tran, Giang Quynh Le Vu, Tu
 Dac Ho, Zhenni Pan, Vo Nhan Van, Symeon Chatzinotas, Dinh-Hieu Tran
Categories: cs.NI cs.LG
Comments: 6 pages, 5 figures, 1 table
\\
 This paper investigates the unmanned aerial vehicle (UAV)-assisted resilience
perspective in the 6G network energy saving (NES) scenario. More specifically,
we consider multiple ground base stations (GBSs) and each GBS has three
different sectors/cells in the terrestrial networks, and multiple cells are
turned off due to NES or incidents, e.g., disasters, hardware failures, or
outages. To address this, we propose a Multi-Agent Deep Deterministic Policy
Gradient (MADDPG) framework to enable UAV-assisted communication by jointly
optimizing UAV trajectories, transmission power, and user-UAV association under
a sleeping ground base station (GBS) strategy. This framework aims to ensure
the resilience of active users in the network and the long-term operability of
UAVs. Specifically, it maximizes service coverage for users during power
outages or NES zones, while minimizing the energy consumption of UAVs.
Simulation results demonstrate that the proposed MADDPG policy consistently
achieves high coverage ratio across different testing episodes, outperforming
other baselines. Moreover, the MADDPG framework attains the lowest total energy
consumption, with a reduction of approximately 24\% compared to the
conventional all GBS ON configuration, while maintaining a comparable user
service rate. These results confirm the effectiveness of the proposed approach
in achieving a superior trade-off between energy efficiency and service
performance, supporting the development of sustainable and resilient
UAV-assisted cellular networks.
\\ ( https://arxiv.org/abs/2511.07366 ,  571kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07398 (*cross-listing*)
Date: Mon, 10 Nov 2025 18:51:05 GMT   (36kb)

Title: Solving bilevel optimization via sequential minimax optimization
Authors: Zhaosong Lu and Sanyou Mei
Categories: math.OC cs.LG cs.NA math.NA stat.ML
Comments: Accepted by Mathematics of Operations Research
MSC-class: 90C26, 90C30, 90C47, 90C99, 65K05
\\
 In this paper we propose a sequential minimax optimization (SMO) method for
solving a class of constrained bilevel optimization problems in which the
lower-level part is a possibly nonsmooth convex optimization problem, while the
upper-level part is a possibly nonconvex optimization problem. Specifically,
SMO applies a first-order method to solve a sequence of minimax subproblems,
which are obtained by employing a hybrid of modified augmented Lagrangian and
penalty schemes on the bilevel optimization problems. Under suitable
assumptions, we establish an operation complexity of
$O(\varepsilon^{-7}\log\varepsilon^{-1})$ and
$O(\varepsilon^{-6}\log\varepsilon^{-1})$, measured in terms of fundamental
operations, for SMO in finding an $\varepsilon$-KKT solution of the bilevel
optimization problems with merely convex and strongly convex lower-level
objective functions, respectively. The latter result improves the previous
best-known operation complexity by a factor of $\varepsilon^{-1}$. Preliminary
numerical results demonstrate significantly superior computational performance
compared to the recently developed first-order penalty method.
\\ ( https://arxiv.org/abs/2511.07398 ,  36kb)
%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%
------------------------------------------------------------------------------
\\
arXiv:2407.19405
replaced with revised version Mon, 10 Nov 2025 02:09:42 GMT   (12079kb)

Title: Logic Distillation: Learning from Code Function by Function for
 Decision-making Tasks
Authors: Dong Chen, Shilin Zhang, Fei Gao, Yueting Zhuang, Siliang Tang, Qidong
 Liu, Mingliang Xu
Categories: cs.AI
Comments: 9 pages, 7 figures
\\ ( https://arxiv.org/abs/2407.19405 ,  12079kb)
------------------------------------------------------------------------------
\\
arXiv:2410.01739
replaced with revised version Sat, 8 Nov 2025 20:50:45 GMT   (61600kb)

Title: Conceptual Belief-Informed Reinforcement Learning
Authors: Xingrui Gu, Chuyi Jiang, Laixi Shi
Categories: cs.AI cs.LG
Comments: Accepted by ICML 2025 Workshop on Models of Human Feedback for AI
 Alignment
Journal-ref: ICML 2025 Workshop on Models of Human Feedback for AI Alignment
\\ ( https://arxiv.org/abs/2410.01739 ,  61600kb)
------------------------------------------------------------------------------
\\
arXiv:2410.15052
replaced with revised version Mon, 10 Nov 2025 15:34:45 GMT   (736kb)

Title: GlitchMiner: Mining Glitch Tokens in Large Language Models via
 Gradient-based Discrete Optimization
Authors: Zihui Wu, Haichang Gao, Ping Wang, Shudong Zhang, Zhaoxiang Liu,
 Shiguo Lian
Categories: cs.AI
\\ ( https://arxiv.org/abs/2410.15052 ,  736kb)
------------------------------------------------------------------------------
\\
arXiv:2412.11939
replaced with revised version Mon, 10 Nov 2025 04:10:15 GMT   (1410kb)

Title: SEAGraph: Unveiling the Whole Story of Paper Review Comments
Authors: Jianxiang Yu, Jiaqi Tan, Zichen Ding, Jiapeng Zhu, Jiahao Li, Yao
 Cheng, Qier Cui, Yunshi Lan, Yao Liu, Xiang Li
Categories: cs.AI cs.CL
\\ ( https://arxiv.org/abs/2412.11939 ,  1410kb)
------------------------------------------------------------------------------
\\
arXiv:2502.09649
replaced with revised version Sat, 8 Nov 2025 07:31:30 GMT   (2062kb)

Title: ImitDiff: Transferring Foundation-Model Priors for Distraction Robust
 Visuomotor Policy
Authors: Yuhang Dong, Haizhou Ge, Yupei Zeng, Jiangning Zhang, Beiwen Tian,
 Hongrui Zhu, Yufei Jia, Ruixiang Wang, Zhucun Xue, Guyue Zhou, Longhua Ma,
 Guanzhong Tian
Categories: cs.AI cs.CV cs.LG cs.RO
\\ ( https://arxiv.org/abs/2502.09649 ,  2062kb)
------------------------------------------------------------------------------
\\
arXiv:2503.22342
replaced with revised version Sat, 8 Nov 2025 10:39:26 GMT   (201kb)

Title: CPPO: Accelerating the Training of Group Relative Policy
 Optimization-Based Reasoning Models
Authors: Zhihang Lin, Mingbao Lin, Yuan Xie, Rongrong Ji
Categories: cs.AI
Comments: 19 pages
\\ ( https://arxiv.org/abs/2503.22342 ,  201kb)
------------------------------------------------------------------------------
\\
arXiv:2504.00299
replaced with revised version Sat, 8 Nov 2025 06:45:44 GMT   (741kb)

Title: Collaborative LLM Numerical Reasoning with Local Data Protection
Authors: Min Zhang, Yuzhe Lu, Yun Zhou, Panpan Xu, Lin Lee Cheong, Chang-Tien
 Lu, Haozhu Wang
Categories: cs.AI
Comments: Accepted to AAAI-2026
\\ ( https://arxiv.org/abs/2504.00299 ,  741kb)
------------------------------------------------------------------------------
\\
arXiv:2506.00708
replaced with revised version Mon, 10 Nov 2025 08:45:20 GMT   (467kb)

Title: DrKGC: Dynamic Subgraph Retrieval-Augmented LLMs for Knowledge Graph
 Completion across General and Biomedical Domains
Authors: Yongkang Xiao, Sinian Zhang, Yi Dai, Huixue Zhou, Jue Hou, Jie Ding,
 Rui Zhang
Categories: cs.AI cs.CL cs.LG
Comments: Accepted at EMNLP 2025 Findings
DOI: 10.18653/v1/2025.findings-emnlp.892
\\ ( https://arxiv.org/abs/2506.00708 ,  467kb)
------------------------------------------------------------------------------
\\
arXiv:2506.14496
replaced with revised version Mon, 10 Nov 2025 12:31:54 GMT   (1863kb)

Title: LLM-Powered Swarms: A New Frontier or a Conceptual Stretch?
Authors: Muhammad Atta Ur Rahman, Melanie Schranz, Samira Hayat
Categories: cs.AI
Comments: This is the author's version of a paper submitted to IEEE Intelligent
 Systems. 2 Tables, 2 Figures
Report-no: IS-2025-06-0222.R1
\\ ( https://arxiv.org/abs/2506.14496 ,  1863kb)
------------------------------------------------------------------------------
\\
arXiv:2508.02073
replaced with revised version Sat, 8 Nov 2025 17:17:26 GMT   (1650kb)

Title: Large model retrieval enhancement framework for construction site risk
 identification
Authors: Jiawei Li, Chengye Yang, Yaochen Zhang, Weilin Sun, Lei Meng, Xiangxu
 Meng
Categories: cs.AI
Comments: in Chinese language
\\ ( https://arxiv.org/abs/2508.02073 ,  1650kb)
------------------------------------------------------------------------------
\\
arXiv:2508.08501
replaced with revised version Sat, 8 Nov 2025 02:07:15 GMT   (1658kb)

Title: GVGAI-LLM: Evaluating Large Language Model Agents with Infinite Games
Authors: Yuchen Li, Cong Lin, Muhammad Umair Nasir, Philip Bontrager, Jialin
 Liu, Julian Togelius
Categories: cs.AI
\\ ( https://arxiv.org/abs/2508.08501 ,  1658kb)
------------------------------------------------------------------------------
\\
arXiv:2508.10747
replaced with revised version Sun, 9 Nov 2025 00:48:50 GMT   (992kb)

Title: Scaling Up without Fading Out: Goal-Aware Sparse GNN for RL-based
 Generalized Planning
Authors: Sangwoo Jeon, Juchul Shin, Gyeong-Tae Kim, YeonJe Cho and Seongwoo Kim
Categories: cs.AI cs.RO
Comments: Accepted for publication in International Journal of Control,
 Automation, and Systems (IJCAS). The Version of Record is available via the
 publisher
Journal-ref: International Journal of Control, Automation, and Systems, 23,
 2025
DOI: 10.1007/s12555-025-0543-2
\\ ( https://arxiv.org/abs/2508.10747 ,  992kb)
------------------------------------------------------------------------------
\\
arXiv:2508.21800
replaced with revised version Sun, 9 Nov 2025 02:11:42 GMT   (4019kb)

Title: Tree-Guided Diffusion Planner
Authors: Hyeonseong Jeon, Cheolhong Min, Jaesik Park
Categories: cs.AI cs.RO
Comments: NeurIPS 2025
\\ ( https://arxiv.org/abs/2508.21800 ,  4019kb)
------------------------------------------------------------------------------
\\
arXiv:2509.01396
replaced with revised version Sat, 8 Nov 2025 05:52:13 GMT   (1244kb)

Title: DeepResearch Arena: The First Exam of LLMs' Research Abilities via
 Seminar-Grounded Tasks
Authors: Haiyuan Wan, Chen Yang, Junchi Yu, Meiqi Tu, Jiaxuan Lu, Di Yu,
 Jianbao Cao, Ben Gao, Jiaqing Xie, Aoran Wang, Wenlong Zhang, Philip Torr,
 Dongzhan Zhou
Categories: cs.AI
\\ ( https://arxiv.org/abs/2509.01396 ,  1244kb)
------------------------------------------------------------------------------
\\
arXiv:2509.02547
replaced with revised version Sat, 8 Nov 2025 05:55:03 GMT   (5352kb)

Title: The Landscape of Agentic Reinforcement Learning for LLMs: A Survey
Authors: Guibin Zhang, Hejia Geng, Xiaohang Yu, Zhenfei Yin, Zaibin Zhang,
 Zelin Tan, Heng Zhou, Zhongzhi Li, Xiangyuan Xue, Yijiang Li, Yifan Zhou,
 Yang Chen, Chen Zhang, Yutao Fan, Zihu Wang, Songtao Huang, Francisco
 Piedrahita-Velez, Yue Liao, Hongru Wang, Mengyue Yang, Heng Ji, Jun Wang,
 Shuicheng Yan, Philip Torr, Lei Bai
Categories: cs.AI cs.CL
\\ ( https://arxiv.org/abs/2509.02547 ,  5352kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13333
replaced with revised version Sun, 9 Nov 2025 17:13:27 GMT   (662kb)

Title: Evaluation Awareness Scales Predictably in Open-Weights Large Language
 Models
Authors: Maheep Chaudhary, Ian Su, Nikhil Hooda, Nishith Shankar, Julia Tan,
 Kevin Zhu, Ryan Lagasse, Vasu Sharma, Ashwinee Panda
Categories: cs.AI
\\ ( https://arxiv.org/abs/2509.13333 ,  662kb)
------------------------------------------------------------------------------
\\
arXiv:2509.17354
replaced with revised version Mon, 10 Nov 2025 09:08:56 GMT   (1136kb)

Title: Multi-Scenario Highway Lane-Change Intention Prediction: A
 Physics-Informed AI Framework for Three-Class Classification
Authors: Jiazhao Shi, Yichen Lin, Yiheng Hua, Ziyu Wang, Zijian Zhang, Wenjia
 Zheng, Yun Song, Kuan Lu, and Shoufeng Lu
Categories: cs.AI cs.LG
\\ ( https://arxiv.org/abs/2509.17354 ,  1136kb)
------------------------------------------------------------------------------
\\
arXiv:2509.18101
replaced with revised version Sat, 8 Nov 2025 07:26:07 GMT   (81kb)

Title: A Cost-Benefit Analysis of On-Premise Large Language Model Deployment:
 Breaking Even with Commercial LLM Services
Authors: Guanzhong Pan, Vishal Chodnekar, Abinas Roy, Haibo Wang
Categories: cs.AI cs.LG
\\ ( https://arxiv.org/abs/2509.18101 ,  81kb)
------------------------------------------------------------------------------
\\
arXiv:2509.18667
replaced with revised version Mon, 10 Nov 2025 14:28:10 GMT   (367kb)

Title: TERAG: Token-Efficient Graph-Based Retrieval-Augmented Generation
Authors: Qiao Xiao, Hong Ting Tsang and Jiaxin Bai
Categories: cs.AI
Comments: 16 pages, 3 figures, 4 tables. Code available at
 https://github.com/wocqcm2/TERAG
\\ ( https://arxiv.org/abs/2509.18667 ,  367kb)
------------------------------------------------------------------------------
\\
arXiv:2510.10909
replaced with revised version Mon, 10 Nov 2025 03:21:21 GMT   (3966kb)

Title: PaperArena: An Evaluation Benchmark for Tool-Augmented Agentic Reasoning
 on Scientific Literature
Authors: Daoyu Wang, Mingyue Cheng, Shuo Yu, Zirui Liu, Ze Guo, Qi Liu
Categories: cs.AI
Comments: 12 pages, 9 figures
\\ ( https://arxiv.org/abs/2510.10909 ,  3966kb)
------------------------------------------------------------------------------
\\
arXiv:2510.14150
replaced with revised version Mon, 10 Nov 2025 14:12:41 GMT   (215kb)

Title: CodeEvolve: An open source evolutionary coding agent for algorithm
 discovery and optimization
Authors: Henrique Assump\c{c}\~ao, Diego Ferreira, Leandro Campos, Fabricio
 Murai
Categories: cs.AI cs.LG cs.NE
Comments: 11 pages, 9 figures, 2 tables
ACM-class: I.2.7; I.2.2
\\ ( https://arxiv.org/abs/2510.14150 ,  215kb)
------------------------------------------------------------------------------
\\
arXiv:2510.18318
replaced with revised version Fri, 7 Nov 2025 22:10:34 GMT   (4276kb)

Title: Earth AI: Unlocking Geospatial Insights with Foundation Models and
 Cross-Modal Reasoning
Authors: Aaron Bell, Amit Aides, Amr Helmy, Arbaaz Muslim, Aviad Barzilai, Aviv
 Slobodkin, Bolous Jaber, David Schottlander, George Leifman, Joydeep Paul,
 Mimi Sun, Nadav Sherman, Natalie Williams, Per Bjornsson, Roy Lee, Ruth
 Alcantara, Thomas Turnbull, Tomer Shekel, Vered Silverman, Yotam Gigi, Adam
 Boulanger, Alex Ottenwess, Ali Ahmadalipour, Anna Carter, Behzad Vahedi,
 Charles Elliott, David Andre, Elad Aharoni, Gia Jung, Hassler Thurston, Jacob
 Bien, Jamie McPike, Jessica Sapick, Juliet Rothenberg, Kartik Hegde, Kel
 Markert, Kim Philipp Jablonski, Luc Houriez, Monica Bharel, Phing VanLee,
 Reuven Sayag, Sebastian Pilarski, Shelley Cazares, Shlomi Pasternak, Siduo
 Jiang, Thomas Colthurst, Yang Chen, Yehonathan Refael, Yochai Blau, Yuval
 Carny, Yael Maguire, Avinatan Hassidim, James Manyika, Tim Thelin, Genady
 Beryozkin, Gautam Prasad, Luke Barrington, Yossi Matias, Niv Efron, Shravya
 Shetty
Categories: cs.AI
\\ ( https://arxiv.org/abs/2510.18318 ,  4276kb)
------------------------------------------------------------------------------
\\
arXiv:2510.18551
replaced with revised version Mon, 10 Nov 2025 14:12:42 GMT   (0kb,I)

Title: SOCIA-Nabla: Textual Gradient Meets Multi-Agent Orchestration for
 Automated Simulator Generation
Authors: Yuncheng Hua, Sion Weatherhead, Mehdi Jafari, Hao Xue, Flora D. Salim
Categories: cs.AI
Comments: superseded by newest version of arXiv:2505.12006
ACM-class: I.2.7
\\ ( https://arxiv.org/abs/2510.18551 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2511.00457
replaced with revised version Sat, 8 Nov 2025 04:47:20 GMT   (853kb)

Title: GraphChain: Large Language Models for Large-scale Graph Analysis via
 Tool Chaining
Authors: Chunyu Wei, Wenji Hu, Xingjia Hao, Xin Wang, Yifan Yang, Yueguo Chen,
 Yang Tian, Yunhai Wang
Categories: cs.AI
Comments: Accepted by NeurIPS 2025
\\ ( https://arxiv.org/abs/2511.00457 ,  853kb)
------------------------------------------------------------------------------
\\
arXiv:2511.00609
replaced with revised version Mon, 10 Nov 2025 07:47:50 GMT   (59900kb)

Title: PreferThinker: Reasoning-based Personalized Image Preference Assessment
Authors: Shengqi Xu, Xinpeng Zhou, Yabo Zhang, Ming Liu, Tao Liang, Tianyu
 Zhang, Yalong Bai, Zuxuan Wu, Wangmeng Zuo
Categories: cs.AI
\\ ( https://arxiv.org/abs/2511.00609 ,  59900kb)
------------------------------------------------------------------------------
\\
arXiv:2511.00710
replaced with revised version Fri, 7 Nov 2025 21:47:55 GMT   (10305kb)

Title: Ariadne: A Controllable Framework for Probing and Extending VLM
 Reasoning Boundaries
Authors: Minghe Shen, Zhuo Zhi, Chonghan Liu, Shuo Xing, Zhengzhong Tu, Che Liu
Categories: cs.AI
\\ ( https://arxiv.org/abs/2511.00710 ,  10305kb)
------------------------------------------------------------------------------
\\
arXiv:2511.03092
replaced with revised version Fri, 7 Nov 2025 19:27:58 GMT   (339kb)

Title: SnapStream: Efficient Long Sequence Decoding on Dataflow Accelerators
Authors: Jonathan Li, Nasim Farahini, Evgenii Iuliugin, Magnus Vesterlund,
 Christian H\"aggstr\"om, Guangtao Wang, Shubhangi Upasani, Ayush Sachdeva,
 Rui Li, Faline Fu, Chen Wu, Ayesha Siddiqua, John Long, Tuowen Zhao, Matheen
 Musaddiq, H\r{a}kan Zeffer, Yun Du, Mingran Wang, Qinghua Li, Bo Li, Urmish
 Thakker and Raghu Prabhakar
Categories: cs.AI cs.AR cs.DC
\\ ( https://arxiv.org/abs/2511.03092 ,  339kb)
------------------------------------------------------------------------------
\\
arXiv:2511.03138
replaced with revised version Mon, 10 Nov 2025 01:31:25 GMT   (116kb)

Title: DeepKnown-Guard: A Proprietary Model-Based Safety Response Framework for
 AI Agents
Authors: Qi Li, Jianjun Xu, Pingtao Wei, Jiu Li, Peiqiang Zhao, Jiwei Shi, Xuan
 Zhang, Yanhui Yang, Xiaodong Hui, Peng Xu, Wenqin Shao
Categories: cs.AI
\\ ( https://arxiv.org/abs/2511.03138 ,  116kb)
------------------------------------------------------------------------------
\\
arXiv:2511.03773
replaced with revised version Mon, 10 Nov 2025 05:02:36 GMT   (471kb)

Title: Scaling Agent Learning via Experience Synthesis
Authors: Zhaorun Chen, Zhuokai Zhao, Kai Zhang, Bo Liu, Qi Qi, Yifan Wu, Tarun
 Kalluri, Sara Cao, Yuanhao Xiong, Haibo Tong, Huaxiu Yao, Hengduo Li,
 Jiacheng Zhu, Xian Li, Dawn Song, Bo Li, Jason Weston, Dat Huynh
Categories: cs.AI
\\ ( https://arxiv.org/abs/2511.03773 ,  471kb)
------------------------------------------------------------------------------
\\
arXiv:2511.04053
replaced with revised version Mon, 10 Nov 2025 13:39:09 GMT   (345kb)

Title: Interpreting Multi-Attribute Confounding through Numerical Attributes in
 Large Language Models
Authors: Hirohane Takagi, Gouki Minegishi, Shota Kizawa, Issey Sukeda, Hitomi
 Yanaka
Categories: cs.AI
Comments: Accepted to IJCNLP-AACL 2025 (Main). Code available at
 https://github.com/htkg/num_attrs
\\ ( https://arxiv.org/abs/2511.04053 ,  345kb)
------------------------------------------------------------------------------
\\
arXiv:2511.04076
replaced with revised version Sun, 9 Nov 2025 02:33:32 GMT   (2813kb)

Title: Agentmandering: A Game-Theoretic Framework for Fair Redistricting via
 Large Language Model Agents
Authors: Hao Li, Haotian Chen, Ruoyuan Gong, Juanjuan Wang, Hao Jiang
Categories: cs.AI
Comments: Accepted by AAAI AISI 2026
\\ ( https://arxiv.org/abs/2511.04076 ,  2813kb)
------------------------------------------------------------------------------
\\
arXiv:2511.04307
replaced with revised version Mon, 10 Nov 2025 12:27:15 GMT   (1533kb)

Title: GUI-360$^\circ$: A Comprehensive Dataset and Benchmark for
 Computer-Using Agents
Authors: Jian Mu, Chaoyun Zhang, Chiming Ni, Lu Wang, Bo Qiao, Kartik Mathur,
 Qianhui Wu, Yuhang Xie, Xiaojun Ma, Mengyu Zhou, Si Qin, Liqun Li, Yu Kang,
 Minghua Ma, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang
Categories: cs.AI
\\ ( https://arxiv.org/abs/2511.04307 ,  1533kb)
------------------------------------------------------------------------------
\\
arXiv:2511.04583
replaced with revised version Mon, 10 Nov 2025 15:05:28 GMT   (4951kb)

Title: Jr. AI Scientist and Its Risk Report: Autonomous Scientific Exploration
 from a Baseline Paper
Authors: Atsuyuki Miyai, Mashiro Toyooka, Takashi Otonari, Zaiying Zhao,
 Kiyoharu Aizawa
Categories: cs.AI cs.CL cs.CV cs.LG
Comments: Issues, comments, and questions are all welcome in
 https://github.com/Agent4Science-UTokyo/Jr.AI-Scientist
\\ ( https://arxiv.org/abs/2511.04583 ,  4951kb)
------------------------------------------------------------------------------
\\
arXiv:2402.11903
replaced with revised version Fri, 7 Nov 2025 22:58:42 GMT   (516kb)

Title: DiLA: Enhancing LLM Tool Learning with Differential Logic Layer
Authors: Yu Zhang, Hui-Ling Zhen, Zehua Pei, Yingzhao Lian, Lihao Yin, Mingxuan
 Yuan, Bei Yu
Categories: cs.CL cs.AI
Comments: arXiv admin note: text overlap with arXiv:2305.12295 by other authors
\\ ( https://arxiv.org/abs/2402.11903 ,  516kb)
------------------------------------------------------------------------------
\\
arXiv:2402.15987
replaced with revised version Mon, 10 Nov 2025 05:11:10 GMT   (7330kb)

Title: Likelihood-based Mitigation of Evaluation Bias in Large Language Models
Authors: Masanari Oi, Masahiro Kaneko, Ryuto Koike, Mengsay Loem, Naoaki
 Okazaki
Categories: cs.CL cs.AI
Comments: 5 main pages
Journal-ref: ACL2024 (findings)
\\ ( https://arxiv.org/abs/2402.15987 ,  7330kb)
------------------------------------------------------------------------------
\\
arXiv:2405.20318
replaced with revised version Sun, 9 Nov 2025 13:31:00 GMT   (695kb)

Title: Quriosity: Analyzing Human Questioning Behavior and Causal Inquiry
 through Curiosity-Driven Queries
Authors: Roberto Ceraolo, Dmitrii Kharlapenko, Ahmad Khan, Am\'elie Reymond,
 Punya Syon Pandey, Rada Mihalcea, Bernhard Sch\"olkopf, Mrinmaya Sachan,
 Zhijing Jin
Categories: cs.CL cs.AI cs.LG stat.ML
Comments: IJCNLP-AACL 2025 Findings
\\ ( https://arxiv.org/abs/2405.20318 ,  695kb)
------------------------------------------------------------------------------
\\
arXiv:2406.11177
replaced with revised version Mon, 10 Nov 2025 01:45:42 GMT   (668kb)

Title: Retrieval-Augmented Feature Generation for Domain-Specific
 Classification
Authors: Xinhao Zhang, Jinghan Zhang, Fengran Mo, Dakshak Keerthi Chandra,
 Yu-Zhong Chen, Fei Xie, Kunpeng Liu
Categories: cs.CL
Comments: Accepted by ICDM 2025
\\ ( https://arxiv.org/abs/2406.11177 ,  668kb)
------------------------------------------------------------------------------
\\
arXiv:2406.12403
replaced with revised version Sun, 9 Nov 2025 03:13:03 GMT   (1658kb)

Title: FedCoT: Federated Chain-of-Thought Distillation for Large Language
 Models
Authors: Tao Fan, Weijing Chen, Yan Kang, Guoqiang Ma, Hanlin Gu, Yuanfeng
 Song, Lixin Fan, Qiang Yang
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2406.12403 ,  1658kb)
------------------------------------------------------------------------------
\\
arXiv:2407.01599
replaced with revised version Fri, 7 Nov 2025 20:21:15 GMT   (1678kb)

Title: JailbreakZoo: Survey, Landscapes, and Horizons in Jailbreaking Large
 Language and Vision-Language Models
Authors: Haibo Jin, Leyang Hu, Xinnuo Li, Peiyan Zhang, Chonghan Chen, Jun
 Zhuang, Haohan Wang
Categories: cs.CL cs.CR cs.CV cs.LG
Comments: 45 pages
\\ ( https://arxiv.org/abs/2407.01599 ,  1678kb)
------------------------------------------------------------------------------
\\
arXiv:2407.10807
replaced with revised version Mon, 10 Nov 2025 12:59:40 GMT   (761kb)

Title: Employing Sentence Space Embedding for Classification of Data Stream
 from Fake News Domain
Authors: Pawe{\l} Zyblewski, Jakub Klikowski, Weronika Borek-Marciniec,
 Pawe{\l} Ksieniewicz
Categories: cs.CL cs.LG
Comments: 16 pages, 7 figures
\\ ( https://arxiv.org/abs/2407.10807 ,  761kb)
------------------------------------------------------------------------------
\\
arXiv:2408.09667
replaced with revised version Mon, 10 Nov 2025 06:38:02 GMT   (16358kb)

Title: BLADE: Benchmarking Language Model Agents for Data-Driven Science
Authors: Ken Gu, Ruoxi Shang, Ruien Jiang, Keying Kuang, Richard-John Lin,
 Donghe Lyu, Yue Mao, Youran Pan, Teng Wu, Jiaqian Yu, Yikun Zhang, Tianmai M.
 Zhang, Lanyi Zhu, Mike A. Merrill, Jeffrey Heer, Tim Althoff
Categories: cs.CL
Comments: EMNLP 2024
\\ ( https://arxiv.org/abs/2408.09667 ,  16358kb)
------------------------------------------------------------------------------
\\
arXiv:2409.13949
replaced with revised version Mon, 10 Nov 2025 03:19:35 GMT   (1083kb)

Title: Mufu: Multilingual Fused Learning for Low-Resource Translation with LLM
Authors: Zheng Wei Lim, Nitish Gupta, Honglin Yu, Trevor Cohn
Categories: cs.CL
Comments: 29 pages
\\ ( https://arxiv.org/abs/2409.13949 ,  1083kb)
------------------------------------------------------------------------------
\\
arXiv:2410.01334
replaced with revised version Mon, 10 Nov 2025 08:10:28 GMT   (6735kb)

Title: Skill Path: Unveiling Language Skills from Circuit Graphs
Authors: Hang Chen and Jiaying Zhu and Xinyu Yang and Wenya Wang
Categories: cs.CL cs.AI
Comments: accepted by AAAI 2026 (oral)
\\ ( https://arxiv.org/abs/2410.01334 ,  6735kb)
------------------------------------------------------------------------------
\\
arXiv:2410.12265
replaced with revised version Sun, 9 Nov 2025 09:14:22 GMT   (765kb)

Title: Auto-PRE: An Automatic and Cost-Efficient Peer-Review Framework for
 Language Generation Evaluation
Authors: Junjie Chen, Weihang Su, Zhumin Chu, Haitao Li, Yujia Zhou, Dingbo
 Yuan, Xudong Wang, Jun Zhou, Yiqun Liu, Min Zhang, Shaoping Ma, Qingyao Ai
Categories: cs.CL
Comments: AAAI 2026
\\ ( https://arxiv.org/abs/2410.12265 ,  765kb)
------------------------------------------------------------------------------
\\
arXiv:2410.17355
replaced with revised version Mon, 10 Nov 2025 14:01:06 GMT   (628kb)

Title: All Entities are Not Created Equal: Examining the Long Tail for
 Ultra-Fine Entity Typing
Authors: Advait Deshmukh, Ashwin Umadi, Dananjay Srinivas, Maria Leonor Pacheco
Categories: cs.CL
\\ ( https://arxiv.org/abs/2410.17355 ,  628kb)
------------------------------------------------------------------------------
\\
arXiv:2411.04822
replaced with revised version Mon, 10 Nov 2025 13:23:23 GMT   (1961kb)

Title: Shared Heritage, Distinct Writing: Rethinking Resource Selection for
 East Asian Historical Documents
Authors: Seyoung Song, Haneul Yoo, Jiho Jin, Kyunghyun Cho, Alice Oh
Categories: cs.CL
Comments: IJCNLP-AACL 2025 Findings
\\ ( https://arxiv.org/abs/2411.04822 ,  1961kb)
------------------------------------------------------------------------------
\\
arXiv:2411.10927
replaced with revised version Mon, 10 Nov 2025 09:58:40 GMT   (10485kb)

Title: Compositional Phoneme Approximation for L1-Grounded L2 Pronunciation
 Training
Authors: Jisang Park, Minu Kim, DaYoung Hong, and Jongha Lee
Categories: cs.CL cs.SD eess.AS
Comments: Accepted to IJCNLP-AACL 2025
ACM-class: H.5.5
\\ ( https://arxiv.org/abs/2411.10927 ,  10485kb)
------------------------------------------------------------------------------
\\
arXiv:2411.19096
replaced with revised version Mon, 10 Nov 2025 10:02:30 GMT   (2622kb)

Title: Pralekha: Cross-Lingual Document Alignment for Indic Languages
Authors: Sanjay Suryanarayanan, Haiyue Song, Mohammed Safi Ur Rahman Khan,
 Anoop Kunchukuttan, Raj Dabre
Categories: cs.CL
\\ ( https://arxiv.org/abs/2411.19096 ,  2622kb)
------------------------------------------------------------------------------
\\
arXiv:2411.19638
replaced with revised version Mon, 10 Nov 2025 08:53:53 GMT   (1836kb)

Title: LLM Teacher-Student Framework for Text Classification With No Manually
 Annotated Data: A Case Study in IPTC News Topic Classification
Authors: Taja Kuzman, Nikola Ljube\v{s}i\'c
Categories: cs.CL
Comments: This work has been accepted and published in the IEEE Access journal.
 This arXiv version is retained for archival purposes. Readers should use and
 cite the IEEE Access Version available at
 https://ieeexplore.ieee.org/document/10900365
Journal-ref: IEEE Access 2025
DOI: 10.1109/ACCESS.2025.3544814
\\ ( https://arxiv.org/abs/2411.19638 ,  1836kb)
------------------------------------------------------------------------------
\\
arXiv:2412.12475
replaced with revised version Mon, 10 Nov 2025 05:32:04 GMT   (3015kb)

Title: RareAgents: Autonomous Multi-disciplinary Team for Rare Disease
 Diagnosis and Treatment
Authors: Xuanzhong Chen, Ye Jin, Xiaohao Mao, Lun Wang, Shuyang Zhang, Ting
 Chen
Categories: cs.CL cs.AI
Comments: AAAI2026 Oral
\\ ( https://arxiv.org/abs/2412.12475 ,  3015kb)
------------------------------------------------------------------------------
\\
arXiv:2501.12547
replaced with revised version Sat, 8 Nov 2025 09:32:54 GMT   (34457kb)

Title: Revealing emergent human-like conceptual representations from language
 prediction
Authors: Ningyu Xu, Qi Zhang, Chao Du, Qiang Luo, Xipeng Qiu, Xuanjing Huang,
 Menghan Zhang
Categories: cs.CL cs.AI
Comments: 66 pages. Accepted manuscript. Final version published in Proceedings
 of the National Academy of Sciences (PNAS):
 https://www.pnas.org/doi/10.1073/pnas.2512514122
Journal-ref: Proceedings of the National Academy of Sciences, U.S.A., 122 (44)
 e2512514122 (2025)
DOI: 10.1073/pnas.2512514122
\\ ( https://arxiv.org/abs/2501.12547 ,  34457kb)
------------------------------------------------------------------------------
\\
arXiv:2502.05390
replaced with revised version Sat, 8 Nov 2025 00:57:22 GMT   (2779kb)

Title: Learning Task Representations from In-Context Learning
Authors: Baturay Saglam, Xinyang Hu, Zhuoran Yang, Dionysis Kalogerias, Amin
 Karbasi
Categories: cs.CL cs.LG
Comments: ACL Findings 2025
\\ ( https://arxiv.org/abs/2502.05390 ,  2779kb)
------------------------------------------------------------------------------
\\
arXiv:2502.07077
replaced with revised version Sun, 9 Nov 2025 04:58:17 GMT   (1569kb)

Title: Multi-turn Evaluation of Anthropomorphic Behaviours in Large Language
 Models
Authors: Lujain Ibrahim, Canfer Akbulut, Rasmi Elasmar, Charvi Rastogi, Minsuk
 Kahng, Meredith Ringel Morris, Kevin R. McKee, Verena Rieser, Murray
 Shanahan, Laura Weidinger
Categories: cs.CL cs.CY cs.HC
\\ ( https://arxiv.org/abs/2502.07077 ,  1569kb)
------------------------------------------------------------------------------
\\
arXiv:2502.07186
replaced with revised version Sat, 8 Nov 2025 14:30:33 GMT   (571kb)

Title: PCS: Perceived Confidence Scoring of Black Box LLMs with Metamorphic
 Relations
Authors: Sina Salimian, Gias Uddin, and Shaina Raza, Henry Leung
Categories: cs.CL cs.LG
\\ ( https://arxiv.org/abs/2502.07186 ,  571kb)
------------------------------------------------------------------------------
\\
arXiv:2502.15857
replaced with revised version Sun, 9 Nov 2025 03:26:55 GMT   (590kb)

Title: PPC-GPT: Federated Task-Specific Compression of Large Language Models
 via Pruning and Chain-of-Thought Distillation
Authors: Tao Fan, Guoqiang Ma, Yuanfeng Song, Lixin Fan, Qiang Yang
Categories: cs.CL cs.AI cs.LG
\\ ( https://arxiv.org/abs/2502.15857 ,  590kb)
------------------------------------------------------------------------------
\\
arXiv:2502.16002
replaced with revised version Mon, 10 Nov 2025 00:11:57 GMT   (357kb)

Title: KVLink: Accelerating Large Language Models via Efficient KV Cache Reuse
Authors: Jingbo Yang, Bairu Hou, Wei Wei, Yujia Bao, Shiyu Chang
Categories: cs.CL
\\ ( https://arxiv.org/abs/2502.16002 ,  357kb)
------------------------------------------------------------------------------
\\
arXiv:2502.19907
replaced with revised version Sun, 9 Nov 2025 09:28:44 GMT   (679kb)

Title: Order Doesn't Matter, But Reasoning Does: Training LLMs with
 Order-Centric Augmentation
Authors: Qianxi He, Qianyu He, Jiaqing Liang, Yanghua Xiao, Weikang Zhou, Zeye
 Sun, Fei Yu
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2502.19907 ,  679kb)
------------------------------------------------------------------------------
\\
arXiv:2502.21228
replaced with revised version Sat, 8 Nov 2025 19:37:13 GMT   (1439kb)

Title: ECLeKTic: a Novel Challenge Set for Evaluation of Cross-Lingual
 Knowledge Transfer
Authors: Omer Goldman, Uri Shaham, Dan Malkin, Sivan Eiger, Avinatan Hassidim,
 Yossi Matias, Joshua Maynez, Adi Mayrav Gilady, Jason Riesa, Shruti Rijhwani,
 Laura Rimell, Idan Szpektor, Reut Tsarfaty, Matan Eyal
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2502.21228 ,  1439kb)
------------------------------------------------------------------------------
\\
arXiv:2503.11881
replaced with revised version Sun, 9 Nov 2025 02:13:20 GMT   (3632kb)

Title: Evaluating Human-LLM Representation Alignment: A Case Study on Affective
 Sentence Generation for Augmentative and Alternative Communication
Authors: Shadab Choudhury, Asha Kumar, Lara J. Martin
Categories: cs.CL
Comments: Published at IJCNLP-AACL 2025 Findings
\\ ( https://arxiv.org/abs/2503.11881 ,  3632kb)
------------------------------------------------------------------------------
\\
arXiv:2503.16040
replaced with revised version Mon, 10 Nov 2025 11:28:29 GMT   (2973kb)

Title: Evaluating Test-Time Scaling LLMs for Legal Reasoning: OpenAI o1,
 DeepSeek-R1, and Beyond
Authors: Yinghao Hu, Yaoyao Yu, Leilei Gan, Bin Wei, Kun Kuang, Fei Wu
Categories: cs.CL
Comments: 23 pages, Published in Findings of the Association for Computational
 Linguistics: EMNLP 2025
DOI: 10.18653/v1/2025.findings-emnlp.742
\\ ( https://arxiv.org/abs/2503.16040 ,  2973kb)
------------------------------------------------------------------------------
\\
arXiv:2504.00597
replaced with revised version Mon, 10 Nov 2025 13:06:24 GMT   (12659kb)

Title: On the Consistency of Multilingual Context Utilization in
 Retrieval-Augmented Generation
Authors: Jirui Qi, Raquel Fern\'andez, Arianna Bisazza
Categories: cs.CL cs.AI
Comments: Best Paper Award at MRL Workshop 2025, colocated with EMNLP 2025. All
 codes and data are released at
 https://github.com/Betswish/mRAG-Context-Consistency
\\ ( https://arxiv.org/abs/2504.00597 ,  12659kb)
------------------------------------------------------------------------------
\\
arXiv:2504.02904
replaced with revised version Sat, 8 Nov 2025 00:46:36 GMT   (3155kb)

Title: How Post-Training Reshapes LLMs: A Mechanistic View on Knowledge,
 Truthfulness, Refusal, and Confidence
Authors: Hongzhe Du, Weikai Li, Min Cai, Karim Saraipour, Zimin Zhang,
 Himabindu Lakkaraju, Yizhou Sun, Shichang Zhang
Categories: cs.CL cs.AI cs.LG
Comments: COLM 2025
\\ ( https://arxiv.org/abs/2504.02904 ,  3155kb)
------------------------------------------------------------------------------
\\
arXiv:2504.03546
replaced with revised version Sun, 9 Nov 2025 20:34:22 GMT   (7348kb)

Title: MultiMed-ST: Large-scale Many-to-many Multilingual Medical Speech
 Translation
Authors: Khai Le-Duc, Tuyen Tran, Bach Phan Tat, Nguyen Kim Hai Bui, Quan Dang,
 Hung-Phong Tran, Thanh-Thuy Nguyen, Ly Nguyen, Tuan-Minh Phan, Thi Thu Phuong
 Tran, Chris Ngo, Nguyen X. Khanh, Thanh Nguyen-Tang
Categories: cs.CL cs.AI cs.LG cs.SD eess.AS
Comments: EMNLP 2025
\\ ( https://arxiv.org/abs/2504.03546 ,  7348kb)
------------------------------------------------------------------------------
\\
arXiv:2505.02311
replaced with revised version Sat, 8 Nov 2025 03:08:11 GMT   (6659kb)

Title: Invoke Interfaces Only When Needed: Adaptive Invocation for Large
 Language Models in Question Answering
Authors: Jihao Zhao, Chunlai Zhou, Daixuan Li, Shuaishuai Zu, Biao Qin
Categories: cs.CL
\\ ( https://arxiv.org/abs/2505.02311 ,  6659kb)
------------------------------------------------------------------------------
\\
arXiv:2505.09039
replaced with revised version Mon, 10 Nov 2025 04:08:26 GMT   (1855kb)

Title: Atomic Consistency Preference Optimization for Long-Form Question
 Answering
Authors: Jingfeng Chen, Raghuveer Thirukovalluru, Junlin Wang, Kaiwei Luo,
 Bhuwan Dhingra
Categories: cs.CL
Comments: 13 pages, 1 figure
\\ ( https://arxiv.org/abs/2505.09039 ,  1855kb)
------------------------------------------------------------------------------
\\
arXiv:2505.13979
replaced with revised version Mon, 10 Nov 2025 18:36:10 GMT   (3520kb)

Title: Mixed Signals: Understanding Model Disagreement in Multimodal Empathy
 Detection
Authors: Maya Srikanth, Run Chen, Julia Hirschberg
Categories: cs.CL
\\ ( https://arxiv.org/abs/2505.13979 ,  3520kb)
------------------------------------------------------------------------------
\\
arXiv:2505.15255
replaced with revised version Sat, 8 Nov 2025 10:51:07 GMT   (447kb)

Title: Enhancing Large Language Models for Detecting Mental Manipulation via
 Annotation-Free Data Augmentation and Anti-Curriculum Distillation
Authors: Yuansheng Gao, Han Bao, Tong Zhang, Bin Li, Jixiang Luo, Ronghao Chen,
 Zonghui Wang, Wenzhi Chen
Categories: cs.CL
\\ ( https://arxiv.org/abs/2505.15255 ,  447kb)
------------------------------------------------------------------------------
\\
arXiv:2505.20335
replaced with revised version Sun, 9 Nov 2025 02:18:08 GMT   (144kb)

Title: Language Model Distillation: A Temporal Difference Imitation Learning
 Perspective
Authors: Zishun Yu, Shangzhe Li, Xinhua Zhang
Categories: cs.CL cs.AI
Comments: AAAI 2026
\\ ( https://arxiv.org/abs/2505.20335 ,  144kb)
------------------------------------------------------------------------------
\\
arXiv:2505.20354
replaced with revised version Mon, 10 Nov 2025 03:48:28 GMT   (2636kb)

Title: Rethinking Text-based Protein Understanding: Retrieval or LLM?
Authors: Juntong Wu, Zijing Liu, He Cao, Hao Li, Bin Feng, Zishan Shu, Ke Yu,
 Li Yuan, Yu Li
Categories: cs.CL cs.AI
Comments: Accepted by Empirical Methods in Natural Language Processing 2025
 (EMNLP 2025) Main Conference
\\ ( https://arxiv.org/abs/2505.20354 ,  2636kb)
------------------------------------------------------------------------------
\\
arXiv:2505.24332
replaced with revised version Mon, 10 Nov 2025 13:43:25 GMT   (477kb)

Title: DeepDiver: Adaptive Search Intensity Scaling via Open-Web Reinforcement
 Learning
Authors: Wenxuan Shi, Haochen Tan, Chuqiao Kuang, Xiaoguang Li, Xiaozhe Ren,
 Chen Zhang, Hanting Chen, Yasheng Wang, Lu Hou, Lifeng Shang
Categories: cs.CL
Comments: Accepted as NeurIPS 2025 Spotlight
\\ ( https://arxiv.org/abs/2505.24332 ,  477kb)
------------------------------------------------------------------------------
\\
arXiv:2505.24409
replaced with revised version Mon, 10 Nov 2025 14:55:15 GMT   (657kb)

Title: When Language Shapes Thought: Cross-Lingual Transfer of Factual
 Knowledge in Question Answering
Authors: Eojin Kang and Juae Kim
Categories: cs.CL cs.AI
Comments: Accepted at CIKM2025 (Expanded version)
DOI: 10.1145/3746252.3760807
\\ ( https://arxiv.org/abs/2505.24409 ,  657kb)
------------------------------------------------------------------------------
\\
arXiv:2505.24826
replaced with revised version Mon, 10 Nov 2025 11:30:26 GMT   (513kb)

Title: LegalEval-Q: A New Benchmark for The Quality Evaluation of LLM-Generated
 Legal Text
Authors: Li yunhan, Wu gengshen
Categories: cs.CL cs.CV
Comments: 10 pages, 11 figures
\\ ( https://arxiv.org/abs/2505.24826 ,  513kb)
------------------------------------------------------------------------------
\\
arXiv:2506.12618
replaced with revised version Sun, 9 Nov 2025 21:03:26 GMT   (782kb)

Title: OpenUnlearning: Accelerating LLM Unlearning via Unified Benchmarking of
 Methods and Metrics
Authors: Vineeth Dorna, Anmol Mekala, Wenlong Zhao, Andrew McCallum, Zachary C.
 Lipton, J. Zico Kolter, Pratyush Maini
Categories: cs.CL
\\ ( https://arxiv.org/abs/2506.12618 ,  782kb)
------------------------------------------------------------------------------
\\
arXiv:2506.14758
replaced with revised version Sat, 8 Nov 2025 04:52:16 GMT   (2480kb)

Title: Reasoning with Exploration: An Entropy Perspective
Authors: Daixuan Cheng, Shaohan Huang, Xuekai Zhu, Bo Dai, Wayne Xin Zhao,
 Zhenliang Zhang, Furu Wei
Categories: cs.CL
Comments: AAAI 2026 Conference
\\ ( https://arxiv.org/abs/2506.14758 ,  2480kb)
------------------------------------------------------------------------------
\\
arXiv:2506.16678
replaced with revised version Sat, 8 Nov 2025 04:36:14 GMT   (864kb)

Title: Mechanisms vs. Outcomes: Probing for Syntax Fails to Explain Performance
 on Targeted Syntactic Evaluations
Authors: Ananth Agarwal, Jasper Jian, Christopher D. Manning, Shikhar Murty
Categories: cs.CL
Journal-ref: Proceedings of the 2025 Conference on Empirical Methods in Natural
 Language Processing
\\ ( https://arxiv.org/abs/2506.16678 ,  864kb)
------------------------------------------------------------------------------
\\
arXiv:2506.20495
replaced with revised version Mon, 10 Nov 2025 14:49:41 GMT   (743kb)

Title: ReCode: Updating Code API Knowledge with Reinforcement Learning
Authors: Haoze Wu, Yunzhi Yao, Wenhao Yu, Ningyu Zhang
Categories: cs.CL cs.AI cs.IR cs.LG cs.SE
Comments: AAAI 2026
\\ ( https://arxiv.org/abs/2506.20495 ,  743kb)
------------------------------------------------------------------------------
\\
arXiv:2507.04531
replaced with revised version Sun, 9 Nov 2025 12:39:22 GMT   (1482kb)

Title: DP-Fusion: Token-Level Differentially Private Inference for Large
 Language Models
Authors: Rushil Thareja, Preslav Nakov, Praneeth Vepakomma, Nils Lukas
Categories: cs.CL cs.AI cs.LG
Comments: Our code and data are publicly available here:
 https://github.com/MBZUAI-Trustworthy-ML/DP-Fusion-DPI
\\ ( https://arxiv.org/abs/2507.04531 ,  1482kb)
------------------------------------------------------------------------------
\\
arXiv:2507.05639
replaced with revised version Sun, 9 Nov 2025 07:32:15 GMT   (621kb)

Title: ECom-Bench: Can LLM Agent Resolve Real-World E-commerce Customer Support
 Issues?
Authors: Haoxin Wang, Xianhan Peng, Xucheng Huang, Yizhe Huang, Ming Gong,
 Chenghan Yang, Yang Liu, Ling Jiang
Categories: cs.CL
Comments: Accepted as a main conference paper at EMNLP 2025
\\ ( https://arxiv.org/abs/2507.05639 ,  621kb)
------------------------------------------------------------------------------
\\
arXiv:2507.12059
replaced with revised version Mon, 10 Nov 2025 13:52:37 GMT   (111kb)

Title: Evaluating the Ability of Large Language Models to Reason about Cardinal
 Directions, Revisited
Authors: Anthony G Cohn and Robert E Blackwell
Categories: cs.CL
Comments: 8 pages, 5 figures. Accepted at QR 2025 : 38th International Workshop
 on Qualitative Reasoning at IJCAI. arXiv admin note: substantial text overlap
 with arXiv:2406.16528
\\ ( https://arxiv.org/abs/2507.12059 ,  111kb)
------------------------------------------------------------------------------
\\
arXiv:2507.20264
replaced with revised version Sun, 9 Nov 2025 21:58:37 GMT   (10087kb)

Title: EMBRACE: Shaping Inclusive Opinion Representation by Aligning Implicit
 Conversations with Social Norms
Authors: Abeer Aldayel, Areej Alokaili
Categories: cs.CL
Comments: Accepted, to appear IJCNLP-AACL 2025 Findings
\\ ( https://arxiv.org/abs/2507.20264 ,  10087kb)
------------------------------------------------------------------------------
\\
arXiv:2507.21652
replaced with revised version Mon, 10 Nov 2025 10:23:44 GMT   (389kb)

Title: UnsafeChain: Enhancing Reasoning Model Safety via Hard Cases
Authors: Raj Vardhan Tomar, Preslav Nakov and Yuxia Wang
Categories: cs.CL
\\ ( https://arxiv.org/abs/2507.21652 ,  389kb)
------------------------------------------------------------------------------
\\
arXiv:2508.01710
replaced with revised version Sun, 9 Nov 2025 11:10:40 GMT   (262kb)

Title: CultureGuard: Towards Culturally-Aware Dataset and Guard Model for
 Multilingual Safety Applications
Authors: Raviraj Joshi, Rakesh Paul, Kanishk Singla, Anusha Kamath, Michael
 Evans, Katherine Luna, Shaona Ghosh, Utkarsh Vaidya, Eileen Long, Sanjay
 Singh Chauhan, Niranjan Wartikar
Categories: cs.CL cs.LG
\\ ( https://arxiv.org/abs/2508.01710 ,  262kb)
------------------------------------------------------------------------------
\\
arXiv:2508.04423
replaced with revised version Sat, 8 Nov 2025 14:35:03 GMT   (12713kb)

Title: Evaluating, Synthesizing, and Enhancing for Customer Support
 Conversation
Authors: Jie Zhu, Huaixia Dou, Junhui Li, Lifan Guo, Feng Chen, Chi Zhang, Fang
 Kong
Categories: cs.CL
Comments: Accepted by AAAI-2026
Journal-ref: The Association for the Advancement of Artificial Intelligence
 (AAAI),2026
\\ ( https://arxiv.org/abs/2508.04423 ,  12713kb)
------------------------------------------------------------------------------
\\
arXiv:2508.05100
replaced with revised version Mon, 10 Nov 2025 10:49:10 GMT   (287kb)

Title: BEE-RAG: Balanced Entropy Engineering for Retrieval-Augmented Generation
Authors: Yuhao Wang, Ruiyang Ren, Yucheng Wang, Jing Liu, Wayne Xin Zhao, Hua
 Wu, Haifeng Wang
Categories: cs.CL
\\ ( https://arxiv.org/abs/2508.05100 ,  287kb)
------------------------------------------------------------------------------
\\
arXiv:2508.05470
replaced with revised version Sat, 8 Nov 2025 11:58:27 GMT   (746kb)

Title: Rethinking Creativity Evaluation: A Critical Analysis of Existing
 Creativity Evaluations
Authors: Li-Chun Lu, Miri Liu, Pin-Chun Lu, Yufei Tian, Shao-Hua Sun, Nanyun
 Peng
Categories: cs.CL
Comments: 23 pages, 6 figures
\\ ( https://arxiv.org/abs/2508.05470 ,  746kb)
------------------------------------------------------------------------------
\\
arXiv:2508.07229
replaced with revised version Mon, 10 Nov 2025 10:16:06 GMT   (1582kb)

Title: How Does a Deep Neural Network Look at Lexical Stress?
Authors: Itai Allouche, Itay Asael, Rotem Rousso, Vered Dassa, Ann Bradlow,
 Seung-Eun Kim, Matthew Goldrick, and Joseph Keshet
Categories: cs.CL cs.LG cs.SD eess.AS
Comments: 11 pages, 5 figures, submitted to the Journal of the Acoustical
 Society of America (JASA)
\\ ( https://arxiv.org/abs/2508.07229 ,  1582kb)
------------------------------------------------------------------------------
\\
arXiv:2508.08424
replaced with revised version Mon, 10 Nov 2025 14:36:09 GMT   (1341kb)

Title: Rethinking Tokenization for Rich Morphology: The Dominance of Unigram
 over BPE and Morphological Alignment
Authors: Saketh Reddy Vemula, Sandipan Dandapat, Dipti Misra Sharma and
 Parameswari Krishnamurthy
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2508.08424 ,  1341kb)
------------------------------------------------------------------------------
\\
arXiv:2508.09091
replaced with revised version Sat, 8 Nov 2025 09:14:23 GMT   (174kb)

Title: Utilizing Multilingual Encoders to Improve Large Language Models for
 Low-Resource Languages
Authors: Imalsha Puranegedara, Themira Chathumina, Nisal Ranathunga, Nisansa de
 Silva, Surangika Ranathunga, Mokanarangan Thayaparan
Categories: cs.CL
DOI: 10.1109/MERCon67903.2025.11216992
\\ ( https://arxiv.org/abs/2508.09091 ,  174kb)
------------------------------------------------------------------------------
\\
arXiv:2508.09115
replaced with revised version Sat, 8 Nov 2025 09:12:17 GMT   (213kb)

Title: SinLlama -- A Large Language Model for Sinhala
Authors: H.W.K.Aravinda, Rashad Sirajudeen, Samith Karunathilake, Nisansa de
 Silva, Surangika Ranathunga, Rishemjit Kaur
Categories: cs.CL
DOI: 10.1109/MERCon67903.2025.11217094
\\ ( https://arxiv.org/abs/2508.09115 ,  213kb)
------------------------------------------------------------------------------
\\
arXiv:2508.10027
replaced with revised version Mon, 10 Nov 2025 09:23:49 GMT   (3440kb)

Title: LLMCARE: early detection of cognitive impairment via transformer models
 enhanced by LLM-generated synthetic data
Authors: Ali Zolnour, Hossein Azadmaleki, Yasaman Haghbin, Fatemeh
 Taherinezhad, Mohamad Javad Momeni Nezhad, Sina Rashidi, Masoud Khani,
 AmirSajjad Taleban, Samin Mahdizadeh Sani, Maryam Dadkhah, James M. Noble,
 Suzanne Bakken, Yadollah Yaghoobzadeh, Abdol-Hossein Vahabie, Masoud
 Rouhizadeh, Maryam Zolnoori
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2508.10027 ,  3440kb)
------------------------------------------------------------------------------
\\
arXiv:2508.10419
replaced with revised version Mon, 10 Nov 2025 10:47:01 GMT   (1130kb)

Title: ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long
 Narrative Reasoning
Authors: Juyuan Wang, Rongchen Zhao, Wei Wei, Yufeng Wang, Mo Yu, Jie Zhou, Jin
 Xu, Liyan Xu
Categories: cs.CL cs.AI cs.LG
Comments: Accepted by AAAI 2026
\\ ( https://arxiv.org/abs/2508.10419 ,  1130kb)
------------------------------------------------------------------------------
\\
arXiv:2508.15250
replaced with revised version Mon, 10 Nov 2025 03:05:52 GMT   (383kb)

Title: EMNLP: Educator-role Moral and Normative Large Language Models Profiling
Authors: Yilin Jiang, Mingzi Zhang, Sheng Jin, Zengyi Yu, Xiangjie Kong,
 Binghao Tu
Categories: cs.CL
Comments: 29pages, 15 figures, Accepted by EMNLP Main Confrence
ACM-class: I.2.7
DOI: 10.18653/v1/2025.emnlp-main.42
\\ ( https://arxiv.org/abs/2508.15250 ,  383kb)
------------------------------------------------------------------------------
\\
arXiv:2508.20325
replaced with revised version Fri, 7 Nov 2025 20:24:13 GMT   (4387kb)

Title: GUARD: Guideline Upholding Test through Adaptive Role-play and Jailbreak
 Diagnostics for LLMs
Authors: Haibo Jin, Ruoxi Chen, Peiyan Zhang, Andy Zhou, Haohan Wang
Categories: cs.CL cs.AI cs.CV
Comments: 54 pages
\\ ( https://arxiv.org/abs/2508.20325 ,  4387kb)
------------------------------------------------------------------------------
\\
arXiv:2508.20916
replaced with revised version Mon, 10 Nov 2025 07:45:48 GMT   (924kb)

Title: SageLM: A Multi-aspect and Explainable Large Language Model for Speech
 Judgement
Authors: Yuan Ge, Junxiang Zhang, Xiaoqian Liu, Bei Li, Xiangnan Ma, Chenglong
 Wang, Kaiyang Ye, Yangfan Du, Linfeng Zhang, Yuxin Huang, Tong Xiao, Zhengtao
 Yu, JingBo Zhu
Categories: cs.CL
\\ ( https://arxiv.org/abs/2508.20916 ,  924kb)
------------------------------------------------------------------------------
\\
arXiv:2508.21382
replaced with revised version Sat, 8 Nov 2025 09:17:07 GMT   (1344kb)

Title: Normality and the Turing Test
Authors: Alexandre Kabbach
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2508.21382 ,  1344kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13624
replaced with revised version Sat, 8 Nov 2025 23:21:05 GMT   (26844kb)

Title: Latent Traits and Cross-Task Transfer: Deconstructing Dataset
 Interactions in LLM Fine-tuning
Authors: Shambhavi Krishna, Atharva Naik, Chaitali Agarwal, Sudharshan
 Govindan, Taesung Lee, Haw-Shiuan Chang
Categories: cs.CL cs.LG
Comments: Proceedings of the 14th Joint Conference on Lexical and Computational
 Semantics (*SEM 2025)
\\ ( https://arxiv.org/abs/2509.13624 ,  26844kb)
------------------------------------------------------------------------------
\\
arXiv:2509.17377
replaced with revised version Sun, 9 Nov 2025 12:20:26 GMT   (221kb)

Title: Robustness of Neurosymbolic Reasoners on First-Order Logic Problems
Authors: Hannah Bansal, Kemal Kurniawan and Lea Frermann
Categories: cs.CL
Comments: Accepted to ALA Conference
\\ ( https://arxiv.org/abs/2509.17377 ,  221kb)
------------------------------------------------------------------------------
\\
arXiv:2509.22812
replaced with revised version Mon, 10 Nov 2025 01:42:57 GMT   (623kb)

Title: EditGRPO: Reinforcement Learning with Post-Rollout Edits for Clinically
 Accurate Chest X-Ray Report Generation
Authors: Kai Zhang, Christopher Malon, Lichao Sun, Martin Renqiang Min
Categories: cs.CL
Comments: AACL 2025
\\ ( https://arxiv.org/abs/2509.22812 ,  623kb)
------------------------------------------------------------------------------
\\
arXiv:2510.10114
replaced with revised version Sun, 9 Nov 2025 11:23:09 GMT   (800kb)

Title: LinearRAG: Linear Graph Retrieval Augmented Generation on Large-scale
 Corpora
Authors: Luyao Zhuang, Shengyuan Chen, Yilin Xiao, Huachi Zhou, Yujing Zhang,
 Hao Chen, Qinggang Zhang, Xiao Huang
Categories: cs.CL
\\ ( https://arxiv.org/abs/2510.10114 ,  800kb)
------------------------------------------------------------------------------
\\
arXiv:2510.11196
replaced with revised version Sun, 9 Nov 2025 10:56:57 GMT   (4459kb)

Title: Evaluating Reasoning Faithfulness in Medical Vision-Language Models
 using Multimodal Perturbations
Authors: Johannes Moll, Markus Graf, Tristan Lemke, Nicolas Lenhart, Daniel
 Truhn, Jean-Benoit Delbrouck, Jiazhen Pan, Daniel Rueckert, Lisa C. Adams,
 Keno K. Bressem
Categories: cs.CL cs.CV
Comments: Accepted to ML4H 2025 Proceedings
\\ ( https://arxiv.org/abs/2510.11196 ,  4459kb)
------------------------------------------------------------------------------
\\
arXiv:2510.13003
replaced with revised version Sat, 8 Nov 2025 10:43:01 GMT   (213kb)

Title: OPLoRA: Orthogonal Projection LoRA Prevents Catastrophic Forgetting
 during Parameter-Efficient Fine-Tuning
Authors: Yifeng Xiong, Xiaohui Xie
Categories: cs.CL
\\ ( https://arxiv.org/abs/2510.13003 ,  213kb)
------------------------------------------------------------------------------
\\
arXiv:2510.13797
replaced with revised version Mon, 10 Nov 2025 00:06:46 GMT   (488kb)

Title: Breadcrumbs Reasoning: Memory-Efficient Reasoning with Compression
 Beacons
Authors: Giovanni Monea, Yair Feldman, Shankar Padmanabhan, Kiant\'e Brantley,
 Yoav Artzi
Categories: cs.CL
\\ ( https://arxiv.org/abs/2510.13797 ,  488kb)
------------------------------------------------------------------------------
\\
arXiv:2510.13839
replaced with revised version Sun, 9 Nov 2025 22:44:44 GMT   (212kb)

Title: Meronymic Ontology Extraction via Large Language Models
Authors: Dekai Zhang, Simone Conia and Antonio Rago
Categories: cs.CL cs.AI
Comments: Accepted to AACL 2025
\\ ( https://arxiv.org/abs/2510.13839 ,  212kb)
------------------------------------------------------------------------------
\\
arXiv:2510.13847
replaced with revised version Mon, 10 Nov 2025 12:41:15 GMT   (154kb)

Title: DynaSpec: Context-aware Dynamic Speculative Sampling for
 Large-Vocabulary Language Models
Authors: Jinbin Zhang, Nasib Ullah, Erik Schultheis, Rohit Babbar
Categories: cs.CL cs.AI cs.LG
\\ ( https://arxiv.org/abs/2510.13847 ,  154kb)
------------------------------------------------------------------------------
\\
arXiv:2510.17013
replaced with revised version Sat, 8 Nov 2025 04:34:52 GMT   (1806kb)

Title: DiscoTrack: A Multilingual LLM Benchmark for Discourse Tracking
Authors: Lanni Bu, Lauren Levine, Amir Zeldes
Categories: cs.CL
\\ ( https://arxiv.org/abs/2510.17013 ,  1806kb)
------------------------------------------------------------------------------
\\
arXiv:2510.18480
replaced with revised version Mon, 10 Nov 2025 13:10:25 GMT   (110kb)

Title: How Efficient Are Diffusion Language Models? A Critical Examination of
 Efficiency Evaluation Practices
Authors: Han Peng, Peiyu Liu, Zican Dong, Daixuan Cheng, Junyi Li, Yiru Tang,
 Shuo Wang, Wayne Xin Zhao
Categories: cs.CL
\\ ( https://arxiv.org/abs/2510.18480 ,  110kb)
------------------------------------------------------------------------------
\\
arXiv:2510.19670
replaced with revised version Mon, 10 Nov 2025 14:37:47 GMT   (1441kb)

Title: CoSense-LLM: Semantics at the Edge with Cost- and Uncertainty-Aware
 Cloud-Edge Cooperation
Authors: Hasan Akgul, Mari Eplik, Javier Rojas, Aina Binti Abdullah, and Pieter
 van der Merwe
Categories: cs.CL
Comments: 19 pages,8 figures
ACM-class: I.2.6; C.2.4; C.3
\\ ( https://arxiv.org/abs/2510.19670 ,  1441kb)
------------------------------------------------------------------------------
\\
arXiv:2510.26512
replaced with revised version Sat, 8 Nov 2025 21:37:40 GMT   (5756kb)

Title: Inside CORE-KG: Evaluating Structured Prompting and Coreference
 Resolution for Knowledge Graphs
Authors: Dipak Meher, Carlotta Domeniconi
Categories: cs.CL cs.AI cs.IR cs.LG
Comments: ICDM 2025
\\ ( https://arxiv.org/abs/2510.26512 ,  5756kb)
------------------------------------------------------------------------------
\\
arXiv:2511.02376
replaced with revised version Sun, 9 Nov 2025 05:14:14 GMT   (23kb)

Title: AutoAdv: Automated Adversarial Prompting for Multi-Turn Jailbreaking of
 Large Language Models
Authors: Aashray Reddy, Andrew Zagula, Nicholas Saban, Kevin Zhu
Categories: cs.CL cs.AI cs.CR cs.LG
Comments: Accepted to NeurIPS 2025 Lock-LLM Workshop. Code is available at
 https://github.com/AAN-AutoAdv/AutoAdv
\\ ( https://arxiv.org/abs/2511.02376 ,  23kb)
------------------------------------------------------------------------------
\\
arXiv:2511.03506
replaced with revised version Sun, 9 Nov 2025 14:39:33 GMT   (775kb)

Title: HaluMem: Evaluating Hallucinations in Memory Systems of Agents
Authors: Ding Chen, Simin Niu, Kehang Li, Peng Liu, Xiangping Zheng, Bo Tang,
 Xinchi Li, Feiyu Xiong, Zhiyu Li
Categories: cs.CL
\\ ( https://arxiv.org/abs/2511.03506 ,  775kb)
------------------------------------------------------------------------------
\\
arXiv:2511.03772
replaced with revised version Sat, 8 Nov 2025 09:38:55 GMT   (35kb)

Title: GRDD+: An Extended Greek Dialectal Dataset with Cross-Architecture
 Fine-tuning Evaluation
Authors: Stergios Chatzikyriakidis, Dimitris Papadakis, Sevasti-Ioanna
 Papaioannou and Erofili Psaltaki
Categories: cs.CL
\\ ( https://arxiv.org/abs/2511.03772 ,  35kb)
------------------------------------------------------------------------------
\\
arXiv:2511.04698
replaced with revised version Mon, 10 Nov 2025 03:54:07 GMT   (1153kb)

Title: multiMentalRoBERTa: A Fine-tuned Multiclass Classifier for Mental Health
 Disorder
Authors: K M Sajjadul Islam, John Fields, Praveen Madiraju
Categories: cs.CL cs.AI
Comments: Accepted in IEEE Big Data, 8-11 December, 2025 @ Macau SAR, China
\\ ( https://arxiv.org/abs/2511.04698 ,  1153kb)
------------------------------------------------------------------------------
\\
arXiv:2511.04875
replaced with revised version Mon, 10 Nov 2025 01:27:05 GMT   (15kb)

Title: Minimal and Mechanistic Conditions for Behavioral Self-Awareness in LLMs
Authors: Matthew Bozoukov, Matthew Nguyen, Shubkarman Singh, Bart Bussmann,
 Patrick Leask
Categories: cs.CL cs.AI cs.LG
\\ ( https://arxiv.org/abs/2511.04875 ,  15kb)
------------------------------------------------------------------------------
\\
arXiv:2511.04910
replaced with revised version Mon, 10 Nov 2025 04:20:56 GMT   (5625kb)

Title: SDS KoPub VDR: A Benchmark Dataset for Visual Document Retrieval in
 Korean Public Documents
Authors: Jaehoon Lee, Sohyun Kim, Wanggeun Park, Geon Lee, Seungkyung Kim,
 Minyoung Lee
Categories: cs.CL
Comments: 27 pages, 15 figures, 6 tables
\\ ( https://arxiv.org/abs/2511.04910 ,  5625kb)
------------------------------------------------------------------------------
\\
arXiv:2310.04912
replaced with revised version Sat, 8 Nov 2025 14:37:42 GMT   (2051kb)

Title: Intelligent Sampling Consensus for Homography Estimation in Football
 Videos Using Featureless Unpaired Points
Authors: George Nousias, Konstantinos Delibasis, Ilias Maglogiannis
Categories: cs.CV
Journal-ref: G. Nousias, K. K. Delibasis and I. G. Maglogiannis, "Intelligent
 Sampling Consensus for Homography Estimation in Football Videos Using
 Featureless Unpaired Points," IEEE Access, vol. 13, pp. 187843-187857, 2025
DOI: 10.1109/ACCESS.2025.3627538
\\ ( https://arxiv.org/abs/2310.04912 ,  2051kb)
------------------------------------------------------------------------------
\\
arXiv:2403.10413
replaced with revised version Mon, 10 Nov 2025 18:15:19 GMT   (2711kb)

Title: HyCTAS: Multi-Objective Hybrid Convolution-Transformer Architecture
 Search for Real-Time Image Segmentation
Authors: Hongyuan Yu, Cheng Wan, Xiyang Dai, Mengchen Liu, Dongdong Chen, Bin
 Xiao, Yan Huang, Yuan Lu, and Liang Wang
Categories: cs.CV
Comments: 24 pages, 5 figures, published at Neurocomputing
DOI: 10.1016/j.neucom.2025.131909
\\ ( https://arxiv.org/abs/2403.10413 ,  2711kb)
------------------------------------------------------------------------------
\\
arXiv:2405.18004
replaced with revised version Sun, 9 Nov 2025 07:10:53 GMT   (8045kb)

Title: SkinCaRe: A Multimodal Dermatology Dataset Annotated with Medical
 Caption and Chain-of-Thought Reasoning
Authors: Yuhao Shen, Liyuan Sun, Yan Xu, Wenbin Liu, Shuping Zhang, Shawn
 Afvari, Zhongyi Han, Jiaoyan Song, Yongzhi Ji, Tao Lu, Xiaonan He, Xin Gao,
 Juexiao Zhou
Categories: cs.CV
\\ ( https://arxiv.org/abs/2405.18004 ,  8045kb)
------------------------------------------------------------------------------
\\
arXiv:2406.12179
replaced with revised version Sat, 8 Nov 2025 20:02:15 GMT   (23663kb)

Title: The Wisdom of a Crowd of Brains: A Universal Brain Encoder
Authors: Roman Beliy, Navve Wasserman, Amit Zalcher, Michal Irani
Categories: cs.CV
\\ ( https://arxiv.org/abs/2406.12179 ,  23663kb)
------------------------------------------------------------------------------
\\
arXiv:2406.19875
replaced with revised version Sat, 8 Nov 2025 15:35:30 GMT   (4364kb)

Title: InfiniBench: A Benchmark for Large Multi-Modal Models in Long-Form
 Movies and TV Shows
Authors: Kirolos Ataallah, Eslam Abdelrahman, Mahmoud Ahmed, Chenhui Gou,
 Khushbu Pahwa, Jian Ding, Mohamed Elhoseiny
Categories: cs.CV
Comments: Accepted for oral presentation at the EMNLP 2025 main conference
\\ ( https://arxiv.org/abs/2406.19875 ,  4364kb)
------------------------------------------------------------------------------
\\
arXiv:2407.04203
replaced with revised version Mon, 10 Nov 2025 08:23:25 GMT   (8257kb)

Title: DeNAS-ViT: Data Efficient NAS-Optimized Vision Transformer for
 Ultrasound Image Segmentation
Authors: Renqi Chen, Xinzhe Zheng, Haoyang Su, Kehan Wu
Categories: cs.CV
Comments: Accepted by AAAI-26 Main Technical Track
\\ ( https://arxiv.org/abs/2407.04203 ,  8257kb)
------------------------------------------------------------------------------
\\
arXiv:2407.04326
replaced with revised version Sat, 8 Nov 2025 19:42:06 GMT   (34217kb)

Title: LMSeg: An end-to-end geometric message-passing network on barycentric
 dual graphs for large-scale landscape mesh segmentation
Authors: Zexian Huang, Kourosh Khoshelham, Martin Tomko
Categories: cs.CV
\\ ( https://arxiv.org/abs/2407.04326 ,  34217kb)
------------------------------------------------------------------------------
\\
arXiv:2407.10935
replaced with revised version Sun, 9 Nov 2025 17:15:02 GMT   (3160kb)

Title: STARS: Self-supervised Tuning for 3D Action Recognition in Skeleton
 Sequences
Authors: Soroush Mehraban, Mohammad Javad Rajabi, Andrea Iaboni, Babak Taati
Categories: cs.CV
\\ ( https://arxiv.org/abs/2407.10935 ,  3160kb)
------------------------------------------------------------------------------
\\
arXiv:2409.07843
replaced with revised version Sun, 9 Nov 2025 17:06:55 GMT   (10661kb)

Title: Real-time Multi-view Omnidirectional Depth Estimation for Real Scenarios
 based on Teacher-Student Learning with Unlabeled Data
Authors: Ming Li, Xiong Yang, Chaofan Wu, Jiaheng Li, Pinzhi Wang, Xuejiao Hu,
 Sidan Du and Yang Li
Categories: cs.CV cs.RO
\\ ( https://arxiv.org/abs/2409.07843 ,  10661kb)
------------------------------------------------------------------------------
\\
arXiv:2409.08782
replaced with revised version Mon, 10 Nov 2025 05:02:46 GMT   (5131kb)

Title: Improving Contactless Fingerprint Recognition with Robust 3D Feature
 Extraction and Graph Embedding
Authors: Yuwei Jia, Siyang Zheng, Fei Feng, Zhe Cui, Fei Su
Categories: cs.CV
Comments: Oral presentation accepted at the 2025 IEEE International Joint
 Conference on Biometrics (IJCB) 2025, Osaka, Japan (9/8-9/11/2025)
\\ ( https://arxiv.org/abs/2409.08782 ,  5131kb)
------------------------------------------------------------------------------
\\
arXiv:2410.01539
replaced with revised version Sun, 9 Nov 2025 11:37:11 GMT   (1927kb)

Title: Multi-Scale Fusion for Object Representation
Authors: Rongzhen Zhao, Vivienne Wang, Juho Kannala, Joni Pajarinen
Categories: cs.CV
Comments: Accepted to ICLR 2025
\\ ( https://arxiv.org/abs/2410.01539 ,  1927kb)
------------------------------------------------------------------------------
\\
arXiv:2410.05664
replaced with revised version Mon, 10 Nov 2025 07:29:24 GMT   (4381kb)

Title: Holistic Unlearning Benchmark: A Multi-Faceted Evaluation for
 Text-to-Image Diffusion Model Unlearning
Authors: Saemi Moon, Minjong Lee, Sangdon Park, Dongwoo Kim
Categories: cs.CV cs.LG
Comments: ICCV 2025
\\ ( https://arxiv.org/abs/2410.05664 ,  4381kb)
------------------------------------------------------------------------------
\\
arXiv:2411.00078
replaced with revised version Sun, 9 Nov 2025 03:27:10 GMT   (10942kb)

Title: Evaluating Cell AI Foundation Models in Kidney Pathology with
 Human-in-the-Loop Enrichment
Authors: Junlin Guo, Siqi Lu, Can Cui, Ruining Deng, Tianyuan Yao, Zhewen Tao,
 Yizhe Lin, Marilyn Lionts, Quan Liu, Juming Xiong, Yu Wang, Shilin Zhao,
 Catie Chang, Mitchell Wilkes, Mengmeng Yin, Haichun Yang, Yuankai Huo
Categories: cs.CV cs.AI eess.IV
\\ ( https://arxiv.org/abs/2411.00078 ,  10942kb)
------------------------------------------------------------------------------
\\
arXiv:2411.02299
replaced with revised version Sun, 9 Nov 2025 11:35:44 GMT   (8097kb)

Title: Grouped Discrete Representation for Object-Centric Learning
Authors: Rongzhen Zhao, Vivienne Wang, Juho Kannala, Joni Pajarinen
Categories: cs.CV cs.LG
Comments: Accepted to ECML-PKDD 2025
\\ ( https://arxiv.org/abs/2411.02299 ,  8097kb)
------------------------------------------------------------------------------
\\
arXiv:2411.05007
replaced with revised version Sat, 8 Nov 2025 06:29:02 GMT   (35902kb)

Title: SVDQuant: Absorbing Outliers by Low-Rank Components for 4-Bit Diffusion
 Models
Authors: Muyang Li, Yujun Lin, Zhekai Zhang, Tianle Cai, Xiuyu Li, Junxian Guo,
 Enze Xie, Chenlin Meng, Jun-Yan Zhu and Song Han
Categories: cs.CV cs.LG
Comments: ICLR 2025 Spotlight Quantization Library:
 https://github.com/mit-han-lab/deepcompressor Inference Engine:
 https://github.com/mit-han-lab/nunchaku Website:
 https://hanlab.mit.edu/projects/svdquant Demo: https://demo.nunchaku.tech/
 Blog: https://hanlab.mit.edu/blog/svdquant
\\ ( https://arxiv.org/abs/2411.05007 ,  35902kb)
------------------------------------------------------------------------------
\\
arXiv:2411.18267
replaced with revised version Sun, 9 Nov 2025 10:22:38 GMT   (2287kb)

Title: Incomplete Multi-view Multi-label Classification via a Dual-level
 Contrastive Learning Framework
Authors: Bingyan Nie, Wulin Xie, Jiang Long, Xiaohuan Lu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2411.18267 ,  2287kb)
------------------------------------------------------------------------------
\\
arXiv:2412.02261
replaced with revised version Mon, 10 Nov 2025 14:11:29 GMT   (22367kb)

Title: Diffusion Implicit Policy for Unpaired Scene-aware Motion Synthesis
Authors: Jingyu Gong, Chong Zhang, Fengqi Liu, Ke Fan, Qianyu Zhou, Xin Tan,
 Zhizhong Zhang, Yuan Xie
Categories: cs.CV
\\ ( https://arxiv.org/abs/2412.02261 ,  22367kb)
------------------------------------------------------------------------------
\\
arXiv:2412.09199
replaced with revised version Sat, 8 Nov 2025 09:20:20 GMT   (3514kb)

Title: MutualVPR: A Mutual Learning Framework for Resolving Supervision
 Inconsistencies via Adaptive Clustering
Authors: Qiwen Gu, Xufei Wang, Junqiao Zhao, Siyue Tao, Tiantian Feng, Ziqiao
 Wang, Guang Chen
Categories: cs.CV
Comments: 15 pages, 39th Conference on Neural Information Processing Systems
 (NeurIPS 2025)
\\ ( https://arxiv.org/abs/2412.09199 ,  3514kb)
------------------------------------------------------------------------------
\\
arXiv:2412.10566
replaced with revised version Sat, 8 Nov 2025 02:56:36 GMT   (3015kb)

Title: EVLM: Self-Reflective Multimodal Reasoning for Cross-Dimensional Visual
 Editing
Authors: Umar Khalid, Kashif Munir, Hasan Iqbal, Azib Farooq, Jing Hua, Nazanin
 Rahnavard, Chen Chen, Victor Zhu, Zhengping Ji
Categories: cs.CV
Comments: Technical Report
\\ ( https://arxiv.org/abs/2412.10566 ,  3015kb)
------------------------------------------------------------------------------
\\
arXiv:2412.18933
replaced with revised version Mon, 10 Nov 2025 03:04:01 GMT   (40860kb)

Title: Temporal Inconsistency Guidance for Super-resolution Video Quality
 Assessment
Authors: Yixiao Li, Xiaoyuan Yang, Weide Liu, Xin Jin, Xu Jia, Yukun Lai, Paul
 L Rosin, Haotao Liu, and Wei Zhou
Categories: cs.CV cs.MM eess.IV
Comments: 15 pages, 10 figures, AAAI CONFERENCE ON ARTIFICIAL
 INTELLIGENCE(AAAI-26)
\\ ( https://arxiv.org/abs/2412.18933 ,  40860kb)
------------------------------------------------------------------------------
\\
arXiv:2412.20206
replaced with revised version Mon, 10 Nov 2025 05:20:13 GMT   (3827kb)

Title: Towards Visual Grounding: A Survey
Authors: Linhui Xiao, Xiaoshan Yang, Xiangyuan Lan, Yaowei Wang, Changsheng Xu
Categories: cs.CV
Comments: Accepted by TPAMI 2025.We keep tracing related works at
 https://github.com/linhuixiao/Awesome-Visual-Grounding
DOI: 10.1109/TPAMI.2025.3630635
\\ ( https://arxiv.org/abs/2412.20206 ,  3827kb)
------------------------------------------------------------------------------
\\
arXiv:2412.20665
replaced with revised version Mon, 10 Nov 2025 06:57:08 GMT   (1727kb)

Title: SM3Det: A Unified Model for Multi-Modal Remote Sensing Object Detection
Authors: Yuxuan Li, Xiang Li, Yunheng Li, Yicheng Zhang, Yimian Dai, Qibin Hou,
 Ming-Ming Cheng, Jian Yang
Categories: cs.CV cs.MM
Comments: Accepted as Oral in AAAI 2026
\\ ( https://arxiv.org/abs/2412.20665 ,  1727kb)
------------------------------------------------------------------------------
\\
arXiv:2501.10040
replaced with revised version Sun, 9 Nov 2025 15:44:23 GMT   (5389kb)

Title: LWGANet: Addressing Spatial and Channel Redundancy in Remote Sensing
 Visual Tasks with Light-Weight Grouped Attention
Authors: Wei Lu, Xue Yang, and Si-Bao Chen
Categories: cs.CV
Comments: Accepted by AAAI 2026 (Oral)
\\ ( https://arxiv.org/abs/2501.10040 ,  5389kb)
------------------------------------------------------------------------------
\\
arXiv:2501.18232
replaced with revised version Mon, 10 Nov 2025 09:54:26 GMT   (4255kb)

Title: Free-T2M: Robust Text-to-Motion Generation for Humanoid Robots via
 Frequency-Domain
Authors: Wenshuo Chen, Haozhe Jia, Songning Lai, Lei Wang, Yuqi Lin, Hongru
 Xiao, Lijie Hu, Yutao Yue
Categories: cs.CV
\\ ( https://arxiv.org/abs/2501.18232 ,  4255kb)
------------------------------------------------------------------------------
\\
arXiv:2501.18877
replaced with revised version Mon, 10 Nov 2025 15:18:58 GMT   (11324kb)

Title: Mitigating Sexual Content Generation via Embedding Distortion in
 Text-conditioned Diffusion Models
Authors: Jaesin Ahn, Heechul Jung
Categories: cs.CV cs.CR cs.LG
Comments: NeurIPS 2025 accepted. Official code: https://github.com/amoeba04/des
\\ ( https://arxiv.org/abs/2501.18877 ,  11324kb)
------------------------------------------------------------------------------
\\
arXiv:2502.00801
replaced with revised version Sun, 9 Nov 2025 15:10:08 GMT   (6576kb)

Title: Environment-Driven Online LiDAR-Camera Extrinsic Calibration
Authors: Zhiwei Huang, Jiaqi Li, Hongbo Zhao, Xiao Ma, Ping Zhong, Xiaohu Zhou,
 Wei Ye, Rui Fan
Categories: cs.CV cs.AI cs.RO
\\ ( https://arxiv.org/abs/2502.00801 ,  6576kb)
------------------------------------------------------------------------------
\\
arXiv:2502.05606
replaced with revised version Sun, 9 Nov 2025 11:33:47 GMT   (18224kb)

Title: FreeBlend: Advancing Concept Blending with Staged Feedback-Driven
 Interpolation Diffusion
Authors: Yufan Zhou, Haoyu Shen, Huan Wang
Categories: cs.CV
Comments: Webpage: https://petershen-csworld.github.io/FreeBlend
\\ ( https://arxiv.org/abs/2502.05606 ,  18224kb)
------------------------------------------------------------------------------
\\
arXiv:2502.07278
replaced with revised version Sun, 9 Nov 2025 20:06:13 GMT   (37116kb)

Title: Articulate That Object Part (ATOP): 3D Part Articulation via Text and
 Motion Personalization
Authors: Aditya Vora, Sauradip Nag, Kai Wang, Hao Zhang
Categories: cs.CV
Comments: Technical Report, 16 pages
\\ ( https://arxiv.org/abs/2502.07278 ,  37116kb)
------------------------------------------------------------------------------
\\
arXiv:2502.14520
replaced with revised version Mon, 10 Nov 2025 07:08:02 GMT   (6627kb)

Title: Learning Temporal 3D Semantic Scene Completion via Optical Flow Guidance
Authors: Meng Wang, Fan Wu, Ruihui Li, Yunchuan Qin, Zhuo Tang and Kenli Li
Categories: cs.CV
Comments: Accepted by NeurIPS 2025
\\ ( https://arxiv.org/abs/2502.14520 ,  6627kb)
------------------------------------------------------------------------------
\\
arXiv:2503.10037
replaced with revised version Fri, 7 Nov 2025 19:05:06 GMT   (29840kb)

Title: Role Bias in Diffusion Models: Diagnosing and Mitigating through
 Intermediate Decomposition
Authors: Sina Malakouti and Adriana Kovashka
Categories: cs.CV
\\ ( https://arxiv.org/abs/2503.10037 ,  29840kb)
------------------------------------------------------------------------------
\\
arXiv:2503.15106
replaced with revised version Mon, 10 Nov 2025 13:42:43 GMT   (22578kb)

Title: Distilling 3D distinctive local descriptors for 6D pose estimation
Authors: Amir Hamza, Andrea Caraffa, Davide Boscaini, Fabio Poiesi
Categories: cs.CV
Comments: Project Website: https://tev-fbk.github.io/dGeDi/
Journal-ref: 2025 IEEE/RSJ International Conference on Intelligent Robots and
 Systems (IROS)
\\ ( https://arxiv.org/abs/2503.15106 ,  22578kb)
------------------------------------------------------------------------------
\\
arXiv:2503.16855
replaced with revised version Sun, 9 Nov 2025 04:14:51 GMT   (518kb)

Title: Stack Transformer Based Spatial-Temporal Attention Model for Dynamic
 Sign Language and Fingerspelling Recognition
Authors: Koki Hirooka, Abu Saleh Musa Miah, Tatsuya Murakami, Md. Al Mehedi
 Hasan, Yong Seok Hwang, Jungpil Shin
Categories: cs.CV
Comments: 15 pages, 12 figures. Submitted to IEEE Access (under review)
\\ ( https://arxiv.org/abs/2503.16855 ,  518kb)
------------------------------------------------------------------------------
\\
arXiv:2503.18135
replaced with revised version Sat, 8 Nov 2025 16:02:38 GMT   (14557kb)

Title: MLLM-For3D: Adapting Multimodal Large Language Model for 3D Reasoning
 Segmentation
Authors: Jiaxin Huang, Runnan Chen, Ziwen Li, Zhengqing Gao, Xiao He, Yandong
 Guo, Mingming Gong, Tongliang Liu
Categories: cs.CV
Comments: 10 pages, 3 figures
\\ ( https://arxiv.org/abs/2503.18135 ,  14557kb)
------------------------------------------------------------------------------
\\
arXiv:2503.19404
replaced with revised version Mon, 10 Nov 2025 16:02:33 GMT   (2339kb)

Title: LangBridge: Interpreting Image as a Combination of Language Embeddings
Authors: Jiaqi Liao, Yuwei Niu, Fanqing Meng, Hao Li, Changyao Tian, Yinuo Du,
 Yuwen Xiong, Dianqi Li, Xizhou Zhu, Li Yuan, Jifeng Dai, Yu Cheng
Categories: cs.CV
Comments: The code and weights are open-sourced. Project page:
 https://curryx-001.github.io/LangBridge.github.io/
\\ ( https://arxiv.org/abs/2503.19404 ,  2339kb)
------------------------------------------------------------------------------
\\
arXiv:2504.08915
replaced with revised version Sun, 9 Nov 2025 01:32:03 GMT   (5493kb)

Title: Parameter-Free Fine-tuning via Redundancy Elimination for Vision
 Foundation Models
Authors: Jiahuan Long, Tingsong Jiang, Wen Yao, Yizhe Xiong, Zhengqin Xu, Shuai
 Jia, Hanqing Liu, Chao Ma
Categories: cs.CV cs.AI
Comments: Accepted by AAAI 2026
\\ ( https://arxiv.org/abs/2504.08915 ,  5493kb)
------------------------------------------------------------------------------
\\
arXiv:2504.10117
replaced with revised version Mon, 10 Nov 2025 14:14:04 GMT   (11425kb)

Title: AGO: Adaptive Grounding for Open World 3D Occupancy Prediction
Authors: Peizheng Li, Shuxiao Ding, You Zhou, Qingwen Zhang, Onat Inak, Larissa
 Triess, Niklas Hanselmann, Marius Cordts, Andreas Zell
Categories: cs.CV
\\ ( https://arxiv.org/abs/2504.10117 ,  11425kb)
------------------------------------------------------------------------------
\\
arXiv:2504.10514
replaced with revised version Sat, 8 Nov 2025 22:27:42 GMT   (43447kb)

Title: ColorBench: Can VLMs See and Understand the Colorful World? A
 Comprehensive Benchmark for Color Perception, Reasoning, and Robustness
Authors: Yijun Liang, Ming Li, Chenrui Fan, Ziyue Li, Dang Nguyen, Kwesi
 Cobbina, Shweta Bhardwaj, Jiuhai Chen, Fuxiao Liu, Tianyi Zhou
Categories: cs.CV cs.AI cs.CL cs.LG
Comments: Accepted by NeurIPS2025. 36 pages, including references and appendix.
 Code is available at https://github.com/tianyi-lab/ColorBench
\\ ( https://arxiv.org/abs/2504.10514 ,  43447kb)
------------------------------------------------------------------------------
\\
arXiv:2504.18800
replaced with revised version Sat, 8 Nov 2025 07:58:54 GMT   (1821kb)

Title: Video CLIP Model for Multi-View Echocardiography Interpretation
Authors: Ryo Takizawa, Satoshi Kodera, Tempei Kabayama, Ryo Matsuoka, Yuta
 Ando, Yuto Nakamura, Haruki Settai, Norihiko Takeda
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2504.18800 ,  1821kb)
------------------------------------------------------------------------------
\\
arXiv:2504.19637
replaced with revised version Mon, 10 Nov 2025 11:12:42 GMT   (0kb,I)

Title: Enhanced Partially Relevant Video Retrieval through Inter- and
 Intra-Sample Analysis with Coherence Prediction
Authors: Junlong Ren, Gangjian Zhang, Hao Wang, Yu Hu, Jian Shu, Hui Xiong
Categories: cs.CV
Comments: Upon further consideration, we have concluded that the current
 version requires revision and may not yet be ready for publication. We plan
 to conduct additional experiments and make necessary improvements to ensure
 the paper meets the standards for future submission
\\ ( https://arxiv.org/abs/2504.19637 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2504.20303
replaced with revised version Sun, 9 Nov 2025 02:43:29 GMT   (30344kb)

Title: DeepAndes: A Self-Supervised Vision Foundation Model for Multi-Spectral
 Remote Sensing Imagery of the Andes
Authors: Junlin Guo, James R. Zimmer-Dauphinee, Jordan M. Nieusma, Siqi Lu,
 Quan Liu, Ruining Deng, Can Cui, Jialin Yue, Yizhe Lin, Tianyuan Yao, Juming
 Xiong, Junchao Zhu, Chongyu Qu, Yuechen Yang, Mitchell Wilkes, Xiao Wang,
 Parker VanValkenburgh, Steven A. Wernke, and Yuankai Huo
Categories: cs.CV
Journal-ref: 10.1109/JSTARS.2025.3619423
\\ ( https://arxiv.org/abs/2504.20303 ,  30344kb)
------------------------------------------------------------------------------
\\
arXiv:2505.01322
replaced with revised version Sat, 8 Nov 2025 09:52:22 GMT   (10099kb)

Title: FreeInsert: Disentangled Text-Guided Object Insertion in 3D Gaussian
 Scene without Spatial Priors
Authors: Chenxi Li, Weijie Wang, Qiang Li, Bruno Lepri, Nicu Sebe, Weizhi Nie
Categories: cs.CV
Comments: Accepted by ACMMM2025, Our project webpage:
 https://tjulcx.github.io/FreeInsert/
\\ ( https://arxiv.org/abs/2505.01322 ,  10099kb)
------------------------------------------------------------------------------
\\
arXiv:2505.09997
replaced with revised version Mon, 10 Nov 2025 05:05:30 GMT   (0kb,I)

Title: Descriptive Image-Text Matching with Graded Contextual Similarity
Authors: Jinhyun Jang, Jiyoung Lee, Kwanghoon Sohn
Categories: cs.CV
Comments: This version is incomplete and requires substantial revisions and
 extensions. We withdraw the paper and plan to submit a thoroughly revised
 version as a new submission
\\ ( https://arxiv.org/abs/2505.09997 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2505.11454
replaced with revised version Sun, 9 Nov 2025 23:48:51 GMT   (6249kb)

Title: HumaniBench: A Human-Centric Framework for Large Multimodal Models
 Evaluation
Authors: Shaina Raza, Aravind Narayanan, Vahid Reza Khazaie, Ashmal Vayani,
 Mukund S. Chettiar, Amandeep Singh, Mubarak Shah, Deval Pandya
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2505.11454 ,  6249kb)
------------------------------------------------------------------------------
\\
arXiv:2505.11468
replaced with revised version Sat, 8 Nov 2025 20:54:08 GMT   (9228kb)

Title: PSDiffusion: Harmonized Multi-Layer Image Generation via Layout and
 Appearance Alignment
Authors: Dingbang Huang, Wenbo Li, Yifei Zhao, Xinyu Pan, Chun Wang, Yanhong
 Zeng, Bo Dai
Categories: cs.CV
\\ ( https://arxiv.org/abs/2505.11468 ,  9228kb)
------------------------------------------------------------------------------
\\
arXiv:2505.12310
replaced with revised version Sat, 8 Nov 2025 07:54:35 GMT   (1339kb)

Title: DNOI-4DRO: Deep 4D Radar Odometry with Differentiable
 Neural-Optimization Iterations
Authors: Shouyi Lu, Huanyu Zhou, Guirong Zhuo, Xiao Tang
Categories: cs.CV cs.AI cs.RO
Comments: 9 pages,5 figures
\\ ( https://arxiv.org/abs/2505.12310 ,  1339kb)
------------------------------------------------------------------------------
\\
arXiv:2505.18584
replaced with revised version Sun, 9 Nov 2025 06:44:40 GMT   (24097kb)

Title: Unleashing Diffusion Transformers for Visual Correspondence by
 Modulating Massive Activations
Authors: Chaofan Gan, Yuanpeng Tu, Xi Chen, Tieyuan Chen, Yuxi Li, Mehrtash
 Harandi, Weiyao Lin
Categories: cs.CV
Comments: NeurIPS 2025, code: https://github.com/ganchaofan0000/DiTF
\\ ( https://arxiv.org/abs/2505.18584 ,  24097kb)
------------------------------------------------------------------------------
\\
arXiv:2505.19291
replaced with revised version Sun, 9 Nov 2025 15:49:22 GMT   (1103kb)

Title: TextDiffuser-RL: Efficient and Robust Text Layout Optimization for
 High-Fidelity Text-to-Image Synthesis
Authors: Kazi Mahathir Rahman, Showrin Rahman, Sharmin Sultana Srishty
Categories: cs.CV cs.AI
Comments: 19 pages, 36 figures
\\ ( https://arxiv.org/abs/2505.19291 ,  1103kb)
------------------------------------------------------------------------------
\\
arXiv:2505.20617
replaced with revised version Mon, 10 Nov 2025 08:52:12 GMT   (7507kb)

Title: OccLE: Label-Efficient 3D Semantic Occupancy Prediction
Authors: Naiyu Fang, Zheyuan Zhou, Fayao Liu, Xulei Yang, Jiacheng Wei, Lemiao
 Qiu, Guosheng Lin
Categories: cs.CV
\\ ( https://arxiv.org/abs/2505.20617 ,  7507kb)
------------------------------------------------------------------------------
\\
arXiv:2505.21844
replaced with revised version Sun, 9 Nov 2025 06:14:26 GMT   (1602kb)

Title: Test-Time Adaptation of Vision-Language Models for Open-Vocabulary
 Semantic Segmentation
Authors: Mehrdad Noori, David Osowiechi, Gustavo Adolfo Vargas Hakim, Ali
 Bahri, Moslem Yazdanpanah, Sahar Dastani, Farzad Beizaee, Ismail Ben Ayed,
 Christian Desrosiers
Categories: cs.CV
\\ ( https://arxiv.org/abs/2505.21844 ,  1602kb)
------------------------------------------------------------------------------
\\
arXiv:2505.24838
replaced with revised version Sat, 8 Nov 2025 18:27:03 GMT   (7432kb)

Title: VideoCAD: A Dataset and Model for Learning Long-Horizon 3D CAD UI
 Interactions from Video
Authors: Brandon Man, Ghadi Nehme, Md Ferdous Alam, Faez Ahmed
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2505.24838 ,  7432kb)
------------------------------------------------------------------------------
\\
arXiv:2506.00596
replaced with revised version Mon, 10 Nov 2025 08:02:07 GMT   (11916kb)

Title: Seg2Any: Open-set Segmentation-Mask-to-Image Generation with Precise
 Shape and Semantic Control
Authors: Danfeng Li, Hui Zhang, Sheng Wang, Jiacheng Li, Zuxuan Wu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2506.00596 ,  11916kb)
------------------------------------------------------------------------------
\\
arXiv:2506.02695
replaced with revised version Sat, 8 Nov 2025 07:12:23 GMT   (965kb)

Title: FaceSleuth-R: Adaptive Orientation-Aware Attention for Robust
 Micro-Expression Recognition
Authors: Linquan Wu, Tianxiang Jiang, Haoyu Yang, Wenhao Duan, Shaochao Lin,
 Zixuan Wang, Yini Fang, Jacky Keung
Categories: cs.CV
\\ ( https://arxiv.org/abs/2506.02695 ,  965kb)
------------------------------------------------------------------------------
\\
arXiv:2506.03229
replaced with revised version Mon, 10 Nov 2025 17:19:19 GMT   (3880kb)

Title: Bridging Weakly-Supervised Learning and VLM Distillation: Noisy Partial
 Label Learning for Efficient Downstream Adaptation
Authors: Qian-Wei Wang, Yuqiu Xie, Letian Zhang, Zimo Liu and Shu-Tao Xia
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2506.03229 ,  3880kb)
------------------------------------------------------------------------------
\\
arXiv:2506.04561
replaced with revised version Sun, 9 Nov 2025 04:01:01 GMT   (1299kb)

Title: LGM-Pose: A Lightweight Global Modeling Network for Real-time Human Pose
 Estimation
Authors: Biao Guo, Fangmin Guo, Guibo Luo, Xiaonan Luo, Feng Zhang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2506.04561 ,  1299kb)
------------------------------------------------------------------------------
\\
arXiv:2506.06120
replaced with revised version Mon, 10 Nov 2025 12:47:02 GMT   (8739kb)

Title: Bidirectional Image-Event Guided Fusion Framework for Low-Light Image
 Enhancement
Authors: Zhanwen Liu, Huanna Song, Yang Wang, Nan Yang, Weiping Ding, Yisheng
 An
Categories: cs.CV
\\ ( https://arxiv.org/abs/2506.06120 ,  8739kb)
------------------------------------------------------------------------------
\\
arXiv:2506.08009
replaced with revised version Mon, 10 Nov 2025 04:36:27 GMT   (3312kb)

Title: Self Forcing: Bridging the Train-Test Gap in Autoregressive Video
 Diffusion
Authors: Xun Huang, Zhengqi Li, Guande He, Mingyuan Zhou, Eli Shechtman
Categories: cs.CV cs.AI cs.LG
Comments: NeurIPS 2025 spotlight. Project website:
 http://self-forcing.github.io/
\\ ( https://arxiv.org/abs/2506.08009 ,  3312kb)
------------------------------------------------------------------------------
\\
arXiv:2506.09612
replaced with revised version Mon, 10 Nov 2025 15:49:42 GMT   (40604kb)

Title: Consistent Story Generation: Unlocking the Potential of Zigzag Sampling
Authors: Mingxiao Li, Mang Ning, Marie-Francine Moens
Categories: cs.CV
Comments: 20 pages, 10 figures
Journal-ref: published at NeurIPS 2025
\\ ( https://arxiv.org/abs/2506.09612 ,  40604kb)
------------------------------------------------------------------------------
\\
arXiv:2506.15675
replaced with revised version Sun, 9 Nov 2025 16:58:41 GMT   (5260kb)

Title: Sekai: A Video Dataset towards World Exploration
Authors: Zhen Li, Chuanhao Li, Xiaofeng Mao, Shaoheng Lin, Ming Li, Shitian
 Zhao, Zhaopan Xu, Xinyue Li, Yukang Feng, Jianwen Sun, Zizhen Li, Fanrui
 Zhang, Jiaxin Ai, Zhixiang Wang, Yuwei Wu, Tong He, Jiangmiao Pang, Yu Qiao,
 Yunde Jia, Kaipeng Zhang
Categories: cs.CV cs.AI
Comments: 14 pages, 5 figures
\\ ( https://arxiv.org/abs/2506.15675 ,  5260kb)
------------------------------------------------------------------------------
\\
arXiv:2506.16273
replaced with revised version Mon, 10 Nov 2025 07:00:26 GMT   (1744kb)

Title: Fine-grained Image Retrieval via Dual-Vision Adaptation
Authors: Xin Jiang, Meiqi Cao, Hao Tang, Fei Shen, Zechao Li
Categories: cs.CV cs.MM
Comments: Accepted by AAAI2026
\\ ( https://arxiv.org/abs/2506.16273 ,  1744kb)
------------------------------------------------------------------------------
\\
arXiv:2506.20756
replaced with revised version Sat, 8 Nov 2025 21:12:27 GMT   (6839kb)

Title: StereoDiff: Stereo-Diffusion Synergy for Video Depth Estimation
Authors: Haodong Li, Chen Wang, Jiahui Lei, Kostas Daniilidis, Lingjie Liu
Categories: cs.CV
Comments: Work done in Nov 2024, during an internship at the University of
 Pennsylvania. Project page: https://stereodiff.github.io/
\\ ( https://arxiv.org/abs/2506.20756 ,  6839kb)
------------------------------------------------------------------------------
\\
arXiv:2506.22146
replaced with revised version Mon, 10 Nov 2025 11:12:13 GMT   (12562kb)

Title: Visual Structures Helps Visual Reasoning: Addressing the Binding Problem
 in VLMs
Authors: Amirmohammad Izadi, Mohammad Ali Banayeeanzade, Fatemeh Askari, Ali
 Rahimiakbar, Mohammad Mahdi Vahedi, Hosein Hasani, Mahdieh Soleymani Baghshah
Categories: cs.CV cs.AI cs.LG
Comments: Accepted to NeurIPS 2025 (Thirty-ninth Conference on Neural
 Information Processing Systems)
\\ ( https://arxiv.org/abs/2506.22146 ,  12562kb)
------------------------------------------------------------------------------
\\
arXiv:2507.00825
replaced with revised version Mon, 10 Nov 2025 07:51:21 GMT   (12941kb)

Title: High-Frequency Semantics and Geometric Priors for End-to-End Detection
 Transformers in Challenging UAV Imagery
Authors: Hongxing Peng, Lide Chen, Hui Zhu and Yan Chen
Categories: cs.CV
Comments: 12 pages, 9 figures
ACM-class: I.2.10; I.4.8; I.5.1
\\ ( https://arxiv.org/abs/2507.00825 ,  12941kb)
------------------------------------------------------------------------------
\\
arXiv:2507.03739
replaced with revised version Mon, 10 Nov 2025 14:40:44 GMT   (2307kb)

Title: ChestGPT: Integrating Large Language Models and Vision Transformers for
 Disease Detection and Localization in Chest X-Rays
Authors: Shehroz S. Khan, Petar Przulj, Ahmed Ashraf, Ali Abedi
Categories: cs.CV
Comments: 8 pages, 5 figures, 4 tables
\\ ( https://arxiv.org/abs/2507.03739 ,  2307kb)
------------------------------------------------------------------------------
\\
arXiv:2507.04465
replaced with revised version Sun, 9 Nov 2025 13:30:35 GMT   (2859kb)

Title: Visual Hand Gesture Recognition with Deep Learning: A Comprehensive
 Review of Methods, Datasets, Challenges and Future Research Directions
Authors: Konstantinos Foteinos, Jorgen Cani, Manousos Linardakis, Panagiotis
 Radoglou-Grammatikis, Vasileios Argyriou, Panagiotis Sarigiannidis, Iraklis
 Varlamis, Georgios Th. Papadopoulos
Categories: cs.CV
\\ ( https://arxiv.org/abs/2507.04465 ,  2859kb)
------------------------------------------------------------------------------
\\
arXiv:2507.07908
replaced with revised version Mon, 10 Nov 2025 12:12:47 GMT   (9078kb)

Title: Not Only Consistency: Enhance Test-Time Adaptation with Spatio-temporal
 Inconsistency for Remote Physiological Measurement
Authors: Xiao Yang, Jiyao Wang, Yuxuan Fan, Can Liu, Houcheng Su, Weichen Guo,
 Zitong Yu, Dengbo He and Kaishun Wu
Categories: cs.CV
Comments: This work has been submitted to the IEEE for possible publication
\\ ( https://arxiv.org/abs/2507.07908 ,  9078kb)
------------------------------------------------------------------------------
\\
arXiv:2507.13659
replaced with revised version Sun, 9 Nov 2025 14:46:39 GMT   (4053kb)

Title: When Person Re-Identification Meets Event Camera: A Benchmark Dataset
 and An Attribute-guided Re-Identification Framework
Authors: Xiao Wang, Qian Zhu, Shujuan Wu, Bo Jiang, Shiliang Zhang
Categories: cs.CV cs.AI cs.LG cs.NE
Comments: Accepted by AAAI 2026
\\ ( https://arxiv.org/abs/2507.13659 ,  4053kb)
------------------------------------------------------------------------------
\\
arXiv:2507.16476
replaced with revised version Sun, 9 Nov 2025 07:54:47 GMT   (2117kb)

Title: Survival Modeling from Whole Slide Images via Patch-Level Graph
 Clustering and Mixture Density Experts
Authors: Ardhendu Sekhar, Vasu Soni, Keshav Aske, Garima Jain, Pranav Jeevan,
 Amit Sethi
Categories: cs.CV
\\ ( https://arxiv.org/abs/2507.16476 ,  2117kb)
------------------------------------------------------------------------------
\\
arXiv:2507.17047
replaced with revised version Fri, 7 Nov 2025 19:03:42 GMT   (1108kb)

Title: Controllable Hybrid Captioner for Improved Long-form Video Understanding
Authors: Kuleen Sasse, Efsun Sarioglu Kayi, Arun Reddy
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2507.17047 ,  1108kb)
------------------------------------------------------------------------------
\\
arXiv:2507.17088
replaced with revised version Sat, 8 Nov 2025 00:10:26 GMT   (2660kb)

Title: FedVLM: Scalable Personalized Vision-Language Models through Federated
 Learning
Authors: Arkajyoti Mitra (1), Afia Anjum (1), Paul Agbaje (1), Mert Pes\'e (2),
 Habeeb Olufowobi (1) ((1) University of Texas at Arlington, (2) Clemson
 University)
Categories: cs.CV
Comments: Accepted to ECAI 2025 Main Track
DOI: 10.3233/FAIA251319
\\ ( https://arxiv.org/abs/2507.17088 ,  2660kb)
------------------------------------------------------------------------------
\\
arXiv:2507.19856
replaced with revised version Sat, 8 Nov 2025 15:42:10 GMT   (2501kb)

Title: RaGS: Unleashing 3D Gaussian Splatting from 4D Radar and Monocular Cues
 for 3D Object Detection
Authors: Xiaokai Bai, Chenxu Zhou, Lianqing Zheng, Si-Yuan Cao, Jianan Liu,
 Xiaohan Zhang, Yiming Li, Zhengzhuang Zhang, Hui-liang Shen
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2507.19856 ,  2501kb)
------------------------------------------------------------------------------
\\
arXiv:2507.23755
replaced with revised version Sun, 9 Nov 2025 11:40:46 GMT   (945kb)

Title: Slot Attention with Re-Initialization and Self-Distillation
Authors: Rongzhen Zhao, Yi Zhao, Juho Kannala, Joni Pajarinen
Categories: cs.CV
Comments: Accepted to ACM MM 2025
\\ ( https://arxiv.org/abs/2507.23755 ,  945kb)
------------------------------------------------------------------------------
\\
arXiv:2508.01312
replaced with revised version Sat, 8 Nov 2025 20:13:36 GMT   (61kb)

Title: P3P Made Easy
Authors: Seong Hun Lee, Patrick Vandewalle, Javier Civera
Categories: cs.CV
\\ ( https://arxiv.org/abs/2508.01312 ,  61kb)
------------------------------------------------------------------------------
\\
arXiv:2508.01345
replaced with revised version Sun, 9 Nov 2025 11:45:15 GMT   (824kb)

Title: Predicting Video Slot Attention Queries from Random Slot-Feature Pairs
Authors: Rongzhen Zhao, Jian Li, Juho Kannala, Joni Pajarinen
Categories: cs.CV
Comments: Accepted to AAAI 2026
\\ ( https://arxiv.org/abs/2508.01345 ,  824kb)
------------------------------------------------------------------------------
\\
arXiv:2508.01579
replaced with revised version Sun, 9 Nov 2025 12:20:39 GMT   (18123kb)

Title: Harnessing Textual Semantic Priors for Knowledge Transfer and Refinement
 in CLIP-Driven Continual Learning
Authors: Lingfeng He, De Cheng, Huaijie Wang, Nannan Wang
Categories: cs.CV
Comments: AAAI-2026 Poster
\\ ( https://arxiv.org/abs/2508.01579 ,  18123kb)
------------------------------------------------------------------------------
\\
arXiv:2508.01766
replaced with revised version Sun, 9 Nov 2025 16:48:06 GMT   (8587kb)

Title: VPN: Visual Prompt Navigation
Authors: Shuo Feng, Zihan Wang, Yuchen Li, Rui Kong, Hengyi Cai, Shuaiqiang
 Wang, Gim Hee Lee, Piji Li, Shuqiang Jiang
Categories: cs.CV
Comments: Accepted by AAAI 2026
\\ ( https://arxiv.org/abs/2508.01766 ,  8587kb)
------------------------------------------------------------------------------
\\
arXiv:2508.02240
replaced with revised version Sat, 8 Nov 2025 11:53:33 GMT   (18302kb)

Title: Forecasting When to Forecast: Accelerating Diffusion Models with
 Confidence-Gated Taylor
Authors: Xiaoliu Guan, Lielin Jiang, Hanqi Chen, Xu Zhang, Jiaxing Yan,
 Guanzhong Wang, Yi Liu, Zetao Zhang, Yu Wu
Categories: cs.CV cs.AI
Comments: 15 pages, 4 figures
\\ ( https://arxiv.org/abs/2508.02240 ,  18302kb)
------------------------------------------------------------------------------
\\
arXiv:2508.04090
replaced with revised version Fri, 7 Nov 2025 20:19:02 GMT   (3261kb)

Title: Bridging Diffusion Models and 3D Representations: A 3D Consistent
 Super-Resolution Framework
Authors: Yi-Ting Chen, Ting-Hsuan Liao, Pengsheng Guo, Alexander Schwing,
 Jia-Bin Huang
Categories: cs.CV
Comments: Accepted to ICCV 2025. Project website:
 https://consistent3dsr.github.io/
\\ ( https://arxiv.org/abs/2508.04090 ,  3261kb)
------------------------------------------------------------------------------
\\
arXiv:2508.07607
replaced with revised version Sun, 9 Nov 2025 01:42:53 GMT   (44687kb)

Title: X2Edit: Revisiting Arbitrary-Instruction Image Editing through
 Self-Constructed Data and Task-Aware Representation Learning
Authors: Jian Ma, Xujie Zhu, Zihao Pan, Qirong Peng, Xu Guo, Chen Chen, Haonan
 Lu
Categories: cs.CV
Comments: Accepted to AAAI 2026
\\ ( https://arxiv.org/abs/2508.07607 ,  44687kb)
------------------------------------------------------------------------------
\\
arXiv:2508.12226
replaced with revised version Sun, 9 Nov 2025 17:56:00 GMT   (21366kb)

Title: Generative neural physics enables quantitative volumetric ultrasound of
 tissue mechanics
Authors: Zhijun Zeng, Youjia Zheng, Chang Su, Qianhang Wu, Hao Hu, Zeyuan Dong,
 Shan Gao, Yang Lv, Rui Tang, Ligang Cui, Zhiyong Hou, Weijun Lin, Zuoqiang
 Shi, Yubing Li, He Sun
Categories: cs.CV
MSC-class: 65N21, 92C55, 68T07
\\ ( https://arxiv.org/abs/2508.12226 ,  21366kb)
------------------------------------------------------------------------------
\\
arXiv:2508.17714
replaced with revised version Mon, 10 Nov 2025 03:33:57 GMT   (22667kb)

Title: F2RVLM: Boosting Fine-grained Fragment Retrieval for Multi-Modal
 Long-form Dialogue with Vision Language Model
Authors: Hanbo Bi, Zhiqiang Yuan, Zexi Jia, Jiapei Zhang, Chongyang Li,
 Peixiang Luo, Ying Deng, Xiaoyue Duan, Jinchao Zhang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2508.17714 ,  22667kb)
------------------------------------------------------------------------------
\\
arXiv:2508.19730
replaced with revised version Mon, 10 Nov 2025 12:17:56 GMT   (0kb,I)

Title: Improving Generalization in Deepfake Detection with Face Foundation
 Models and Metric Learning
Authors: Stelios Mylonas, Symeon Papadopoulos
Categories: cs.CV
Comments: The authors did not manage to secure approval by the funder of this
 research on time
DOI: 10.1145/3746275.3762208
\\ ( https://arxiv.org/abs/2508.19730 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2508.19895
replaced with revised version Sun, 9 Nov 2025 18:18:21 GMT   (2756kb)

Title: PersonaAnimator: Personalized Motion Transfer from Unconstrained Videos
Authors: Ziyun Qian, Runyu Xiao, Shuyuan Tu, Wei Xue, Dingkang Yang, Mingcheng
 Li, Dongliang Kou, Minghao Han, Zizhi Chen, Lihua Zhang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2508.19895 ,  2756kb)
------------------------------------------------------------------------------
\\
arXiv:2509.02560
replaced with revised version Sun, 9 Nov 2025 15:12:33 GMT   (2918kb)

Title: FastVGGT: Training-Free Acceleration of Visual Geometry Transformer
Authors: You Shen, Zhipeng Zhang, Yansong Qu, Xiawu Zheng, Jiayi Ji, Shengchuan
 Zhang, Liujuan Cao
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.02560 ,  2918kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03044
replaced with revised version Sat, 8 Nov 2025 16:35:53 GMT   (0kb,I)

Title: DCDB: Dynamic Conditional Dual Diffusion Bridge for Ill-posed
 Multi-Tasks
Authors: Chengjie Huang, Jiafeng Yan, Jing Li, Lu Bai
Categories: cs.CV
Comments: The article contains factual errors
\\ ( https://arxiv.org/abs/2509.03044 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2509.06165
replaced with revised version Sun, 9 Nov 2025 17:05:22 GMT   (12068kb)

Title: UNO: Unifying One-stage Video Scene Graph Generation via Object-Centric
 Visual Representation Learning
Authors: Huy Le, Nhat Chung, Tung Kieu, Jingkang Yang, Ngan Le
Categories: cs.CV cs.AI
Comments: 11 pages, 7 figures. Accepted at WACV 2026
\\ ( https://arxiv.org/abs/2509.06165 ,  12068kb)
------------------------------------------------------------------------------
\\
arXiv:2509.11169
replaced with revised version Mon, 10 Nov 2025 05:10:03 GMT   (2097kb)

Title: Multispectral-NeRF:a multispectral modeling approach based on neural
 radiance fields
Authors: Hong Zhang, Fei Guo, Zihan Xie, Dizhao Yao
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.11169 ,  2097kb)
------------------------------------------------------------------------------
\\
arXiv:2509.12742
replaced with revised version Sun, 9 Nov 2025 10:44:05 GMT   (18661kb)

Title: Effective Gaussian Management for High-fidelity Object Reconstruction
Authors: Jiateng Liu, Hao Gao, Jiu-Cheng Xie, Chi-Man Pun, Jian Xiong, Haolun
 Li, Junxin Chen and Feng Xu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.12742 ,  18661kb)
------------------------------------------------------------------------------
\\
arXiv:2509.18094
replaced with revised version Mon, 10 Nov 2025 14:50:20 GMT   (11048kb)

Title: UniPixel: Unified Object Referring and Segmentation for Pixel-Level
 Visual Reasoning
Authors: Ye Liu, Zongyang Ma, Junfu Pu, Zhongang Qi, Yang Wu, Ying Shan, Chang
 Wen Chen
Categories: cs.CV cs.AI
Comments: NeurIPS 2025 Camera Ready. Project Page:
 https://polyu-chenlab.github.io/unipixel/
\\ ( https://arxiv.org/abs/2509.18094 ,  11048kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19230
replaced with revised version Sun, 9 Nov 2025 19:01:08 GMT   (1135kb)

Title: DevFD: Developmental Face Forgery Detection by Learning Shared and
 Orthogonal LoRA Subspaces
Authors: Tianshuo Zhang, Li Gao, Siran Peng, Xiangyu Zhu, Zhen Lei
Categories: cs.CV
Comments: Accepted by NeurIPS 2025
\\ ( https://arxiv.org/abs/2509.19230 ,  1135kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20358
replaced with revised version Fri, 7 Nov 2025 19:14:11 GMT   (24899kb)

Title: PhysCtrl: Generative Physics for Controllable and Physics-Grounded Video
 Generation
Authors: Chen Wang, Chuhao Chen, Yiming Huang, Zhiyang Dou, Yuan Liu, Jiatao
 Gu, Lingjie Liu
Categories: cs.CV
Comments: NeurIPS 2025 Camera Ready Version
\\ ( https://arxiv.org/abs/2509.20358 ,  24899kb)
------------------------------------------------------------------------------
\\
arXiv:2509.21227
replaced with revised version Fri, 7 Nov 2025 20:05:09 GMT   (533kb)

Title: Evaluating the Evaluators: Metrics for Compositional Text-to-Image
 Generation
Authors: Seyed Amir Kasaei, Ali Aghayari, Arash Marioriyad, Niki Sepasian,
 MohammadAmin Fazli, Mahdieh Soleymani Baghshah, and Mohammad Hossein Rohban
Categories: cs.CV cs.CL
Comments: Accepted at GenProCC NeurIPS 2025 Workshop
\\ ( https://arxiv.org/abs/2509.21227 ,  533kb)
------------------------------------------------------------------------------
\\
arXiv:2509.21257
replaced with revised version Fri, 7 Nov 2025 19:44:36 GMT   (10kb)

Title: Hallucination as an Upper Bound: A New Perspective on Text-to-Image
 Evaluation
Authors: Seyed Amir Kasaei, Mohammad Hossein Rohban
Categories: cs.CV cs.CL
Comments: Accepted at GenProCC NeurIPS 2025 Workshop
\\ ( https://arxiv.org/abs/2509.21257 ,  10kb)
------------------------------------------------------------------------------
\\
arXiv:2509.23919
replaced with revised version Sun, 9 Nov 2025 08:46:20 GMT   (4958kb)

Title: Token Painter: Training-Free Text-Guided Image Inpainting via Mask
 Autoregressive Models
Authors: Longtao Jiang, Jie Huang, Mingfei Han, Lei Chen, Yongqiang Yu, Feng
 Zhao, Xiaojun Chang, Zhihui Li
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.23919 ,  4958kb)
------------------------------------------------------------------------------
\\
arXiv:2509.24741
replaced with revised version Sun, 9 Nov 2025 08:05:02 GMT   (3820kb)

Title: Collaborating Vision, Depth, and Thermal Signals for Multi-Modal
 Tracking: Dataset and Algorithm
Authors: Xue-Feng Zhu, Tianyang Xu, Yifan Pan, Jinjie Gu, Xi Li, Jiwen Lu,
 Xiao-Jun Wu, Josef Kittler
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.24741 ,  3820kb)
------------------------------------------------------------------------------
\\
arXiv:2509.26618
replaced with revised version Sat, 8 Nov 2025 21:21:48 GMT   (28378kb)

Title: DA$^{2}$: Depth Anything in Any Direction
Authors: Haodong Li, Wangguangdong Zheng, Jing He, Yuhao Liu, Xin Lin, Xin
 Yang, Ying-Cong Chen, Chunchao Guo
Categories: cs.CV
Comments: Work primarily done during an internship at Tencent Hunyuan. Project
 page: https://depth-any-in-any-dir.github.io/
\\ ( https://arxiv.org/abs/2509.26618 ,  28378kb)
------------------------------------------------------------------------------
\\
arXiv:2510.10534
replaced with revised version Sat, 8 Nov 2025 10:28:24 GMT   (396kb)

Title: MCE: Towards a General Framework for Handling Missing Modalities under
 Imbalanced Missing Rates
Authors: Binyu Zhao, Wei Zhang, Zhaonian Zou
Categories: cs.CV cs.LG cs.MM
Comments: This is the accepted version of an article that has been published in
 \textbf{Pattern Recognition}. The final version is available via the DOI, or
 for 50 days' free access via this Share Link:
 https://authors.elsevier.com/a/1m40D77nKsBm- (valid until December 28, 2025)
DOI: 10.1016/j.patcog.2025.112591
\\ ( https://arxiv.org/abs/2510.10534 ,  396kb)
------------------------------------------------------------------------------
\\
arXiv:2510.10606
replaced with revised version Sun, 9 Nov 2025 08:50:17 GMT   (2897kb)

Title: ViSurf: Visual Supervised-and-Reinforcement Fine-Tuning for Large
 Vision-and-Language Models
Authors: Yuqi Liu, Liangyu Chen, Jiazhen Liu, Mingkang Zhu, Zhisheng Zhong, Bei
 Yu, Jiaya Jia
Categories: cs.CV
\\ ( https://arxiv.org/abs/2510.10606 ,  2897kb)
------------------------------------------------------------------------------
\\
arXiv:2510.12132
replaced with revised version Mon, 10 Nov 2025 12:09:03 GMT   (6598kb)

Title: FedHUG: Federated Heterogeneous Unsupervised Generalization for Remote
 Physiological Measurements
Authors: Xiao Yang, Dengbo He, Jiyao Wang, Kaishun Wu
Categories: cs.CV
Comments: This work has been submitted to the IEEE for possible publication
\\ ( https://arxiv.org/abs/2510.12132 ,  6598kb)
------------------------------------------------------------------------------
\\
arXiv:2510.14270
replaced with revised version Mon, 10 Nov 2025 16:16:00 GMT   (4613kb)

Title: GauSSmart: Enhanced 3D Reconstruction through 2D Foundation Models and
 Geometric Filtering
Authors: Alexander Valverde, Brian Xu, Yuyin Zhou, Meng Xu, Hongyun Wang
Categories: cs.CV cs.GR
\\ ( https://arxiv.org/abs/2510.14270 ,  4613kb)
------------------------------------------------------------------------------
\\
arXiv:2510.14376
replaced with revised version Mon, 10 Nov 2025 08:22:27 GMT   (26598kb)

Title: DOS: Directional Object Separation in Text Embeddings for Multi-Object
 Image Generation
Authors: Dongnam Byun, Jungwon Park, Jungmin Ko, Changin Choi, Wonjong Rhee
Categories: cs.CV
Comments: Accepted to AAAI 2026
\\ ( https://arxiv.org/abs/2510.14376 ,  26598kb)
------------------------------------------------------------------------------
\\
arXiv:2510.22067
replaced with revised version Mon, 10 Nov 2025 17:37:52 GMT   (14447kb)

Title: Capturing Gaze Shifts for Guidance: Cross-Modal Fusion Enhancement for
 VLM Hallucination Mitigation
Authors: Zheng Qi, Chao Shang, Evangelia Spiliopoulou, Nikolaos Pappas
Categories: cs.CV
\\ ( https://arxiv.org/abs/2510.22067 ,  14447kb)
------------------------------------------------------------------------------
\\
arXiv:2510.27285
replaced with revised version Sat, 8 Nov 2025 05:17:37 GMT   (3601kb)

Title: Rethinking Robust Adversarial Concept Erasure in Diffusion Models
Authors: Qinghong Yin and Yu Tian and Heming Yang and Xiang Chen and Xianlin
 Zhang and Xueming Li and Yue Zhan
Categories: cs.CV cs.CR
\\ ( https://arxiv.org/abs/2510.27285 ,  3601kb)
------------------------------------------------------------------------------
\\
arXiv:2511.00504
replaced with revised version Sun, 9 Nov 2025 09:03:27 GMT   (2953kb)

Title: VinDr-CXR-VQA: A Visual Question Answering Dataset for Explainable Chest
 X-Ray Analysis with Multi-Task Learning
Authors: Dang H. Nguyen, Hieu H. Pham, Hao T. Nguyen, Hieu H. Pham
Categories: cs.CV
Comments: ISBI submission. Contains 5 pages, 2 figures, and 6 tables. Code &
 data: https://huggingface.co/datasets/Dangindev/VinDR-CXR-VQA
\\ ( https://arxiv.org/abs/2511.00504 ,  2953kb)
------------------------------------------------------------------------------
\\
arXiv:2511.01450
replaced with revised version Mon, 10 Nov 2025 03:10:25 GMT   (0kb,I)

Title: Reg-DPO: SFT-Regularized Direct Preference Optimization with GT-Pair for
 Improving Video Generation
Authors: Jie Du, Xinyu Gong, Qingshan Tan, Wen Li, Yangming Cheng, Weitao Wang,
 Chenlu Zhan, Suhui Wu, Hao Zhang, Jun Zhang
Categories: cs.CV cs.AI
Comments: The paper is withdrawn due to the need for further revision and
 verification of experimental results. A revised version will be resubmitted
 once the updates are completed
\\ ( https://arxiv.org/abs/2511.01450 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2511.02193
replaced with revised version Mon, 10 Nov 2025 12:21:53 GMT   (10638kb)

Title: MM-UNet: Morph Mamba U-shaped Convolutional Networks for Retinal Vessel
 Segmentation
Authors: Jiawen Liu, Yuanbo Zeng, Jiaming Liang, Yizhen Yang, Yiheng Zhang,
 Enhui Cai, Xiaoqi Sheng, Hongmin Cai
Categories: cs.CV cs.AI
Comments: This paper was accepted by IEEE BIBM 2025 conference
\\ ( https://arxiv.org/abs/2511.02193 ,  10638kb)
------------------------------------------------------------------------------
\\
arXiv:2511.03943
replaced with revised version Sun, 9 Nov 2025 10:03:03 GMT   (161kb)

Title: Temporal Zoom Networks: Distance Regression and Continuous Depth for
 Efficient Action Localization
Authors: Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma
Categories: cs.CV
\\ ( https://arxiv.org/abs/2511.03943 ,  161kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05271
replaced with revised version Mon, 10 Nov 2025 15:43:16 GMT   (4918kb)

Title: DeepEyesV2: Toward Agentic Multimodal Model
Authors: Jack Hong, Chenxiao Zhao, ChengLin Zhu, Weiheng Lu, Guohai Xu, Xing Yu
Categories: cs.CV cs.AI
Comments: Homepage: https://visual-agent.github.io/
\\ ( https://arxiv.org/abs/2511.05271 ,  4918kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05308
replaced with revised version Mon, 10 Nov 2025 08:55:03 GMT   (45277kb)

Title: Rethinking Metrics and Diffusion Architecture for 3D Point Cloud
 Generation
Authors: Matteo Bastico, David Ryckelynck, Laurent Cort\'e, Yannick Tillier,
 Etienne Decenci\`ere
Categories: cs.CV cs.AI cs.LG
Comments: This paper has been accepted at International Conference on 3D Vision
 (3DV) 2026
\\ ( https://arxiv.org/abs/2511.05308 ,  45277kb)
------------------------------------------------------------------------------
\\
arXiv:2306.06590
replaced with revised version Sun, 9 Nov 2025 11:15:15 GMT   (148kb)

Title: Mean-Variance Efficient Collaborative Filtering for Stock Recommendation
Authors: Munki Chung, Junhyeong Lee, Yongjae Lee, Woo Chang Kim
Categories: cs.IR cs.CE
Comments: To appear in the 6th ACM International Conference on AI in Finance
 (ICAIF '25), November 15-18, 2025, Singapore. 8 pages, 3 tables, 3 figures
DOI: 10.1145/3768292.3770427
\\ ( https://arxiv.org/abs/2306.06590 ,  148kb)
------------------------------------------------------------------------------
\\
arXiv:2407.03580
replaced with revised version Mon, 10 Nov 2025 12:56:55 GMT   (2693kb)

Title: Deep Pareto Reinforcement Learning for Multi-Objective Recommender
 Systems
Authors: Pan Li, Alexander Tuzhilin
Categories: cs.IR
\\ ( https://arxiv.org/abs/2407.03580 ,  2693kb)
------------------------------------------------------------------------------
\\
arXiv:2505.15874
replaced with revised version Mon, 10 Nov 2025 14:42:35 GMT   (25047kb)

Title: Text-to-Pipeline: Bridging Natural Language and Data Preparation
 Pipelines
Authors: Yuhang Ge, Yachuan Liu, Zhangyan Ye, Yuren Mao, Yunjun Gao
Categories: cs.IR cs.CL
\\ ( https://arxiv.org/abs/2505.15874 ,  25047kb)
------------------------------------------------------------------------------
\\
arXiv:2510.20276
replaced with revised version Sat, 8 Nov 2025 11:54:10 GMT   (3596kb)

Title: From Generation to Attribution: Music AI Agent Architectures for the
 Post-Streaming Era
Authors: Wonil Kim, Hyeongseok Wi, Seungsoon Park, Taejun Kim, Sangeun Keum,
 Keunhyoung Kim, Taewan Kim, Jongmin Jung, Taehyoung Kim, Gaetan Guerrero,
 Mael Le Goff, Julie Po, Dongjoo Moon, Juhan Nam, Jongpil Lee
Categories: cs.IR cs.HC cs.MA cs.SD
Comments: Accepted to the NeurIPS 2025 AI4Music Workshop
\\ ( https://arxiv.org/abs/2510.20276 ,  3596kb)
------------------------------------------------------------------------------
\\
arXiv:2511.02113
replaced with revised version Mon, 10 Nov 2025 06:11:16 GMT   (3984kb)

Title: Enhancing Multimodal Recommendations with Vision-Language Models and
 Information-Aware Fusion
Authors: Hai-Dang Kieu, Min Xu, Thanh Trung Huynh, Dung D. Le
Categories: cs.IR
\\ ( https://arxiv.org/abs/2511.02113 ,  3984kb)
------------------------------------------------------------------------------
\\
arXiv:2005.06394
replaced with revised version Fri, 7 Nov 2025 23:15:24 GMT   (5158kb)

Title: A CNN-LSTM Quantifier for Single Access Point CSI Indoor Localization
Authors: Minh Tu Hoang, Brosnan Yuen, Kai Ren, Xiaodai Dong, Tao Lu, Hung Le
 Nguyen, Robert Westendorp, and Kishore Reddy
Categories: cs.LG eess.SP stat.ML
Comments: Channel state information (CSI), WiFi indoor localization,
 convolutional neural network, long short-term memory, fingerprint-based
 localization
\\ ( https://arxiv.org/abs/2005.06394 ,  5158kb)
------------------------------------------------------------------------------
\\
arXiv:2012.03800
replaced with revised version Sun, 9 Nov 2025 02:04:44 GMT   (1497kb)

Title: Revenue Maximization and Learning in Products Ranking
Authors: Ningyuan Chen, Anran Li, Shuoguang Yang
Categories: cs.LG
\\ ( https://arxiv.org/abs/2012.03800 ,  1497kb)
------------------------------------------------------------------------------
\\
arXiv:2108.10346
replaced with revised version Mon, 10 Nov 2025 12:29:15 GMT   (6752kb)

Title: Explaining Bayesian Neural Networks
Authors: Kirill Bykov, Marina M.-C. H\"ohne, Adelaida Creosteanu, Klaus-Robert
 M\"uller, Frederick Klauschen, Shinichi Nakajima, Marius Kloft
Categories: cs.LG cs.AI cs.CV stat.ML
Comments: 25 pages, 8 figures Accepted to Transactions on Machine Learning
 Research
\\ ( https://arxiv.org/abs/2108.10346 ,  6752kb)
------------------------------------------------------------------------------
\\
arXiv:2202.11966
replaced with revised version Sun, 9 Nov 2025 12:13:41 GMT   (2403kb)

Title: Impacts of Individual Fairness on Group Fairness from the Perspective of
 Generalized Entropy
Authors: Youngmi Jin and Jio Gim and Tae-Jin Lee and Young-Joo Suh
Categories: cs.LG
Comments: 30 pages and 10 figures, Title has been changed. Some results are
 newly added
\\ ( https://arxiv.org/abs/2202.11966 ,  2403kb)
------------------------------------------------------------------------------
\\
arXiv:2307.08643
replaced with revised version Mon, 10 Nov 2025 10:58:30 GMT   (91kb)

Title: Corruptions of Supervised Learning Problems: Typology and Mitigations
Authors: Laura Iacovissi and Nan Lu and Robert C. Williamson
Categories: cs.LG stat.ML
Comments: 72 pages. Submitted to JMLR
\\ ( https://arxiv.org/abs/2307.08643 ,  91kb)
------------------------------------------------------------------------------
\\
arXiv:2312.10440
replaced with revised version Mon, 10 Nov 2025 13:18:25 GMT   (907kb)

Title: Weight-Entanglement Meets Gradient-Based Neural Architecture Search
Authors: Rhea Sanjay Sukthanker, Arjun Krishnakumar, Mahmoud Safari, Frank
 Hutter
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2312.10440 ,  907kb)
------------------------------------------------------------------------------
\\
arXiv:2402.00152
replaced with revised version Sun, 9 Nov 2025 21:16:24 GMT   (204kb)

Title: Deeper or Wider: A Perspective from Optimal Generalization Error with
 Sobolev Loss
Authors: Yahong Yang and Juncai He
Categories: cs.LG cs.NA math.NA stat.ML
Comments: arXiv admin note: text overlap with arXiv:2310.10766,
 arXiv:2305.08466
MSC-class: 68T05
\\ ( https://arxiv.org/abs/2402.00152 ,  204kb)
------------------------------------------------------------------------------
\\
arXiv:2402.12727
replaced with revised version Sun, 9 Nov 2025 08:46:09 GMT   (528kb)

Title: Diffusion Posterior Sampling is Computationally Intractable
Authors: Shivam Gupta, Ajil Jalal, Aditya Parulekar, Eric Price, Zhiyang Xun
Categories: cs.LG cs.AI math.ST stat.ML stat.TH
\\ ( https://arxiv.org/abs/2402.12727 ,  528kb)
------------------------------------------------------------------------------
\\
arXiv:2405.01702
replaced with revised version Sat, 8 Nov 2025 11:08:49 GMT   (1588kb)

Title: Optimization without Retraction on the Random Generalized Stiefel
 Manifold
Authors: Simon Vary, Pierre Ablin, Bin Gao, P.-A. Absil
Categories: cs.LG math.OC stat.ML
Comments: This v4 is a corrected version of the ICML 2024 paper (PMLR
 235:49226-49248); see the errata at the end for the list of changes
MSC-class: 90C26, 90C15
Journal-ref: Proceedings of the 41st International Conference on Machine
 Learning (ICML 2024), PMLR 235 (2024), 49226-49248
\\ ( https://arxiv.org/abs/2405.01702 ,  1588kb)
------------------------------------------------------------------------------
\\
arXiv:2406.00153
replaced with revised version Mon, 10 Nov 2025 04:46:07 GMT   (1600kb)

Title: $\mu$LO: Compute-Efficient Meta-Generalization of Learned Optimizers
Authors: Benjamin Th\'erien, Charles-\'Etienne Joseph, Boris Knyazev, Edouard
 Oyallon, Irina Rish, Eugene Belilovsky
Categories: cs.LG
\\ ( https://arxiv.org/abs/2406.00153 ,  1600kb)
------------------------------------------------------------------------------
\\
arXiv:2406.16715
replaced with revised version Sun, 9 Nov 2025 19:28:31 GMT   (181kb)

Title: GC4NC: A Benchmark Framework for Graph Condensation on Node
 Classification with New Insights
Authors: Shengbo Gong, Juntong Ni, Noveen Sachdeva, Carl Yang, Wei Jin
Categories: cs.LG
Comments: 30 pages, Accepted by NeurIPS 2025 Datasets & Benchmarks Track
\\ ( https://arxiv.org/abs/2406.16715 ,  181kb)
------------------------------------------------------------------------------
\\
arXiv:2406.16756
replaced with revised version Mon, 10 Nov 2025 14:10:10 GMT   (456kb)

Title: Addressing Polarization and Unfairness in Performative Prediction
Authors: Kun Jin, Tian Xie, Yang Liu, Xueru Zhang
Categories: cs.LG cs.AI cs.CY
\\ ( https://arxiv.org/abs/2406.16756 ,  456kb)
------------------------------------------------------------------------------
\\
arXiv:2407.06503
replaced with revised version Mon, 10 Nov 2025 10:56:56 GMT   (10067kb)

Title: Preference-Guided Reinforcement Learning for Efficient Exploration
Authors: Guojian Wang, Jianxiang Liu, Xinyuan Li, Faguo Wu, Xiao Zhang,
 Tianyuan Chen, Xuyang Chen
Categories: cs.LG
Comments: 13 pages, 15 figures
\\ ( https://arxiv.org/abs/2407.06503 ,  10067kb)
------------------------------------------------------------------------------
\\
arXiv:2408.13567
replaced with revised version Fri, 7 Nov 2025 21:27:43 GMT   (853kb)

Title: Hybrid Training for Enhanced Multi-task Generalization in Multi-agent
 Reinforcement Learning
Authors: Mingliang Zhang, Sichang Su, Chengyang He, and Guillaume Sartoretti
Categories: cs.LG cs.MA
Comments: NeurIPS 2025 ARLET Workshop
\\ ( https://arxiv.org/abs/2408.13567 ,  853kb)
------------------------------------------------------------------------------
\\
arXiv:2408.13850
replaced with revised version Mon, 10 Nov 2025 05:52:04 GMT   (2492kb)

Title: Condensed Data Expansion Using Model Inversion for Knowledge
 Distillation
Authors: Kuluhan Binici, Shivam Aggarwal, Cihan Acar, Nam Trung Pham, Karianto
 Leman, Gim Hee Lee, Tulika Mitra
Categories: cs.LG cs.AI
Comments: Accepted by the Fortieth AAAI Conference on Artificial Intelligence
 (AAAI-26)
\\ ( https://arxiv.org/abs/2408.13850 ,  2492kb)
------------------------------------------------------------------------------
\\
arXiv:2409.06525
replaced with revised version Sun, 9 Nov 2025 17:01:21 GMT   (793kb)

Title: MENSA: A Multi-Event Network for Survival Analysis with Trajectory-based
 Likelihood Estimation
Authors: Christian Marius Lillelund, Ali Hossein Gharari Foomani, Weijie Sun,
 Shi-ang Qi, Russell Greiner
Categories: cs.LG
Comments: Accepted at ML4H 2025. Camera-ready version
\\ ( https://arxiv.org/abs/2409.06525 ,  793kb)
------------------------------------------------------------------------------
\\
arXiv:2409.15922
replaced with revised version Sat, 8 Nov 2025 04:37:05 GMT   (12690kb)

Title: The Dark Side of Rich Rewards: Understanding and Mitigating Noise in VLM
 Rewards
Authors: Sukai Huang, Shu-Wei Liu, Nir Lipovetzky and Trevor Cohn
Categories: cs.LG cs.RO
Comments: accepted by PRL Workshop Series @ ICAPS 2025. 11 main body pages, 21
 appendix pages
\\ ( https://arxiv.org/abs/2409.15922 ,  12690kb)
------------------------------------------------------------------------------
\\
arXiv:2410.03070
replaced with revised version Mon, 10 Nov 2025 15:48:19 GMT   (2156kb)

Title: FedMAC: Tackling Partial-Modality Missing in Federated Learning with
 Cross-Modal Aggregation and Contrastive Regularization
Authors: Manh Duong Nguyen, Trung Thanh Nguyen, Huy Hieu Pham, Trong Nghia
 Hoang, Phi Le Nguyen, Thanh Trung Huynh
Categories: cs.LG cs.MM
Comments: The 22nd International Symposium on Network Computing and
 Applications (NCA 2024)
\\ ( https://arxiv.org/abs/2410.03070 ,  2156kb)
------------------------------------------------------------------------------
\\
arXiv:2410.15483
replaced with revised version Mon, 10 Nov 2025 03:00:46 GMT   (5117kb)

Title: Understanding Forgetting in LLM Supervised Fine-Tuning and Preference
 Learning - A Convex Optimization Perspective
Authors: Heshan Fernando, Han Shen, Parikshit Ram, Yi Zhou, Horst Samulowitz,
 Nathalie Baracaldo, Tianyi Chen
Categories: cs.LG cs.AI cs.CL math.OC stat.ML
\\ ( https://arxiv.org/abs/2410.15483 ,  5117kb)
------------------------------------------------------------------------------
\\
arXiv:2411.04372
replaced with revised version Sat, 8 Nov 2025 23:06:19 GMT   (2616kb)

Title: Benchmarking Large Language Models with Integer Sequence Generation
 Tasks
Authors: Daniel O'Malley, Manish Bhattarai, Nishath Rajiv Ranasinghe, Erick
 Draayer, Javier Santos
Categories: cs.LG cs.AI cs.SE
\\ ( https://arxiv.org/abs/2411.04372 ,  2616kb)
------------------------------------------------------------------------------
\\
arXiv:2411.07066
replaced with revised version Mon, 10 Nov 2025 11:02:31 GMT   (3178kb)

Title: Zeroth-Order Adaptive Neuron Alignment Based Pruning without Re-Training
Authors: Elia Cunegatti, Leonardo Lucio Custode, Giovanni Iacca
Categories: cs.LG cs.AI cs.CL
Comments: Published in Transactions on Machine Learning Research (TMLR)
\\ ( https://arxiv.org/abs/2411.07066 ,  3178kb)
------------------------------------------------------------------------------
\\
arXiv:2411.07959
replaced with revised version Sun, 9 Nov 2025 18:59:05 GMT   (1174kb)

Title: On the Convergence of Continual Federated Learning Using Incrementally
 Aggregated Gradients
Authors: Satish Kumar Keshri, Nazreen Shah, Ranjitha Prasad
Categories: cs.LG cs.DC
Comments: Accepted at AISTATS 2025.
 (https://proceedings.mlr.press/v258/keshri25a.html)
\\ ( https://arxiv.org/abs/2411.07959 ,  1174kb)
------------------------------------------------------------------------------
\\
arXiv:2411.11293
replaced with revised version Mon, 10 Nov 2025 09:03:57 GMT   (1296kb)

Title: AnomalyAID: Reliable Interpretation for Semi-supervised Network Anomaly
 Detection
Authors: Yachao Yuan, Yu Huang, Yingwen Wu, Jin Wang
Categories: cs.LG
\\ ( https://arxiv.org/abs/2411.11293 ,  1296kb)
------------------------------------------------------------------------------
\\
arXiv:2411.14984
replaced with revised version Mon, 10 Nov 2025 17:42:17 GMT   (269kb)

Title: Adaptive Group Robust Ensemble Knowledge Distillation
Authors: Patrik Kenfack, Ulrich A\"ivodji, Samira Ebrahimi Kahou
Categories: cs.LG
Comments: Published in Transactions on Machine Learning Research (TMLR)
\\ ( https://arxiv.org/abs/2411.14984 ,  269kb)
------------------------------------------------------------------------------
\\
arXiv:2412.04845
replaced with revised version Sat, 8 Nov 2025 04:54:47 GMT   (16628kb)

Title: Using Machine Learning to Discover Parsimonious and
 Physically-Interpretable Representations of Catchment-Scale Rainfall-Runoff
 Dynamics
Authors: Yuan-Heng Wang, Hoshin V. Gupta
Categories: cs.LG cs.AI
Comments: Main Text: 122 Pages, 4 Tables, 18 Figures; Supplementary Material: 1
 Preface, 3 texts, 18 Tables and 13 Figures
\\ ( https://arxiv.org/abs/2412.04845 ,  16628kb)
------------------------------------------------------------------------------
\\
arXiv:2412.11044
replaced with revised version Mon, 10 Nov 2025 01:32:49 GMT   (684kb)

Title: Understanding and Mitigating Memorization in Diffusion Models for
 Tabular Data
Authors: Zhengyu Fang, Zhimeng Jiang, Huiyuan Chen, Xiao Li, Jing Li
Categories: cs.LG
Comments: Published in ICML 2025 (PMLR Volume 267):
 https://proceedings.mlr.press/v267/fang25f.html
Journal-ref: Proceedings of the 42nd International Conference on Machine
 Learning (ICML 2025), PMLR 267, Vancouver, Canada
\\ ( https://arxiv.org/abs/2412.11044 ,  684kb)
------------------------------------------------------------------------------
\\
arXiv:2501.03937
replaced with revised version Mon, 10 Nov 2025 09:08:50 GMT   (7515kb)

Title: A solvable model of learning generative diffusion: theory and insights
Authors: Hugo Cui, Cengiz Pehlevan, Yue M. Lu
Categories: cs.LG cond-mat.dis-nn
\\ ( https://arxiv.org/abs/2501.03937 ,  7515kb)
------------------------------------------------------------------------------
\\
arXiv:2501.11002
replaced with revised version Sun, 9 Nov 2025 21:21:28 GMT   (6840kb)

Title: pMixFed: Efficient Personalized Federated Learning through Adaptive
 Layer-Wise Mixup
Authors: Yasaman Saadati, Mohammad Rostami, M. Hadi Amini
Categories: cs.LG cs.DC
Comments: 45 pages, 10 Images
\\ ( https://arxiv.org/abs/2501.11002 ,  6840kb)
------------------------------------------------------------------------------
\\
arXiv:2501.13677
replaced with revised version Mon, 10 Nov 2025 15:53:56 GMT   (539kb)

Title: HumorReject: Decoupling LLM Safety from Refusal Prefix via A Little
 Humor
Authors: Zihui Wu, Haichang Gao, Jiacheng Luo, Zhaoxiang Liu
Categories: cs.LG cs.CR
\\ ( https://arxiv.org/abs/2501.13677 ,  539kb)
------------------------------------------------------------------------------
\\
arXiv:2501.15758
replaced with revised version Sun, 9 Nov 2025 11:38:07 GMT   (129kb)

Title: Distributional Surgery for Language Model Activations
Authors: Bao Nguyen and Binh Nguyen and Duy Nguyen and Viet Anh Nguyen
Categories: cs.LG cs.CL math.OC
Comments: 3 figures
\\ ( https://arxiv.org/abs/2501.15758 ,  129kb)
------------------------------------------------------------------------------
\\
arXiv:2502.01276
replaced with revised version Mon, 10 Nov 2025 16:43:45 GMT   (7675kb)

Title: HyperSHAP: Shapley Values and Interactions for Explaining Hyperparameter
 Optimization
Authors: Marcel Wever, Maximilian Muschalik, Fabian Fumagalli, Marius Lindauer
Categories: cs.LG cs.AI stat.ML
Comments: Accepted at AAAI-26 (oral)
\\ ( https://arxiv.org/abs/2502.01276 ,  7675kb)
------------------------------------------------------------------------------
\\
arXiv:2502.01717
replaced with revised version Sat, 8 Nov 2025 17:15:42 GMT   (5926kb)

Title: Choose Your Model Size: Any Compression of Large Language Models Without
 Re-Computation
Authors: Martin Genzel, Patrick Putzky, Pengfei Zhao, Sebastian Schulze, Mattes
 Mollenhauer, Robert Seidel, Stefan Dietzel, Thomas Wollmann
Categories: cs.LG
Comments: Code available under https://github.com/merantix-momentum/acip
Journal-ref: Transactions on Machine Learning Research, November 2025
\\ ( https://arxiv.org/abs/2502.01717 ,  5926kb)
------------------------------------------------------------------------------
\\
arXiv:2502.03988
replaced with revised version Sun, 9 Nov 2025 13:35:09 GMT   (593kb)

Title: Tight Bounds for Jensen's Gap with Applications to Variational Inference
Authors: Marcin Mazur, Tadeusz Dziarmaga, Piotr Ko\'scielniak, {\L}ukasz
 Struski
Categories: cs.LG
Comments: accepted for CIKM '25
Journal-ref: Proceedings of the 34th ACM International Conference on
 Information and Knowledge Management, Pages 2074-2083
DOI: 10.1145/3746252.3761065
\\ ( https://arxiv.org/abs/2502.03988 ,  593kb)
------------------------------------------------------------------------------
\\
arXiv:2502.05743
replaced with revised version Mon, 10 Nov 2025 05:05:24 GMT   (4371kb)

Title: Understanding Representation Dynamics of Diffusion Models via
 Low-Dimensional Modeling
Authors: Xiao Li, Zekai Zhang, Xiang Li, Siyi Chen, Zhihui Zhu, Peng Wang, Qing
 Qu
Categories: cs.LG cs.CV
Comments: First two authors contributed equally. Accepted at NeurIPS 2025
\\ ( https://arxiv.org/abs/2502.05743 ,  4371kb)
------------------------------------------------------------------------------
\\
arXiv:2502.10307
replaced with revised version Sun, 9 Nov 2025 07:02:18 GMT   (1327kb)

Title: SPIRIT: Short-term Prediction of solar IRradIance for zero-shot Transfer
 learning using Foundation Models
Authors: Aditya Mishra, Ravindra T, Srinivasan Iyengar, Shivkumar Kalyanaraman,
 Ponnurangam Kumaraguru
Categories: cs.LG cs.CV
\\ ( https://arxiv.org/abs/2502.10307 ,  1327kb)
------------------------------------------------------------------------------
\\
arXiv:2502.16406
replaced with revised version Sat, 8 Nov 2025 02:19:47 GMT   (2078kb)

Title: TrustChain: A Blockchain Framework for Auditing and Verifying
 Aggregators in Decentralized Federated Learning
Authors: Ehsan Hallaji, Roozbeh Razavi-Far, Mehrdad Saif
Categories: cs.LG cs.AI cs.CR
Comments: Accepted for publication in IEEE Transactions on Big Data
\\ ( https://arxiv.org/abs/2502.16406 ,  2078kb)
------------------------------------------------------------------------------
\\
arXiv:2502.17493
replaced with revised version Fri, 7 Nov 2025 23:27:12 GMT   (2108kb)

Title: A Novel Loss Function for Deep Learning Based Daily Stock Trading System
Authors: Ruoyu Guo, Haochen Qiu, Xuelun Hou
Categories: cs.LG cs.AI q-fin.CP
Comments: 27 pages, 11 figures, GitHub repo:
 https://github.com/Tony-Guo-1/daily_trading_strategy
ACM-class: I.2.1; I.2.6
\\ ( https://arxiv.org/abs/2502.17493 ,  2108kb)
------------------------------------------------------------------------------
\\
arXiv:2503.02877
replaced with revised version Sun, 9 Nov 2025 23:17:55 GMT   (338kb)

Title: Weak-to-Strong Generalization Even in Random Feature Networks, Provably
Authors: Marko Medvedev, Kaifeng Lyu, Dingli Yu, Sanjeev Arora, Zhiyuan Li,
 Nathan Srebro
Categories: cs.LG stat.ML
Comments: Edits: Fixed typesetting errors from v2
\\ ( https://arxiv.org/abs/2503.02877 ,  338kb)
------------------------------------------------------------------------------
\\
arXiv:2503.05029
replaced with revised version Mon, 10 Nov 2025 05:32:48 GMT   (3051kb)

Title: Continual Pre-training of MoEs: How robust is your router?
Authors: Benjamin Th\'erien, Charles-\'Etienne Joseph, Zain Sarwar, Ashwinee
 Panda, Anirban Das, Shi-Xiong Zhang, Stephen Rawls, Sambit Sahu, Eugene
 Belilovsky, Irina Rish
Categories: cs.LG cs.AI cs.CL
\\ ( https://arxiv.org/abs/2503.05029 ,  3051kb)
------------------------------------------------------------------------------
\\
arXiv:2504.00467
replaced with revised version Mon, 10 Nov 2025 11:53:45 GMT   (1443kb)

Title: Bayesian Network Structural Consensus via Greedy Min-Cut Analysis
Authors: Pablo Torrijos, Jos\'e M. Puerta, Juan A. Aledo, Jos\'e A. G\'amez
Categories: cs.LG
Comments: Camera-ready version accepted at AAAI-26. The official proceedings
 version will appear in the Proceedings of the 40th AAAI Conference on
 Artificial Intelligence (AAAI-26)
\\ ( https://arxiv.org/abs/2504.00467 ,  1443kb)
------------------------------------------------------------------------------
\\
arXiv:2504.06319
replaced with revised version Sat, 8 Nov 2025 02:40:48 GMT   (571kb)

Title: Accelerating LLM Inference Throughput via Asynchronous KV Cache
 Prefetching
Authors: Yanhao Dong, Yubo Miao, Weinan Li, Xiao Zheng, Chao Wang, Jiesheng Wu,
 Feng Lyu
Categories: cs.LG cs.AI
Comments: 8 pages, 5 figures
\\ ( https://arxiv.org/abs/2504.06319 ,  571kb)
------------------------------------------------------------------------------
\\
arXiv:2504.07863
replaced with revised version Mon, 10 Nov 2025 15:06:04 GMT   (1489kb)

Title: Robust Hallucination Detection in LLMs via Adaptive Token Selection
Authors: Mengjia Niu, Hamed Haddadi, Guansong Pang
Categories: cs.LG
Comments: Accepted by NeurIPS 2025
\\ ( https://arxiv.org/abs/2504.07863 ,  1489kb)
------------------------------------------------------------------------------
\\
arXiv:2504.16275
replaced with revised version Fri, 7 Nov 2025 21:08:34 GMT   (1999kb)

Title: Quantum Doubly Stochastic Transformers
Authors: Jannis Born, Filip Skogh, Kahn Rhrissorrakrai, Filippo Utro, Nico
 Wagner, Aleksandros Sobczyk
Categories: cs.LG cs.AI cs.CE cs.CV
Comments: NeurIPS 2025 (Spotlight)
Journal-ref: Advances of Neural Information Processing Systems 2025
\\ ( https://arxiv.org/abs/2504.16275 ,  1999kb)
------------------------------------------------------------------------------
\\
arXiv:2505.12096
replaced with revised version Mon, 10 Nov 2025 17:11:27 GMT   (22388kb)

Title: When Bias Helps Learning: Bridging Initial Prejudice and Trainability
Authors: Alberto Bassi, Marco Baity-Jesi, Aurelien Lucchi, Carlo Albert and
 Emanuele Francazi
Categories: cs.LG cs.AI stat.ML
\\ ( https://arxiv.org/abs/2505.12096 ,  22388kb)
------------------------------------------------------------------------------
\\
arXiv:2505.12387
replaced with revised version Sat, 8 Nov 2025 13:18:40 GMT   (4012kb)

Title: Neural Thermodynamics: Entropic Forces in Deep and Universal
 Representation Learning
Authors: Liu Ziyin, Yizhou Xu, Isaac Chuang
Categories: cs.LG cond-mat.dis-nn cond-mat.stat-mech math-ph math.MP q-bio.NC stat.ML
Comments: Published at NeurIPS 2025
\\ ( https://arxiv.org/abs/2505.12387 ,  4012kb)
------------------------------------------------------------------------------
\\
arXiv:2505.12541
replaced with revised version Fri, 7 Nov 2025 20:38:51 GMT   (61kb)

Title: Private Statistical Estimation via Truncation
Authors: Manolis Zampetakis, Felix Zhou
Categories: cs.LG cs.CR cs.DS stat.ML
Comments: to appear at NeurIPS'25
\\ ( https://arxiv.org/abs/2505.12541 ,  61kb)
------------------------------------------------------------------------------
\\
arXiv:2505.13413
replaced with revised version Sat, 8 Nov 2025 12:53:47 GMT   (20653kb)

Title: Joint Velocity-Growth Flow Matching for Single-Cell Dynamics Modeling
Authors: Dongyi Wang, Yuanwei Jiang, Zhenyi Zhang, Xiang Gu, Peijie Zhou, Jian
 Sun
Categories: cs.LG
\\ ( https://arxiv.org/abs/2505.13413 ,  20653kb)
------------------------------------------------------------------------------
\\
arXiv:2505.14733
replaced with revised version Sun, 9 Nov 2025 19:54:46 GMT   (106kb)

Title: The Energy Cost of Reasoning: Analyzing Energy Usage in LLMs with
 Test-time Compute
Authors: Yunho Jin, Gu-Yeon Wei, David Brooks
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2505.14733 ,  106kb)
------------------------------------------------------------------------------
\\
arXiv:2505.15251
replaced with revised version Mon, 10 Nov 2025 06:28:26 GMT   (3949kb)

Title: Loss-Guided Auxiliary Agents for Overcoming Mode Collapse in GFlowNets
Authors: Idriss Malek, Aya Laajil, Abhijith Sharma, Eric Moulines, Salem Lahlou
Categories: cs.LG
Comments: Accepted to AAAI 2026
\\ ( https://arxiv.org/abs/2505.15251 ,  3949kb)
------------------------------------------------------------------------------
\\
arXiv:2505.15668
replaced with revised version Mon, 10 Nov 2025 18:05:11 GMT   (209kb)

Title: Graph-Conditional Flow Matching for Relational Data Generation
Authors: Davide Scassola, Sebastiano Saccani, Luca Bortolussi
Categories: cs.LG
Comments: 9 pages of main content, accepted to AAAI26 conference
MSC-class: 68T07
\\ ( https://arxiv.org/abs/2505.15668 ,  209kb)
------------------------------------------------------------------------------
\\
arXiv:2505.16649
replaced with revised version Mon, 10 Nov 2025 02:21:05 GMT   (2371kb)

Title: Stochastic Forward-Forward Learning through Representational
 Dimensionality Compression
Authors: Zhichao Zhu, Yang Qi, Hengyuan Ma, Wenlian Lu, Jianfeng Feng
Categories: cs.LG cs.NE
Comments: 14 pages, 9 figures, 2 tables
\\ ( https://arxiv.org/abs/2505.16649 ,  2371kb)
------------------------------------------------------------------------------
\\
arXiv:2505.17004
replaced with revised version Mon, 10 Nov 2025 05:54:16 GMT   (3998kb)

Title: Guided Diffusion Sampling on Function Spaces with Applications to PDEs
Authors: Jiachen Yao, Abbas Mammadov, Julius Berner, Gavin Kerrigan, Jong Chul
 Ye, Kamyar Azizzadenesheli, Anima Anandkumar
Categories: cs.LG cs.AI cs.NA math.NA stat.ML
\\ ( https://arxiv.org/abs/2505.17004 ,  3998kb)
------------------------------------------------------------------------------
\\
arXiv:2505.19712
replaced with revised version Mon, 10 Nov 2025 10:54:53 GMT   (4402kb)

Title: On the Relation between Rectified Flows and Optimal Transport
Authors: Johannes Hertrich, Antonin Chambolle, Julie Delon
Categories: cs.LG math.PR stat.ML
Comments: Accepted for NeurIPS 2025
\\ ( https://arxiv.org/abs/2505.19712 ,  4402kb)
------------------------------------------------------------------------------
\\
arXiv:2505.20535
replaced with revised version Sat, 8 Nov 2025 01:53:01 GMT   (1257kb)

Title: Rotary Masked Autoencoders are Versatile Learners
Authors: Uros Zivanovic, Serafina Di Gioia, Andre Scaffidi, Mart\'in de los
 Rios, Gabriella Contardo, Roberto Trotta
Categories: cs.LG
Comments: NeurIPS 2025 Camera Ready
\\ ( https://arxiv.org/abs/2505.20535 ,  1257kb)
------------------------------------------------------------------------------
\\
arXiv:2505.24434
replaced with revised version Mon, 10 Nov 2025 02:52:17 GMT   (25442kb)

Title: Graph Flow Matching: Enhancing Image Generation with Neighbor-Aware Flow
 Fields
Authors: Md Shahriar Rahim Siddiqui, Moshe Eliasof, Eldad Haber
Categories: cs.LG cs.CV
Comments: The 40th Annual AAAI Conference on Artificial Intelligence
\\ ( https://arxiv.org/abs/2505.24434 ,  25442kb)
------------------------------------------------------------------------------
\\
arXiv:2505.24843
replaced with revised version Mon, 10 Nov 2025 16:59:58 GMT   (1558kb)

Title: From Invariant Representations to Invariant Data: Provable Robustness to
 Spurious Correlations via Noisy Counterfactual Matching
Authors: Ruqi Bai, Yao Ji, Zeyu Zhou, David I. Inouye
Categories: cs.LG
\\ ( https://arxiv.org/abs/2505.24843 ,  1558kb)
------------------------------------------------------------------------------
\\
arXiv:2506.00660
replaced with revised version Sun, 9 Nov 2025 16:10:12 GMT   (2903kb)

Title: Differential privacy for medical deep learning: methods, tradeoffs, and
 deployment implications
Authors: Marziyeh Mohammadi, Mohsen Vejdanihemmat, Mahshad Lotfinia, Mirabela
 Rusu, Daniel Truhn, Andreas Maier, Soroosh Tayebi Arasteh
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2506.00660 ,  2903kb)
------------------------------------------------------------------------------
\\
arXiv:2506.02703
replaced with revised version Mon, 10 Nov 2025 10:30:51 GMT   (395kb)

Title: Data Leakage and Deceptive Performance: A Critical Examination of Credit
 Card Fraud Detection Methodologies
Authors: Khizar Hayat and Baptiste Magnier
Categories: cs.LG cs.AI cs.CY
Journal-ref: Mathematics 2025, 13(16), 2563
DOI: 10.3390/math13162563
\\ ( https://arxiv.org/abs/2506.02703 ,  395kb)
------------------------------------------------------------------------------
\\
arXiv:2506.03163
replaced with revised version Mon, 10 Nov 2025 15:51:13 GMT   (0kb,I)

Title: Causal Discovery in Dynamic Fading Wireless Networks
Authors: Oluwaseyi Giwa
Categories: cs.LG eess.SP stat.ME
Comments: Inaccurate contextual grounding of the methodology explored in the
 paper. This inaccuracy could lead to false results if other researchers read
 and use the method in their projects. To prevent such scenario from
 happening, it is appropriate if this paper is withdrawn. Thank you
\\ ( https://arxiv.org/abs/2506.03163 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2506.04913
replaced with revised version Mon, 10 Nov 2025 12:38:29 GMT   (1568kb)

Title: Dissecting Long-Chain-of-Thought Reasoning Models: An Empirical Study
Authors: Yongyu Mu, Jiali Zeng, Bei Li, Xinyan Guan, Fandong Meng, Jie Zhou,
 Tong Xiao and Jingbo Zhu
Categories: cs.LG cs.CL
Comments: Working in process
\\ ( https://arxiv.org/abs/2506.04913 ,  1568kb)
------------------------------------------------------------------------------
\\
arXiv:2506.10315
replaced with revised version Mon, 10 Nov 2025 15:14:05 GMT   (10971kb)

Title: PyLO: Towards Accessible Learned Optimizers in PyTorch
Authors: Paul Janson, Benjamin Therien, Quentin Anthony, Xiaolong Huang,
 Abhinav Moudgil, Eugene Belilovsky
Categories: cs.LG
Comments: Accepted at ICML CODEML Workshop 2025
\\ ( https://arxiv.org/abs/2506.10315 ,  10971kb)
------------------------------------------------------------------------------
\\
arXiv:2506.17631
replaced with revised version Mon, 10 Nov 2025 12:01:48 GMT   (2755kb)

Title: Time-Prompt: Integrated Heterogeneous Prompts for Unlocking LLMs in Time
 Series Forecasting
Authors: Zesen Wang, Lijuan Lan, Yonggang Li
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2506.17631 ,  2755kb)
------------------------------------------------------------------------------
\\
arXiv:2506.20746
replaced with revised version Mon, 10 Nov 2025 17:00:02 GMT   (2736kb)

Title: Multiple Streams of Knowledge Retrieval: Enriching and Recalling in
 Transformers
Authors: Todd Nief, David Reber, Sean Richardson, Ari Holtzman
Categories: cs.LG
\\ ( https://arxiv.org/abs/2506.20746 ,  2736kb)
------------------------------------------------------------------------------
\\
arXiv:2506.22655
replaced with revised version Fri, 7 Nov 2025 23:02:26 GMT   (6113kb)

Title: Learning Stochastic Multiscale Models
Authors: Andrew F. Ilersich and Prasanth B. Nair
Categories: cs.LG
\\ ( https://arxiv.org/abs/2506.22655 ,  6113kb)
------------------------------------------------------------------------------
\\
arXiv:2506.23165
replaced with revised version Mon, 10 Nov 2025 14:37:45 GMT   (1184kb)

Title: Mirror Descent Policy Optimisation for Robust Constrained Markov
 Decision Processes
Authors: David M. Bossens and Atsushi Nitanda
Categories: cs.LG cs.NE
\\ ( https://arxiv.org/abs/2506.23165 ,  1184kb)
------------------------------------------------------------------------------
\\
arXiv:2507.01693
replaced with revised version Mon, 10 Nov 2025 15:40:58 GMT   (1418kb)

Title: GPT, But Backwards: Exactly Inverting Language Model Outputs
Authors: Adrians Skapars, Edoardo Manino, Youcheng Sun, Lucas C. Cordeiro
Categories: cs.LG cs.AI
Comments: 7 pages, ICML 2025 Workshop on Reliable and Responsible Foundation
 Models
\\ ( https://arxiv.org/abs/2507.01693 ,  1418kb)
------------------------------------------------------------------------------
\\
arXiv:2507.02944
replaced with revised version Sun, 9 Nov 2025 05:46:25 GMT   (1512kb)

Title: Beyond Parallelism: Synergistic Computational Graph Effects in
 Multi-Head Attention
Authors: Haitz S\'aez de Oc\'ariz Borde
Categories: cs.LG
Comments: 16 pages, 4 figures, 6 tables. Accepted at NeurIPS 2025 Workshop on
 Symmetry and Geometry in Neural Representations
\\ ( https://arxiv.org/abs/2507.02944 ,  1512kb)
------------------------------------------------------------------------------
\\
arXiv:2507.07328
replaced with revised version Mon, 10 Nov 2025 04:20:52 GMT   (351kb)

Title: Bridging the Plausibility-Validity Gap by Fine-Tuning a
 Reasoning-Enhanced LLM for Chemical Synthesis and Discovery
Authors: Malikussaid, Hilal Hudan Nuha, Isman Kurniawan
Categories: cs.LG cs.AI cs.CE physics.chem-ph
Comments: 8 pages, 1 equation, 5 tables, to be published in IEEE MCSoC 2025,
 unabridged version exists as arXiv:2507.07328v1
MSC-class: 68T07 (Primary) 92E10, 68T50, 68T30 (Secondary)
ACM-class: I.2.7; J.2; I.2.6; I.2.1
\\ ( https://arxiv.org/abs/2507.07328 ,  351kb)
------------------------------------------------------------------------------
\\
arXiv:2507.08721
replaced with revised version Sat, 8 Nov 2025 11:23:16 GMT   (5006kb)

Title: Monitoring Risks in Test-Time Adaptation
Authors: Mona Schirmer and Metod Jazbec and Christian A. Naesseth and Eric
 Nalisnick
Categories: cs.LG cs.AI stat.ML
\\ ( https://arxiv.org/abs/2507.08721 ,  5006kb)
------------------------------------------------------------------------------
\\
arXiv:2507.13207
replaced with revised version Sat, 8 Nov 2025 12:28:14 GMT   (1296kb)

Title: MoTM: Towards a Foundation Model for Time Series Imputation based on
 Continuous Modeling
Authors: Etienne Le Naour, Tahar Nabil, Ghislain Agoua
Categories: cs.LG
Comments: 10th Workshop on Advanced Analytics and Learning on Temporal Data
 (AALTD), ECML 2025
\\ ( https://arxiv.org/abs/2507.13207 ,  1296kb)
------------------------------------------------------------------------------
\\
arXiv:2507.16795
replaced with revised version Sun, 9 Nov 2025 22:39:01 GMT   (4860kb)

Title: Steering Out-of-Distribution Generalization with Concept Ablation
 Fine-Tuning
Authors: Helena Casademunt, Caden Juang, Adam Karvonen, Samuel Marks,
 Senthooran Rajamanoharan, Neel Nanda
Categories: cs.LG cs.AI cs.CL
\\ ( https://arxiv.org/abs/2507.16795 ,  4860kb)
------------------------------------------------------------------------------
\\
arXiv:2507.23534
replaced with revised version Mon, 10 Nov 2025 03:21:00 GMT   (8036kb)

Title: Continual Learning with Synthetic Boundary Experience Blending
Authors: Chih-Fan Hsu, Ming-Ching Chang, Wei-Chao Chen
Categories: cs.LG cs.CV
\\ ( https://arxiv.org/abs/2507.23534 ,  8036kb)
------------------------------------------------------------------------------
\\
arXiv:2508.00357
replaced with revised version Sun, 9 Nov 2025 10:24:49 GMT   (1470kb)

Title: Sheaf Graph Neural Networks via PAC-Bayes Spectral Optimization
Authors: Yoonhyuk Choi, Jiho Choi, Chong-Kwon Kim
Categories: cs.LG
Comments: AAAI 2026
\\ ( https://arxiv.org/abs/2508.00357 ,  1470kb)
------------------------------------------------------------------------------
\\
arXiv:2508.00903
replaced with revised version Sun, 9 Nov 2025 03:00:24 GMT   (5868kb)

Title: Universal Neurons in GPT-2: Emergence, Persistence, and Functional
 Impact
Authors: Advey Nandan, Cheng-Ting Chou, Amrit Kurakula, Cole Blondin, Kevin
 Zhu, Vasu Sharma, Sean O'Brien
Categories: cs.LG cs.AI cs.NE
\\ ( https://arxiv.org/abs/2508.00903 ,  5868kb)
------------------------------------------------------------------------------
\\
arXiv:2508.05144
replaced with revised version Sun, 9 Nov 2025 14:39:28 GMT   (1101kb)

Title: PSEO: Optimizing Post-hoc Stacking Ensemble Through Hyperparameter
 Tuning
Authors: Beicheng Xu, Wei Liu, Keyao Ding, Yupeng Lu, Bin Cui
Categories: cs.LG
\\ ( https://arxiv.org/abs/2508.05144 ,  1101kb)
------------------------------------------------------------------------------
\\
arXiv:2508.06986
replaced with revised version Sat, 8 Nov 2025 14:44:15 GMT   (810kb)

Title: UniMove: A Unified Model for Multi-city Human Mobility Prediction
Authors: Chonghua Han, Yuan Yuan, Yukun Liu, Jingtao Ding, Jie Feng, Yong Li
Categories: cs.LG
Comments: Accepted by SIGSPATIAL 2025
\\ ( https://arxiv.org/abs/2508.06986 ,  810kb)
------------------------------------------------------------------------------
\\
arXiv:2508.07392
replaced with revised version Mon, 10 Nov 2025 14:22:44 GMT   (17145kb)

Title: Tight Bounds for Schr\"odinger Potential Estimation in Unpaired Data
 Translation
Authors: Nikita Puchkin, Denis Suchkov, Alexey Naumov, Denis Belomestny
Categories: cs.LG math.ST stat.ML stat.TH
Comments: 54 pages, 4 figures
\\ ( https://arxiv.org/abs/2508.07392 ,  17145kb)
------------------------------------------------------------------------------
\\
arXiv:2508.07659
replaced with revised version Mon, 10 Nov 2025 02:06:30 GMT   (6955kb)

Title: Discovering Spatial Correlations of Earth Observations for weather
 forecasting by using Graph Structure Learning
Authors: Hyeon-Ju Jeon, Jeon-Ho Kang, In-Hyuk Kwon, O-Joun Lee
Categories: cs.LG cs.AI
Comments: 8 pages
DOI: 10.1145/3769002.3769956
\\ ( https://arxiv.org/abs/2508.07659 ,  6955kb)
------------------------------------------------------------------------------
\\
arXiv:2508.08875
replaced with revised version Sat, 8 Nov 2025 06:01:37 GMT   (37076kb)

Title: Oblivionis: A Lightweight Learning and Unlearning Framework for
 Federated Large Language Models
Authors: Fuyao Zhang, Xinyu Yan, Tiantong Wu, Wenjie Li, Tianxiang Chen, Yang
 Cao, Ran Yan, Longtao Huang, Wei Yang Bryan Lim, Qiang Yang
Categories: cs.LG cs.AI cs.CR
\\ ( https://arxiv.org/abs/2508.08875 ,  37076kb)
------------------------------------------------------------------------------
\\
arXiv:2508.10684
replaced with revised version Sat, 8 Nov 2025 03:10:03 GMT   (2883kb)

Title: MDNS: Masked Diffusion Neural Sampler via Stochastic Optimal Control
Authors: Yuchen Zhu, Wei Guo, Jaemoo Choi, Guan-Horng Liu, Yongxin Chen, Molei
 Tao
Categories: cs.LG math.OC stat.CO stat.ML
Comments: NeurIPS 2025
\\ ( https://arxiv.org/abs/2508.10684 ,  2883kb)
------------------------------------------------------------------------------
\\
arXiv:2508.12104
replaced with revised version Fri, 7 Nov 2025 23:40:06 GMT   (3160kb)

Title: Generative Medical Event Models Improve with Scale
Authors: Shane Waxler, Paul Blazek, Davis White, Daniel Sneider, Kevin Chung,
 Mani Nagarathnam, Patrick Williams, Hank Voeller, Karen Wong, Matthew
 Swanhorst, Sheng Zhang, Naoto Usuyama, Cliff Wong, Tristan Naumann, Hoifung
 Poon, Andrew Loza, Daniella Meeker, Seth Hain, and Rahul Shah
Categories: cs.LG cs.AI cs.CL
\\ ( https://arxiv.org/abs/2508.12104 ,  3160kb)
------------------------------------------------------------------------------
\\
arXiv:2508.12997
replaced with revised version Sat, 8 Nov 2025 14:50:53 GMT   (1735kb)

Title: Fairness-Aware Multi-view Evidential Learning with Adaptive Prior
Authors: Haishun Chen, Cai Xu, Jinlong Yu, Yilin Zhang, Ziyu Guan, Wei Zhao,
 Fangyuan Zhao, Xin Yang
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/2508.12997 ,  1735kb)
------------------------------------------------------------------------------
\\
arXiv:2508.17032
replaced with revised version Fri, 7 Nov 2025 21:01:10 GMT   (2238kb)

Title: Learned Structure in Cartridges: Keys as Shareable Routers in
 Self-Studied Representations
Authors: Maurizio Diaz
Categories: cs.LG
\\ ( https://arxiv.org/abs/2508.17032 ,  2238kb)
------------------------------------------------------------------------------
\\
arXiv:2508.18258
replaced with revised version Mon, 10 Nov 2025 15:31:41 GMT   (710kb)

Title: ANO : Faster is Better in Noisy Landscape
Authors: Adrien Kegreisz
Categories: cs.LG cs.AI
Comments: Under Review for ICLR 2026, 25 pages total with appendix, 7 figures,
 12 tables
\\ ( https://arxiv.org/abs/2508.18258 ,  710kb)
------------------------------------------------------------------------------
\\
arXiv:2508.20013
replaced with revised version Sun, 9 Nov 2025 13:18:27 GMT   (1455kb)

Title: Cross-Platform E-Commerce Product Categorization and Recategorization: A
 Multimodal Hierarchical Classification Approach
Authors: Lotte Gross, Rebecca Walter, Nicole Zoppi, Adrien Justus, Alessandro
 Gambetti, Qiwei Han, Maximilian Kaiser
Categories: cs.LG cs.AI cs.IR
Comments: Accetped at IEEE BigData 2025, 10 pages, 5 figures, 3 tables
\\ ( https://arxiv.org/abs/2508.20013 ,  1455kb)
------------------------------------------------------------------------------
\\
arXiv:2509.02803
replaced with revised version Sun, 9 Nov 2025 02:45:32 GMT   (383kb)

Title: A Graph Laplacian Eigenvector-based Pre-training Method for Graph Neural
 Networks
Authors: Howard Dai, Nyambura Njenga, Hiren Madhu, Siddharth Viswanath, Ryan
 Pellico, Ian Adelstein, Smita Krishnaswamy
Categories: cs.LG
\\ ( https://arxiv.org/abs/2509.02803 ,  383kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05281
replaced with revised version Sun, 9 Nov 2025 16:28:13 GMT   (4641kb)

Title: Dual-Branch Convolutional Framework for Spatial and Frequency-Based
 Image Forgery Detection
Authors: Naman Tyagi and Riya Jain
Categories: cs.LG
Comments: 14 pages, 5 figures
\\ ( https://arxiv.org/abs/2509.05281 ,  4641kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08625
replaced with revised version Sun, 9 Nov 2025 02:23:29 GMT   (388kb)

Title: An upper bound of the silhouette validation metric for clustering
Authors: Hugo Str\"ang, Tai Dinh
Categories: cs.LG
\\ ( https://arxiv.org/abs/2509.08625 ,  388kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08736
replaced with revised version Mon, 10 Nov 2025 15:52:53 GMT   (1494kb)

Title: ChemBOMAS: Accelerated BO in Chemistry with LLM-Enhanced Multi-Agent
 System
Authors: Dong Han, Zhehong Ai, Pengxiang Cai, Shanya Lu, Jianpeng Chen, Zihao
 Ye, Shuzhou Sun, Ben Gao, Lingli Ge, Weida Wang, Xiangxin Zhou, Xihui Liu,
 Mao Su, Wanli Ouyang, Lei Bai, Dongzhan Zhou, Tao Xu, Yuqiang Li, Shufei
 Zhang
Categories: cs.LG
\\ ( https://arxiv.org/abs/2509.08736 ,  1494kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10516
replaced with revised version Mon, 10 Nov 2025 14:44:47 GMT   (2280kb)

Title: Privacy-Preserving Personalization in Education: A Federated Recommender
 System for Student Performance Prediction
Authors: Rodrigo Tertulino, Ricardo Almeida
Categories: cs.LG cs.AI cs.CY
\\ ( https://arxiv.org/abs/2509.10516 ,  2280kb)
------------------------------------------------------------------------------
\\
arXiv:2509.12344
replaced with revised version Sun, 9 Nov 2025 03:56:00 GMT   (15672kb)

Title: FEDONet : Fourier-Embedded DeepONet for Spectrally Accurate Operator
 Learning
Authors: Arth Sojitra, Mrigank Dhingra, Omer San
Categories: cs.LG
\\ ( https://arxiv.org/abs/2509.12344 ,  15672kb)
------------------------------------------------------------------------------
\\
arXiv:2509.15816
replaced with revised version Sun, 9 Nov 2025 08:11:57 GMT   (169kb)

Title: On the Convergence of Muon and Beyond
Authors: Da Chang, Yongxiang Liu, Ganzhao Yuan
Categories: cs.LG
\\ ( https://arxiv.org/abs/2509.15816 ,  169kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19406
replaced with revised version Mon, 10 Nov 2025 13:17:12 GMT   (6213kb)

Title: TimeMosaic: Temporal Heterogeneity Guided Time Series Forecasting via
 Adaptive Granularity Patch and Segment-wise Decoding
Authors: Kuiye Ding and Fanda Fan and Chunyi Hou and Zheya Wang and Lei Wang
 and Zhengxin Yang and Jianfeng Zhan
Categories: cs.LG cs.AI
Comments: This paper has been accepted by AAAI
\\ ( https://arxiv.org/abs/2509.19406 ,  6213kb)
------------------------------------------------------------------------------
\\
arXiv:2509.23089
replaced with revised version Sat, 8 Nov 2025 23:32:07 GMT   (218kb)

Title: Demystifying Network Foundation Models
Authors: Sylee Beltiukov, Satyandra Guthula, Wenbo Guo, Walter Willinger, Arpit
 Gupta
Categories: cs.LG cs.NI
\\ ( https://arxiv.org/abs/2509.23089 ,  218kb)
------------------------------------------------------------------------------
\\
arXiv:2510.00574
replaced with revised version Sun, 9 Nov 2025 06:41:21 GMT   (47kb)

Title: Private Online Learning against an Adaptive Adversary: Realizable and
 Agnostic Settings
Authors: Bo Li, Wei Wang, Peng Ye
Categories: cs.LG
\\ ( https://arxiv.org/abs/2510.00574 ,  47kb)
------------------------------------------------------------------------------
\\
arXiv:2510.00885
replaced with revised version Mon, 10 Nov 2025 12:09:59 GMT   (46kb)

Title: Rectifying Regression in Reinforcement Learning
Authors: Alex Ayoub, David Szepesv\'ari, Alireza Bakhtiari, Csaba Szepesv\'ari,
 Dale Schuurmans
Categories: cs.LG
\\ ( https://arxiv.org/abs/2510.00885 ,  46kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04058
replaced with revised version Mon, 10 Nov 2025 13:26:21 GMT   (18537kb)

Title: Variational Diffusion Unlearning: A Variational Inference Framework for
 Unlearning in Diffusion Models under Data Constraints
Authors: Subhodip Panda, MS Varun, Shreyans Jain, Sarthak Kumar Maharana and
 Prathosh A.P
Categories: cs.LG
\\ ( https://arxiv.org/abs/2510.04058 ,  18537kb)
------------------------------------------------------------------------------
\\
arXiv:2510.06367
replaced with revised version Mon, 10 Nov 2025 18:25:10 GMT   (224kb)

Title: Lagrangian neural ODEs: Measuring the existence of a Lagrangian with
 Helmholtz metrics
Authors: Luca Wolf, Tobias Buck, Bjoern Malte Schaefer
Categories: cs.LG math.DS physics.comp-ph physics.data-an
Comments: Accepted for the NeurIPS 2025 Machine Learning and the Physical
 Sciences workshop. 6 pages, 3 figures
\\ ( https://arxiv.org/abs/2510.06367 ,  224kb)
------------------------------------------------------------------------------
\\
arXiv:2510.06557
replaced with revised version Mon, 10 Nov 2025 03:21:14 GMT   (764kb)

Title: The Markovian Thinker
Authors: Milad Aghajohari, Kamran Chitsaz, Amirhossein Kazemnejad, Sarath
 Chandar, Alessandro Sordoni, Aaron Courville, Siva Reddy
Categories: cs.LG cs.AI cs.CL
\\ ( https://arxiv.org/abs/2510.06557 ,  764kb)
------------------------------------------------------------------------------
\\
arXiv:2510.08662
replaced with revised version Mon, 10 Nov 2025 14:28:13 GMT   (1109kb)

Title: DPCformer: An Interpretable Deep Learning Model for Genomic Prediction
 in Crops
Authors: Pengcheng Deng, Kening Liu, Mengxi Zhou, Mingxi Li, Rui Yang, Chuzhe
 Cao, Maojun Wang, Zeyu Zhang
Categories: cs.LG cs.AI
Comments: This work has been accepted by BIBM 2025
\\ ( https://arxiv.org/abs/2510.08662 ,  1109kb)
------------------------------------------------------------------------------
\\
arXiv:2510.09041
replaced with revised version Sat, 8 Nov 2025 06:11:19 GMT   (1188kb)

Title: Robust Driving Control for Autonomous Vehicles: An Intelligent
 General-sum Constrained Adversarial Reinforcement Learning Approach
Authors: Junchao Fan, Qi Wei, Ruichen Zhang, Dusit Niyato, Yang Lu, Jianhua
 Wang, Xiaolin Chang, and Bo Ai
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2510.09041 ,  1188kb)
------------------------------------------------------------------------------
\\
arXiv:2510.10211
replaced with revised version Sat, 8 Nov 2025 00:57:35 GMT   (0kb,I)

Title: Hierarchical Bayesian Flow Networks for Molecular Graph Generation
Authors: Yida Xiong, Jiameng Chen, Kun Li, Hongzhi Zhang, Xiantao Cai, Wenbin
 Hu
Categories: cs.LG
Comments: For better performance and efficiency, the model has undergone
 significant updates, and we will upload the latest work as soon as possible
\\ ( https://arxiv.org/abs/2510.10211 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2510.17383
replaced with revised version Mon, 10 Nov 2025 10:23:35 GMT   (1342kb)

Title: The Evolving Nature of Latent Spaces: From GANs to Diffusion
Authors: Ludovica Schaerf
Categories: cs.LG cs.CV cs.CY
Comments: Presented and published at Ethics and Aesthetics of Artificial
 Intelligence Conference (EA-AI'25)
\\ ( https://arxiv.org/abs/2510.17383 ,  1342kb)
------------------------------------------------------------------------------
\\
arXiv:2510.17486
replaced with revised version Fri, 7 Nov 2025 19:39:45 GMT   (291kb)

Title: Local properties of neural networks through the lens of layer-wise
 Hessians
Authors: Maxim Bolshim (1) and Alexander Kugaevskikh (1) ((1) ITMO University,
 Saint Petersburg, Russia)
Categories: cs.LG
Comments: Comments: 22 pages, 8 figures. Submitted to arXiv:cs.LG
MSC-class: 68T07, 68T05, 65K10, 90C30
ACM-class: I.2.6; G.1.6; I.5.1
\\ ( https://arxiv.org/abs/2510.17486 ,  291kb)
------------------------------------------------------------------------------
\\
arXiv:2510.18406
replaced with revised version Mon, 10 Nov 2025 07:41:24 GMT   (6576kb)

Title: Learning from N-Tuple Data with M Positive Instances: Unbiased Risk
 Estimation and Theoretical Guarantees
Authors: Miao Zhang, Junpeng Li, ChangChun HUa, Yana Yang
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2510.18406 ,  6576kb)
------------------------------------------------------------------------------
\\
arXiv:2510.18784
replaced with revised version Mon, 10 Nov 2025 17:53:51 GMT   (247kb)

Title: CAGE: Curvature-Aware Gradient Estimation For Accurate
 Quantization-Aware Training
Authors: Soroush Tabesh, Mher Safaryan, Andrei Panferov, Alexandra Volkova, Dan
 Alistarh
Categories: cs.LG
\\ ( https://arxiv.org/abs/2510.18784 ,  247kb)
------------------------------------------------------------------------------
\\
arXiv:2510.19672
replaced with revised version Sun, 9 Nov 2025 02:02:00 GMT   (4609kb)

Title: Policy Learning with Abstention
Authors: Ayush Sawarni, Jikai Jin, Justin Whitehouse, Vasilis Syrgkanis
Categories: cs.LG econ.EM stat.ML
\\ ( https://arxiv.org/abs/2510.19672 ,  4609kb)
------------------------------------------------------------------------------
\\
arXiv:2510.25108
replaced with revised version Fri, 7 Nov 2025 19:17:34 GMT   (123kb)

Title: Shift is Good: Mismatched Data Mixing Improves Test Performance
Authors: Marko Medvedev, Kaifeng Lyu, Zhiyuan Li, Nathan Srebro
Categories: cs.LG stat.ML
Comments: Changes: Fixed small typesetting errors
\\ ( https://arxiv.org/abs/2510.25108 ,  123kb)
------------------------------------------------------------------------------
\\
arXiv:2510.27486
replaced with revised version Mon, 10 Nov 2025 16:37:40 GMT   (7588kb)

Title: FedAdamW: A Communication-Efficient Optimizer with Convergence and
 Generalization Guarantees for Federated Large Models
Authors: Junkang Liu and Fanhua Shang and Kewen Zhu and Hongying Liu and
 Yuanyuan Liu and Jin Liu
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2510.27486 ,  7588kb)
------------------------------------------------------------------------------
\\
arXiv:2511.00051
replaced with revised version Mon, 10 Nov 2025 09:39:41 GMT   (347kb)

Title: Calibrating and Rotating: A Unified Framework for Weight Conditioning in
 PEFT
Authors: Da Chang, Peng Xue, Yu Li, Yongxiang Liu, Pengxiang Xu, Shixun Zhang
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2511.00051 ,  347kb)
------------------------------------------------------------------------------
\\
arXiv:2511.00065
replaced with revised version Mon, 10 Nov 2025 02:52:40 GMT   (15069kb)

Title: Aligning Brain Signals with Multimodal Speech and Vision Embeddings
Authors: Kateryna Shapovalenko, Quentin Auster
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2511.00065 ,  15069kb)
------------------------------------------------------------------------------
\\
arXiv:2511.00521
replaced with revised version Mon, 10 Nov 2025 03:30:17 GMT   (528kb)

Title: Reasoning Planning for Language Models
Authors: Bao Nguyen, Hieu Trung Nguyen, Ruifeng She, Xiaojin Fu, Viet Anh
 Nguyen
Categories: cs.LG cs.AI cs.CL
Comments: 27 pages, 5 figures
\\ ( https://arxiv.org/abs/2511.00521 ,  528kb)
------------------------------------------------------------------------------
\\
arXiv:2511.00663
replaced with revised version Mon, 10 Nov 2025 18:07:41 GMT   (2647kb)

Title: Sensitivity Analysis for Climate Science with Generative Flow Models
Authors: Alex Dobra, Jakiw Pidstrigach, Tim Reichelt, Christian Schroeder de
 Witt, Philip Torr, Philip Stier
Categories: cs.LG
\\ ( https://arxiv.org/abs/2511.00663 ,  2647kb)
------------------------------------------------------------------------------
\\
arXiv:2511.00804
replaced with revised version Sun, 9 Nov 2025 05:29:02 GMT   (42941kb)

Title: EraseFlow: Learning Concept Erasure Policies via GFlowNet-Driven
 Alignment
Authors: Abhiram Kusumba, Maitreya Patel, Kyle Min, Changhoon Kim, Chitta
 Baral, Yezhou Yang
Categories: cs.LG cs.CV
Comments: NeurIPS'25 Spotlight | Project page: https://eraseflow.github.io/
\\ ( https://arxiv.org/abs/2511.00804 ,  42941kb)
------------------------------------------------------------------------------
\\
arXiv:2511.01836
replaced with revised version Sun, 9 Nov 2025 08:26:10 GMT   (38748kb)

Title: Priors in Time: Missing Inductive Biases for Language Model
 Interpretability
Authors: Ekdeep Singh Lubana, Can Rager, Sai Sumedh R. Hindupur, Valerie Costa,
 Greta Tuckute, Oam Patel, Sonia Krishna Murthy, Thomas Fel, Daniel Wurgaft,
 Eric J. Bigelow, Johnny Lin, Demba Ba, Martin Wattenberg, Fernanda Viegas,
 Melanie Weber, Aaron Mueller
Categories: cs.LG
Comments: Preprint
\\ ( https://arxiv.org/abs/2511.01836 ,  38748kb)
------------------------------------------------------------------------------
\\
arXiv:2511.01934
replaced with revised version Mon, 10 Nov 2025 16:36:41 GMT   (626kb)

Title: Tool Zero: Training Tool-Augmented LLMs via Pure RL from Scratch
Authors: Yirong Zeng, Xiao Ding, Yutai Hou, Yuxian Wang, Li Du, Juyi Dai,
 Qiuyang Ding, Duyu Tang, Dandan Tu, Weiwen Liu, Bing Qin, Ting Liu
Categories: cs.LG cs.AI
Comments: EMNLP 2025 finding
\\ ( https://arxiv.org/abs/2511.01934 ,  626kb)
------------------------------------------------------------------------------
\\
arXiv:2511.02029
replaced with revised version Sat, 8 Nov 2025 00:25:01 GMT   (7336kb)

Title: RobustFSM: Submodular Maximization in Federated Setting with Malicious
 Clients
Authors: Duc A. Tran and Dung Truong and Duy Le
Categories: cs.LG cs.AI cs.DC
Comments: 9 pages
Journal-ref: Proceedings of the IEEE International Conference on Big Data (IEEE
 BigData 2025)
\\ ( https://arxiv.org/abs/2511.02029 ,  7336kb)
------------------------------------------------------------------------------
\\
arXiv:2511.02481
replaced with revised version Mon, 10 Nov 2025 17:57:10 GMT   (22796kb)

Title: NOWS: Neural Operator Warm Starts for Accelerating Iterative Solvers
Authors: Mohammad Sadegh Eshaghi, Cosmin Anitescu, Navid Valizadeh, Yizheng
 Wang, Xiaoying Zhuang, Timon Rabczuk
Categories: cs.LG
\\ ( https://arxiv.org/abs/2511.02481 ,  22796kb)
------------------------------------------------------------------------------
\\
arXiv:2511.02894
replaced with revised version Mon, 10 Nov 2025 00:01:56 GMT   (11554kb)

Title: Adaptive and Robust Data Poisoning Detection and Sanitization in
 Wearable IoT Systems using Large Language Models
Authors: W.K.M Mithsara, Ning Yang, Ahmed Imteaj, Hussein Zangoti, Abdur R.
 Shahid
Categories: cs.LG cs.CR
\\ ( https://arxiv.org/abs/2511.02894 ,  11554kb)
------------------------------------------------------------------------------
\\
arXiv:2511.03239
replaced with revised version Sun, 9 Nov 2025 18:27:29 GMT   (489kb)

Title: A Feedback-Control Framework for Efficient Dataset Collection from
 In-Vehicle Data Streams
Authors: Philipp Reis, Philipp Rigoll, Christian Steinhauser, Jacob Langner,
 and Eric Sax
Categories: cs.LG cs.CV
Comments: 7 Pages, Submitted to IEEE Intelligent Vehicles Symposium 2026
\\ ( https://arxiv.org/abs/2511.03239 ,  489kb)
------------------------------------------------------------------------------
\\
arXiv:2511.04505
replaced with revised version Sat, 8 Nov 2025 02:46:09 GMT   (19kb)

Title: Alternative Fairness and Accuracy Optimization in Criminal Justice
Authors: Shaolong Wu, James Blume, Geshi Yeung
Categories: cs.LG cs.AI cs.CY
Comments: In Proceedings of the the 3rd International AI Governance Workshop
 (AIGOV), AAAI 2026
Journal-ref: Proceedings of the the 3rd International AI Governance Workshop
 (AIGOV), AAAI 2026
\\ ( https://arxiv.org/abs/2511.04505 ,  19kb)
------------------------------------------------------------------------------
\\
arXiv:2511.04638
replaced with revised version Sun, 9 Nov 2025 20:35:15 GMT   (6122kb)

Title: Addressing divergent representations from causal interventions on neural
 networks
Authors: Satchel Grant, Simon Jerome Han, Alexa R. Tartaglini, Christopher
 Potts
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2511.04638 ,  6122kb)
------------------------------------------------------------------------------
\\
arXiv:2511.04647
replaced with revised version Sun, 9 Nov 2025 04:30:18 GMT   (40kb)

Title: Optimal Inference Schedules for Masked Diffusion Models
Authors: Sitan Chen, Kevin Cong, Jerry Li
Categories: cs.LG
Comments: 33 pages, 1 figure. [added discussion of additional related work]
\\ ( https://arxiv.org/abs/2511.04647 ,  40kb)
------------------------------------------------------------------------------
\\
arXiv:2511.04659
replaced with revised version Mon, 10 Nov 2025 13:55:46 GMT   (19537kb)

Title: Nowcast3D: Reliable precipitation nowcasting via gray-box learning
Authors: Huaguan Chen, Wei Han, Haofei Sun, Ning Lin, Xingtao Song, Yunfan
 Yang, Jie Tian, Yang Liu, Ji-Rong Wen, Xiaoye Zhang, Xueshun Shen, Hao Sun
Categories: cs.LG physics.ao-ph
\\ ( https://arxiv.org/abs/2511.04659 ,  19537kb)
------------------------------------------------------------------------------
\\
arXiv:2406.01044 (*cross-listing*)
replaced with revised version Sat, 8 Nov 2025 03:19:26 GMT   (205kb)

Title: Nuclear Medicine AI in Action: The Bethesda Report (AI Summit 2024)
Authors: Arman Rahmim, Tyler J. Bradshaw, Guido Davidzon, Joyita Dutta, Georges
 El Fakhri, Munir Ghesani, Nicolas A. Karakatsanis, Quanzheng Li, Chi Liu,
 Emilie Roncali, Babak Saboury, Tahir Yusufaly, Abhinav K. Jha
Categories: physics.med-ph cs.AI
\\ ( https://arxiv.org/abs/2406.01044 ,  205kb)
------------------------------------------------------------------------------
\\
arXiv:2406.16995 (*cross-listing*)
replaced with revised version Sat, 8 Nov 2025 05:41:56 GMT   (1884kb)

Title: tcrLM: a lightweight protein language model for predicting T cell
 receptor and epitope binding specificity
Authors: Xing Fang, Chenpeng Yu, Shiye Tian, Hui Liu
Categories: q-bio.QM cs.AI
\\ ( https://arxiv.org/abs/2406.16995 ,  1884kb)
------------------------------------------------------------------------------
\\
arXiv:2409.09684 (*cross-listing*)
replaced with revised version Sun, 9 Nov 2025 09:34:25 GMT   (314kb)

Title: Return Prediction for Mean-Variance Portfolio Selection: How
 Decision-Focused Learning Shapes Forecasting Models
Authors: Junhyeong Lee, Haeun Jeon, Hyunglip Bae, Yongjae Lee
Categories: q-fin.PM cs.AI
Comments: 9 pages, 5 figures, 2 tables
DOI: 10.1145/3768292.3770423
\\ ( https://arxiv.org/abs/2409.09684 ,  314kb)
------------------------------------------------------------------------------
\\
arXiv:2410.12538
replaced with revised version Sun, 9 Nov 2025 14:27:51 GMT   (4928kb)

Title: Automated Vehicles at Unsignalized Intersections: Safety and Efficiency
 Implications of Mixed Human and Automated Traffic
Authors: Saeed Rahmani, Zhenlin Xu, Simeon C. Calvert, Bart van Arem
Categories: cs.RO cs.AI stat.AP
Comments: Published OnlineFirst in Transportation Research Record (TRR), DOI:
 10.1177/03611981251370343
DOI: 10.1177/03611981251370343
\\ ( https://arxiv.org/abs/2410.12538 ,  4928kb)
------------------------------------------------------------------------------
\\
arXiv:2410.21673
replaced with revised version Mon, 10 Nov 2025 00:13:25 GMT   (1666kb)

Title: Knowledge-Guided Prompt Learning for Request Quality Assurance in Public
 Code Review
Authors: Lin Li, Xinchun Yu, Xinyu Chen, Peng Liang
Categories: cs.SE cs.AI
Comments: Preprint accepted for publication in ACM Transactions on Software
 Engineering and Methodology (TOSEM), 2025
\\ ( https://arxiv.org/abs/2410.21673 ,  1666kb)
------------------------------------------------------------------------------
\\
arXiv:2412.12987 (*cross-listing*)
replaced with revised version Sun, 9 Nov 2025 22:00:53 GMT   (1099kb)

Title: Stochastic interior-point methods for smooth conic optimization with
 applications
Authors: Chuan He, Zhanwang Deng
Categories: math.OC cs.AI cs.LG
Comments: Accepted by Journal of Machine Learning Research
MSC-class: 90C25, 90C30
\\ ( https://arxiv.org/abs/2412.12987 ,  1099kb)
------------------------------------------------------------------------------
\\
arXiv:2412.14194
replaced with revised version Fri, 7 Nov 2025 20:58:32 GMT   (418kb)

Title: Feasibility of Detecting Cognitive Impairment and Psychological
 Well-being among Older Adults Using Facial, Acoustic, Linguistic, and
 Cardiovascular Patterns Derived from Remote Conversations
Authors: Xiaofan Mu, Merna Bibars, Salman Seyedi, Iris Zheng, Zifan Jiang, Liu
 Chen, Bolaji Omofojoye, Rachel Hershenberg, Allan I. Levey, Gari D. Clifford,
 Hiroko H. Dodge, Hyeokhyen Kwon
Categories: cs.HC cs.AI
\\ ( https://arxiv.org/abs/2412.14194 ,  418kb)
------------------------------------------------------------------------------
\\
arXiv:2503.08936
replaced with revised version Sun, 9 Nov 2025 21:15:21 GMT   (3794kb)

Title: Simulator Ensembles for Trustworthy Autonomous Driving Testing
Authors: Lev Sorokin, Matteo Biagiola, Andrea Stocco
Categories: cs.SE cs.AI cs.RO
\\ ( https://arxiv.org/abs/2503.08936 ,  3794kb)
------------------------------------------------------------------------------
\\
arXiv:2503.21514 (*cross-listing*)
replaced with revised version Mon, 10 Nov 2025 06:36:31 GMT   (2761kb)

Title: Quantitative Evaluation of Quantum/Classical Neural Network Using a Game
 Solver Metric
Authors: Suzukaze Kamei, Hideaki Kawaguchi, Shin Nishio and Takahiko Satoh
Categories: quant-ph cs.AI cs.LG
Comments: 12 pages, 15 figures
\\ ( https://arxiv.org/abs/2503.21514 ,  2761kb)
------------------------------------------------------------------------------
\\
arXiv:2505.01185
replaced with revised version Mon, 10 Nov 2025 13:09:10 GMT   (36453kb)

Title: Environment-Aware Indoor LoRaWAN Ranging Using Path Loss Model Inversion
 and Adaptive RSSI Filtering
Authors: Nahshon Mokua Obiri and Kristof Van Laerhoven
Categories: cs.NI cs.AI cs.LG eess.SP
\\ ( https://arxiv.org/abs/2505.01185 ,  36453kb)
------------------------------------------------------------------------------
\\
arXiv:2505.07096
replaced with revised version Sun, 9 Nov 2025 01:00:32 GMT   (10620kb)

Title: X-Sim: Cross-Embodiment Learning via Real-to-Sim-to-Real
Authors: Prithwish Dan and Kushal Kedia and Angela Chao and Edward Weiyi Duan
 and Maximus Adrian Pace and Wei-Chiu Ma and Sanjiban Choudhury
Categories: cs.RO cs.AI cs.LG
\\ ( https://arxiv.org/abs/2505.07096 ,  10620kb)
------------------------------------------------------------------------------
\\
arXiv:2506.00934
replaced with revised version Mon, 10 Nov 2025 10:58:32 GMT   (1855kb)

Title: GRAM: Spatial general-purpose audio representation models for real-world
 applications
Authors: Goksenin Yuksel, Marcel van Gerven, Kiki van der Heijden
Categories: cs.SD cs.AI eess.AS
Comments: Still under review
\\ ( https://arxiv.org/abs/2506.00934 ,  1855kb)
------------------------------------------------------------------------------
\\
arXiv:2506.06344 (*cross-listing*)
replaced with revised version Sat, 8 Nov 2025 15:42:34 GMT   (1002kb)

Title: A Fairness-Aware Strategy for B5G Physical-layer Security Leveraging
 Reconfigurable Intelligent Surfaces
Authors: Alex Pierron, Michel Barbeau, Luca De Cicco, Jose Rubio-Hernan,
 Joaquin Garcia-Alfaro
Categories: eess.SP cs.AI cs.LG
Comments: 19 pages, 5 figures, 2 tables, 35 references
\\ ( https://arxiv.org/abs/2506.06344 ,  1002kb)
------------------------------------------------------------------------------
\\
arXiv:2506.07315 (*cross-listing*)
replaced with revised version Sat, 8 Nov 2025 07:11:54 GMT   (4387kb)

Title: Towards Competent AI for Fundamental Analysis in Finance: A Benchmark
 Dataset and Evaluation
Authors: Zonghan Wu, Congyuan Zou, Junlin Wang, Chenhan Wang, Hangjing Yang,
 Yilei Shao
Categories: q-fin.ST cs.AI
\\ ( https://arxiv.org/abs/2506.07315 ,  4387kb)
------------------------------------------------------------------------------
\\
arXiv:2507.02735
replaced with revised version Mon, 10 Nov 2025 16:30:10 GMT   (186kb)

Title: Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks
Authors: Sizhe Chen, Arman Zharmagambetov, David Wagner, Chuan Guo
Categories: cs.CR cs.AI
\\ ( https://arxiv.org/abs/2507.02735 ,  186kb)
------------------------------------------------------------------------------
\\
arXiv:2507.05269
replaced with revised version Fri, 7 Nov 2025 22:38:06 GMT   (1077kb)

Title: CoRe: Benchmarking LLMs Code Reasoning Capabilities through Static
 Analysis Tasks
Authors: Danning Xie, Mingwei Zheng, Xuwei Liu, Jiannan Wang, Chengpeng Wang,
 Lin Tan, Xiangyu Zhang
Categories: cs.SE cs.AI
Comments: NeurIPS 2025 Datasets & Benchmarks Spotlight
\\ ( https://arxiv.org/abs/2507.05269 ,  1077kb)
------------------------------------------------------------------------------
\\
arXiv:2507.08540
replaced with revised version Sun, 9 Nov 2025 15:19:55 GMT   (87kb)

Title: White-Basilisk: A Hybrid Model for Code Vulnerability Detection
Authors: Ioannis Lamprou, Alexander Shevtsov, Ioannis Arapakis, Sotiris
 Ioannidis
Categories: cs.CR cs.AI
\\ ( https://arxiv.org/abs/2507.08540 ,  87kb)
------------------------------------------------------------------------------
\\
arXiv:2507.10639
replaced with revised version Fri, 7 Nov 2025 14:25:55 GMT   (678kb)

Title: Evaluating LLM-based Workflows for Switched-Mode Power Supply Design
Authors: Simon Nau, Jan Krummenauer, Andr\'e Zimmermann
Categories: cs.AR cs.AI
\\ ( https://arxiv.org/abs/2507.10639 ,  678kb)
------------------------------------------------------------------------------
\\
arXiv:2508.00024 (*cross-listing*)
replaced with revised version Mon, 10 Nov 2025 18:08:37 GMT   (1684kb)

Title: Embedding-Aware Quantum-Classical SVMs for Scalable Quantum Machine
 Learning
Authors: Sebasti\'an Andr\'es Cajas Ord\'o\~nez, Luis Fernando Torres Torres,
 Mario Bifulco, Carlos Andr\'es Dur\'an, Cristian Bosch and Ricardo Sim\'on
 Carbajo
Categories: quant-ph cs.AI cs.LG
Comments: Accepted for Poster, Presentation and Proceedings at: 3rd
 International Workshop on AI for Quantum and Quantum for AI (AIQxQIA 2025),
 co-located with ECAI 2025, Bologna, Italy, 25-30 October 2025
\\ ( https://arxiv.org/abs/2508.00024 ,  1684kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10591
replaced with revised version Mon, 10 Nov 2025 12:37:31 GMT   (13128kb)

Title: Assisting the Grading of a Handwritten General Chemistry Exam with
 Artificial Intelligence
Authors: Jan Cvengros, Gerd Kortemeyer
Categories: cs.CY cs.AI
\\ ( https://arxiv.org/abs/2509.10591 ,  13128kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19012
replaced with revised version Mon, 10 Nov 2025 07:53:21 GMT   (1793kb)

Title: Pure Vision Language Action (VLA) Models: A Comprehensive Survey
Authors: Dapeng Zhang, Jing Sun, Chenghui Hu, Xiaoyan Wu, Zhenlong Yuan, Rui
 Zhou, Fei Shen, and Qingguo Zhou
Categories: cs.RO cs.AI
\\ ( https://arxiv.org/abs/2509.19012 ,  1793kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20835
replaced with revised version Mon, 10 Nov 2025 14:34:08 GMT   (0kb,I)

Title: Security-aware Semantic-driven ISAC via Paired Adversarial Residual
 Networks
Authors: Yu Liu, Boxiang He, and Fanggang Wang
Categories: cs.CR cs.AI
Comments: This paper contains errors, including insufficient technical
 elaboration, incorrect expression of PSR, lack of benchmark, and incomplete
 simulation justification. We politely request withdrawal of the current
 version (v1) to prevent misunderstanding
\\ ( https://arxiv.org/abs/2509.20835 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2509.21275
replaced with revised version Mon, 10 Nov 2025 02:27:38 GMT   (841kb)

Title: Data-Centric Elastic Pipeline Parallelism for Efficient Long-Context LLM
 Training
Authors: Shiju Wang, Yujie Wang, Ao Sun, Fangcheng Fu, Zijian Zhu, Bin Cui, Xu
 Han, Kaisheng Ma
Categories: cs.DC cs.AI
\\ ( https://arxiv.org/abs/2509.21275 ,  841kb)
------------------------------------------------------------------------------
\\
arXiv:2509.25884 (*cross-listing*)
replaced with revised version Mon, 10 Nov 2025 03:55:13 GMT   (7328kb)

Title: scUnified: An AI-Ready Standardized Resource for Single-Cell RNA
 Sequencing Analysis
Authors: Ping Xu, Zaitian Wang, Zhirui Wang, Pengjiang Li, Ran Zhang, Gaoyang
 Li, Hanyu Xie, Jiajia Wang, Yuanchun Zhou, and Pengfei Wang
Categories: q-bio.GN cs.AI
\\ ( https://arxiv.org/abs/2509.25884 ,  7328kb)
------------------------------------------------------------------------------
\\
arXiv:2510.17959 (*cross-listing*)
replaced with revised version Mon, 10 Nov 2025 16:51:19 GMT   (1309kb)

Title: Universal Spectral Tokenization via Self-Supervised Panchromatic
 Representation Learning
Authors: Jeff Shen, Francois Lanusse, Liam Holden Parker, Ollie Liu, Tom Hehir,
 Leopoldo Sarra, Lucas Meyer, Micah Bowles, Sebastian Wagner-Carena, Sebastian
 Wagner-Carena, Helen Qu, Siavash Golkar, Alberto Bietti, Hatim Bourfoune,
 Nathan Cassereau, Pierre Cornette, Keiya Hirashima, Geraud Krawezik, Ruben
 Ohana, Nicholas Lourie, Michael McCabe, Rudy Morel, Payel Mukhopadhyay,
 Mariel Pettee, Bruno R\'egaldo-Saint Blancard, Kyunghyun Cho, Miles Cranmer,
 Shirley Ho
Categories: astro-ph.IM cs.AI cs.LG
Comments: Accepted at NeurIPS 2025 Machine Learning and the Physical Sciences
 Workshop; v2: added collaboration
\\ ( https://arxiv.org/abs/2510.17959 ,  1309kb)
------------------------------------------------------------------------------
\\
arXiv:2510.26828 (*cross-listing*)
replaced with revised version Mon, 10 Nov 2025 13:23:39 GMT   (573kb)

Title: Beyond Data Scarcity Optimizing R3GAN for Medical Image Generation from
 Small Datasets
Authors: Tsung-Wei Pan, Chang-Hong Wu, Jung-Hua Wang, Ming-Jer Chen, Yu-Chiao
 Yi, Tsung-Hsien Lee
Categories: eess.IV cs.AI
\\ ( https://arxiv.org/abs/2510.26828 ,  573kb)
------------------------------------------------------------------------------
\\
arXiv:2511.03170
replaced with revised version Sat, 8 Nov 2025 02:05:57 GMT   (6711kb)

Title: GraphCliff: Short-Long Range Gating for Subtle Differences but Critical
 Changes
Authors: Hajung Kim, Jueon Park, Junseok Choe, Sheunheun Baek, Hyeon Hwang,
 Jaewoo Kang
Categories: cs.CE cs.AI
\\ ( https://arxiv.org/abs/2511.03170 ,  6711kb)
------------------------------------------------------------------------------
\\
arXiv:2511.03481
replaced with revised version Sun, 9 Nov 2025 02:49:13 GMT   (9371kb)

Title: Development of the Bioinspired Tendon-Driven DexHand 021 with
 Proprioceptive Compliance Control
Authors: Jianbo Yuan, Haohua Zhu, Jing Dai, and Sheng Yi
Categories: cs.RO cs.AI
Comments: 8 pages 18 fogures, IEEE RAL accept
\\ ( https://arxiv.org/abs/2511.03481 ,  9371kb)
------------------------------------------------------------------------------
\\
arXiv:2511.03643 (*cross-listing*)
replaced with revised version Mon, 10 Nov 2025 18:36:37 GMT   (228kb)

Title: Explaining Human Choice Probabilities with Simple Vector Representations
Authors: Peter DiBerardino and Britt Anderson
Categories: q-bio.NC cs.AI
\\ ( https://arxiv.org/abs/2511.03643 ,  228kb)
------------------------------------------------------------------------------
\\
arXiv:2511.03732
replaced with revised version Sun, 9 Nov 2025 14:47:07 GMT   (543kb)

Title: Conversational Collective Intelligence (CCI) using Hyperchat AI in a
 Real-world Forecasting Task
Authors: Hans Schumann, Louis Rosenberg, Ganesh Mani, Gregg Willcox
Categories: cs.HC cs.AI
Comments: updated version matches the final accepted IEEE conference paper with
 added statistics
ACM-class: H.5; I.2
\\ ( https://arxiv.org/abs/2511.03732 ,  543kb)
------------------------------------------------------------------------------
\\
arXiv:2511.03758 (*cross-listing*)
replaced with revised version Sat, 8 Nov 2025 02:59:31 GMT   (534kb)

Title: Leveraging LLM-based agents for social science research: insights from
 citation network simulations
Authors: Jiarui Ji, Runlin Lei, Xuchen Pan, Zhewei Wei, Hao Sun, Yankai Lin, Xu
 Chen, Yongzheng Yang, Yaliang Li, Bolin Ding, Ji-Rong Wen
Categories: physics.soc-ph cs.AI cs.CY cs.MA cs.SI
Comments: accepted by HSSCOMMS'25
\\ ( https://arxiv.org/abs/2511.03758 ,  534kb)
------------------------------------------------------------------------------
\\
arXiv:2511.04914
replaced with revised version Mon, 10 Nov 2025 06:49:45 GMT   (114kb)

Title: MERaLiON-SER: Robust Speech Emotion Recognition Model for English and
 SEA Languages
Authors: Hardik B. Sailor, Aw Ai Ti, Chen Fang Yih Nancy, Chiu Ying Lay, Ding
 Yang, He Yingxu, Jiang Ridong, Li Jingtao, Liao Jingyi, Liu Zhuohan, Lu
 Yanfeng, Ma Yi, Manas Gupta, Muhammad Huzaifah Bin Md Shahrin, Nabilah Binte
 Md Johan, Nattadaporn Lertcheva, Pan Chunlei, Pham Minh Duc, Siti Maryam
 Binte Ahmad Subaidi, Siti Umairah Binte Mohammad Salleh, Sun Shuo, Tarun
 Kumar Vangani, Wang Qiongqiong, Won Cheng Yi Lewis, Wong Heng Meng Jeremy, Wu
 Jinyang, Zhang Huayun, Zhang Longyin, Zou Xunlong
Categories: cs.SD cs.AI
Comments: https://huggingface.co/MERaLiON/MERaLiON-SER-v1
\\ ( https://arxiv.org/abs/2511.04914 ,  114kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05350
replaced with revised version Mon, 10 Nov 2025 14:11:02 GMT   (416kb)

Title: Perceptually Aligning Representations of Music via Noise-Augmented
 Autoencoders
Authors: Mathias Rose Bjare, Giorgia Cantisani, Marco Pasini, Stefan Lattner,
 Gerhard Widmer
Categories: cs.SD cs.AI
Comments: Accepted at NeurIPS 2025 - AI for Music Workshop, 11 pages, 5
 figures, 1 table
\\ ( https://arxiv.org/abs/2511.05350 ,  416kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05459
replaced with revised version Mon, 10 Nov 2025 03:18:54 GMT   (8468kb)

Title: SWE-Compass: Towards Unified Evaluation of Agentic Coding Abilities for
 Large Language Models
Authors: Jingxuan Xu, Ken Deng, Weihao Li, Songwei Yu, Huaixi Tang, Haoyang
 Huang, Zhiyi Lai, Zizheng Zhan, Yanan Wu, Chenchen Zhang, Kepeng Lei, Yifan
 Yao, Xinping Lei, Wenqiang Zhu, Zongxian Feng, Han Li, Junqi Xiong, Dailin
 Li, Zuchen Gao, Kun Wu, Wen Xiang, Ziqi Zhan, Yuanxing Zhang, Wuxuan Gong,
 Ziyuan Gao, Guanxiang Wang, Yirong Xue, Xiaojiang Zhang, Jinghui Wang,
 Huiming Wang, Wenhao Zhuang, Zhaoxiang Zhang, Yuqun Zhang, Haotian Zhang, Bin
 Chen, Jiaheng Liu
Categories: cs.SE cs.AI
\\ ( https://arxiv.org/abs/2511.05459 ,  8468kb)
------------------------------------------------------------------------------
\\
arXiv:2407.17716
replaced with revised version Sat, 8 Nov 2025 19:30:16 GMT   (710kb)

Title: Describe Where You Are: Improving Noise-Robustness for Speech Emotion
 Recognition with Text Description of the Environment
Authors: Seong-Gyun Leem, Daniel Fulford, Jukka-Pekka Onnela, David Gard, and
 Carlos Busso
Categories: cs.SD cs.CL cs.LG eess.AS
\\ ( https://arxiv.org/abs/2407.17716 ,  710kb)
------------------------------------------------------------------------------
\\
arXiv:2507.18224
replaced with revised version Fri, 7 Nov 2025 23:47:54 GMT   (813kb)

Title: Assemble Your Crew: Automatic Multi-agent Communication Topology Design
 via Autoregressive Graph Generation
Authors: Shiyuan Li, Yixin Liu, Qingsong Wen, Chengqi Zhang, Shirui Pan
Categories: cs.MA cs.CL
Comments: Accepted by AAAI 2026
\\ ( https://arxiv.org/abs/2507.18224 ,  813kb)
------------------------------------------------------------------------------
\\
arXiv:2510.16830
replaced with revised version Mon, 10 Nov 2025 08:02:49 GMT   (2423kb)

Title: Verifiable Fine-Tuning for LLMs: Zero-Knowledge Training Proofs Bound to
 Data Provenance and Policy
Authors: Hasan Akgul, Daniel Borg, Arta Berisha, Amina Rahimova, Andrej Novak,
 and Mila Petrov
Categories: cs.CR cs.CL
Comments: 20 pages, 10 figures
MSC-class: 68T07, 94A60, 68Q25
ACM-class: I.2.6; G.1.6; E.3; C.2.4
\\ ( https://arxiv.org/abs/2510.16830 ,  2423kb)
------------------------------------------------------------------------------
\\
arXiv:2510.25677
replaced with revised version Mon, 10 Nov 2025 14:51:36 GMT   (2056kb)

Title: ZK-SenseLM: Verifiable Large-Model Wireless Sensing with Selective
 Abstention and Zero-Knowledge Attestation
Authors: Hasan Akgul, Mari Eplik, Javier Rojas, Aina Binti Abdullah, and Pieter
 van der Merwe
Categories: cs.CR cs.CL
Comments: 45 pages
ACM-class: C.2.1; D.4.6; E.3; I.2.6; I.5.4
\\ ( https://arxiv.org/abs/2510.25677 ,  2056kb)
------------------------------------------------------------------------------
\\
arXiv:2511.04106 (*cross-listing*)
replaced with revised version Sat, 8 Nov 2025 06:36:58 GMT   (32969kb)

Title: Sub-exponential Growth of New Words and Names Online: A Piecewise
 Power-Law Model
Authors: Hayafumi Watanabe
Categories: physics.soc-ph cs.CL cs.CY stat.AP
\\ ( https://arxiv.org/abs/2511.04106 ,  32969kb)
------------------------------------------------------------------------------
\\
arXiv:2404.19604 (*cross-listing*)
replaced with revised version Sun, 9 Nov 2025 14:43:38 GMT   (44234kb)

Title: X-Diffusion: Generating Detailed 3D MRI Volumes From a Single Image
 Using Cross-Sectional Diffusion Models
Authors: Emmanuelle Bourigault, Abdullah Hamdi, Amir Jamaludin
Categories: eess.IV cs.CV
Comments: accepted at ICCV 2025 GAIA workshop
 https://era-ai-biomed.github.io/GAIA/ , project website:
 https://emmanuelleb985.github.io/XDiffusion/
\\ ( https://arxiv.org/abs/2404.19604 ,  44234kb)
------------------------------------------------------------------------------
\\
arXiv:2408.05697 (*cross-listing*)
replaced with revised version Mon, 10 Nov 2025 18:40:47 GMT   (1748kb)

Title: Evaluating BM3D and NBNet: A Comprehensive Study of Image Denoising
 Across Multiple Datasets
Authors: Ghazal Kaviani, Reza Marzban, Ghassan AlRegib
Categories: eess.IV cs.CV
\\ ( https://arxiv.org/abs/2408.05697 ,  1748kb)
------------------------------------------------------------------------------
\\
arXiv:2409.13055
replaced with revised version Sat, 8 Nov 2025 23:45:04 GMT   (13261kb)

Title: MGSO: Monocular Real-time Photometric SLAM with Efficient 3D Gaussian
 Splatting
Authors: Yan Song Hu, Nicolas Abboud, Muhammad Qasim Ali, Adam Srebrnjak Yang,
 Imad Elhajj, Daniel Asmar, Yuhao Chen, John S. Zelek
Categories: cs.RO cs.CV
Comments: This is the pre-print version of a work that has been published in
 ICRA 2025 with doi: 10.1109/ICRA55743.2025.11127380. This version may no
 longer be accessible without notice. Copyright 2025 IEEE. Personal use of
 this material is permitted. Permission from IEEE must be obtained for all
 other uses. Please cite the official version
Journal-ref: 2025 IEEE International Conference on Robotics and Automation
 (ICRA), Atlanta, GA, USA, 2025, pp. 11061-11067
DOI: 10.1109/ICRA55743.2025.11127380
\\ ( https://arxiv.org/abs/2409.13055 ,  13261kb)
------------------------------------------------------------------------------
\\
arXiv:2410.17494 (*cross-listing*)
replaced with revised version Mon, 10 Nov 2025 17:50:31 GMT   (13699kb)

Title: Enhancing Multimodal Medical Image Classification using Cross-Graph
 Modal Contrastive Learning
Authors: Jun-En Ding, Chien-Chin Hsu, Chi-Hsiang Chu, Shuqiang Wang, and Feng
 Liu
Categories: eess.IV cs.CV
\\ ( https://arxiv.org/abs/2410.17494 ,  13699kb)
------------------------------------------------------------------------------
\\
arXiv:2411.00527 (*cross-listing*)
replaced with revised version Mon, 10 Nov 2025 12:44:18 GMT   (33747kb)

Title: MAROON: A Dataset for the Joint Characterization of Near-Field
 High-Resolution Radio-Frequency and Optical Depth Imaging Techniques
Authors: Vanessa Wirth, Johanna Br\"aunig, Nikolai Hofmann, Martin Vossiek, Tim
 Weyrich, Marc Stamminger
Categories: eess.IV cs.CV
\\ ( https://arxiv.org/abs/2411.00527 ,  33747kb)
------------------------------------------------------------------------------
\\
arXiv:2412.05853 (*cross-listing*)
replaced with revised version Sat, 8 Nov 2025 07:31:23 GMT   (20522kb)

Title: Unsupervised Multi-Parameter Inverse Solving for Reducing Ring Artifacts
 in 3D X-Ray CBCT
Authors: Qing Wu, Hongjiang Wei, Jingyi Yu, Yuyao Zhang
Categories: eess.IV cs.CV
Comments: Accepted by AAAI 2026
\\ ( https://arxiv.org/abs/2412.05853 ,  20522kb)
------------------------------------------------------------------------------
\\
arXiv:2501.09935 (*cross-listing*)
replaced with revised version Sat, 8 Nov 2025 13:06:49 GMT   (35740kb)

Title: Physics-informed DeepCT: Sinogram Wavelet Decomposition Meets Masked
 Diffusion
Authors: Zekun Zhou and Tan Liu and Bing Yu and Yanru Gong and Liu Shi and
 Qiegen Liu
Categories: eess.IV cs.CV physics.med-ph
\\ ( https://arxiv.org/abs/2501.09935 ,  35740kb)
------------------------------------------------------------------------------
\\
arXiv:2503.10287
replaced with revised version Sun, 9 Nov 2025 16:21:16 GMT   (3107kb)

Title: MACS: Multi-source Audio-to-image Generation with Contextual
 Significance and Semantic Alignment
Authors: Hao Zhou, Xiaobao Guo, Yuzhe Zhu, Adams Wai-Kin Kong
Categories: cs.SD cs.CV cs.GR eess.AS
Comments: Accepted at AAAI 2026. Code available at
 https://github.com/alxzzhou/MACS
\\ ( https://arxiv.org/abs/2503.10287 ,  3107kb)
------------------------------------------------------------------------------
\\
arXiv:2503.10637
replaced with revised version Mon, 10 Nov 2025 15:36:25 GMT   (37831kb)

Title: Distilling Diversity and Control in Diffusion Models
Authors: Rohit Gandikota and David Bau
Categories: cs.GR cs.CV
Comments: Project Page: https://distillation.baulab.info/
\\ ( https://arxiv.org/abs/2503.10637 ,  37831kb)
------------------------------------------------------------------------------
\\
arXiv:2505.08239
replaced with revised version Sat, 8 Nov 2025 09:01:50 GMT   (25756kb)

Title: ACT-R: Adaptive Camera Trajectories for Single View 3D Reconstruction
Authors: Yizhi Wang, Mingrui Zhao, Hao Zhang
Categories: cs.GR cs.CV
Comments: 3DV 2026, Project Page: https://mingrui-zhao.github.io/ACT-R/
\\ ( https://arxiv.org/abs/2505.08239 ,  25756kb)
------------------------------------------------------------------------------
\\
arXiv:2506.14542 (*cross-listing*)
replaced with revised version Mon, 10 Nov 2025 07:51:46 GMT   (1928kb)

Title: A Lightweight Complex-Valued Deformable CNN for High-Quality
 Computer-Generated Holography
Authors: Shuyang Xie, Jie Zhou, Bo Xu, Jun Wang, Renjing Xu
Categories: physics.optics cs.CV
Comments: 13 pages, 9 figures
\\ ( https://arxiv.org/abs/2506.14542 ,  1928kb)
------------------------------------------------------------------------------
\\
arXiv:2507.20765 (*cross-listing*)
replaced with revised version Mon, 10 Nov 2025 17:03:13 GMT   (5183kb)

Title: Onboard Hyperspectral Super-Resolution with Deep Pushbroom Neural
 Network
Authors: Davide Piccinini, Diego Valsesia, Enrico Magli
Categories: eess.IV cs.CV
Journal-ref: Remote Sensing, volume 17, year 2025, number 21, article-number
 3634, URL = {https://www.mdpi.com/2072-4292/17/21/3634} }
DOI: 10.3390/rs17213634
\\ ( https://arxiv.org/abs/2507.20765 ,  5183kb)
------------------------------------------------------------------------------
\\
arXiv:2510.08571
replaced with revised version Mon, 10 Nov 2025 03:22:29 GMT   (1816kb)

Title: Scalable Offline Metrics for Autonomous Driving
Authors: Animikh Aich, Adwait Kulkarni, Eshed Ohn-Bar
Categories: cs.RO cs.CV
Comments: Accepted at IROS 2025 (IEEE/RSJ International Conference on
 Intelligent Robots and Systems); typos corrected
\\ ( https://arxiv.org/abs/2510.08571 ,  1816kb)
------------------------------------------------------------------------------
\\
arXiv:2511.02097
replaced with revised version Mon, 10 Nov 2025 03:45:44 GMT   (1498kb)

Title: A Step Toward World Models: A Survey on Robotic Manipulation
Authors: Peng-Fei Zhang, Ying Cheng, Xiaofan Sun, Shijie Wang, Fengling Li, Lei
 Zhu, Heng Tao Shen
Categories: cs.RO cs.CV
Comments: 24 pages, 5 figures
\\ ( https://arxiv.org/abs/2511.02097 ,  1498kb)
------------------------------------------------------------------------------
\\
arXiv:2511.04665
replaced with revised version Mon, 10 Nov 2025 17:28:23 GMT   (3508kb)

Title: Real-to-Sim Robot Policy Evaluation with Gaussian Splatting Simulation
 of Soft-Body Interactions
Authors: Kaifeng Zhang, Shuo Sha, Hanxiao Jiang, Matthew Loper, Hyunjong Song,
 Guangyan Cai, Zhuo Xu, Xiaochen Hu, Changxi Zheng, Yunzhu Li
Categories: cs.RO cs.CV cs.LG
Comments: The first two authors contributed equally. Website:
 https://real2sim-eval.github.io/
\\ ( https://arxiv.org/abs/2511.04665 ,  3508kb)
------------------------------------------------------------------------------
\\
arXiv:2510.25025
replaced with revised version Mon, 10 Nov 2025 03:50:42 GMT   (219kb)

Title: Secure Retrieval-Augmented Generation against Poisoning Attacks
Authors: Zirui Cheng, Jikai Sun, Anjun Gao, Yueyang Quan, Zhuqing Liu, Xiaohua
 Hu, Minghong Fang
Categories: cs.CR cs.IR cs.LG
Comments: To appear in IEEE BigData 2025
\\ ( https://arxiv.org/abs/2510.25025 ,  219kb)
------------------------------------------------------------------------------
\\
arXiv:2510.27141
replaced with revised version Sat, 8 Nov 2025 03:29:25 GMT   (1223kb)

Title: Compass: General Filtered Search across Vector and Structured Data
Authors: Chunxiao Ye, Xiao Yan, Eric Lo
Categories: cs.DB cs.IR
\\ ( https://arxiv.org/abs/2510.27141 ,  1223kb)
------------------------------------------------------------------------------
\\
arXiv:2302.09526 (*cross-listing*)
replaced with revised version Mon, 10 Nov 2025 09:37:33 GMT   (283kb)

Title: Mixed Semi-Supervised Generalized-Linear-Regression with Applications to
 Deep-Learning and Interpolators
Authors: Oren Yuval, Saharon Rosset
Categories: stat.ME cs.LG stat.ML
Comments: 45 pages, 10 figures
MSC-class: 62F10, 62J12, 68T07
\\ ( https://arxiv.org/abs/2302.09526 ,  283kb)
------------------------------------------------------------------------------
\\
arXiv:2306.16617 (*cross-listing*)
replaced with revised version Mon, 10 Nov 2025 01:07:30 GMT   (744kb)

Title: Last-Iterate Convergence of Adaptive Riemannian Gradient Descent for
 Equilibrium Computation
Authors: Yang Cai, Michael I. Jordan, Tianyi Lin, Argyris Oikonomou,
 Emmanouil-Vasileios Vlatakis-Gkaragkounis
Categories: math.OC cs.GT cs.LG
Comments: 28 pages; 12 figures
\\ ( https://arxiv.org/abs/2306.16617 ,  744kb)
------------------------------------------------------------------------------
\\
arXiv:2310.10559 (*cross-listing*)
replaced with revised version Mon, 10 Nov 2025 10:23:33 GMT   (378kb)

Title: Causal Dynamic Variational Autoencoder for Counterfactual Regression in
 Longitudinal Data
Authors: Mouad El Bouchattaoui, Myriam Tami, Benoit Lepetit, Paul-Henry
 Courn\`ede
Categories: stat.ML cs.LG
Comments: Published at TMLR
\\ ( https://arxiv.org/abs/2310.10559 ,  378kb)
------------------------------------------------------------------------------
\\
arXiv:2311.14114
replaced with revised version Sun, 9 Nov 2025 03:32:49 GMT   (1080kb)

Title: SONIQ: System-Optimized Noise-Injected Ultra-Low-Precision Quantization
 with Full-Precision Parity
Authors: Cyrus Zhou, Pedro Savarese, Zack Hassman, Vaughn Richard, Michael
 DiBrino, Michael Maire, Yanjing Li
Categories: cs.AR cs.LG cs.PF
\\ ( https://arxiv.org/abs/2311.14114 ,  1080kb)
------------------------------------------------------------------------------
\\
arXiv:2401.16492
replaced with revised version Sun, 9 Nov 2025 09:45:26 GMT   (1642kb)

Title: GPU Cluster Scheduling for Network-Sensitive Deep Learning
Authors: Aakash Sharma, Vivek M. Bhasi, Sonali Singh, George Kesidis, Mahmut T.
 Kandemir, Chita R. Das
Categories: cs.PF cs.DC cs.LG
\\ ( https://arxiv.org/abs/2401.16492 ,  1642kb)
------------------------------------------------------------------------------
\\
arXiv:2402.02196 (*cross-listing*)
replaced with revised version Sun, 9 Nov 2025 10:28:32 GMT   (1505kb)

Title: Sample-Efficient "Clustering and Conquer" Procedures for Parallel
 Large-Scale Ranking and Selection
Authors: Zishi Zhang, Yijie Peng
Categories: stat.ME cs.LG
\\ ( https://arxiv.org/abs/2402.02196 ,  1505kb)
------------------------------------------------------------------------------
\\
arXiv:2404.08878
replaced with revised version Sat, 8 Nov 2025 12:31:59 GMT   (4569kb)

Title: Large Language Model Empowered Next-Generation MIMO Networks:
 Fundamentals, Challenges, and Visions
Authors: Zhe Wang, Jiayi Zhang, Hongyang Du, Ruichen Zhang, Dusit Niyato, Bo
 Ai, Khaled B. Letaief
Categories: cs.NI cs.IT cs.LG eess.SP math.IT
Comments: 9 pages, 4 figures, 1 table, to appear in Digital Communications and
 Networks
\\ ( https://arxiv.org/abs/2404.08878 ,  4569kb)
------------------------------------------------------------------------------
\\
arXiv:2405.16564 (*cross-listing*)
replaced with revised version Mon, 10 Nov 2025 00:35:15 GMT   (234kb)

Title: Contextual Linear Optimization with Partial Feedback
Authors: Yichun Hu, Nathan Kallus, Xiaojie Mao, Yanchen Wu
Categories: stat.ML cs.LG stat.ME
\\ ( https://arxiv.org/abs/2405.16564 ,  234kb)
------------------------------------------------------------------------------
\\
arXiv:2406.14682 (*cross-listing*)
replaced with revised version Mon, 10 Nov 2025 16:05:46 GMT   (62kb)

Title: Uniform Convergence of Adversarially Robust Classifiers
Authors: Rachel Morris and Ryan Murray
Categories: math.AP cs.LG math.OC
Comments: 36 pages, 3 figures; v2: Appendix added to clarify U and Lambda sets
 and their properties, minor edits to all sections based on review process
MSC-class: 28A75, 62G35, 68Q32, 35B25
\\ ( https://arxiv.org/abs/2406.14682 ,  62kb)
------------------------------------------------------------------------------
\\
arXiv:2407.18929
replaced with revised version Mon, 10 Nov 2025 13:45:54 GMT   (6564kb)

Title: Disturbance-based Discretization, Differentiable IDS Channel, and an
 IDS-Correcting Code for DNA-based Storage
Authors: Alan J.X. Guo, Mengyi Wei, Yufan Dai, Yali Wei, Pengchen Zhang
Categories: cs.IT cs.ET cs.LG math.IT
\\ ( https://arxiv.org/abs/2407.18929 ,  6564kb)
------------------------------------------------------------------------------
\\
arXiv:2408.04406 (*cross-listing*)
replaced with revised version Mon, 10 Nov 2025 10:12:42 GMT   (2447kb)

Title: Finite sample learning of moving targets
Authors: Nikolaus Vertovec, Kostas Margellos, Maria Prandini
Categories: math.OC cs.LG
Comments: 13 pages, 7 figures
\\ ( https://arxiv.org/abs/2408.04406 ,  2447kb)
------------------------------------------------------------------------------
\\
arXiv:2409.19791 (*cross-listing*)
replaced with revised version Sat, 8 Nov 2025 16:06:58 GMT   (3080kb)

Title: Gradient descent with adaptive stepsize converges (nearly) linearly
 under fourth-order growth
Authors: Damek Davis, Dmitriy Drusvyatskiy, Liwei Jiang
Categories: math.OC cs.LG
Comments: 62 pages, 5 figures
MSC-class: 65K05, 65K10, 90C30, 90C06
\\ ( https://arxiv.org/abs/2409.19791 ,  3080kb)
------------------------------------------------------------------------------
\\
arXiv:2411.09645
replaced with revised version Mon, 10 Nov 2025 14:45:16 GMT   (3188kb)

Title: How do Machine Learning Models Change?
Authors: Joel Casta\~no, Rafael Caba\~nas, Antonio Salmer\'on, David Lo,
 Silverio Mart\'inez-Fern\'andez
Categories: cs.SE cs.LG
Comments: This paper has been accepted for publication in ACM Transactions on
 Software Engineering and Methodology (TOSEM)
DOI: 10.1145/3767157
\\ ( https://arxiv.org/abs/2411.09645 ,  3188kb)
------------------------------------------------------------------------------
\\
arXiv:2411.14664 (*cross-listing*)
replaced with revised version Sun, 9 Nov 2025 01:08:33 GMT   (206kb)

Title: Sparsifying Suprema of Gaussian Processes
Authors: Anindya De and Shivam Nadimpalli and Ryan O'Donnell and Rocco A.
 Servedio
Categories: stat.ML cs.CC cs.DS cs.LG math.PR
Comments: 33 pages
\\ ( https://arxiv.org/abs/2411.14664 ,  206kb)
------------------------------------------------------------------------------
\\
arXiv:2412.13049
replaced with revised version Fri, 7 Nov 2025 21:46:37 GMT   (980kb)

Title: TIMESAFE: Timing Interruption Monitoring and Security Assessment for
 Fronthaul Environments
Authors: Joshua Groen, Simone Di Valerio, Imtiaz Karim, Davide Villa, Yiewi
 Zhang, Leonardo Bonati, Michele Polese, Salvatore D'Oro, Tommaso Melodia,
 Elisa Bertino, Francesca Cuomo, Kaushik Chowdhury
Categories: cs.NI cs.CR cs.LG cs.SY eess.SY
ACM-class: C.2; C.4
DOI: 10.1145/3775060
\\ ( https://arxiv.org/abs/2412.13049 ,  980kb)
------------------------------------------------------------------------------
\\
arXiv:2501.19277 (*cross-listing*)
replaced with revised version Mon, 10 Nov 2025 02:20:00 GMT   (485kb)

Title: On (Approximate) Pareto Optimality for the Multinomial Logistic Bandit
Authors: Jierui Zuo, Hanzhang Qin
Categories: stat.ML cs.LG
\\ ( https://arxiv.org/abs/2501.19277 ,  485kb)
------------------------------------------------------------------------------
\\
arXiv:2502.02870 (*cross-listing*)
replaced with revised version Sun, 9 Nov 2025 23:04:35 GMT   (4253kb)

Title: Uncertainty Quantification with the Empirical Neural Tangent Kernel
Authors: Joseph Wilson, Chris van der Heide, Liam Hodgkinson and Fred Roosta
Categories: stat.ML cs.LG
Comments: 39 pages, 6 figures, 13 tables
\\ ( https://arxiv.org/abs/2502.02870 ,  4253kb)
------------------------------------------------------------------------------
\\
arXiv:2502.19086 (*cross-listing*)
replaced with revised version Mon, 10 Nov 2025 07:58:55 GMT   (2005kb)

Title: Forecasting intermittent time series with Gaussian Processes and Tweedie
 likelihood
Authors: Stefano Damato, Dario Azzimonti and Giorgio Corani
Categories: stat.ML cs.LG stat.AP
Comments: Published in International Journal of Forecasting
MSC-class: 62M10, 62F15, 62P20
ACM-class: I.2.6; I.5.4; G.3
DOI: 10.1016/j.ijforecast.2025.10.001
\\ ( https://arxiv.org/abs/2502.19086 ,  2005kb)
------------------------------------------------------------------------------
\\
arXiv:2503.04981 (*cross-listing*)
replaced with revised version Sat, 8 Nov 2025 22:40:21 GMT   (2930kb)

Title: Topology-Aware Conformal Prediction for Stream Networks
Authors: Jifan Zhang, Fangxin Wang, Zihe Song, Philip S. Yu, Kaize Ding,
 Shixiang Zhu
Categories: stat.ML cs.LG
Comments: 27 pages, 7 figures
\\ ( https://arxiv.org/abs/2503.04981 ,  2930kb)
------------------------------------------------------------------------------
\\
arXiv:2503.05009 (*cross-listing*)
replaced with revised version Sun, 9 Nov 2025 08:07:14 GMT   (1994kb)

Title: Seismic inversion using hybrid quantum neural networks
Authors: Divakar Vashisth, Rohan Sharma, Tejas Ganesh Iyer, Tapan Mukerji and
 Mrinal K. Sen
Categories: quant-ph cs.LG physics.geo-ph
\\ ( https://arxiv.org/abs/2503.05009 ,  1994kb)
------------------------------------------------------------------------------
\\
arXiv:2503.09649 (*cross-listing*)
replaced with revised version Sun, 9 Nov 2025 22:47:36 GMT   (266kb)

Title: Technical and Legal Aspects of Federated Learning in Bioinformatics:
 Applications, Challenges and Opportunities
Authors: Daniele Malpetti and Marco Scutari and Francesco Gualdi and Jessica
 van Setten and Sander van der Laan and Saskia Haitjema and Aaron Mark Lee and
 Isabelle Hering and Francesca Mangili
Categories: q-bio.OT cs.LG stat.ML
Comments: 28 pages, 4 figures
\\ ( https://arxiv.org/abs/2503.09649 ,  266kb)
------------------------------------------------------------------------------
\\
arXiv:2504.05004 (*cross-listing*)
replaced with revised version Mon, 10 Nov 2025 11:18:18 GMT   (9980kb)

Title: Stacking Variational Bayesian Monte Carlo
Authors: Francesco Silvestrin, Chengkun Li, Luigi Acerbi
Categories: stat.ML cs.LG
Comments: Published in Transactions on Machine Learning Research (November
 2025), https://openreview.net/forum?id=M2ilYAJdPe. 38 pages, 13 figures
Journal-ref: Silvestrin, F., Li, C., & Acerbi, L. (2025). Stacking Variational
 Bayesian Monte Carlo. In Transactions on Machine Learning Research
\\ ( https://arxiv.org/abs/2504.05004 ,  9980kb)
------------------------------------------------------------------------------
\\
arXiv:2505.09026 (*cross-listing*)
replaced with revised version Sun, 9 Nov 2025 15:04:35 GMT   (2619kb)

Title: Probabilistic Wind Power Modelling via Heteroscedastic Non-Stationary
 Gaussian Processes
Authors: Domniki Ladopoulou, Dat Minh Hong, Petros Dellaportas
Categories: stat.AP cs.LG stat.ML
Comments: 13 pages, 3 figures
\\ ( https://arxiv.org/abs/2505.09026 ,  2619kb)
------------------------------------------------------------------------------
\\
arXiv:2505.11343 (*cross-listing*)
replaced with revised version Mon, 10 Nov 2025 17:14:23 GMT   (26kb)

Title: Revisiting Stochastic Approximation and Stochastic Gradient Descent
Authors: Rajeeva Laxman Karandikar, Bhamidi Visweswara Rao and Mathukumalli
 Vidyasagar
Categories: math.OC cs.LG stat.ML
Comments: 31 pages
MSC-class: 62L20, 60G17, 93D05
\\ ( https://arxiv.org/abs/2505.11343 ,  26kb)
------------------------------------------------------------------------------
\\
arXiv:2506.01755
replaced with revised version Mon, 10 Nov 2025 14:07:39 GMT   (3480kb)

Title: Data-assimilated model-informed reinforcement learning
Authors: Defne E. Ozan, Andrea N\'ovoa, Georgios Rigas, Luca Magri
Categories: eess.SY cs.LG cs.SY
\\ ( https://arxiv.org/abs/2506.01755 ,  3480kb)
------------------------------------------------------------------------------
\\
arXiv:2506.03464
replaced with revised version Fri, 7 Nov 2025 20:30:07 GMT   (419kb)

Title: From Average-Iterate to Last-Iterate Convergence in Games: A Reduction
 and Its Applications
Authors: Yang Cai, Haipeng Luo, Chen-Yu Wei, Weiqiang Zheng
Categories: cs.GT cs.LG math.OC
Comments: NeurIPS 2025. 24 pages. Updated version with more discussions and
 robustness in the bandit feedback setting
\\ ( https://arxiv.org/abs/2506.03464 ,  419kb)
------------------------------------------------------------------------------
\\
arXiv:2506.03467
replaced with revised version Sun, 9 Nov 2025 04:45:47 GMT   (496kb)

Title: Differentially Private Distribution Release of Gaussian Mixture Models
 via KL-Divergence Minimization
Authors: Hang Liu, Anna Scaglione, and Sean Peisert
Categories: cs.IT cs.CR cs.LG eess.SP math.IT stat.ME
Comments: This work has been submitted to the IEEE for possible publication
\\ ( https://arxiv.org/abs/2506.03467 ,  496kb)
------------------------------------------------------------------------------
\\
arXiv:2506.04667
replaced with revised version Sat, 8 Nov 2025 04:20:44 GMT   (2086kb)

Title: FlashMoE: Fast Distributed MoE in a Single Kernel
Authors: Osayamen Jonathan Aimuyo and Byungsoo Oh and Rachee Singh
Categories: cs.DC cs.AR cs.LG
Comments: To appear at NeurIPS '25
\\ ( https://arxiv.org/abs/2506.04667 ,  2086kb)
------------------------------------------------------------------------------
\\
arXiv:2506.10153 (*cross-listing*)
replaced with revised version Fri, 7 Nov 2025 20:36:33 GMT   (3909kb)

Title: Attention on flow control: transformer-based reinforcement learning for
 lift regulation in highly disturbed flows
Authors: Zhecheng Liu and Jeff D. Eldredge (University of California, Los
 Angeles)
Categories: physics.flu-dyn cs.LG
\\ ( https://arxiv.org/abs/2506.10153 ,  3909kb)
------------------------------------------------------------------------------
\\
arXiv:2506.18106 (*cross-listing*)
replaced with revised version Sat, 8 Nov 2025 11:45:18 GMT   (729kb)

Title: CT Radiomics-Based Explainable Machine Learning Model for Accurate
 Differentiation of Malignant and Benign Endometrial Tumors: A Two-Center
 Study
Authors: Tingrui Zhang, Honglin Wu, Zekun Jiang, Yingying Wang, Rui Ye, Huiming
 Ni, Chang Liu, Jin Cao, Xuan Sun, Rong Shao, Xiaorong Wei, Yingchun Sun
Categories: eess.IV cs.LG
Comments: 33 pages, 5 figures, 3 tables
DOI: 10.1186/s12938-025-01462-w
\\ ( https://arxiv.org/abs/2506.18106 ,  729kb)
------------------------------------------------------------------------------
\\
arXiv:2506.22552 (*cross-listing*)
replaced with revised version Sun, 9 Nov 2025 22:47:27 GMT   (466kb)

Title: Probing forced responses and causality in data-driven climate emulators:
 conceptual limitations and the role of reduced-order models
Authors: Fabrizio Falasca
Categories: nlin.CD cond-mat.stat-mech cs.LG physics.ao-ph
\\ ( https://arxiv.org/abs/2506.22552 ,  466kb)
------------------------------------------------------------------------------
\\
arXiv:2508.05559 (*cross-listing*)
replaced with revised version Sat, 8 Nov 2025 16:39:29 GMT   (3411kb)

Title: On the Design of Expressive and Trainable Pulse-based Quantum Machine
 Learning Models
Authors: Han-Xiao Tao, Xin Wang, and Re-Bing Wu
Categories: quant-ph cs.LG
Comments: 11 pages, 4 figures
\\ ( https://arxiv.org/abs/2508.05559 ,  3411kb)
------------------------------------------------------------------------------
\\
arXiv:2509.06272
replaced with revised version Mon, 10 Nov 2025 09:19:57 GMT   (16364kb)

Title: Explainable Swarm: A Methodological Framework for Interpreting Swarm
 Intelligence
Authors: Nitin Gupta, Bapi Dutta, Anupam Yadav
Categories: cs.NE cs.LG
Comments: Upated: 29-10-25
\\ ( https://arxiv.org/abs/2509.06272 ,  16364kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19161
replaced with revised version Fri, 7 Nov 2025 21:36:10 GMT   (53kb)

Title: Realizable Circuit Complexity: Embedding Computation in Space-Time
Authors: Benjamin Prada, Ankur Mali
Categories: cs.CC cs.LG
Comments: 40 pages
ACM-class: F.1.0; F.1.3
\\ ( https://arxiv.org/abs/2509.19161 ,  53kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20172
replaced with revised version Sun, 9 Nov 2025 19:22:28 GMT   (148kb)

Title: Benchmarking Web API Integration Code Generation
Authors: Daniel Maninger, Leon Chemnitz, Amir Molzam Sharifloo, Jannis Brugger,
 Mira Mezini
Categories: cs.SE cs.LG
Comments: To be published in Proceedings of 2025 2nd IEEE/ACM International
 Conference on AI-powered Software (AIware), Data & Benchmark Track; restored
 original paper title
\\ ( https://arxiv.org/abs/2509.20172 ,  148kb)
------------------------------------------------------------------------------
\\
arXiv:2509.22018 (*cross-listing*)
replaced with revised version Mon, 10 Nov 2025 15:47:45 GMT   (529kb)

Title: Exploring the Early Universe with Deep Learning
Authors: Emmanuel de Salis, Massimo De Santis, Davide Piras, Sambit K. Giri,
 Michele Bianco, Nicolas Cerardi, Philipp Denzel, Merve Selcuk-Simsek, Kelley
 M. Hess, M. Carmen Toribio, Franz Kirsten, Hatem Ghorbel
Categories: astro-ph.CO astro-ph.IM cs.LG
Comments: EPIA 2025 preprint version, 12 pages, 3 figures
Journal-ref: Valente de Oliveira, J., Leite, J., Rodrigues, J., Dias, J.,
 Cardoso, P. (eds) Progress in Artificial Intelligence. EPIA 2025. Lecture
 Notes in Computer Science(), vol 16121. Springer, Cham
DOI: 10.1007/978-3-032-05176-9_33
\\ ( https://arxiv.org/abs/2509.22018 ,  529kb)
------------------------------------------------------------------------------
\\
arXiv:2509.24257
replaced with revised version Mon, 10 Nov 2025 16:52:26 GMT   (500kb)

Title: VeriLLM: A Lightweight Framework for Publicly Verifiable Decentralized
 Inference
Authors: Ke Wang, Zishuo Zhao, Xinyuan Song, Bill Shi, Libin Xia, Chris Tong,
 Lynn Ai, Felix Qu, Eric Yang
Categories: cs.CR cs.LG
Comments: 20 pages, 4 figures, 6 tables
ACM-class: C.2.1
\\ ( https://arxiv.org/abs/2509.24257 ,  500kb)
------------------------------------------------------------------------------
\\
arXiv:2509.24493 (*cross-listing*)
replaced with revised version Sat, 8 Nov 2025 02:21:58 GMT   (1015kb)

Title: Preference-Based Dynamic Ranking Structure Recognition
Authors: Nan Lu, Jian Shi, Xin-Yu Tian
Categories: stat.ML cs.LG stat.ME
\\ ( https://arxiv.org/abs/2509.24493 ,  1015kb)
------------------------------------------------------------------------------
\\
arXiv:2510.01112 (*cross-listing*)
replaced with revised version Sat, 8 Nov 2025 12:15:38 GMT   (2329kb)

Title: The causal structure of galactic astrophysics
Authors: Harry Desmond and Joseph Ramsey
Categories: astro-ph.GA astro-ph.CO cs.LG stat.AP stat.ME
Comments: 6 pages, 3 figures; submitted to The Open Journal of Astrophysics
\\ ( https://arxiv.org/abs/2510.01112 ,  2329kb)
------------------------------------------------------------------------------
\\
arXiv:2510.20030 (*cross-listing*)
replaced with revised version Sun, 9 Nov 2025 16:00:53 GMT   (257kb)

Title: On Encoding Matrices using Quantum Circuits
Authors: Liron Mor Yosef, Haim Avron
Categories: quant-ph cs.LG cs.NA math.NA
\\ ( https://arxiv.org/abs/2510.20030 ,  257kb)
------------------------------------------------------------------------------
\\
arXiv:2510.25687
replaced with revised version Mon, 10 Nov 2025 12:22:59 GMT   (8593kb)

Title: Model Inversion Attacks Meet Cryptographic Fuzzy Extractors
Authors: Mallika Prabhakar, Louise Xu, and Prateek Saxena
Categories: cs.CR cs.LG
\\ ( https://arxiv.org/abs/2510.25687 ,  8593kb)
------------------------------------------------------------------------------
\\
arXiv:2510.26586 (*cross-listing*)
replaced with revised version Sun, 9 Nov 2025 00:04:44 GMT   (1184kb)

Title: Physics-Informed Mixture Models and Surrogate Models for Precision
 Additive Manufacturing
Authors: Sebastian Basterrech, Shuo Shan, Debabrata Adhikari, Sankhya Mohanty
Categories: math-ph cs.LG math.MP
Comments: Five pages, four figures, to be presented at the AI in Science
 Summit, Denmark, November, 2025
\\ ( https://arxiv.org/abs/2510.26586 ,  1184kb)
------------------------------------------------------------------------------
\\
arXiv:2510.27408 (*cross-listing*)
replaced with revised version Mon, 10 Nov 2025 17:53:57 GMT   (6389kb)

Title: Estimation of aboveground biomass in a tropical dry forest: An
 intercomparison of airborne, unmanned, and space laser scanning
Authors: Nelson Matti\'e, Arturo Sanchez-Azofeifa, Pablo Crespo-Peremarch,
 Juan-Ygnacio L\'opez-Hern\'andez
Categories: eess.SP cs.LG
Comments: 32 pages, 17 figures, research paper
\\ ( https://arxiv.org/abs/2510.27408 ,  6389kb)
------------------------------------------------------------------------------
\\
arXiv:2511.01813 (*cross-listing*)
replaced with revised version Mon, 10 Nov 2025 13:20:19 GMT   (665kb)

Title: Disciplined Biconvex Programming
Authors: Hao Zhu and Joschka Boedecker
Categories: math.OC cs.CE cs.LG cs.MS
MSC-class: 90C25, 90C59, 90C90
\\ ( https://arxiv.org/abs/2511.01813 ,  665kb)
------------------------------------------------------------------------------
\\
arXiv:2511.03746
replaced with revised version Sun, 9 Nov 2025 12:39:10 GMT   (2759kb)

Title: A Dynamic Recurrent Adjacency Memory Network for Mixed-Generation Power
 System Stability Forecasting
Authors: Guang An Ooi, Otavio Bertozzi, Mohd Asim Aftab, Charalambos
 Konstantinou, Shehab Ahmed
Categories: eess.SY cs.LG cs.SY
Comments: Submitted to IEEE Transactions on Power Systems
\\ ( https://arxiv.org/abs/2511.03746 ,  2759kb)
------------------------------------------------------------------------------
\\
arXiv:2511.03849
replaced with revised version Mon, 10 Nov 2025 17:32:16 GMT   (4141kb)

Title: Which Similarity-Sensitive Entropy?
Authors: Phuc Nguyen, Josiah Couch, Rahul Bansal, Alexandra Morgan, Chris Tam,
 Miao Li, Rima Arnaout, Ramy Arnaout
Categories: cs.IT cs.LG math.IT q-bio.PE
Comments: 21 pages, 8 figures
\\ ( https://arxiv.org/abs/2511.03849 ,  4141kb)
%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---
